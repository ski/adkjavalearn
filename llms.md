
# Advanced RAG — Using Gemini and long context for indexing rich documents (PDF, HTML...)


A very common question I get when presenting and talking about advanced RAG
(Retrieval Augmented Generation) techniques, is
**how to best index and search rich documents like PDF** (or web pages),
that contain both text and rich elements, like pictures or diagrams.

Another very frequent question that people ask me is about **RAG versus long context windows**.
Indeed, models with long context windows usually have a more global understanding of a document,
and each excerpt in its overall context. But of course,
you can't feed all the documents of your users or customers in one single augmented prompt.
Also, RAG has other advantages like offering a much lower latency, and is generally cheaper.

However, the answer I usually give is that you can take the best of both worlds, with a **hybrid approach**:

- You can **use a RAG approach** (or a mix of keyword search engine, graph RAG, or vector-based RAG) to find relevant documents for the user query.
- And then **feed only those key documents in the context window** of a model like [Gemini](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstart?usertype=adc&utm_campaign=CDR_0x7a40493f_default_b431756993&utm_medium=external&utm_source=blog) that accepts 1+ million tokens.

That way, the model can focus on whole documents, with a finer understanding of each one,
but is not overwhelmed with too many documents to find the needle in the haystack.

> The current trending topic of **context engineering** is exactly about this:
> it's crucial to give the best contextual information to your favorite LLM!

# **Using Gemini to finely index a rich PDF document for RAG search**

Before feeding the relevant document in the context window of the LLM, we first need to index it.

## About hypothetical question generation

In my last article, I explored an interesting technique called [Hypothetical Questions embedding]({{<ref "posts/2025/07/06/advanced-rag-hypothetical-question-embedding.md">}}). This technique works great with question/answer tasks, as the idea is to compare _"hypothetical"_ questions to user questions. This tends to give higher levels of similarity when calculating the vector similarity for the semantic search.

One aspect I haven't explained in detail is how many questions we should generate for a given paragraph or set of sentences. It seemed to me that 10 questions or so per chunks of 2000 characters or less was a good rule of thumb. But if you use an LLM to parse a document, and let it figure out sections of text that make sense together, the LLM can as well figure out which questions to ask, and how many of them, depending on both the length of the given text, and its semantic density.

## What about diagrams and other pictures?

Sometimes customers I talk to manage to extract and embed the text in rich documents, however, they're not sure how to treat the various diagrams and images in those documents. They may also use an image model to calculate embeddings for whole pages (containing both the text and the pictures). It's possible to use image models to extract bounding boxes around images and then somehow extract just the boxes containing the pictures. Then they analyze the picture, get a text description, and embed that text.

Again, a multimodal model like Gemini is actually able to look at each page, see where all the diagrams are, and see all the images in each page, to extract some meaningful description.

## 💡 The idea: Use an LLM to chunk text, generate questions, and describe pictures

All at once! Let’s use Gemini to do this for us (or any multimodal LLM with a context window large enough to contain a whole document of your corpus). We’ll use structured output to be get a JSON output that you can easily parse to extract the key information (chunks, questions, image descriptions, but also pages or titles).

# **The smart prompt**

Let’s have a look at the following prompt which we can use as system instructions for an LLM call:

```
Your goal is to analyze long documents for Retrieval Augmented
Generation (RAG) by splitting the content in pieces.
The content pieces will be the chunks that will be embedded
thanks to an embedding model to calculate vector embedding
to store in a vector database.

Given a long PDF document, you must extract and format the
content so that each piece of content is meaningful
as a standalone unit of text.

Each piece of content should be tagged with the page number
it appears in, and the title of the section it's situated in,
as well as a list of questions whose answers can be provided
by this piece of content.

If there is a table of content, you can use it for adding
more context to a given excerpt, or for the section titles,
but don't return the table of content as an excerpt.

When you encounter an image, a picture, or a diagram,
the piece of content you return should be the description
of the image with as much detail as possible.
If the figure has a caption, use it as the title
of the piece of content.
Like for text excerpts, use the title of the current section
the image is in in its description.

Don't create pieces of text for menu, navigation,
and other unrelated elements.
But be sure to create a piece of content for all the text
of the document.
Go through ALL the pages of the document.
The piece of text should be the exact text found in the article.
DON'T change a single world. DON'T summarize.
```

Let’s examine the prompt, but feel free to enhance or expand it for your needs:

- The first paragraph gives the general **goal** we try to achieve, and explains the general idea of the task we ask the LLM.
- The second paragraph tells the LLM it’s important to **create pieces of content** (chunks\!) **that are meaningful**. It tends to help it find relevant chunks that talk about the same topic or aspect, instead of splitting the document into random and/or fixed length spaces.
- The third paragraph details what information to carry for each individual piece of content. We want to retain:
  - the **page number** (in particular for PDF documents),
  - the **title of the section** the text appears in (if it’s a structured document with various sections and header titles),
  - a **list of questions** in the spirit of the Hypothetical Question Embedding technique we’ve used in the previous article,
  - and of course the **chunk** itself.
- The fourth paragraph says that we don’t need to create chunks for the table of contents, but that a table of contents can actually be useful for crafting the titles of the sections.
- The fifth paragraph now talks about diagrams, pictures, etc. It tells the LLM it should actually create a detailed description of the image as a textual representation. It also advises to pay attention to captions or the section the picture appears in.
- The last paragraph suggests to ignore certain elements of the page or document, like navigation elements, and also ask the LLM to create chunks of text for the whole document without missing anything, and to quote the text as is, without any rewriting or summarization.

Generally, the LLM will generate a number of questions that makes sense for the length and semantic density of the chunk. A smaller paragraph with more pieces of key information could yield more questions than a much longer paragraph that doesn’t carry much semantic meaning.

It’s important to give further advice on which content it can safely ignore, or that it should really take the text verbatim without any creative changes it could think of.

For the illustrations, not only will the LLM give you a detailed description of them, but it will also generate questions that can be answered by these illustrations. For example, if it’s a picture of a flag of Germany, it may generate a question like what are the colors of the German flag.

## Defining the structured output

In order to guide the LLM to generate a useful JSON output that you can then later parse easily, you can define its structured output JSON schema. Models like Gemini support this feature. Sometimes, some models require you to define the format of the JSON output via prompting, but more modern and bigger models usually support this feature out of the box.

The structured output I defined:

```json
{
  "type": "array",
  "items": {
    "type": "object",
    "properties": {
      "title": {
        "type": "string",
        "description": "The title of the content."
      },
      "text": {
        "type": "string",
        "description": "The text content."
      },
      "page": {
        "type": "integer",
        "description": "The page number."
      },
      "questions": {
        "type": "array",
        "description": "A list of questions whose answers can be found in this pience of text.",
        "items": {
          "type": "string"
        }
      }
    },
    "required": ["title", "text", "page", "questions"]
  }
}
```

Here, we have an array of pieces that contain a title, a text chunk (which might be the detailed description of a picture), a page, and a list of hypothetical questions. All those fields are required.

I didn’t put any top level information like the title of the whole document, its location (URL/URI or unique ID), or potentially some tags that help categorize the document. But these are extremely useful bits of information you can also request the LLM to generate for you. I wrote about [using LLMs to tag pictures]({{< ref "posts/2024/08/12/let-llm-suggest-instagram-hashtags/" >}}) in an older article.

# **The prompt in action**

I’ve exported the Wikipedia article about the city of [Berlin](https://en.wikipedia.org/wiki/Berlin). I saved it as a PDF document.
Then I used the prompt from the previous section as **system instructions**. I passed the PDF document as a user message. I simply tweaked my prompt by using [Google AI Studio](https://aistudio.google.com/prompts/new_chat) but feel free to use any tool you prefer.

Let’s see some extracts of the JSON that Gemini generated for this PDF.

For the first chunk, it followed exactly the content of the first paragraph of the Wikipedia page:

```json
{
  "page": 1,
  "questions": [
    "What is Berlin's status in Germany?",
    "What is the population of Berlin?",
    "Which state surrounds Berlin?",
    "What is the population of Berlin's urban and metropolitan areas?"
  ],
  "text": "Berlin (/bɜːrˈlɪn/ bur-LIN; German: [bɛɐ̯ˈliːn]) is the capital and largest city of Germany, by both area and population.[10] With 3.7 million inhabitants,[5] it has the highest population within its city limits of any city in the European Union. The city is also one of the states of Germany, being the third smallest state in the country by area. Berlin is surrounded by the state of Brandenburg, and Brandenburg's capital Potsdam is nearby. The urban area of Berlin has a population of over 4.6 million and is therefore the most populous urban area in Germany.[6][11] The Berlin-Brandenburg capital region has around 6.2 million inhabitants and is Germany's second-largest metropolitan region after the Rhine-Ruhr region,[5] as well as the fifth-biggest metropolitan region by GDP in the European Union.[12]",
  "title": "Berlin"
}
```

It used `Berlin` as title, `1` as we’re on the first page, and it generated 4 questions, including questions related to the information about the population of the city, where it’s geographically situated, or what its relationship with the country itself (it’s the capital).

For the info box showing the flag and coat of arms of the city:

```json
 {
    "page": 1,
    "questions": [
      "What does the flag of Berlin look like?",
      "What does the coat of arms of Berlin depict?"
    ],
    "text": "The infobox shows the flag of Berlin, which is a horizontal tricolor of red, white, and red, with the city's coat of arms in the center of the white band. The coat of arms of Berlin is also shown, depicting a black bear standing rampant with its tongue out on a silver shield, topped by a golden crown.",
    "title": "Flag and Coat of arms"
  },
```

It described clearly the orientation and colors of the bands of the German flag, and described the bear on the coat of arms. The title also mentioned the flag and coat of arms. Some embedding models sometimes accept some title metadata that help them better understand the context for calculating vector embeddings. The questions are also quite obvious: what the flag looks like or what is depicted in the coat of arms.

I won’t go through the whole (and long\!) document, but you’ll notice that for some short paragraphs with dense information, the LLM can generate a lot more questions than for a paragraph that doesn’t say much (for example with more descriptive but less important details).

# **What to do with this structured output?**

As we’ve activated structured output, we had the following JSON structure returned by the LLM:

```json
[
  {
     "page": 1,
     "questions": [
       "question 1", "question 2"...
     ],
    "text": "...",
    "title": "..."
  }...
]
```

With that JSON document, you can go through each chunk, calculate vector embeddings for both questions and the chunk itself, and store the page and title as metadata, in a database supporting vector operations. Then you’re ready to go with your RAG pipeline\!

# **Implementation with LangChain4j**

This approach is pretty straightforward to implement with any framework, and of course, with [LangChain4j](https://docs.langchain4j.dev/) in Java.

{{< details summary="Click to view the code and explanations" >}}
First, describe the data structure that will be used for the structured output:

```java
@Description("A single piece of content")
record PieceOfContent(
    @Description("Number of the page this text appears in")
    int page,
    @Description("Title of the section of this text")
    String title,
    @Description("The text chunk")
    String text,
    @Description("List of questions that can be answered by this text")
    List<String> questions
) {}
```

Then, configure the chat model, here we’ll use Gemini 2.5 Flash, and load the document:

```java
try (VertexAiGeminiChatModel model = VertexAiGeminiChatModel.builder()
    .project(System.getenv("GCP_PROJECT_ID"))
    .location(System.getenv("GCP_LOCATION"))
    .modelName("gemini-2.5-flash")
    .responseSchema(SchemaHelper.fromClass(PieceOfContent[].class))
    .build()) {

    Path pathToPdf = Path.of("src/main/resources/Berlin-Wikipedia.pdf");
    byte[] pdfBytes = Files.readAllBytes(pathToPdf);
    String encodedPdf = new String(Base64.getEncoder().encode(pdfBytes));
```

Now, it’s time to prepare the call to the model:

```java
ChatResponse chatResponse = model.chat(ChatRequest.builder()
.messages(SystemMessage.from("""
        Your goal is to analyze long documents for Retrieval Augmented
        Generation (RAG) by splitting the content in pieces.
        The content pieces will be the chunks that will be embedded
        thanks to an embedding model to calculate vector embedding
        to store in a vector database.

        Given a long PDF document, you must extract and format
        the content so that each piece of content is meaningful
        as a standalone unit of text.

        Each piece of content should be tagged with the page number
        it appears in, and the title of the section it's situated in,
        as well as a list of questions whose answers can be provided
        by this piece of content.

        If there is a table of content, you can use it for adding
        more context to a given excerpt, or for the section titles,
        but don't return the table of content as an excerpt.

        When you encounter an image, a picture, or a diagram, the piece
        of content you return should be the description of the image
        with as much detail as possible.
        If the figure has a caption, use it as the title of the piece
        of content.
        Like for text excerpts, use the title of the current section
        the image is in in its description.

        Don't create pieces of text for menu, navigation, references,
        and other unrelated elements.
        But be sure to create a piece of content
        for all the text of the document.
        Go through ALL the pages of the document.
        The piece of text should be the exact text found in the article.
        DON'T change a single world. DON'T summarize.
        """),
    UserMessage.from(
        TextContent.from("Analyze the following document:"),
        PdfFileContent.from(PdfFile.builder()
            .base64Data(encodedPdf)
            .mimeType("application/pdf")
            .build()))
)
.build());

String responseText = chatResponse.aiMessage().text();
PieceOfContent[] piecesOfContent =
    new Gson().fromJson(responseText, PieceOfContent[].class);
```

We passed the prompt we talked about, and the PDF file of the Wikipedia page. The model then returns the JSON structure that we unmarshal into an array of our record.

{{</details>}}

# **Conclusion**

Taking advantage of a large language model like Gemini allows you to avoid going through the chunking in your own way, and instead rely on the LLM to do semantic chunking for you. You can read more about Retrieval Augmented Generation in some of my [previous articles]({{<ref "tags/retrieval-augmented-generation/">}}) on the topic.

# Advanced RAG — Hypothetical Question Embedding


In the first article of this Advanced RAG series, I talked about an approach I called
[sentence window retrieval]({{<ref "posts/2025/02/25/advanced-rag-sentence-window-retrieval.md">}}),
where we calculate vector embeddings per sentence, but the chunk of text returned
(and added in the context of the LLM) actually contains also surrounding sentences
to add more context to that embedded sentence.
This tends to give a better vector similarity than the whole surrounding context.
It is one of the techniques I'm covering in my talk on [advanced RAG techniques]({{<ref "talks/2024/10/14/advanced-rag-techniques/">}}).

Today, I'd like to cover another technique I often use in **applications which are more Question/Answer focused**,
where users ask questions, to find answers contained in the indexed documents: **Hypothetical Question Embedding**.

This is an approach I first discovered in this article which covers both
[hypothetical question embedding and hypothetical document embedding](https://pixion.co/blog/rag-strategies-hypothetical-questions-hyde) (HyDE, which we might cover in another article later on).
Comparing user queries to hypothetical questions is the technique we'll study today.

## The intuition behind Hypothetical Questions

When explaining vector similarity (or distance), we usually say that embedding vectors of user queries are closer to vector embeddings of text chunks that contain the answer to that query.
It's generally true, and that's why simple fixed-size chunking approaches (with overlap) work usually pretty well enough.
However, this naive approach compares questions to text containing potential answers.

:bulb: Intuitively, wouldn't it be better to **compare user questions to other questions**?
Or to compare an hypothetical answer (even if wrong) to text chunks with the answer?

Let's say you want to embed this chunk of text from the Wikipedia page of Berlin:

> Berlin is the capital and largest city of Germany, by both area and population. With 3.7 million inhabitants, it has the highest population within its city limits of any city in the European Union. The city is also one of the states of Germany, being the third smallest state in the country by area. Berlin is surrounded by the state of Brandenburg, and Brandenburg's capital Potsdam is nearby. The urban area of Berlin has a population of over 4.6 million and is therefore the most populous urban area in Germany. The Berlin-Brandenburg capital region has around 6.2 million inhabitants and is Germany's second-largest metropolitan region after the Rhine-Ruhr region, as well as the fifth-biggest metropolitan region by GDP in the European Union.

The idea is to ask an LLM, like [Gemini](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-pro?utm_campaign=CDR_0x7a40493f_default_b429992869&utm_medium=external&utm_source=blog), to generate questions about this paragraph, with a prompt similar to the following:

> Suggest 10 clear questions whose answer could be given by the user provided text.
> Don't use pronouns, be explicit about the subjects and objects of the question.

You might want to **change the number of questions generated, depending on the length of the chunk of text**,
or if you know that some documents you embed seem to have a higher or lower density of information.
You can also let the LLM figure out on its own how many questions it could ask.

The second sentence of the prompt is critical to avoid the LLM to generate questions with pronouns, like `its population is...`.
You want **_fully-qualified_ named entities**, to have the whole context of the information.

For this paragraph, the LLM could generate 10 questions like the following ones:

> 1. What city is the capital of Germany?
> 2. What is the population of Berlin within the city limits?
> 3. Which city in the European Union has the highest population within its city limits?
> 4. What is Berlin's rank by area among the states of Germany?
> 5. Which German state surrounds the city of Berlin?
> 6. What is the population of the urban area of Berlin?
> 7. What is the most populous urban area in Germany?
> 8. How many inhabitants does the Berlin-Brandenburg capital region have?
> 9. What is Germany's second-largest metropolitan region?
> 10. What is the rank of the Berlin-Brandenburg metropolitan region by GDP in the European Union?

When comparing the user query `What is the population of Berlin` or `How many inhabitants live in Berlin?`,
it would match better (higher similarity) with the second generated question: `What is the population of Berlin within the city limits?`.

**When storing the results in the database with vector support, you will have one record per question.**
You will have the vector embedding of each question, associated with the whole paragraph each time.
There's redundancy here, as the chunk of text is repeated as many times as there are questions.
So this is a technique that uses more space.
And it takes also more time (and potentially higher cost) to embed a whole document as you have to call an LLM for each chunk.
But we'll come back to the pros and cons in the following section.

**Upon retrieval, the user question is compared to all those generated questions.**
**And at prompt augmentation time, it's the text chunk that is returned, not the generated question.**

> :arrow_right: If you want to test this idea of **hypothetical question embeddidng**, feel free to go ahead and try this
> [application](https://hypothetical-questions-1029513523185.europe-west1.run.app/)
> I vibe-coded with [Gemini Canvas](https://gemini.google.com/canvas) (for scaffolding the UI) and
> [Gemini CLI](https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/?utm_campaign=CDR_0x7a40493f_default_b429992869&utm_medium=external&utm_source=blog)
> (for creating the server app) and deployed to Cloud Run.
>
> You can:
>
> - enter a chunk of text,
> - generate hypothetical questions for that chunk,
> - compare the vector embeddings between the user query, the document, and the hypothetical questions.
>
> [![](/img/rag/hypothetical-questions-ui.png)](https://hypothetical-questions-1029513523185.europe-west1.run.app/)

## Hypothetical Question embedding vs fixed-sized chunk embedding

What are the pros and cons of each approach?

### Classical Fixed-Sized Chunk Embedding

This is the most straightforward method. You simply split your documents into chunks of a fixed size (e.g., 500 characters) and then create an embedding for each chunk.

**Pros: 👍**

- **Simplicity and speed**: It's easy to implement and computationally efficient, making it great for large datasets.
- **Predictable size**: Uniform chunk sizes make it easy to manage and process without resource spikes.

**Cons: 👎**

- **Context splitting**: This method can cut sentences or even words in half, leading to a loss of meaning and context. However this is generally mitigated thanks to using an overlap between chunks.
- **Loss of coherence**: Arbitrarily splitting text can make it difficult for the model to understand the overall narrative or argument.
- **_"Lost in the middle"_ problem**: Important information can be lost if it's located in the middle of a long document, as the smaller, more focused chunks might not capture the broader context. It can be mitigated with storing and returning a wider surrounding context than what was embedded (i.e. the technique from the [first article]({{<ref "posts/2025/02/25/advanced-rag-sentence-window-retrieval.md">}}) of this series).

### Hypothetical Question Embedding

With this technique, you use a language model to generate questions for each chunk of your document. Then, you embed these questions instead of the document chunks themselves. When a user asks a question, the system compares their query to the embedded hypothetical questions. But when augmenting the context of the LLM with the results of the vector search, you actually return the inital text from which questions were extracted.

**Pros: 👍**

- **Improved alignment**: You are comparing a question to a question, which can lead to better semantic matching than comparing a question to a document chunk. This can significantly improve retrieval accuracy.
- **Addresses the _"Lost in the Middle"_ problem**: By generating questions for all parts of a document, you're more likely to retrieve relevant information regardless of where it is.

**Cons: 👎**

- **Increased index size**: Generating multiple questions per document chunk means your vector index can become much larger, potentially slowing down search and increasing storage costs. This is because you store the chunk of text as many times as the number of questions which were generated.
- **Upfront computational cost**: You need to use a language model to generate all the hypothetical questions, which can be time-consuming and expensive if you use hosted models that you pay by the token.
- **Quality depends on generated questions**: The effectiveness of this method is entirely dependent on the quality of the generated questions. If the language model fails to generate relevant questions, the retrieval will suffer.
- **Non-deterministic questions**: When you re-index your documents (for example because there was an update) even when using the same embedding model, as this approach relies on an LLM, the new batch of questions might be quite different, as the LLM won't necessarily generate the same questions each time.

## Implementation details

The Hypothetical Question approach can be implemented in any language or framework.
But for the sake of this article, I'll be using [LangChain4j](https://docs.langchain4j.dev/) in Java.

You can have a look at the whole [source code](https://github.com/datastaxdevs/conference-2024-devoxx/blob/main/devoxx-rag-naive-to-advanced/src/test/java/devoxx/rag/_3_advanced_rag_ingestion/_37_hypothetical_questions_embedding.java) of this implementation, but I'll explain in details below what's happening.

### At ingestion time

Let's ingest the documents, generate questions, and calculate the vector embeddings.

{{< details summary="Click to view the code and explanations" >}}

The first thing to do is to load the document (I saved the Wikipedia article as a text file):

```java
Document documentAboutBerlin = FileSystemDocumentLoader.loadDocument("berlin.txt", new TextDocumentParser());
```

Let's configure the large language model, here with Gemini from Vertex AI,
using a response schema, to force the model to return a JSON array of hypothetical question strings:

```java
VertexAiGeminiChatModel gemini = VertexAiGeminiChatModel.builder()
    .project(System.getenv("GCP_PROJECT_ID"))
    .location(System.getenv("GCP_LOCATION"))
    .modelName(MODEL_GEMINI_FLASH)
    .maxRetries(5)
    .responseSchema(Schema.newBuilder()
        .setType(Type.ARRAY)
        .setItems(Schema.newBuilder().setType(Type.STRING).build())
        .build())
    .build();
```

The `QuestionParagraph` record will hold a pair of question and the current text paragraph whose content can answer the question:

```java
record QuestionParagraph(
    String question,
    TextSegment paragraph
) {}
```

The question/paragraph pairs are held in a list:

```java
List<QuestionParagraph> allQuestionParagraphs = new ArrayList<>();
```

I'm splitting the document into paragraphs, with paragraphs no longer than 2000 characters, and with an overlap of 100 characters, when the threshold is hit:

```java
DocumentByParagraphSplitter splitter =
    new DocumentByParagraphSplitter(2000, 100);
List<TextSegment> paragraphs = splitter.split(documentAboutBerlin);
```

Now comes the interesting part!
For each paragraph, I ask the LLM to generate 10 questions, and I store the question/paragraphs pairs in the `allQuestionParagraphs` list:

```java
for (TextSegment paragraphSegment : paragraphs) {
    ChatResponse aiResult = gemini.chat(
        SystemMessage.from("""
            Suggest 10 clear questions whose answer could be given
            by the user provided text.

            Don't use pronouns, be explicit about the subjects
            and objects of the question.
            """),
        UserMessage.from(paragraphSegment.text())
    );
    String[] questions =
        gson.fromJson(aiResult.aiMessage().text(), String[].class);

    for (int i = 0; i < questions.length; i++) {
        String question = questions[i];
        allQuestionParagraphs.add(
            new QuestionParagraph(question, paragraphSegment));
    }
}
```

The other important piece is to calculate the vector embeddings of the questions,
but save the text of the paragraph in the embedding vector store:

```java
List<TextSegment> embeddedSegments = allQuestionParagraphs.stream()
    .map(questionParagraph -> TextSegment.from(
        questionParagraph.question(),
        new Metadata().put(
            PARAGRAPH_KEY, questionParagraph.paragraph().text())))
    .toList();

List<Embedding> embeddings =
    embeddingModel.embedAll(embeddedSegments).content();
embeddingStore.addAll(embeddings, embeddedSegments);
```

I'm using the `text-embedding-004` model (configured elsewhere in the code).
You can use also `text-embedding-005` or the new `gemini-embedding-01` model,
but the latter lacks batching for now, so you can't embed several text segments at once.

The key aspect to pay attention to is that I store extra metadata: the actual paragraph.
But it's really the hypothetical question whose embedding vector is calculated.
But the metadata will be useful at retrieval time, to inject the paragraph in the LLM prompt.

{{</details>}}

### At retrieval time

Now that the ingestion is done, let's have a look at the retrieval phase, when users ask questions.

{{< details summary="Click to view the code and explanations" >}}

Let's use the low-level components of LangChain4j to do the search:

```java
EmbeddingSearchResult<TextSegment> searchResults =
    embeddingStore.search(EmbeddingSearchRequest.builder()
        .maxResults(4)
        .minScore(0.7)
        .queryEmbedding(embeddingModel.embed(queryString).content())
        .build());
```

This means we're calculating the vector embedding of `queryString` (the user's question), and compare it with the other vectors stored in the database. We want to retrieve only 4 results with a minimum similarity score of 0.7 (value ranging between 0 and 1).

> :warning: A very important remark: be sure to **use the same embedding model for both ingestion and retrieval**.
> Otherwise the vector embedding values will likely be drastically different, and will give totally garbage results.

Now it's time to do the prompt augmentation, by injecting all the paragraphs associated with the closest vectors of the query:

Concatenate all the relevant paragraphs:

```java
String concatenatedExtracts = searchResults.matches().stream()
    .map(match -> match.embedded().metadata().getString(PARAGRAPH_KEY))
    .distinct()
    .collect(Collectors.joining("\n---\n", "\n---\n", "\n---\n"));
```

And augment the prompt with those extracts:

```java
UserMessage userMessage = PromptTemplate.from("""
    You must answer the following question:
    {{question}}

    Base your answer on the following documentation extracts:
    {{extracts}}
    """).apply(Map.of(
    "question", queryString,
    "extracts", concatenatedExtracts
)).toUserMessage();
```

At the end, it's time to ask the LLM to formulate a response with this augmented prompt:

```java
String response = chatModel.chat(userMessage).aiMessage().text();
```

And voilà!

{{</details>}}

## Fixed chunk embedding or Hypothetical Question Embedding?

The question I often get is to know which technique should be used: fixed chunking, hypothetical question embedding, or another?
I'll reply with the typical consultant answer: **it depends!**

That's the point where I'll tell you that **evaluation is key!**
Hypothetical Question embedding typically work better for applications that are indeed Question/Answer focused.
If users ask questions about their data (let's say, an HR chatbot to ask questions about the vacation policy)
this technique works well.
But maybe for applications where the semantic search is more about finding similar documents, this might not yield the same kind of performance.

It's important to run evaluation on your data, with typical user queries, and check which technique yields better results.
We might cover evaluation in another article, later on.

> :arrow_right: If you want to learn more about evaluation techniques, be sure to check out the [articles](https://atamel.dev/)
> from my colleague [Mete Atamel](https://x.com/meteatamel).

## Going forward

- Play with the [hypothetical question application](https://hypothetical-questions-1029513523185.europe-west1.run.app/)
  I deployed on [Cloud Run](https://cloud.google.com/run?utm_campaign=CDR_0x7a40493f_default_b429992869&utm_medium=external&utm_source=blog) to see the impact on vector similarity.
- Have another read of my article on the
  [sentence window retrieval]({{<ref "posts/2025/02/25/advanced-rag-sentence-window-retrieval.md">}}) technique,
  to see if it fits better with the kind of documents you have in your corpus.
- You can also watch the [talk on advanced RAG techniques]({{<ref "talks/2024/10/14/advanced-rag-techniques/">}}),
  as well as the slides, to see all the other techniques that can be combined.
- But never forget to prepare evaluations on your data, with typical user queries, to compare which techniques yield better results!

# Expanding ADK AI agent capabilities with tools


In a nutshell, the **AI agent equation** is the following:

> _**AI Agent = LLM + Memory + Planning + Tool Use**_

AI agents are nothing without tools!
And they are actually more than mere Large Language Model calls.
They require some memory management to handle the context of the interactions (short term, long term, or contextual information like in the
[Retrieval Augmented Generation approach]({{< ref "/tags/retrieval-augmented-generation/" >}}).
Planning is important (with variations around the Chain-of-Thought prompting approach, and LLM with reasoning or thinking capabilities) for an agent to realize its tasks.

But for agents to be useful and to be able to sense or act upon their environment, the need access to tools.
Generally speaking, _tool use_ is about leveraging LLM's _function calling_ ability, to understand when it needs to request some kind of function to be called to proceed further in its next actions or next steps.

In my previous articles about [ADK](https://google.github.io/adk-docs/), I guided you through the
[creation of your first AI agent with ADK for Java]({{<ref "/posts/2025/05/20/writing-java-ai-agents-with-adk-for-java-getting-started.md" >}}),
and I even shared a [Github project template]({{<ref "/posts/2025/05/27/adk-java-github-template.md" >}}) to help you get started faster.
But today, I want to explore with you the concept of tools, and what tools are at your disposal when **creating AI agents in Java with ADK**.

## Built-in tools

ADK comes with a handful of very useful built-in tools:

- a Google Search tool,
- a Python code executor,
- an artifact service to store and load files.

### Circumventing LLM's cut-off date with Google Search

LLMs' knowledge is as recent as the last information of the corpus of training data they were trained on.
For example, if you asked an LLM who won the Roland Garros tennis tournament, since the finals ended just a week ago,
it wouldn't be able to tell you who won the 2025 edition.
However, if you give an LLM access to a search engine, it can answer that question with _grounded_ facts.

To do that with ADK, you need to add the `GoogleSearchTool` tool:

```java
// Given
LlmAgent agent = LlmAgent.builder()
    .name("helpful-assistant")
    .description("a helpful assistant who can search in Google")
    .instruction("""
        You're a helpful assistant
        who knows how to search in Google Search.
        Today is 2025-06-15.
        """)
    .model("gemini-2.0-flash")
    .tools(new GoogleSearchTool())
    .build();

// When
List<Event> events = askAgent(agent,
        "Who's the man won Roland Garos 2025?");

// Then
assertThat(events.get(0).content().get().text())
        .containsIgnoringCase("Alcaraz");
```

The Google Search tool is also very useful if you want to build some kind of _deep research_ agent that is able to search the web to collect key information to create complex reports.

### Executing code when advanced calculations or algorithms are needed

LLMs are notoriously bad at math or letter games, and at unrolling complex algorithms needed for reasoning purposes (like logic puzzles).
However, they are pretty good at generating code.
For math or algorithms, they are totally capable of generating the right piece of code that could solve the task at hand.
So if you give an LLM the ability to execute some code it generates, and examine the output of that execution, it's going to be able to understand the problem and give a correct answer.

ADK gives you access to the `BuiltInCodeExecutionTool` tool:

```java
// Given
LlmAgent agent = LlmAgent.builder()
    .name("helpful-assistant")
    .description("a helpful assistant that knows how to code")
    .instruction("""
        You're a helpful assistant.
        Today is 2025-06-10.
        """)
    .model("gemini-2.0-flash")
    .tools(new BuiltInCodeExecutionTool())
    .build();

// When
List<Event> events = askAgent(agent,
        "How much is Fibonacci(12) + Hackermann(3,3)?");

// Then
Content content = events.get(0).content().get();
assertThat(content.text()).contains("205");
```

In the example above, Gemini will write some Python code, and execute it inside a sandboxed Python interpreter, to give you the final answer.

### Tool to save and load artifacts

Last built-in tool I'd like to mention briefly: the `LoadArtifactsTool` tool, to deal with [artifacts](https://google.github.io/adk-docs/artifacts/)
(although they'd deserve their own article too).

Artifacts are named, versioned text or binary data associated with a user session or associated with a user across sessions.
Such _files_ can be persisted via the artifact service (there's even a Google Cloud Storage artifact service for long term storage).

Artifacts are accessible via methods like `saveArtifact()`, `loadArtifact()`, or `listArtifacts()` on objects like `CallbackContext` (when adding callbacks to your agents), or `ToolContext` (when adding tools to your agents in methods taking a `ToolContext` parameter).
Artifacts can also be accessed via the system instructions used to declare your agent.

I won't dive into details today, but for the sake of completeness, here's how you can configure the tool and mention artifacts in the agent system instructions:

```java
LlmAgent agent = LlmAgent.builder()
    .name("helpful-movie-assistant")
    .description("""
        a helpful assistant who knows
        about some rather unknown or obscure movies
        """)
    .instruction("""
        You're a helpful movie assistant.

        When asked questions about actors in a movie,
        forget about all intrinsic knowledge, and
        lookup the details in the artifact {artifact.movies.txt}.
        """)
    .model("gemini-2.0-flash")
    .tools(new LoadArtifactsTool())
    .build();
```

## Custom tools

When you need your own piece of logic to help your AI agent, you can create custom tools, via the `FunctionTool` class.
Custom tools are just regular methods, but with a twist: with some carefully crafted annotations to describe the tool to help LLMs understand what this tool can do.

Let's give the agent access to a `moonPhase` method inside the `ToolsTest` class to compute the phase of the moon for a given date:

```java
// Given
LlmAgent agent = LlmAgent.builder()
    .name("helpful-assistant")
    .description("a helpful assistant")
    .instruction("""
        You're a helpful assistant who knows about the moon.
        Today is 2025-06-15.
        """)
    .model("gemini-2.0-flash")
    .tools(FunctionTool.create(ToolsTest.class, "moonPhase"))
    .build();

// When
List<Event> events = askAgent(agent,
        "What's the moon phase today?");

// Then
String text = events.get(2).parts().get().get(0).text().get();
assertThat(text).containsIgnoringCase("full moon");
```

And now let's see what the `moonPhase` method does (with a hard-coded answer):

```java
@Schema(description = "get the moon phase for a given date")
public static Map<String, String> moonPhase(
    @Schema(name = "date",
        description = "the date for which to get the moon phase")
    String date) {
    return Map.of("moon-phase", "full moon");
}
```

I annotated the `moonPhase()` method with a `@Schema` with a description,
as well as the `date` parameter with both a description and a name.

> :warning: **Important:** This is very important to properly document your custom tool
> as LLMs will understand this information and that will help them
> figure out how to find the right method to invoke, and which parameters to pass it.

As of the time of this writing, the `0.1.0` release of ADK for Java supports `static` methods,
but in an upcoming version, it'll be possible to use instance methods as well.

Also note that it is mandatory to return a `Map`.
The reason is that you either return some kind of complex JSON object (that can be transparently un/marshalled),
or you return a map with some `status` field in addition to the normal return object,
to help the LLM understand if the execution was successful or not.
For example: `{"status": "success", "moon-phase": "full moon"}`.

### What about multimodal tools?

Since tool support is done via LLM's function calling capability, it's also limited by it!
Currently, I'm not aware of LLMs that are able to generate function calls that contain non-textual information, such as images, videos, etc.
Fortunately, there's a way to circumvent this limitation, thanks to ADK's `ToolContext`.

Let's say you want to leverage LLM's multimodal ability, by looking at a picture of the moon, and guess the phase of the moon depicted in that image.
Function calling can't pass the image directly, so let's see how you can access the user's full multimodal message via the `ToolContext`:

```java
// Given
LlmAgent agent = LlmAgent.builder()
    .name("helpful-assistant")
    .description(
        "a helpful assistant who can analyze pictures of the moon")
    .instruction("""
        You're a helpful assistant who knows about the moon.
        When asked a question about the moon, or pictures of the moon,
        you MUST call the `moonPhaseFromImage` function.
        """)
    .model("gemini-2.0-flash")
    .tools(FunctionTool.create(ToolsTest.class, "moonPhaseFromImage"))
    .build();
```

We're still creating a custom tool with `FunctionTool.create()` as before.
However, our method definition will have an additional parameter: an instance of `ToolContext`.
Note that it should be named `toolContext`, otherwise ADK won't be happy.

```java
@Schema(description = "get the moon phase by analyzing pictures")
public static Map<String, String> moonPhaseFromImage(
    @Schema(name = "toolContext")
    ToolContext toolContext) {

    Optional<List<Part>> optionalParts =
            toolContext.userContent().flatMap(Content::parts);
    if (optionalParts.isPresent()) {
        List<Part> imageParts = optionalParts.get().stream()
                .filter(part -> part.inlineData().isPresent()).toList();
        if (imageParts.size() == 1) {
            Part imagePart = imageParts.get(0);
            byte[] imageBytes =
                imagePart.inlineData().get().data().get();
            // do something with the image bytes...
            // make a normal multimodal LLM call
            // and return the result
            return Map.of("moon-phase", "half moon");
        }
    }
    return Map.of("moon-phase", "unknown");
}
```

The key line to look at (in addition to the `toolContext` parameter in the signature of the method) is the `toolContext.userContent()` call.
It gives you access to the `Part`s of the `Content` object which represents the user request.

In this code snippet above, we just retrieve the bytes of the uploaded image, and we're faking doing something with them.
But that's the place where you could make an LLM invocation to ask to analyze the image, and guess the phase of the moon depicted in the image.

## Long running custom tools

So far, I've talked about tools that are pretty much synchronous in nature, as they usually answer quite rapidly.
But what about situations where you have **long-running workflows** that take several hours or even days to run?

Or what about scenarios where there's the need for a **human in the loop** to validate some action, like a manager who needs to accept or reject an expense report from an employee? That's where **long-running custom tools** come in handy.

ADK offers `LongRunningFunctionTool`s.
In terms of API, they are exactly like `FunctionTool`s.
It's just that the framework knows the function will acknowledge the reception of the request, but the full completion of the request may happen at a later time.

Something that confused me initially was that working with LLMs is very _request / response_ oriented,
in the sense that there's always an input from a user, that leads to an output from the LLM.
And the conversation goes on and so forth.

What bothered me was the fact that I didn't know what would happen when we actually receive the final completion answer from the LLM.
Or even how will we receive that completion status?
Well, the thing is that we need to shift our mindset from the request / response turns approach,
and instead think of the fact that ADK is more like an _event loop_, which doesn't need a response to always follow a request,
but events can flow in and out, from the user, or from the system itself, in any order.

Let's configure a long running function:

```java
// Given
LlmAgent agent = LlmAgent.builder()
    .name("helpful-assistant")
    .description("a helpful assistant who can execute workflows")
    .instruction("You're a helpful assistant.")
    .model("gemini-2.0-flash")
    .tools(LongRunningFunctionTool.create(ToolsTest.class,
                                          "executeWorkflow"))
    .build();
```

This looks just like a normal `FunctionTool` declaration.

Now let's send a... _recipe_ workflows!

```java
// When
List<Event> events = askAgent(agent, """
    Execute the following workflow:
    - peel the potatoes
    - cut the potatoes in dice
    - put olive oil in the pan
    - heat pan
    - put the potato dices
    - stir regularly
    - cook for 10 minutes
    """);
```

Baking some potatoes can take some time, so you're not going to eat your cooked potatoes immediately!

Let's have a look at what our `executeWorkflow` method does:

```java
@Schema(description = """
    execute a long running workflow made of
    several steps explained in natural language
    """)
public static Map<String, Object> executeWorkflow(
    @Schema(name = "workflowDescription",
        description = "description of the workflow to execute")
    String workflowDescription,
    @Schema(name = "workflowSteps",
        description = "a list of workflow steps")
    List<String> workflowSteps) {
    return Map.of(
        "status", LongRunningOperation.Status.STARTED,
        "longRunningOperation", new LongRunningOperation(
            LongRunningOperation.Status.STARTED,
            workflowDescription, workflowSteps));
}
```

My `executeWorkflow` method actually returns immediately, to acknowledge the reception of the request.
We can imagine here that we're sending the steps (here a list of strings) to some workflow execution engine.
As return type of the method, I've decided to return a `status` indicating that the long running operation has started.
And I also return (in the same map) some `LongRunningOperation` object with the status, the workflow description, and the steps.

I've defined this `LongRunningOperation` as a record, and the status itself as a `Status` `enum`.

```java
record LongRunningOperation(
    LongRunningOperation.Status status,
    String description, List<String> steps) {
    enum Status {
        STARTED, FINISHED, ERROR
    }
}
```

But you can, of course, return some more complex object that contains an ID to be able to identify the workflow execution.
So that we know which execution completed.

At this point, the LLM used by ADK will reply to the user to acknowledge the reception of the request, and the start of the workflow.
Later on, an event should be sent back via ADK somehow, to notify your application of the completion of the workflow,
in a more event-oriented approach compared to the usual request/response approach of LLM conversations.

The example above is a dummy one, as we're not really executing a long running operation, and we're not going to receive an event upon completion.
So my idea is that I'll come back with an article later on that will dive deeper into long running operations and human in the loop scenarios,
as I believe we need a full article and complete demonstration to illustrate this concept more thoroughly.

## An agent as a tool

So far, we talked about built-in tools, and custom tools, but there's another kind of tool which is quite powerful, and which turn another agent into a tool itself!

Let's come back to our moon phase example.
First, let's define the agent that has access to the `moonPhase()` function.
It'll be the agent that will serve as a tool:

```java
LlmAgent moonAgent = LlmAgent.builder()
    .name("moon-agent")
    .description("Agent that knows about the moon")
    .instruction("""
        You know everything about the moon!

        Today is 2025-06-15.

        When asked about the phase of the moon,
        call the `moonPhase` tool with the current date as parameter.
        """)
    .model("gemini-2.0-flash")
    .tools(
        FunctionTool.create(ToolsTest.class, "moonPhase")
    )
    .build();
```

Now let's see how we can turn this sidekick agent into a tool, via the `AgentTool.create()` method:

```java
LlmAgent mainAgent = LlmAgent.builder()
    .name("helpful-assistant")
    .description("a helpful assistant who knows about the moon")
    .instruction("""
        You're a helpful assistant.

        When a question about the moon is asked,
        ask the question to the `moon-agent` tool.
        """)
    .model("gemini-2.0-flash")
    .tools(AgentTool.create(moonAgent))
    .build();

// When
List<Event> events = askAgent(mainAgent, "What's the moon phase today?");
```

I'm not showing all the `assert` statements, but there will be 3 events:
a function execution request addressed to the `moon-agent`, a function response from the `moon-agent`, and the final answer by the LLM who will reformulate the function response into a nice human readable answer.

I haven't talked about the various [agent flows supported by ADK](https://google.github.io/adk-docs/agents/workflow-agents/),
like _sub-agents_, _sequential_ agents, _loop_ agents, and _parallel_ agents, but **agent as tool** is a very powerful pattern for creating more complex agents composed or more specific agents.

Generally, a multi-agent system will be more powerful and more reliable than a big monolithic agent, when tasks can be split and shared among more specialized agents.
I'll come back to this later, in a subsequent article.

> :warning: **Important:** Today, a limitation of Gemini is that you can't use a function call and a built-in tool at the same time.
> ADK, when using Gemini as the underlying LLM, takes advantage of Gemini's built-in ability to do Google searches, and uses function calling to invoke your custom ADK tools.
> So agent tools can come in handy, as you can have a main agent, that delegates live searches to a search agent that has the `GoogleSearchTool` configured,
> and another tool agent that makes use of a custom tool function.
>
> Usually, this happens when you get a mysterious error like this [one](https://github.com/google/adk-python/issues/134) (reported against ADK for Python):
> `{'error': {'code': 400, 'message': 'Tool use with function calling is unsupported', 'status': 'INVALID_ARGUMENT'}}`.
> This means that you can't use a built-in tool and function calling at the same time in the same agent.
> The workaround, then, is to decompose the problem into multiple agents, and taking advantage of agent tools.

## Calling MCP tools

Last but not least, let's finish the round of tools with the most trendy one: **MCP** tools ([Model Context Protocol]({{< ref "/tags/model-context-protocol/" >}}))!

Last week, I wrote about how to
[create an MCP SSE server with Quarkus]({{< ref "/posts/2025/06/09/building-an-mcp-server-with-quarkus-and-deploying-on-google-cloud-run/" >}}),
where I exposed a couple of MCP tools that allow you to know the phase of the moon today or at a custom date — hence the theme again today with the moon.
Let's see how we can configure an agent to use this tool.

It is possible to use Server-Sent Event (SSE for short), or STDIO (standard-in / standard-out) protocols.
The moon phases MCP tool I created the other day was an SSE one.

The first thing to do is to configure it by giving the endpoint of the MCP server:

```java
SseServerParameters sseParams = SseServerParameters.builder()
    .url("https://moonphases-1234567890.europe-west1.run.app/mcp/sse")
    .build();
```

Then you can list (and potentially filter manually) the tools available:

```java
McpToolset.McpToolsAndToolsetResult toolsAndToolsetResult =
    McpToolset.fromServer(sseParams).get();
List<McpTool> moonPhasesTools = toolsAndToolsetResult.getTools();
```

And now you can configure the agent with the list of MCP tools you want to give it access:

```java
LlmAgent agent = LlmAgent.builder()
    .name("helpful-assistant")
    .description("a helpful assistant who knows about the moon")
    .instruction("""
        You're a helpful assistant.
        """)
    .model("gemini-2.0-flash")
    .tools(moonPhasesTools)
    .build();
```

And that's it! Pretty easy, right?

## Summary

In this article, we explored the concept of tools in AI agents, specifically in the context of ADK for Java.
First, we looked at the **built-in tools**, like Google Search, Python code execution, or the artifacts service.
Next, we explored **custom tools**, including **long-running tools**, or also how to **handle multimodal requests** thanks to the tool context.
We discovered the **agent as tool** concept, as a smart agent can be a tool itself for another agent.
Lastly, we also learned about remote **MCP server tools**.

In upcoming articles in this series, we'll dive deeper into some of those tools, and we'll build more complex use cases.
So stay tuned for the next episode!

# Building an MCP server with Quarkus and deploying on Google Cloud Run


As I’m contributing to [ADK](https://github.com/google/adk-java) (Agent Development Kit) for Java, and [LangChain4j](https://docs.langchain4j.dev/) (the LLM orchestration framework) I interact with [MCP](https://modelcontextprotocol.io/introduction) (Model Context Protocol) servers and tools to further expand the capabilities of my LLMs.

Recently, I showed how to [vibe-code an MCP server using Micronaut](https://glaforge.dev/posts/2025/05/02/vibe-coding-an-mcp-server-with-micronaut-and-gemini/). You know I usually talk about [Micronaut](https://micronaut.io/), but this time, I wanted to experiment with Quarkus, and in particular with its built-in support for [implementing MCP servers](https://docs.quarkiverse.io/quarkus-mcp-server/dev/index.html).

## Getting started with Quarkus’ MCP support

I created a brand new Quarkus project from IntelliJ IDEA, with its Quarkus template, and I added a couple key dependencies for JSON marshalling, but even more important, for the MCP support:

```xml
<dependency>
    <groupId>io.quarkus</groupId>
    <artifactId>quarkus-resteasy-jackson</artifactId>
</dependency>
<dependency>
    <groupId>io.quarkiverse.mcp</groupId>
    <artifactId>quarkus-mcp-server-sse</artifactId>
    <version>1.2.0</version>
</dependency>
```

As I’m going to deploy the server in the cloud, I chose to go with an SSE server: [Server Sent Events](https://modelcontextprotocol.io/docs/concepts/transports#server-sent-events-sse). The STDIO protocol is usually used for MCP servers running locally along the MCP host (i.e. your application invoking the tool).

Instead of going with the usual _weather forecast_ use case, which is a bit like the _hello world_ of MCP servers, I decided to implement a service that calculates the phases of the moon! I got the idea from a recent post on Hackernews that pointed at a GitHub repository that offered [different implementations of the calculation of the moon phases](https://github.com/oliverkwebb/moonphase/tree/main). I used Gemini to convert the algorithm to Java, as there was no Java implementation.

I’ll spare you the details of the calculation, but you can have a look at the [code](https://github.com/glaforge/moon-phases-quarkus-mcp-sse-server) I wrote (or Gemini wrote!) to do the math. However, I’ll show you the structure of my `MoonPhasesService` class:

```java
import jakarta.inject.Singleton;

@Singleton
public class MoonPhasesService {
    public MoonPhase currentMoonPhase() {
        return moonPhaseAtUnixTimestamp(System.currentTimeMillis() / 1000L);
    }

    public MoonPhase moonPhaseAtUnixTimestamp(long timeSeconds) {
        // ...
    }
    // ...
}
```

This service is able to give you the phase of the moon at this current moment in time, or you can specify a particular date, as a UNIX epoch time in seconds.

This service returns a `MoonPhase` object. It’s an `enum` that looks like so:

```java
import com.fasterxml.jackson.annotation.JsonFormat;

@JsonFormat(shape = JsonFormat.Shape.OBJECT)
public enum MoonPhase {
    NEW_MOON(            "🌑", "new moon"),
    WAXING_CRESCENT(     "🌒", "waxing crescent"),
    FIRST_QUARTER(       "🌓", "first quarter"),
    WAXING_GIBBOUS(      "🌔", "waxing gibbous"),
    FULL(                "🌕", "full"),
    WANING_GIBBOUS(      "🌖", "waning gibbous"),
    LAST_QUARTER(        "🌗", "last quarter"),
    WANING_CRESCENT(     "🌘", "waning crescent"),
    NEW_MOON_APPROACHING("🌑", "new moon approaching");

    // constructur
    // getter/setter for emoji and phase name...
}
```

As I didn’t want to just return the moon phase name, I customized the serialization so that Jackson returns the `enum` values as normal objects. So, for example, the full moon will be returned as:

```json
{
  "phase": "full",
  "emoji": "🌕"
}
```

Now comes the interesting part! How to expose an MCP tool that LLMs can access? The `@Tool` and `@ToolArg` annotations are your friends!

Let’s implement a new class, in which I inject the `MoonPhasesService`:

```java
public class MoonPhasesMcpServer {

    @Inject
    MoonPhasesService moonPhasesService;
    // ...
}
```

Now, let’s create two tool methods: one that gives the current phase of the moon, and the other one that gives the phase at a given date.

```java
@Tool(name = "current-moon-phase",
    description = "Provides the current moon phase")
public TextContent currentMoonPhase() {
    return new TextContent(moonPhasesService.currentMoonPhase().toString());
}
```

The first one gives the current phase, as of the date of today. The name and description of the tool are very important, as they help LLMs figure out what this tool is doing, and understand when it should call this tool. I return a `TextContent` result. But it’s also possible other kinds of content pieces, like audio or image content, or a resource.

Let’s have a look at the other method, the one that gives the moon phase for a given date:

```java
@Tool(name = "moon-phase-at-date", description =
        "Provides the moon phase at a certain date " +
        "(with a format of yyyy-MM-dd)")
public ToolResponse moonPhaseAtDate(
    @ToolArg(name = "localDate", description =
        "The date for which the user wants to know the phase " +
        "of the moon (in yyyy-MM-dd format)")
    String localDate) {
    try {
        LocalDate parsedLocalDate = LocalDate.parse(localDate);
        MoonPhase moonPhase =
            moonPhasesService.moonPhaseAtUnixTimestamp(
                parsedLocalDate.toEpochDay() * 86400);
        return ToolResponse.success(
                new TextContent(moonPhase.toString()));
    } catch (DateTimeException dte) {
        return ToolResponse.error(
                "Not a valid date (yyyy-MM-dd): " + localDate);
    }
}
```

This time, the method also takes an argument. That’s why I annotated the parameter with a `@ToolArg` annotation, again with a name and description (including how the date should be formatted). Since this method can fail at the time of parsing the date string, I decided to return a `ToolResponse` which wraps either a result (the moon phase) or an error in case the parsing fails.

As you can see, it’s fairly easy to implement tools for an MCP server! You almost just need annotations, and that’s it!

This server isn’t secured in any way, to keep things simple in this article. But if you need to dig deeper and learn more about securing an MCP server, I invite you to read this article by Sergey Beryozkin on [getting ready for secure MCP with Qurkus MCP server](https://quarkus.io/blog/secure-mcp-sse-server/).

## Running the server and checking it works

To run this MCP server, you can simply run Quarkus in dev mode with the following command (if you’re using Maven):

```shell
./mvnw quarkus:dev
```

You can quickly check that the endpoint is alive and running by simply going to your browser, and hitting this URL: http://localhost:8080/mcp/sse. You’ll see an Server Sent Event like this one:

```
event: endpoint
data: /mcp/messages/OTRiYzEyNTItNWY1Ni00NWJhLWExZTEtYzE5ZWU1YjdkNWQy
```

But we’re not really testing our two MCP tools.

An approach is to invoke the MCP server with LangChain4j, you can read more in this article about [MCP client and server with the Java MCP SDK and LangChain4j](https://glaforge.dev/posts/2025/04/04/mcp-client-and-server-with-java-mcp-sdk-and-langchain4j/) that I wrote earlier. So I won’t repeat myself today. And you can read more about [LangChain4j’s MCP support](https://docs.langchain4j.dev/tutorials/mcp) in its documentation.

But here, I wanted to highlight a very convenient tool: the [MCP inspector](https://modelcontextprotocol.io/docs/tools/inspector). It’s a tool provided by the MCP project itself. It’s a Node-based tool that you can install and run locally on your machine, with the following `npx` command:

```shell
npx @modelcontextprotocol/inspector
```

It provides a UI to interact with an MCP server. Here, my MCP server is already deployed, I connected to it (I selected SSE, gave the URL of my server), requested the list of tools (shown in the middle pane), and invoked the tool that gives the phase of the moon at a given date (panel on the right of the screenshot):

![](/img/adk/mcp-inspector-moon-phases.png)

I really encourage you to use the MCP inspector to test your MCP servers manually. This is a very handy tool in your toolbelt.

## Deploying on Cloud Run

So far so good, _it works on my machine_(™). What about deploying the server in the cloud, since we chose to go with an SSE MCP server? My go-to solution to host my apps quickly and efficiently is to containerize them and deploy them on [Google Cloud Run](https://cloud.google.com/run?utm_campaign=CDR_0x7a40493f_user-journey_b423600838&utm_medium=external&utm_source=blog). Cloud Run is a managed platform to run containers that scale up upon traffic, and down to zero instances when there’s no activity (costing you 0 cent).

[Cloud Run made the highlight at Google I/O](https://cloud.google.com/blog/products/ai-machine-learning/ai-studio-to-cloud-run-and-cloud-run-mcp-server?utm_campaign=CDR_0x7a40493f_user-journey_b423600838&utm_medium=external&utm_source=blog) this year, as it was announced that you can:

- Develop apps within [AI Studio](https://aistudio.google.com/) and deploy them in one click on Cloud Run,
- Deploy a [Gemma 3](https://blog.google/technology/developers/gemma-3/?utm_campaign=CDR_0x7a40493f_user-journey_b423600838&utm_medium=external&utm_source=blog) model on Cloud Run again with one click too from [AI Studio](https://aistudio.google.com/prompts/new_chat?model=gemma-3-27b-it),
- And run [Cloud Run’s own MCP server](https://github.com/GoogleCloudPlatform/cloud-run-mcp) to be able to deploy apps from your MCP powered IDEs and clients.

Since Cloud Run is a container based platform, let’s containerize our application. Quarkus offers a handful of `Dockerfile`s depending on how you want to create your container. For some reason the native build ones didn’t work for me (I got a _“the --chmod option requires BuildKit”_ error message, that I haven’t investigated further) so I went with the `Dockerfile.jvm` file, that I copied into `Dockerfile` at the root of my project, so that Cloud Build could easily pick it up and build it:

```shell
gcloud builds submit \
    --tag gcr.io/YOUR_PROJECT_ID/moonphases
```

Once built, it’s available in Google Cloud [Artifact Registry](https://cloud.google.com/artifact-registry/docs?utm_campaign=CDR_0x7a40493f_user-journey_b423600838&utm_medium=external&utm_source=blog). And I can deploy the containerized moon phases service to Cloud Run with the following command:

```shell
gcloud run deploy moonphases \
    --allow-unauthenticated \
    --image gcr.io/YOUR_PROJECT_ID/moonphases
```

Of course, you’ll have to update the `YOUR_PROJECT_ID` placeholders with the real Google Cloud project ID of your own project. And along the way, you’ll be requested to enable important APIs (artifact registry, cloud run, etc.)

> **NOTE:** If you’re interested, there’s a great page about [hosting MCP servers on Cloud Run](https://cloud.google.com/run/docs/host-mcp-servers?utm_campaign=CDR_0x7a40493f_user-journey_b423600838&utm_medium=external&utm_source=blog), to learn more about the possibilities.

## Bonus: Configuring the MCP server in Agent Development Kit

Of course, you can configure and [invoke this MCP server from LangChain4j](https://glaforge.dev/posts/2025/04/04/mcp-client-and-server-with-java-mcp-sdk-and-langchain4j/), but let’s have a quick look at configuring and invoking it from ADK (Agent Development Kit):

```java
SseServerParameters sseParams = SseServerParameters.builder()
    .url("https://moonphases-2029713823481.europe-west1.run.app/mcp/sse")
    .build();

McpToolset.McpToolsAndToolsetResult toolsAndToolsetResult =
   McpToolset.fromServer(sseParams).get();
List<McpTool> moonPhasesTools = toolsAndToolsetResult.getTools();

LlmAgent scienceTeacherAgent = LlmAgent.builder()
    .name("science-app")
    .description("Science teacher agent")
    .model("gemini-2.0-flash")
    .instruction("""
        You're a friendly science teacher
        answering questions about scientific concepts.

        If the question is about about the phases of the moon,
        you MUST call the `current-moon-phase` function tool
        to know the current phase as of right now,
        or the `moon-phase-at-date` function tool
        to know the phase of the moon on a particular day
        (the date format is then yyyy-MM-dd).
        """)
    .tools(moonPhasesTools)
    .build();
```

I’m not going to detail everything here, but if you want to learn more about ADK for Java, please read my [getting started guide](https://glaforge.dev/posts/2025/05/20/writing-java-ai-agents-with-adk-for-java-getting-started/) that I published recently. What’s needed here is to configure the SSE server parameters, creating an MCP toolset, and then getting the list of tools, to pass to the agent via its `tools()` method.

For the record, here is what the ADK Dev UI shows when asking for the current phase of the moon, and the phase for a later date:

![](/img/adk/mcp-moon-phases.png)

## Summary

In the article, we walked you through building an MCP server with Quarkus and deploying it on Google [Cloud Run](https://cloud.google.com/run?utm_campaign=CDR_0x7a40493f_user-journey_b423600838&utm_medium=external&utm_source=blog).

First, we created a [Quarkus](https://quarkus.io/) project with the necessary dependencies for the [MCP support](https://docs.quarkiverse.io/quarkus-langchain4j/dev/mcp.html). Then, we implemented a service to calculate moon phases and exposed it as MCP tools using `@Tool` and `@ToolArg` annotations provided by Quarkus. We used the [MCP inspector](https://modelcontextprotocol.io/docs/tools/inspector) to test the server and we showed how to configure and invoke it from [ADK](https://google.github.io/adk-docs/), the Agent Development Kit. Finally, we containerized the application and deployed it to Google [Cloud Run](https://cloud.google.com/run?utm_campaign=CDR_0x7a40493f_user-journey_b423600838&utm_medium=external&utm_source=blog) for scalability.

If you want to have a closer look at the full source code, you can [check out this repository](https://github.com/glaforge/moon-phases-quarkus-mcp-sse-server) to learn more about creating your own MCP servers!

# Expanding ADK Java LLM coverage with LangChain4j


Recently on these pages, I've covered [ADK](https://github.com/google/adk-java) (Agent Development Kit) for Java, launched at Google I/O 2025.
I showed how to get started [writing your first Java agent]({{<ref "/posts/2025/05/20/writing-java-ai-agents-with-adk-for-java-getting-started.md" >}}),
and I shared a [Github template]({{<ref "/posts/2025/05/27/adk-java-github-template.md" >}}) that you can use to kick start your development.

But you also know that I'm a big fan of, and a contributor to the [LangChain4j project](https://docs.langchain4j.dev/),
where I've worked on the Gemini support, embedding models, GCS document loaders, Imagen generation, etc.

How can I reconcile both?
By **integrating ADK and LangChain4j together**!
But why?
Because currently, ADK for Java only supports two models: Gemini and Claude,
compared to the Python version that supports other models via its [LiteLLM](https://www.litellm.ai/) integration.
So if I could integrate ADK with LangChain4j, I could make ADK Java access any model that LangChain4j supports!
Then developers could use models from OpenAI, Anthropic, Mistral, and also all the models that can run via Ollama,
like Gemma, Qwen, Phi, and others!

> :warning: **Warning**:
> This is a work-in-progress glimpse into the ADK / LangChain4j integration
> I've been working on with Dmytro (LangChain4j's founder).
> It's not yet been integrated in either ADK or LangChain4j.
> Currently, it lives as a [Pull Request](https://github.com/google/adk-java/pull/102) against the ADK Github project.
> Stay tuned! I'll blog back when it's available!

## Using local Ollama models in ADK

Let's say you want to build a Java agent with ADK, using the [Qwen 3](https://qwenlm.github.io/blog/qwen3/) model,
that you installed locally via Ollama. You have Ollama running on your computer and serving the model.
Then all you have to do is to configure the [Ollama LangChain4j](https://docs.langchain4j.dev/integrations/language-models/ollama) model,
and wrap it in a `LangChain4j` ADK model adapter:

```java
OllamaChatModel ollamaChatModel = OllamaChatModel.builder()
    .modelName("qwen3:1.7b")
    .baseUrl("http://127.0.0.1:11434")
    .build();

LlmAgent scienceTeacherAgent = LlmAgent.builder()
    .name("science-app")
    .description("Science teacher agent")
    .model(new LangChain4j(ollamaChatModel))
    .instruction("""
        You are a helpful science teacher
        who explains science concepts to kids and teenagers.
        """)
    .build();
```

In the following screenshot of the ADK Dev UI, I configured Ollama to serve a [Gemma 3](https://blog.google/technology/developers/gemma-3/) model,
as you can see at the bottom left hand corner, where it shows the events, and LLM requests & responses:

![](/img/adk/adk-lc4j-ollama-gemma.png)

## Using big provider models in ADK

But you can use the _big guns_ as well, including Anthropic models:

```java
AnthropicChatModel claudeModel = AnthropicChatModel.builder()
    .apiKey(System.getenv("ANTHROPIC_API_KEY"))
    .modelName(CLAUDE_3_7_SONNET_20250219)
    .build();

LlmAgent agent = LlmAgent.builder()
    .name("science-app")
    .description("Science teacher agent")
    .model(new LangChain4j(claudeModel, CLAUDE_3_7_SONNET_20250219))
    .instruction("""
        You are a helpful science teacher
        who explains science concepts to kids and teenagers.
        """)
    .build();
```

Or OpenAI, this time using a **streaming model**:

```java
StreamingChatModel openaiStreamingModel = OpenAiStreamingChatModel.builder()
    .apiKey(System.getenv("OPENAI_API_KEY"))
    .modelName("gpt-4o-mini")
    .build();

LlmAgent agent = LlmAgent.builder()
    .name("science-app")
    .description("Science teacher agent")
    .model(new LangChain4j(openaiStreamingModel))
    .instruction("""
        You are a helpful science teacher
        who explains science concepts to kids and teenagers.
        """)
    .build();
```

In the ADK Dev UI, you can flip the switch to enable or disable streaming.
In that case, if you want to support both modes in the UI, **configure two LangChain4j models:
the streaming and the non-streaming one**.

```java
LlmAgent agent = LlmAgent.builder()
    .name("science-app")
    .description("Science teacher agent")
    .model(new LangChain4j(openaiModel, openaiStreamingModel))
    .instruction("""
        You are a helpful science teacher
        who explains science concepts to kids and teenagers.
        """)
    .build();
```

## What about tools?

With ADK, your agents can make use of tools, so if the underlying LangChain4j model supports function calling, tools will work too.
And there's one particular tool that I'd like to mention: agent tools.
An agent can be a tool.
So you can mix and match different LLMs as sub-agents, or use a tool backed by a LangChain4j LLM.

For example, here's a main agent using Claude, and a tool agent using OpenAI to give weather information:

```java
StreamingChatModel openaiStreamingModel = OpenAiStreamingChatModel.builder()
    .apiKey(System.getenv("OPENAI_API_KEY"))
    .modelName("gpt-4o-mini")
    .build();

LlmAgent weatherAgent = LlmAgent.builder()
    .name("weather-agent")
    .description("Weather agent")
    .model(new LangChain4j(openaiStreamingModel))
    .instruction("""
        Your role is to always answer that the weather is sunny and 20°C.
        """)
    .build();

AnthropicChatModel claudeModel = AnthropicChatModel.builder()
    .apiKey(System.getenv("ANTHROPIC_API_KEY"))
    .modelName(CLAUDE_3_7_SONNET_20250219)
    .build();

LlmAgent agent = LlmAgent.builder()
    .name("friendly-weather-app")
    .description("Friend agent that knows about the weather")
    .model(new LangChain4j(claudeModel, CLAUDE_3_7_SONNET_20250219))
    .instruction("""
        You are a friendly assistant.

        If asked about the weather forecast for a city,
        you MUST call the `weather-agent` function.
        """)
    .tools(AgentTool.create(weatherAgent))
    .build();
```

Mixing different models in a multi-agent scenario is quite interesting, as you can use the best model for the job.
Maybe you'll need to use a super fast model to do a simple classification task to route requests depending on the ask,
while you'll use a beefier model for the main task that requires more advanced thinking (like a Gemini 2.5 thinking model).

## Summary

This is still early days, as I mentioned in the beginning, it is just a _work-in-progress_ right now,
but I believe it is a great way to **extend ADK Java to supports a lot more models, including local ones**,
and it opens up some **interesting perspectives in multi-agent scenarios when mixing models together**.

Stay tuned, I'll keep you posted on this development!

# An ADK Java GitHub template for your first Java AI agent


With the unveiling of the [Java version](https://github.com/google/adk-java/) of [Agent Development Kit](https://google.github.io/adk-docs/)
(ADK) which lets you **build AI agents in Java**, I recently covered how to
[get started developing your first agent]({{< ref "/posts/2025/01/27/an-ai-agent-to-generate-short-scifi-stories" >}}).

The installation and quickstart [documentation](https://google.github.io/adk-docs/get-started/) also helps for the first steps,
but I realized that it would be handy to provide a **template project**, to further accelarate your _time-to-first-conversation_ with your Java agents!
This led me to play with GitHub's _template project_ feature, which allows you to create a copy of the template project on your own account or organization.
It comes with a ready-made project structure, a configured `pom.xml` file, and a first Java agent you can customize at will, and run from both the command-line or the ADK Dev UI.

> :arrow_right: **Clone the [`adk-java-maven-template`](https://github.com/glaforge/adk-java-maven-template) project!** :arrow_left:

The project follows a standard Java project structure:

```
project_folder/
├── pom.xml
└── src/
    └── main/
        └── java/
            └── com/
                └── example/
                    └── agent/
                        └── HelloWeatherAgent.java
```

The `pom.xml` build file declares the two ADK dependencies:

```xml
<!-- The ADK core dependency -->
<dependency>
    <groupId>com.google.adk</groupId>
    <artifactId>google-adk</artifactId>
    <version>0.1.0</version>
</dependency>
<!-- The ADK dev web UI to debug your agent -->
<dependency>
    <groupId>com.google.adk</groupId>
    <artifactId>google-adk-dev</artifactId>
    <version>0.1.0</version>
</dependency>
```

And the `HelloWeatherAgent.java` class shows how to create a simple agent:

```java
//...
LlmAgent.builder()
    .name("hello-weather-agent")
    .description("Hello World")
    .instruction("""
        You are a friendly assistant,
        answering questions in a concise manner.

        When asked about weather information,
        you MUST use the `getWeather` function.
        """)
    .model("gemini-2.0-flash")
    .tools(FunctionTool.create(HelloWeatherAgent.class, "getWeather"))
    .build();
//...
```

An agent that makes use of a tool to request weather forecasts:

```java
//...
@Schema(description = "Get the weather forecast for a given city")
public static Map<String, String> getWeather(
        @Schema(name = "city",
        description = "Name of the city to get the weather forecast for")
        String city) {
    return Map.of(
        "city", city,
        "forecast", "Sunny day, clear blue sky, temperature up to 24°C"
    );
}
//...
```

There are two ways to run the agent, via the command-line:

```shell
mvn compile exec:java \
    -Dexec.mainClass="com.example.agent.HelloWeatherAgent"
```

Or the ADK Dev UI:

```shell
mvn compile exec:java \
    -Dexec.mainClass="com.google.adk.web.AdkWebServer" \
    -Dexec.classpathScope="compile"
```

Which will show the nice and handy development UI, to help you prototype and debug your agent:

![](https://github.com/glaforge/adk-java-maven-template/raw/main/adk-dev-ui.png)

:smiley: **Happy Java AI agent building!** :hammer_and_wrench:

# Things you never dared to ask about LLMs — Take 2


Recently, I had the chance to deliver this talk on the mysteries of LLMs, at [Devoxx France](https://www.devoxx.fr/agenda-2025/talk/sous-le-capot-des-llms-toutes-ces-questions-que-vous-n-avez-jamais-ose-poser/), with my good friend [Didier Girard](https://www.linkedin.com/in/DidierGirard/),
It was fun to uncover the oddities of LLMs, and better understand where they thrive or fail, and why.

In this post, I'd like to share an update of the presentation deck, with a few additional slides here and there, to cover for example

- the difficulty of LLMs to work with acronyms, scientific molecule names, plant names, special uncommon vocabulary, which require more tokens and weakens _attention_,
- the difference between deterministic and probabilistic problems, and why predictive models are still important,
- some limits of LLMs with regards to understanding dates, data ownership, or the fact they can't easily forget what they learned.

{{< speakerdeck 1d3eae3a34d846888f7183bed5f0597e >}}

This was fun delivering the talk with Didier, as a friendly dialogue makes things more entertaining!
We were lucky that this talk was recorded (however, in French :fr:) and you can watch the [video](https://www.youtube.com/watch?v=C6tZE5OgqUc) below:

{{< youtube C6tZE5OgqUc >}}

> **NOTE:** if the video is not properly embedded above, please follow this [direct link on YouTube](https://www.youtube.com/watch?v=C6tZE5OgqUc).
# Beyond the chatbot or AI sparkle: a seamless AI integration


When I talk about [Generative AI](http://localhost:1313/tags/generative-ai), whether it's with developers at conferences or with customers, I often find myself saying the same thing: **chatbots are just one way to use Large Language Models** (LLMs).

Unfortunately, I see many articles or presentations that just focus on demonstrating LLMs at work within the context of chatbots. I feel guilty of showing the traditional chat interfaces too. But there's so much more to it!

For example, when I [analyzed Bluesky topic trends](https://glaforge.dev/posts/2025/01/06/analyzing-trends-and-topics-from-blueskys-firehose-with-generative-ai/), there was no chatbot involved, but [Gemini](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal?utm_campaign=CDR_0x7a40493f_default_b419777287&utm_medium=external&utm_source=blog) and [embedding models](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings?utm_campaign=CDR_0x7a40493f_default_b419777287&utm_medium=external&utm_source=blog) helped me make sense of clusters of posts. Or when I played with [generating short science fiction stories](https://glaforge.dev/posts/2025/01/27/an-ai-agent-to-generate-short-scifi-stories/), there was again no chat interface, but the LLM and the [Imagen](https://cloud.google.com/vertex-ai/generative-ai/docs/models/imagen/3-0-generate-002?utm_campaign=CDR_0x7a40493f_default_b419777287&utm_medium=external&utm_source=blog) image generation models were used for their creative facet.

LLMs are also very powerful to replicate more classical Natural Language Processing tasks (NLP) like sentiment analysis, entity extraction, etc. But sometimes dedicated predictive models are more (cost) effective at those tasks. However, **LLMs allow developers to implement those NLP use cases easily** by properly prompting their favorite model. And developers may then be able to add nice and seamless features here and there in their applications.

## The trigger

What led me to share my views on these usage patterns of AI? It’s when I read Kojo Osei’s article titled “[there should be no AI button](https://kojo.blog/ai-button/)”. Indeed, we’re seeing a **proliferation of AI “_sparkle”_ buttons** in various applications and websites. This feels like a quick hack, an extra patch, to say that the application is smart, but it also adds unnecessary cognitive load and breaks the user's focus. **It takes more than an AI sparkle button to make an application intuitive and seamlessly smart**!

The author argues that dedicated "AI buttons" in user interfaces are a flawed and temporary design choice. The author says, and I agree, that **the best AI user experience is seamless and integrated**, and that AI buttons create unnecessary limitations and frustrations. The article calls for more contextual alternatives that don't artificially segregate AI functionalities, and avoid breaking the flow of the user.

## My take

In my opinion, the best way to use AI is to build it right into your applications, making them smarter and more helpful **in a way that feels completely natural to the user**. It's not about hiding the fact that AI is involved – on the contrary, I believe users should know. But, as people go about their daily tasks in an app or on a website, AI should be there to assist them smoothly, **without them needing to click a special "AI button"** to make something happen, or **having to open a chat window to ask for help**.

I see chat interfaces as one specific use case for LLMs, and that's fine. But they aren't the only option, and I don't think they're always the most intuitive or the least disruptive. **People need to stay in their flow**, focused on what they're doing. Their **work should be augmented by AI**, not broken up by extra clicks or messages.

Think about it: if someone is deep in concentration, writing or designing, the last thing they need is to stop, look for a button, and then start a conversation with an AI to get a suggestion. That kind of interruption significantly increases their cognitive load, breaks their focus and makes the whole process feel clunky.

## Examples of more seamless and intuitive flows

Personally, I like when a smart application is proactive but doesn’t get in the way of my normal flow. To illustrate this, let’s think about some common patterns I’ve seen that I found successful at this:

- In Gmail and Chat, the UI shows me a [summary of the ongoing conversation](https://support.google.com/chat/answer/12918975?hl=en&co=GENIE.Platform%3DDesktop) that I missed. I can still go through the unread messages, but I can also be up-to-speed rapidly by reading the summary, and then quickly glancing through the messages to get more details.

- Another summarization example is when I use [Obsidian](https://obsidian.md/) to take notes of articles I find interesting and want to remember. I installed a Chrome add-on, the [Obsidian web clipper and its “interpreter”](https://help.obsidian.md/web-clipper/interpreter), that I configured to use Gemini, to create a bullet point summary of the articles, and create relevant tags that help me navigate through similar content I’ve already in my notes.

- For coding, we (developers) are now used to the seamless LLM-powered code completion. I like how it waits a little before suggesting anything. And often, when I use [Gemini Code Assist](https://codeassist.google/), I have the impression that the LLM read my mind and knew exactly about the code I wanted to write. And if it’s not what I wanted, I’m not really disrupted or distracted, as I can continue typing if the suggestion doesn’t make sense.

- To stay in the realm of developer workflows, your AI peer is at work as the first responder to the tickets users create, then you can hop in the conversation as the user details their issues. Similarly, for PRs (Pull Requests), your AI coding bot can analyze the code you submitted and make first recommendations to improve it, like the [Gemini Code Assist bot does on Github](https://github.com/marketplace/gemini-code-assist).

- Before creating a ticket, the bug tracker could also take advantage of LLM-powered or embedding-based semantic search to find similar issues, to avoid creating duplicates, or guide the reporter to pick up the right component or category, depending on what the issue is all about.

- Large Language Models are great at creating first drafts of documents. Give it the right outline, directions, ideas, and you’ll get a first sketch that you can refine — even a few sentences in this very article that you read were first drafted with Gemini!

- You can also imagine this draft generation in contexts like CRM apps, where users can create a first draft of something they want to send their customers, depending on the current situation of that customer. Or like in the linked article, with this image creation app, where the user draws a few broad strokes of colors to guide the image generation to follow along.

- But of course if you’re already working in a chat environment (like Slack or similar messaging platforms), it still makes sense to be able to chat with an AI-powered bot! I don’t want to get rid of chat spaces altogether. But an AI assistant should be that: an assistant, a peer, a colleague you can involve where needed, or who can nudge you to tell you _“hey, you forgot to add a test”_, or _“here are the relevant PRDs or bug entries about this new feature you’re talking about”_, or _“here’s a summary of the relevant past conversations on that topic”_.

These are some examples of non-intrusive and seamless integrations, but **UX designers need to rethink the app** or website, and be acquainted with what LLMs can offer. **Making an application smart isn’t just adding an AI sparkle button or a chatbot interface**.

## Conclusion

While chatbots are great for things like customer support or answering direct questions, they're not always the best fit for every situation. For many tasks, I believe AI assistance should be **more like a quiet, helpful partner** — there when you need it, maybe even anticipating what you need, without you having to constantly ask.

What I really believe we should aim for is AI that boosts what people are already doing, making their work easier and more powerful without adding extra steps. We should be **creating experiences where AI enhances the tools people use every day**, making them more efficient and insightful, **without forcing them to constantly switch contexts** or explicitly request AI intervention for every little thing via a sparkle button or a chat message.

Ultimately, I think the AI integrations that will truly succeed are the ones that don't feel like an add-on. Instead, they'll feel like a natural, intelligent part of the system. My ideal is to see us build AI experiences that genuinely empower people by **working seamlessly in the background**, helping them **stay focused** and achieve more, more rapidly.

# Write AI agents in Java — Agent Development Kit getting started guide


At Google Cloud Next ‘25, last April, Google released [Agent Development Kit](https://google.github.io/adk-docs/) (ADK) for Python, a **flexible and modular framework for developing and deploying AI agents**.

Now at Google I/O, a **Java version of ADK** has been made available! And I’m glad to have had the chance to participate in its launch, via code samples, documentation, and helping shape the API so it’s idiomatic for Java developers.

In this article, my goal is to give you the basis to get started with the ADK framework, in Java, using the Gemini model, and running your first Java agents locally.

> Be sure to checkout this video I recorded on how to get started
> and learn more about some key concepts of ADK:
>
> {{< youtube VM3b3csBeUc >}}
>
> And if you want to start from a ready-made project with a sample agent using tools,
> checkout the article on my
> [GitHub template project]({{< ref "/posts/2025/05/27/adk-java-github-template.md" >}}),
> or a direct link to the
> [template project](https://github.com/glaforge/adk-java-maven-template).
>
> In the meantime, let's now focus on the key steps to write your first AI agents with ADK!

## Project structure

Create a usual Java project structure like the following, with your Java sources in `src/main/java`:

```
[YOUR_PROJECT_DIRECTORY]/
 └—— pom.xml
 └—— src/
     └—— main/
         └—— java/
             └—— agents/
                 └—— ScienceTeacherAgent.java
```

Let’s have a look at a minimal `pom.xml` to compile and run your agent:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>adk-agents</groupId>
    <artifactId>adk-agents</artifactId>
    <version>1.0-SNAPSHOT</version>

    <dependencies>
        <!-- ADK core dependency -->
        <dependency>
            <groupId>com.google.adk</groupId>
            <artifactId>google-adk</artifactId>
            <version>0.1.0</version>
        </dependency>
        <!-- ADK dev web UI and API server -->
        <dependency>
            <groupId>com.google.adk</groupId>
            <artifactId>google-adk-dev</artifactId>
            <version>0.1.0</version>
        </dependency>
    </dependencies>
</project>

```

You just need a couple of dependencies:

- the Core ADK framework dependency, and
- the ADK web server that provides a nice and useful Dev UI to interact with your agents, as well as an API server.

## Your first agent

Now that the project is set up, let’s implement a very simple agent. It’ll be a single agent. And it won’t yet use tools to interact with the external world. We’ll explore multi agents and tool support later on, in more advanced articles.

So let’s have a look at a science teacher agent, whose role is to help kids and teenagers understand scientific concepts in a friendly and approachable way.

Here’s the full source code. You can expand this block to see it all, but we’ll explain everything further down, in a piecemeal fashion.

{{< details summary="Click to see the full source code" >}}

```java
package agents;

import static java.nio.charset.StandardCharsets.UTF_8;
import java.util.Scanner;

import com.google.adk.agents.BaseAgent;
import com.google.adk.agents.LlmAgent;
import com.google.adk.events.Event;
import com.google.adk.runner.InMemoryRunner;
import com.google.adk.sessions.Session;
import com.google.genai.types.Content;
import com.google.genai.types.Part;

import io.reactivex.rxjava3.core.Flowable;

/** Science teacher agent. */
public class ScienceTeacherAgent {

    public static BaseAgent ROOT_AGENT = initAgent();

    public static BaseAgent initAgent() {
        return LlmAgent.builder()
            .name("science-app")
            .description("Science teacher agent")
            .model("gemini-2.0-flash")
            .instruction("""
                You are a helpful science teacher that explains
                science concepts to kids and teenagers.
                """)
            .build();
    }

    public static void main(String[] args) {
        InMemoryRunner runner = new InMemoryRunner(ROOT_AGENT);

        Session session = runner
                .sessionService()
                .createSession(runner.appName(), "student")
                .blockingGet();

        try (Scanner scanner = new Scanner(System.in, UTF_8)) {
            while (true) {
                System.out.print("\nYou > ");
                String userInput = scanner.nextLine();
                if ("quit".equalsIgnoreCase(userInput)) {
                    break;
                }

                Content userMsg = Content.fromParts(Part.fromText(userInput));
                Flowable<Event> events =
                    runner.runAsync(session.userId(), session.id(), userMsg);

                System.out.print("\nAgent > ");
                events.blockingForEach(event -> {
                    System.out.println(event.stringifyContent());
                });
            }
        }
    }
}
```

{{< /details >}}

So what does the simplest agent look like?

```java
LlmAgent.builder()
    .name("science-app")
    .description("Science teacher agent")
    .model("gemini-2.0-flash")
    .instruction("""
        You are a helpful science teacher that explains
        science concepts to kids and teenagers.
        """)
    .build();
```

An agent consists of a name, a description, a model, and some instructions, and that’s it! In other articles, we’ll also see how to give it tools, how to use state, how it can interact with other agents and workflows, but for now, let’s stick with this simple science teacher agent.

## Running your agent

Let’s say you’ve saved the above agent in a `ROOT_AGENT` static field of your class (it’ll come in handy for the Dev UI later on). Now we need to instantiate a _runner_ and a _session_ to run the agent.

First, you instantiate an `InMemoryRunner` with your agent:

```java
InMemoryRunner runner = new InMemoryRunner(ROOT_AGENT);
```

Then you create a session with the `SessionService` that you can grab from the runner itself (passing an application name and user ID):

```java
Session session = runner
        .sessionService()
        .createSession(runner.appName(), "student")
        .blockingGet();
```

Now, if you want to have a familiar chatbot-like experience, you’ll loop over and alternate between user provided messages, and LLM generated answers. Let’s use a `Scanner` to get the input from the user, inside a big `while` loop, and send the user’s prompt to the LLM agent, via runner’s `runAsync()` method, passing the session and the message. The agent will reply with a flow of events that we can then print:

```java
try (Scanner scanner = new Scanner(System.in, UTF_8)) {
    while (true) {
        System.out.print("\nYou > ");
        String userInput = scanner.nextLine();
        if ("quit".equalsIgnoreCase(userInput)) {
            break;
        }

        Content userMsg = Content.fromParts(Part.fromText(userInput));
        Flowable<Event> events = runner
            .runAsync(session.userId(), session.id(), userMsg);

        System.out.print("\nAgent > ");
        events.blockingForEach(event -> {
            System.out.println(event.stringifyContent());
        });
    }
}
```

## Define environment variables

You’ll need to export two environment variables:

- a Gemini key that you can [get from AI Studio](https://ai.google.dev/gemini-api/docs/api-key),
- a variable to specify you’re not using Vertex AI this time.

```shell
export GOOGLE_GENAI_USE_VERTEXAI=FALSE
export GOOGLE_API_KEY=AIzaSyDF...
```

In this article, let’s use the Google AI / DeepMind endpoint and API key for Gemini, but you can also use Gemini from Google Cloud Vertex AI.

## Executing the agent from the command line

From the command line, let’s use Maven’s exec java plugin to launch this science teacher agent:

```shell
mvn compile exec:java -Dexec.mainClass="agents.ScienceTeacherAgent"
```

Let’s see the output when asking a simple question about _“qubits”_!

```
[INFO] Scanning for projects...
[INFO]
[INFO] -----------------------< adk-agents:adk-agents >------------------------
[INFO] Building adk-agents 1.0-SNAPSHOT
[INFO]   from pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO]
[INFO] --- resources:3.3.1:resources (default-resources) @ adk-agents ---
[INFO] skip non existing resourceDirectory /Users/me/Projects/adk-agents/src/main/resources
[INFO]
[INFO] --- compiler:3.13.0:compile (default-compile) @ adk-agents ---
[INFO] Nothing to compile - all classes are up to date.
[INFO]
[INFO] --- exec:3.5.0:java (default-cli) @ adk-agents ---

You > What is a qbit? Please answer in a concise manner.

Agent > Hey there, future tech wiz! 👋

A **qubit** (short for "quantum bit") is the basic unit of information
in a quantum computer. Unlike a regular bit in your computer, which is
either a 0 or a 1, a qubit can be a 0, a 1, or *both at the same time*
thanks to something called **superposition**! This "both at once"
ability is what makes quantum computers super powerful for certain
kinds of problems.

You > quit
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  0:22 min
[INFO] Finished at: 2025-05-19T01:00:12+02:00
[INFO] ------------------------------------------------------------------------
```

And the conversation can go on and on, till you’re bored and you enter _“quit”_ to end the chat.

## Executing the agent in the Dev UI

ADK comes with a Dev web UI (and API server) that you can use to run your agents, see how they behave, the data they exchange, how they interact with the underlying LLM. So let’s talk about this.

The following Maven command will launch the Dev UI:

```shell
mvn exec:java \
    -Dexec.mainClass="com.google.adk.web.AdkWebServer" \
    -Dexec.classpathScope="compile"
```

**Note**: You can add a different path or even use a sub-directory (if you want to expose only agents in a certain package) by adding and customising this flag: `-Dexec.args="--adk.agents.source-dir=src/main/java/com/foo/agents"`.

This time, you run the `AdkWebServer` class from the second dependency (`google-adk-dev`). There’s one constraint currently for the Dev UI to grab and run your agents: they have to be statically initialized and stored in a `public static BaseAgent ROOT_AGENT` field. That’s why the class had the following structure:

```java
public class ScienceTeacherAgent {
    public static BaseAgent ROOT_AGENT = initAgent();

    public static BaseAgent initAgent() { ... }
}
```

To access the Dev UI, just head over to your browser and open the following URL: http://localhost:8080/dev-ui

You should see something similar to this:

![adk-dev-ui-science-teacher.png](/img/adk/adk-dev-ui-science-teacher.png)

- You can **select an agent** from the loaded agents in the top left hand corner.
- When clicking on the **events**, you can see the popup over the left pane that shows all the details of the events that are flowing through, as well as the **input request** and **output response** from the LLM.
- On the right side, in the chat area, you can see the **dialogue** between the user and the AI, as well as potential **tool calls**.
- You can also **enable token streaming** at the top of the screen with the slide if you want to see responses being streamed as they are generated by the model.

## Congratulations!

Wait, what? Are we already done?
Yes, you’ve coded and executed your first Java agent with the ADK framework!

## Now what?

Many possible next steps, and also pointers, that I’d like to share with you.

- First of all, read the [article announcing the launch of Java ADK](https://developers.googleblog.com/en/agents-adk-agent-engine-a2a-enhancements-google-io/?utm_campaign=CDR_0x7a40493f_default_b418955413&utm_medium=external&utm_source=blog), and other news related to [Agent Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview?utm_campaign=CDR_0x7a40493f_default_b418955413&utm_medium=external&utm_source=blog), and [A2A](https://github.com/google/A2A) (Agent to Agent Protocol).
- Think about how you can integrate such an agent inside an existing Java application that you want to enhance with advanced agentic capabilities.
- You may want to [deploy an agent on Cloud Run](https://google.github.io/adk-docs/deploy/cloud-run/), for example, or host it anywhere else you’d like, as it’s just an open source framework not tied to [Google Cloud](https://cloud.google.com/?utm_campaign=CDR_0x7a40493f_default_b418955413&utm_medium=external&utm_source=blog).
- Start [learning more](https://google.github.io/adk-docs/) about the concepts behind the framework, and what it’s capable of.
- Check out the [source code on Github](https://github.com/google/adk-java).
- I’d like to invite you to look at more substantial [examples](https://github.com/google/adk-docs/tree/main/examples/java/snippets/src/main/java) and [samples](https://github.com/google/adk-samples/tree/main/java) than my science teacher.
- My colleague Abi implemented a [patent research and analysis agent](https://medium.com/google-cloud/build-powerful-stateful-ai-agents-in-java-with-agent-development-kit-adk-0f7e2cd3d094) in Java, with ADK, deployed on Cloud Run, with data on AlloyDB.

I’m really looking forward to hearing from you about what you’ll be building with ADK for Java! You can expect many more articles on this blog on the topic of ADK. So stay tuned!

# Vibe coding an MCP server with Micronaut, LangChain4j, and Gemini


Unlike Quarkus and Spring Boot, Micronaut doesn't (yet?) provide a module to facilitate the implementation of [MCP](https://modelcontextprotocol.io/) servers (Model Context Protocol).
But being my favorite framework, I decided to see what it takes to build a quick implementation, by _vibe coding_ it, with the help of Gemini!

In a recent article, I explored [how to use the MCP reference implementation for Java to implement an MCP server](https://glaforge.dev/posts/2025/05/02/vibe-coding-an-mcp-server-with-micronaut-and-gemini/),
served as a servlet via Jetty, and to call that server from [LangChain4j's great MCP support](https://docs.langchain4j.dev/tutorials/mcp/).
One approach with Micronaut may have been to somehow integrate the servlet I had built via Micronaut's servlet support, but that didn't really feel like a genuine and native way to implement a server, so I decided to do it from scratch.

## Vibe coding with Gemini

The concept of _vibe coding_ came from a [tweet from Andrej Karpathy](https://x.com/karpathy/status/1886192184808149383)
who defined the concept as interacting with an LLM to build a new prototype or weekend project, and iterating with the LLM till it works, but without looking at or touching the code yourself.
It's quite a bit different than using AI assistance to build a production-ready code base.
And Simon Willison's just written a good piece on [what is and what is not _vibe coding_](https://simonwillison.net/2025/May/1/not-vibe-coding/).

I started throwing **Gemini 2.5 Pro** some simple prompts for creating an MCP server with Micronaut, with Java 21, but it would not generate something really usable, at least not in one-shot!
For example, it would not use Server-Sent Events, or it hadn't figured out how that the protocol is using JSON-RPC, etc.
So instead of steering the LLM in the right direction via multiple prompts, I reused my tacticts of feeding as much information as needed into the prompt.
This is the approach I took to [grok one's own content with LLMs.txt]({{<ref "posts/2025/03/03/llms-txt-to-help-llms-grok-your-content/">}}), or when I wrote about
[the power of large context windows for your documentation efforts]({{<ref "posts/2025/02/15/the-power-of-large-context-windows-for-your-documentation-efforts/">}}).

So what was the successful prompt?

> Let's implement a Model Context Protocol (MCP) using the Micronaut framework.
>
> We will use Micronaut 4.8 and Java 21.
> You can find Micronaut's documentation here: https://docs.micronaut.io/4.8.11/guide/
>
> The details of the Model Context Protocol (MCP) can be found here:
> https://modelcontextprotocol.io/llms-full.txt
>
> For the client, we will use LangChain4j as shown in this article:
> https://glaforge.dev/posts/2025/04/04/mcp-client-and-server-with-java-mcp-sdk-and-langchain4j/
>
> You can find all the code of the LangChain4j MCP client support in the attached file.
>
> :paperclip: _\[gitingest of the LangChain4j MCP client code\]_
>
> You can reuse the Java classes of the LangChain4j MCP client to implement the MCP server support with Micronaut.
>
> Implement a simple MCP server to let MCP clients request the weather forecast. Return fake data like `{"forecast": "sunny"}`

The trick here was to feed the whole MCP specification thanks to the `llms-full.txt` file,
the whole Micronaut single-page documentation, and also the LangChain4j MCP client source code in attachment (via [gitingest](https://gitingest.com/)).

Did it work in one shot? Actually, no.
Because my client wouldn't connect to it somehow, I figured that it wasn't actually using Server-Sent Events.
So I sent a follow-up prompt:

> The Micronaut controller must use HTTP Server Sent Events, as this is what the MCP protocol mandates for MCP remote servers. Please update the controller to use SSE.

Then I had a running server.

Gemini created an [`SseBroadcaster`](https://github.com/glaforge/langchain4j-micronaut-mcp/blob/main/src/main/java/mcp/server/SseBroadcaster.java) class which handles the Server-Sent Event handling,
thanks to Reactor's `Publisher`, `Flux`, and `Sinks`, and Micronaut's `JsonMapper` and SSE support.

It handles the various JSON-RPC operations (`initialize`, `notifications/initialized`, `tools/list`, `tools/call`, and `ping`)
in the [`PostController`](https://github.com/glaforge/langchain4j-micronaut-mcp/blob/main/src/main/java/mcp/server/PostController.java):

```java
private McpResponse processRequest(McpRequest request) {
    // --- Same logic as before to generate the McpResponse object ---
    switch (request.method()) {
        case "initialize":
            log.info("Handling initialize request");
            InitializeResult initResult = new InitializeResult(new ServerCapabilities());
            return new McpResponse(request.id(), initResult);

        case "notifications/initialized":
            log.info("Received initialized notification");
            // This is a notification FROM the client. MCP spec says notifications
            // don't have responses. So we return null here, and the POST handler
            // will just return HTTP OK.
            return null;

        case "tools/list":
            log.info("Handling tools/list request");
            ToolSpecificationData weatherTool = new ToolSpecificationData(
                WEATHER_TOOL_NAME,
                "Gets the current weather forecast.",
                new InputSchema(
                    "object",
                    Map.of("location", Map.of(
                        "type", "string",
                        "description", "Location to get the weather for")
                    ),
                    List.of("location"),
                    false)
            );
            ListToolsResult listResult = new ListToolsResult(List.of(weatherTool));
            return new McpResponse(request.id(), listResult);

        case "tools/call":
            log.info("Handling tools/call request");
            if (request.params() != null && request.params().has("name")) {
                String toolName = request.params().get("name").asText();
                if (WEATHER_TOOL_NAME.equals(toolName)) {
                    log.info("Executing tool: {}", toolName);
                    TextContentData textContent = new TextContentData(FAKE_WEATHER_JSON);
                    CallToolResult callResult = new CallToolResult(List.of(textContent));
                    return new McpResponse(request.id(), callResult);
                } else {
                    log.warn("Unknown tool requested: {}", toolName);
                    return new McpResponse(request.id(), new McpError(-32601, "Method not found: " + toolName));
                }
            } else {
                log.error("Invalid tools/call request: Missing 'name' in params");
                return new McpResponse(request.id(), new McpError(-32602, "Invalid params for tools/call"));
            }

        case "ping":
            log.info("Handling ping request");
            return new McpResponse(request.id(), Collections.emptyMap());

        default:
            log.warn("Unsupported MCP method: {}", request.method());
            return new McpResponse(request.id(), new McpError(-32601, "Method not found: " + request.method()));
    }
}
```

## From vibe coding, to a more classical AI-assisted approach

The vibe coding part ended somewhere here, as I then went on to make a few tweaks here and there to the code base.
When you're a developer, you can't resist tweaking a few things here and there, right?

But I continued the journey also with the help of Gemini, but via [Gemini Code Assist](https://codeassist.google/) within IntelliJ IDEA.

I reused my MCP client from my recent [MCP article]({{<ref "posts/2025/04/04/mcp-client-and-server-with-java-mcp-sdk-and-langchain4j/">}}),
but I asked Gemini Code Assist to transform the Java class into a proper JUnit test.
Since the Micronaut documentation is still part of the context of the conversation, thanks to Gemini's huge context window, it did again a great job at converting my code into a proper Micronaut running unit test, launching an embedded server.

I like that Gemini created three test methods: to test that the server can reply to some simple greeting message, then can list and the available MCP tools at the disposal of the clients:

```java
@Test
void testListTools() {
    log.info("Testing listTools...");
    assertDoesNotThrow(() -> {
        List<dev.langchain4j.agent.tool.ToolSpecification> tools = mcpClient.listTools();
        assertNotNull(tools, "Tool list should not be null");
        assertFalse(tools.isEmpty(), "Tool list should not be empty");
        // Add more specific assertions if needed, e.g., check tool names
        assertTrue(tools.stream().anyMatch(t -> "getWeatherForecast".equals(t.name())),
            "Should find the 'getWeatherForecast' tool");
        log.info("listTools returned: {}", tools);
    }, "Listing tools should not throw an exception");
}
```

And finally is able to reply to a weather request by returning some dummy weather data:

```java
@Test
void testWeatherRequest() {
    log.info("Testing weather request...");
    String question = "What's the weather like in Paris today?";
    String response = assertDoesNotThrow(() -> weatherAssistant.request(question),
        "Weather request should not throw an exception");

    log.info("Question: {}", question);
    log.info("Response: {}", response);

    assertNotNull(response, "Response should not be null");
    assertFalse(response.isBlank(), "Response should not be blank");
    // Check if the response likely contains the mocked forecast
    assertTrue(response.toLowerCase().contains("sunny"),
        "Response should contain the weather information (sunny)");
}
```

## Now, the code!

As you made it till the end, you'll get a reward: I pushed the code in this [Github repository](https://github.com/glaforge/langchain4j-micronaut-mcp)!
The project doesn't implement all the bells and whistles of the MCP specification (like prompts, resources, sampling, etc.)
but it's certainly a starting point if you want to write your own MCP server with Micronaut.
Since LangChain4j released some [new versions today](https://github.com/langchain4j/langchain4j/releases/tag/1.0.0-rc1), I updated the dependencies to use the latest and greatest LangChain4j.

Going further, I'd love to see Micronaut offer a dedicated MCP server module, to make it easier to implement MCP servers, with some clever annotations, to streamline the whole process.
Fingers crossed :crossed_fingers:

And of course, once you're happy with your MCP server implementation, the extra step is to deploy the MCP server to Google's [Cloud Run](http://cloud.run/), like I explained in this article about the
[various ways to deploy Micronaut apps to Cloud Run]({{<ref "posts/2022/10/24/build-deploy-java-17-apps-on-cloud-run-with-cloud-native-buildpacks-on-temurin/">}}).

# MCP Client and Server with the Java MCP SDK and LangChain4j


[MCP](https://modelcontextprotocol.io/introduction) (Model Context Protocol) is making a buzz these days!
MCP is a protocol invented [last November](https://www.anthropic.com/news/model-context-protocol) by Anthropic,
integrated in Claude Desktop and in more and more tools and frameworks,
to **expand LLMs capabilities** by **giving them access to various external tools** and functions.

> My colleague [Philipp Schmid](https://x.com/_philschmid) gave a great
> [introduction to MCP](https://www.philschmid.de/mcp-introduction) recently,
> so if you want to learn more about MCP, this is the place for you.

In this article, I'd like to guide you through the implementation of an MCP server, and an MCP client, in Java.
As I'm contributing to [LangChain4j](https://docs.langchain4j.dev/), I'll be using LangChain4j's `mcp` module for the client.

For the server, it's possible to use [Quarkus](https://quarkus.io/blog/mcp-server/) or
[Spring Boot](https://docs.spring.io/spring-ai/reference/api/mcp/mcp-server-boot-starter-docs.html).
But Christian Tsolov, who built the MCP library used by Spring Boot (which is also the official [Java SDK](https://github.com/modelcontextprotocol/java-sdk) promoted by the Model Context Protocol project), recently [tweeted](https://x.com/christzolov/status/1906341689142243792) that **the MCP reference implementation can also be used standalone** without a mandatory framework:

{{< x user="christzolov" id="1906341689142243792" >}}

## Developing the MCP server

For the server, I need the reference implementation dependency, as well as some Jetty JARs (or the servlet container of your choice)
to expose an HTTP Server-Sent Event endpoint (you can also create `stdio` servers too):

```xml
<dependency>
	<groupId>io.modelcontextprotocol.sdk</groupId>
	<artifactId>mcp</artifactId>
	<version>0.8.1</version>
</dependency>
<dependency>
	<groupId>org.eclipse.jetty</groupId>
	<artifactId>jetty-server</artifactId>
	<version>12.0.18</version>
</dependency>
<dependency>
	<groupId>org.eclipse.jetty.ee10</groupId>
	<artifactId>jetty-ee10-servlet</artifactId>
	<version>12.0.18</version>
</dependency>
```

I'm using Jetty here, as I want to expose the HTTP SSE endpoint as a servlet.

The first thing needed is to create an HTTP servlet SSE transport provider.
I'll expose the `/sse` endpoint that the client will be able to access:

```java
HttpServletSseServerTransportProvider transportProvider =
    new HttpServletSseServerTransportProvider(
        new ObjectMapper(), "/", "/sse");
```

The MCP reference implementation allows you to implement async or sync servers.
I'm going with a synchronous one, as it's easier to implement:

```java
McpSyncServer syncServer = McpServer.sync(transportProvider)
    .serverInfo("custom-server", "0.0.1")
    .capabilities(McpSchema.ServerCapabilities.builder()
        .tools(true)
        .resources(false, false)
        .prompts(false)
        .build())
    .build();
```

MCP servers can expose:

- tools
- resources
- prompts

In my case, I'm just interested in exposing a tool.
I'll go with a classical weather tool, which is a bit like the _Hello World_ of LLM function calling!

Let's define our `weather-forecast` tool:

```java
McpServerFeatures.SyncToolSpecification syncToolSpecification =
    new McpServerFeatures.SyncToolSpecification(
        new McpSchema.Tool("weather-forecast",
            "gives today's weather forecast for a given location",
            """
            {
              "type": "object",
              "properties": {
                "location": {
                  "type": "string"
                }
              },
              "required": ["location"]
            }
            """
        ),
        (mcpSyncServerExchange, stringObjectMap) -> {
            return new McpSchema.CallToolResult(
                List.of(new McpSchema.TextContent("""
                    {
                        "location": "Paris",
                        "forecast": "Nice and sunny weather, with clear blue sky, and temperature of 17°C."
                    }
                    """
                )), false);
        }
    );

syncServer.addTool(syncToolSpecification);
```

I defined the tool, with a description (which helps LLMs know which tools to invoke for which use case).
The schema of the input is described as a JSON string (as I struggled a bit to find the correct way to create the schema programmatically).

Then I defined the lambda function that is called when the tool is invoked.
I'm returning a JSON object that contains the `location` and the `forecast`.

And I'm done with the MCP server implementation!

But now, I need to expose this server thanks to the Jetty Servlet container.

Let's define a new Jetty server, connector, servlet context handler, export the servlet, and start the server:

```java
QueuedThreadPool threadPool = new QueuedThreadPool();
threadPool.setName("server");

Server server = new Server(threadPool);

ServerConnector connector = new ServerConnector(server);
connector.setPort(45450);
server.addConnector(connector);

ServletContextHandler context = new ServletContextHandler();
context.setContextPath("/");
context.addServlet(new ServletHolder(transportProvider), "/*");

server.setHandler(context);
server.start();
```

Now if you run this code, your MCP server function will be waiting for its first invocations.

## Developing the MCP client with LangChain4j

For the MCP client, I use the [LangChain4j MCP module](https://docs.langchain4j.dev/tutorials/mcp/):

```xml
<dependency>
	<groupId>dev.langchain4j</groupId>
	<artifactId>langchain4j-mcp</artifactId>
	<version>${langchain4j.version}</version>
</dependency>
```

Since I'm using Gemini, I need some dependencies for the Vertex AI Gemini model:

```xml
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j</artifactId>
    <version>${langchain4j.version}</version>
</dependency>
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-vertex-ai-gemini</artifactId>
    <version>${langchain4j.version}</version>
</dependency>
```

Let's get started with instantiating our Gemini 2.0 Flash lite model:

```java
try (
    VertexAiGeminiChatModel model = VertexAiGeminiChatModel.builder()
        .project("genai-playground24")
        .location("us-central1")
        .modelName("gemini-2.0-flash-lite")
        .build();
```

I'm defining an `McpTransport` pointing at my local Jetty SSE server:

```java
McpTransport transport = new HttpMcpTransport.Builder()
    .sseUrl("http://0.0.0.0:45450/sse")
    .build()) {
```

Let's create an MCP client using that transport:

```java
McpClient mcpClient = new DefaultMcpClient.Builder()
    .transport(transport)
    .build();
```

And a tool provider that will expose just the `weather-forecast` tool:

```java
ToolProvider toolProvider = McpToolProvider.builder()
    .mcpClients(List.of(mcpClient))
    .build();
```

You can list the available tools as follows:

```java
mcpClient.listTools().forEach(System.out::println);
```

As I'm going to create a LangChain4j AI service, I need a contract.
This will be the following simple interface:

```java
interface WeatherAssistant {
    String request(String message);
}
```

Now, it's time to instantiate that service:

```java
WeatherAssistant meteo = AiServices.builder(WeatherAssistant.class)
    .chatLanguageModel(model)
    .toolProvider(toolProvider)
    .build();
```

And we can now chat with that service, asking mundane questions, as well as weather related questions that will be invoking the `weather-forecast` tool:

```java
List.of(
    "Hello!",
    "What's the weather like in Paris today?"
).forEach((String q) -> {
    System.out.println(blue(q));
    System.out.println(green(meteo.request(q)));
});
}
```

It will print something like:

```
Hello!
The weather in Paris is sunny today, with a clear blue sky,
and a temperature of 17°C.
```

## Conclusion

In this article, we've seen:

- how to **create an MCP server**, using the official **Java MCP SDK**,
- and how to **create an MCP client** with **LangChain4j**.

We've seen how to define a tool, and how to expose it via an HTTP SSE endpoint.
We've also seen how to use the MCP client to invoke that tool, and how to integrate it in a LangChain4j AI service.

This is a great way to expand the capabilities of LLMs, by giving them access to external tools and functions.
And it shows that you can interact with any MCP server with LangChain4j.

# Quick Tip: Clearing disk space in Cloud Shell


Right in the middle of a [workshop](https://glaforge.dev/posts/2024/03/27/gemini-codelab-for-java-developers/) I was delivering, as I was launching Google Cloud console's [Cloud Shell](https://cloud.google.com/shell/docs) environment, I received the dreaded warning message: `no space left on device`.

And indeed, I didn't have much space left, and Cloud Shell was reminding me it was high time I clean up the mess! Fortunately, the shell gives a nice hint, with a pointer to this [documentation page](https://cloud.google.com/shell/docs/quotas-limits#clearing_disk_space) with advice on how to reclaim space.

The document suggests to run the following command:

```bash
du -hs $(ls -A)
```

This command shows the space each file uses within each sub-directory.

Here's the output I got after having cleaned up the many caches, directories and projects I didn't need anymore:

```
20K     .bash_history
4.0K    .bash_logout
4.0K    .bashrc
20M     .cache
320M    .codeoss
112K    .config
8.0K    .docker
247M    gemini-workshop-for-java-developers
4.0K    .gitconfig
341M    .gradle
12K     .gsutil
4.0K    .lesshst
16K     .npm
4.0K    .profile
0       .python_history
4.0K    README-cloudshell.txt
8.0K    .redhat
4.0K    .ssh
0       .sudo_as_admin_successful
8.0K    .vscode
```

You quickly see directories (like `.codeoss` or my `gemini-workshop-for-java-developers`) that fill up the most space, and you can go after each of those repositories and launch some `rm -Rf some-directory` commands here and there. Of course, pay attention to what you're going to delete, as this is irreversible!

# LLMs.txt to help LLMs grok your content


Since I started my career, I've been sharing what I've learned along the way in this blog.
It makes me happy when developers find solutions to their problems, or discover new things, thanks to articles I've written here.
So it's important for me that readers are able to find those posts.
Of course, my blog is indexed by search engines, and people usually find about it from Google or other engines, or they discover it via the links I share on social media.
But with LLM powered tools (like Gemini, ChatGPT, Claude, etc.) you can make your content more easily _grokkable_ by such tools.

A [proposal](https://llmstxt.org/) emerged last year to add a new file websites, `llms.txt`, which is a Markdown document that lists all the posts, pages, articles of that website. In a way, it's similar to other kind of indexing-related files like `robots.txt` or `sitemap.xml`. But this time, the idea is to offer the content of your documentation, website, or blog, as Markdown, easily _grokkable_ by LLM powered tools.

## Updating Hugo to generate LLMs.txt files

This blog post is powered by [Hugo](https://gohugo.io/), a static site generator.
I'll explain how I added 2 new files to my blog:

- [llms.txt](https://glaforge.dev/llms.txt) — which references links to all the blog posts, a bit like a sitemap.
- [llms-full.txt](https://glaforge.dev/llms-full.txt) — which contains all the blog post articles in one giant file.

In `config.toml`, I added two new output formats:

```toml
[outputFormats.llms]
baseName = "llms"
mediaType = "text/plain"
isPlainText = true

[outputFormats.llms-full]
baseName = "llms-full"
mediaType = "text/plain"
isPlainText = true

[outputs]
home = ["HTML", "RSS", "llms", "llms-full"]
```

And in my custom theme `layouts\_default` folder, I added two templates for those two files:

- `index.llms.txt` references all the articles

```
# Blog of {{ .Site.Title }}

> {{ .Site.Params.Description }}

You can find [more information about this site here](/about).

## All articles
{{ range .Site.RegularPages.GroupByDate "2006" }}

### {{ .Key }}
{{ range .Pages }}
- [{{- .Title -}}]({{- .Site.BaseURL -}}{{- .RelPermalink -}})
{{- end -}}
{{ end }}
```

- `index.llms-full.txt` provides the full content of all the articles

```
{{ range .Site.RegularPages }}
# {{ .Title }}

{{ .RawContent }}
{{- end -}}
```

## Now what can you do with that?

In my recent article on [the power of large context windows for your documentation efforts]({{<ref "posts/2025/02/15/the-power-of-large-context-windows-for-your-documentation-efforts/">}})) I mentioned that you could feed all your content into an LLM prompt and have a discussion with it. This is the same idea I'm following here. Thanks to the full export of all my articles, I can ask questions about everything I've written so far.

Let's go to [Google AI Studio](https://aistudio.google.com/) and ask Gemini, and its huge token context window!

![](/img/gemini/llms-txt-blog-content.png)

When I asked about the main topics of this blog, the above screenshot shows Gemini's answer, highlighting my content about [Apache Groovy](https://groovy-lang.org/), Google Cloud Platform, generative AI, Web APIs, software development best practices.

Look at the number of tokens! **My whole blog is about 682k tokens**! Only Gemini could _grok_ all of that and make sense of it.

As a follow up question, I also asked _"Can you detail more the articles about Generative AI?"_, and Gemini highlighted some of my recent articles and summarized them all:

> Okay, based on the file, here's a breakdown of the articles specifically about Generative AI:
>
> *   **The power of large context windows for your documentation efforts:** This article explores using LLMs with large context windows (like Gemini) to chat with reference documentation, to assist in tasks like creating new modules for LangChain4j. It discusses using "gitingest" to convert a GitHub project into a large text file that can be fed to an LLM.
> *   **A Generative AI Agent with a real declarative workflow:** This piece compares an imperative Java-based AI agent with a declarative approach using Google Cloud Workflows. The agent generates short sci-fi stories, and the article details the pros and cons of each method.
> *   **An AI agent to generate short sci-fi stories:** This project details how to build an AI-powered short story generation agent using Java, LangChain4j, Gemini, and Imagen 3, deployed on Cloud Run jobs. It contrasts explicit vs. autonomous agent workflows.
> *   **Analyzing trends and topics from Bluesky's Firehose with generative AI:** This article describes a project that analyzes the Bluesky social media stream, using vector embeddings and clustering to identify trending topics, and using Gemini to generate summaries of these topics.
> *   **Let's think with Gemini Flash 2.0's experimental thinking mode and LangChain4j:** This article explores the new "thinking mode" of Gemini 2.0 Flash, using LangChain4j to solve riddles and multimodal problems.
> *   **Detecting objects with Gemini 2.0 and LangChain4j:** This article discusses using Gemini 2.0's object detection capabilities with LangChain4j to recognize playing cards in images.
> *   **Semantic code search for Programming Idioms with LangChain4j and Vertex AI embedding models:** Explores the use of Vertex AI embedding models for semantic code search on the Programming Idioms community website. It focuses on using code retrieval task types and LangChain4j for efficient retrieval of code examples.
> *   **Redacting sensitive information when using Generative AI models:** Details the importance of redacting Personally Identifiable Information (PII) before sending user messages to LLMs, using the Google Cloud Data Loss Prevention (DLP) API.
> *   **Data extraction: The many ways to get LLMs to spit JSON content:** This article reviews different techniques to make LLMs generate JSON output and extract data from text, using Gemini and LangChain4j.
>
> These articles demonstrate a clear focus on using various LLMs (primarily Gemini) with tools like LangChain4j and Google Cloud services to address different AI-related problems.


Not only did it summarize all those recent articles, but I also like the final sentence that outlines what most of those articles have in common: They are primarily using the Gemini model, with the [LangChain4j framework](https://docs.langchain4j.dev/), and running on Google Cloud Platform.

When asked to dive deeper on what is so special about LangChain4j, for instance, then again it highlighted the key features of the framework (that I demonstrated in my articles):

> LangChain4j appears to be a central tool for building Generative AI solutions in the provided articles, so I collected a few pieces of information to explain what's so special about it:
>
> *   **Java-Centric Approach:** LangChain4j is a Java library. In a field dominated by Python, LangChain4j is a key tool for Java developers to leverage generative AI without having to switch to a different programming language or environment.
> *   **LLM Orchestration:** LangChain4j facilitates the orchestration of different components in an AI pipeline, from loading documents and splitting them into chunks, to calculate their embedding vectors, storing them in vector databases, and retrieve them to be passed to the LLM, and the augment the LLM prompt with context from those vectors. This reduces the complexity of AI application development.
> *   **Integration with Google Cloud Services:** LangChain4j has built-in integrations with Google Cloud's Vertex AI, Google AI Gemini, and Google Cloud Storage. This allows Java developers to easily use Google's LLMs, embedding models, and data storage solutions.
> *   **Extensible and Customizable:** The library offers a way to plug custom logic and algorithms into the different steps, and to define how the information should be used to interact with the LLM.
> *   **Higher-Level Abstractions:** LangChain4j provides higher-level abstractions for interacting with LLMs, such as the `AiServices` abstraction that returns type-safe objects, which allows developers to manipulate real Java objects, in a type-safe manner, instead of dealing with raw JSON strings.
> *   **Capabilities like Tool Calling, Context Window, and the like:** It integrates new LLM capabilities to improve the quality of the AI powered application's responses.
> *   **Metadata Handling**: It eases the handling of metadata in text segments, including filtering based on metadata during the retrieval phase.
>
> In the context of the articles, LangChain4j simplifies the implementation of complex tasks like:
>
> *   Creating chatbots that can answer questions based on a specific knowledge base (RAG).
> *   Analyzing trends in social media data.
> *   Generating structured content (e.g., JSON) from unstructured text.
> *   Implementing semantic code search.
>
> LangChain4j's key value is that it allows Java developers to more easily build, experiment with, and deploy Generative AI applications using their existing skills and infrastructure, while abstracting away much of the underlying complexity.

## Thoughts and summary

For the past months, I've been exploring various Retrieval Augmented Generation (RAG) techniques to improve the quality of answers for questions on heaps of documents and data, often chunked and stored in vector databases. However, RAG hits some limits when you want to ask more general questions, or to analyze some content more deeply, by understanding it in its entirety.

That's where LLMs like Gemini with large context windows help, as they can figure out the fine print, the relationships between various sections, see common patterns across articles. I believe we should take the **best of both worlds, by finding relevant documents with a hybrid search approach mixing keyword and semantic searches, but then feeding LLMs not only with extracts but with whole documents**.

The `llms.txt` initiative is interesting, and I hope it'll be adopted further in the future.
It will make it simpler for users to more easily reason about documentation, blogs, etc. via LLMs.
As LLMs are getting bigger context windows, the discussion with whole docs or sites become richer, with full understanding of the context of the corpus of documents.


# Pretty-print Markdown on the console


With Large Language Models loving to output Markdown responses, I've been wanting to display those Markdown snippets nicely in the console, when developing some LLM-powered apps and experiments.
At first, I thought I could use a Markdown parser library, and implement some kind of output formatter to display the text nicely, taking advantage of [ANSI color codes and formats](https://gist.github.com/fnky/458719343aabd01cfb17a3a4f7296797).
However it felt a bit over-engineered, so I thought _"hey, why not just use some simple regular expressions!"_ (and now you'll tell me I have a second problem with regexes)

In this blog post, I just want to share the few lines of code I've added in a utility class to output Markdown content nicely.
It's not covering all the bells & whistles of the Markdown syntax (in particular things like Github flavored extensions, like arrays, etc.) but it's good enough for my use case.

## Markdown syntax highlighting on the console

````java
public static String markdown(String md) {
  return md
    // Bold
    .replaceAll("\\*\\*(.*?)\\*\\*", "\u001B[1m$1\u001B[0m")
    // Italic
    .replaceAll("\\*(.*?)\\*", "\u001B[3m$1\u001B[0m")
    // Underline
    .replaceAll("__(.*?)__", "\u001B[4m$1\u001B[0m")
    // Strikethrough
    .replaceAll("~~(.*?)~~", "\u001B[9m$1\u001B[0m")
    // Blockquote
    .replaceAll("(> ?.*)",
        "\u001B[3m\u001B[34m\u001B[1m$1\u001B[22m\u001B[0m")
    // Lists (bold magenta number and bullet)
    .replaceAll("([\\d]+\\.|-|\\*) (.*)",
        "\u001B[35m\u001B[1m$1\u001B[22m\u001B[0m $2")
    // Block code (black on gray)
    .replaceAll("(?s)```(\\w+)?\\n(.*?)\\n```",
        "\u001B[3m\u001B[1m$1\u001B[22m\u001B[0m\n\u001B[57;107m$2\u001B[0m\n")
    // Inline code (black on gray)
    .replaceAll("`(.*?)`", "\u001B[57;107m$1\u001B[0m")
    // Headers (cyan bold)
    .replaceAll("(#{1,6}) (.*?)\n",
        "\u001B[36m\u001B[1m$1 $2\u001B[22m\u001B[0m\n")
    // Headers with a single line of text followed by 2 or more equal signs
    .replaceAll("(.*?\n={2,}\n)",
        "\u001B[36m\u001B[1m$1\u001B[22m\u001B[0m\n")
    // Headers with a single line of text followed by 2 or more dashes
    .replaceAll("(.*?\n-{2,}\n)",
        "\u001B[36m\u001B[1m$1\u001B[22m\u001B[0m\n")
    // Images (blue underlined)
    .replaceAll("!\\[(.*?)]\\((.*?)\\)",
        "\u001B[34m$1\u001B[0m (\u001B[34m\u001B[4m$2\u001B[0m)")
    // Links (blue underlined)
    .replaceAll("!?\\[(.*?)]\\((.*?)\\)",
        "\u001B[34m$1\u001B[0m (\u001B[34m\u001B[4m$2\u001B[0m)");
}
````

> This can easily be translated into other programming languages. Just be careful with the small differences in syntax of regular expressions.

For the following Markdown text:

````markdown
# Main title

Big title

## Subtitle

Small title

# Bold and italic

Some **bold text**.
Bits of _italicized text_.
It's **underlined**.
And ~~striked through~~.

## Links

A [link](https://www.example.com) to an article.

![alt text](image.jpg)

### Quoting

> a quote of someone famous, potentially wrapping around multiple lines.

# Lists

1. First item
2. Second item
3. Third item

- First item
- Second item
- Third item

# Code

Some inline `code` inside a paragraph.
Return type is `void` and args are `String[]`.

A fenced code block:

```java
public class Hello {
    public static void main(String[] args) {
        System.out.println("Hello World!");
    }
}
```
````

On the console output, the above Markdow document would be rendered as follows:

![](/img/misc/markdown-rendered-in-console.png)

Do you like this Markdown syntax highlighting?

## Bonus points

At first, in my utility class, I only had methods for adding some colors in my program outputs.
Even if you don't use Markdown, those touches of color can be useful to differentiate key parts of your output.

So I created some methods for wrapping text in ANSI codes:

```java
public static String red(String msg) {
    return "\u001B[31m" + msg + "\u001B[0m";
}

public static String green(String msg) {
    return "\u001B[31m" + msg + "\u001B[0m";
}
//...
public static String bold(String msg) {
    return "\u001B[1m" + msg + "\u001B[0m";
}

public static String italic(String msg) {
    return "\u001B[3m" + msg + "\u001B[0m";
}
//...
```

You can combine them like in `bold(green(msg))`, add more colors, or even write some fancy rainbow text!
As long as the output is still readable, it's all fair game!

# Advanced RAG — Sentence Window Retrieval


Retrieval Augmented Generation (RAG) is a great way to expand the knowledge of Large Language Models to let them know about your own data and documents. With RAG, LLMs can ground their answers on the information your provide, which reduces the chances of hallucinations.

Implementing RAG is fairly trivial with a framework like [LangChain4j](https://docs.langchain4j.dev/tutorials/rag). However, the results may not be on-par with your quality expectations. Often, you'll need to further tweak different aspects of the RAG pipeline, like the document preparation phase (in particular docs chunking), or the retrieval phase to find the best information in your vector database.

In this first article (hopefully of a series on advanced RAG techniques) I'd like to explore an approach that may yield better results: **sentence window retrieval**, inspired by the technique described in this [article](https://www.linkedin.com/pulse/sentence-window-retrieval-optimizing-llm-performance-rutam-bhagat-v24of/).

> I've explored many techniques in my [advanced RAG techniques]({{<ref "talks/2024/10/14/advanced-rag-techniques/">}}) presentation, if you feel like discovering other techniques that we'll explore in more details in this series.

## Let's step back to naive chunking

First, why do we even split documents in smaller chunks?
We split documents into chunks in RAG because:

- It's easier to find the specific, relevant piece of information within a smaller chunk than a huge document.
- Large Language Models have limited memory. Chunks allow us to feed them just the necessary context, instead of overwhelming them with the whole document.
- Smaller chunks lead to more precise retrieval, delivering more accurate answers.

The naive approach is to split in chunks of a certain amount of characters. For example, on the Wikipedia page of Berlin, a 100-character split might look as follows:

![](/img/rag/naive-chunk-1.png)

If a user asks the question _"What is the population of Berlin?"_, the number of inhabitants is split across two chunks. So neither the first, nor the second chunk would yield the correct information, for the LLM to generate an accurate answer.

An obvious improvement is to use overlapping chunks:

![](/img/rag/naive-chunk-2.png)

The red chunk and the orange chunk overlap: both contain the gray part as well. Which means that the second chunk contains the number (in full) we're interesteded in.

Another possible approach, to avoid splits and overlaps, is to chunk by sentences. After all, human beings write sentences for a good reason, because they bear information that represent a unit of semantic meaning.

![](/img/rag/naive-chunk-3.png)

However, both the chunk with overlap example above, as well as the sentence split expose another flaw: Notice that the pronoun `its`, in the second chunk or the second sentence doesn't carry the information that it actually references `Berlin`. So the pronoun misses an important aspect of the sentence: this is a sentence about the population of Berlin. Not any other city.

An alternative may be to increase the size of the chunk, and/or the size of the overlap, to avoid information to be split across chunks (like the population figure), and to give more context about possible links between sentences (like our pronoun-city). However, the wider the chunks, the more diluted the semantic meaning in the resulting vector embeddings.

With more dillution, it's harder to have query vectors (the user prompt) match the chunks of texts with high similarity values.

## Enters sentence window retrieval

The name of the technique comes from this [article](https://www.linkedin.com/pulse/sentence-window-retrieval-optimizing-llm-performance-rutam-bhagat-v24of/) I mentioned.
But maybe it's not the best name we could find. Maybe something like _wider-context-sliding-window-embedding_ would be more explicit, but that's a mouthful!

Let's have a look at this approach:

![](/img/rag/naive-chunk-4.png)

The idea is as follows:

- We calculate vector embeddings for the sentence in dark green.
- But we save the surrounding sentences in light green (for example, one sentence before, and two after).

At retrieval time, the vector similarity calculation will match better with the dark green sentence (in spite of its missing _Berlin_ aspect).
But the whole light + dark green context will be added in the prompt of the LLM, instead of the single sentence.

The advantages are that:

- We keep on carrying meaningful units of meaning with a few sentences, thus avoiding any key information cut between splits, and semantic dillution of bigger chunks.
- It helps the LLM resolve links between pronouns and their related entity. The LLM knows that we're talking about Berlin here.

## The canonical RAG implementation in LangChain4j

With LangChain4j, the base approach is as follows.
Let's start with the **ingestion phase**:

```java
// Load the document (the Wikipedia page about Berlin)

Document capitalDocument = Document.from(text);

// Define an embedding model to calculate vector embeddings,
// both for the text of the article, and for the user queries

var embeddingModel = VertexAiEmbeddingModel.builder()
    .project(System.getenv("GCP_PROJECT_ID"))
    .endpoint(System.getenv("GCP_VERTEXAI_ENDPOINT"))
    .location(System.getenv("GCP_LOCATION"))
    .publisher("google")
    .modelName("text-embedding-005")
    .build();

// Store the chunks and their vectors in a vector database
// (in this example, we'll use a simple in-memory store)

var embeddingStore = new InMemoryEmbeddingStore<TextSegment>();

// Ingest the document in chunks of 100 characters
// with an overlap of 20 characters,
// use the in-memory vector store,
// and the embedding model for vector calculations

EmbeddingStoreIngestor.builder()
    .documentSplitter(DocumentSplitters.recursive(100, 20))
    .embeddingStore(embeddingStore)
    .embeddingModel(embeddingModel)
    .build()
    .ingest(capitalDocument);
```

This is the naive approach using chunks of 100 characters with overlap.
Let's see what it looks like during the **retrieval phase**:

```java
// Declare the LLM model we want to use

VertexAiGeminiChatModel chatModel = VertexAiGeminiChatModel.builder()
    .project(System.getenv("GCP_PROJECT_ID"))
    .location(System.getenv("GCP_LOCATION"))
    .modelName("gemini-2.0-flash-001")
    .build();

// Create an interface contract
// that LangChain4j will implement for us

interface CapitalsAssistant {
    Result<String> learnAboutCapitals(String query);
}

// AiServices implements the interface
// and binds the LLM, and a content retriever
// that links the embedding model and vector store

CapitalsAssistant assistant =
    AiServices.builder(CapitalsAssistant.class)
        .chatLanguageModel(chatModel)
        .contentRetriever(EmbeddingStoreContentRetriever.builder()
            .embeddingModel(embeddingModel)
            .embeddingStore(embeddingStore)
            .build())
        .build();

// Now we can ask questions
Result<String> response = assistant.learnAboutCapitals(
    "How many inhabitants live in Berlin?");
```

We could also add a memory component, to keep track of the ongoing discussion, it's just one extra line. But here, I stick to just single user questions.

## Let's implement the sentence window retrieval

Now, how can we expand the above code to implement the algorithm?

We need to split the text in sentences, and keep track of the surrounding sentences, as a sliding window, to give extra context to the LLM.
We can store that information as metadata of each text segment.
We must prepare the LLM prompt by inserting the surrounding context, instead of single sentences.

At ingestion phase, we can plug a `TextSegmentTransformer` that transforms our text chunks, to compute and store the surrounding context in the text segment metadata. We need to override both `transform()` and `transformAll()` methods, because we need to modify all chunks together (to get the surrounding sentences):

```java
EmbeddingStoreIngestor ingestor = EmbeddingStoreIngestor.builder()
  .documentSplitter(new DocumentBySentenceSplitter(200, 20))
  .embeddingStore(embeddingStore)
  .embeddingModel(embeddingModel)
  .textSegmentTransformer(new TextSegmentTransformer() {
    @Override
    public TextSegment transform(TextSegment segment) {
      return transformAll(Collections.singletonList(segment))
            .getFirst();
    }

    @Override
    public List<TextSegment> transformAll(List<TextSegment> segments) {
      List<TextSegment> list = new ArrayList<>();
      for (int i = 0; i < segments.size(); i++) {
        TextSegment textSegment = segments.get(i);

        // Create a sliding window of sentences to gather
        // the context surrounding the embedded sentence

        // (2 sentences before, 3 after,
        // but you could make it configurable)
        String context = IntStream.rangeClosed(i - 2, i + 3)
            .filter(j -> j >= 0 && j < segments.size())
            .mapToObj(j -> segments.get(j).text())
            .collect(Collectors.joining(" "));

        // Store the surrounding context as metadata
        // of the text segment (the current chunk)

        Metadata metadata =
            new Metadata(textSegment.metadata().toMap());
        metadata.put(METADATA_CONTEXT_KEY, context);
        list.add(TextSegment.from(textSegment.text(), metadata));
      }
      return list;
    }
  })
  .build();
```

That's a bit of code, but I hope to contribute an implementation to LangChain4j directly, so that you don't have to write this algorithm each time you want to apply it.

Let's focus now on the retrieval phase now, because we need to inject the surrounding context in the LLM prompt, instead of the sentence chunk itself. We need to create a `RetrievalAugmentor`, and configure the `ContentRetriever` we used before, and a `ContentInjector`:

```java
CapitalsAssistant assistant =
  AiServices.builder(CapitalsAssistant.class)
    .chatLanguageModel(chatModel)
    .retrievalAugmentor(DefaultRetrievalAugmentor.builder()

    // the content retriever is defined
    // at the level of the retrieval augmentor

    .contentRetriever(EmbeddingStoreContentRetriever.builder()
      .embeddingModel(embeddingModel)
      .embeddingStore(embeddingStore)
      .build())

    // We create a content injector that injects
    // the surrounding context in the LLM prompt

    .contentInjector((contents, userMessage) -> {

      // Retrieves the surrounding sentences
      // from the text segment's metadata

      String excerpts = contents.stream()
        .map(content ->
          content
            .textSegment()
            .metadata()
            .getString(METADATA_CONTEXT_KEY))
        .collect(Collectors.joining("\n\n"));

      // Customize the prompt for our geography use case

      return PromptTemplate.from("""
        You are a helpful geography assistant
        knowing everything about the capitals of the world.

        Here's the question from the user:
        <question>
        {{userMessage}}
        </question>

        Answer the question using the following information:
        <excerpts>
        {{contents}}
        </excerpts>
        """).apply(Map.of(
          "userMessage", userMessage.singleText(),
          "contents", excerpts
        )).toUserMessage();
    })).build())
  .build();
```

Again, that's a bit of code, but we can make it reusable easily if needed in different contexts.

## Summary

With this _sentence window retrieval_ approach, we calculate and store the vector embedding of a sentence, but we inject a wider surrounding context (a few sentences before and after) into the context of the LLM to generate its response with more information than just the single sentence. This tends to avoid the problem of key pieces of information cut in the middle, and to resolve references between sentences (like a pronoun pointing at a named entity defined earlier).

It's a technique worth experimenting with, to see if it gives better results in your own scenario.
However, before blindly applying a particular technique, be sure to prepare some evaluations: Measure the quality of your RAG pipeline before making changes. Then, measure after having applied a new technique, to see if the answers are better.

We'll have to explore the topic of evaluation another day, but in the meantime, I encourage you to read the blog posts of my colleague Mete Atamel who covered [RAG pipeline evaluation](https://atamel.dev/posts/2025/01-09_evaluating_rag_pipelines/), the [DeepEval](https://atamel.dev/posts/2025/01-14_rag_evaluation_deepeval/) tool, and the [RAG triad metric](https://atamel.dev/posts/2025/01-21_improve-rag-with-rag-triad-metrics/).
# The power of large context windows for your documentation efforts


My colleague Jaana Dogan was [pointing](https://x.com/rakyll/status/) at the Anthropic's MCP (Model Context Protocol) documentation pages which were describing [how to build MCP servers and clients](https://modelcontextprotocol.io/tutorials/building-mcp-with-llms).
The interesting twist was about _preparing the documentation_ in order to have Claude _assist you_ in building those MCP servers & clients, _rather than clearly documenting how to do so_.

{{< x user="rakyll" id="1890521760690270409" >}}

No more tutorials:

- **You discuss with the reference documentation.**
- **Your chat with the LLM becomes the tutorial!**

LLM-powered documentation chats become your tailored tutorial, for your very own specific need and requirements.
Not only LLMs can assist you authoring articles, documentation, reports, but **LLMs can craft explanations that help you achieve a particular goal for which there's not already a tutorial or how-to guide available**.

Also, sometimes, you overlook some key paragraph of section when browsing through the documentation, and you miss the key information that would have helped you fix the problem at hand. This happened to me recently while using an Obsidian plugin: I needed to configure the plugin in a certain way, and I had the impression it wasn't possible, but the plugin author pointed me at the key paragraph that I somehow glanced over. **Had I asked the question to an LLM-powered chat that has all the reference documentation in its context, maybe it would have found that paragraph I missed?**

## Here come the large context window LLMs...

As you may already know, I contribute to the [LangChain4j](https://docs.langchain4j.dev/) open source project, which provides integrations with various LLMs (like Gemini) or vector databases. I hope to start working on an additional module to integrate the new _unified_ [Gemini SDK](https://github.com/googleapis/java-genai).
The advantage of this new SDK is that you can call both Gemini _flavors_: the one provided by Google Cloud's Vertex AI offering, as well as DeepMind's Google AI version.
One SDK to rule them all!

I'm also interested in potentially creating a new vector store module for Google [Cloud Firestore](https://cloud.google.com/firestore/docs/vector-search), which recently added vector calculation support in its Java client library. It would be neat to be able to use Firestore for RAG (Retrieval Augmented Generation) scenarios, taking advantage of the document database, its filtering capabilities, and its ability to do vector similarity searches.

LangChain4j's documentation provides some explanations on how to contribute new integrations, but I was interested in trying this approach of chatting with the reference documentation to guide my steps in creating a new LLM module, and a new vector store implementation module.

Fortunately, my favorite large language model, [Gemini](https://gemini.google.com/app), has a **huge context window** of [up to 2 million tokens](https://developers.googleblog.com/en/gemini-2-family-expands/)!
This should be enough to ingurgitate the whole sources and documentation pages of the project.

Additionally, I discovered `gitingest` a great [online tool](https://gitingest.com/) that allows you to **convert a Github project and all its sources into one gigantic text file**... that you can then feed to an LLM. Basically, you take the URL of a Github repository, and you replace the `github.com` part with `gitingest.com`. For example, for LangChain4j, the URL becomes: `https://gitingest.com/langchain4j/langchain4j`. Then, a download button lets you get the whole content of the repository.

## The prompt

For this experiment, I didn't code anything, I simply used [Google AI Studio](https://aistudio.google.com/app/prompts/new_chat).

I selected `Gemini 2.0 Pro experimental`:

![](/img/gemini/gemini-2.0-pro-exp.png)

Then, I loaded the big text file of the LangChain4j project, created by gitingest, and look at the number of tokens:

![](/img/gemini/2-million-tokens.png)

Yes, the whole repository and documentation is almost 2 million tokens long!
Only Gemini can ingest that many tokens!

Time to ask my question:

> I'd like to create a new language module for LangChain4j. How should I do that? What are the key steps to follow to propose a new model?

## The response

{{< details summary="Click to reveal the detailed answer" >}}

Okay, let's outline the steps to create a new language model module for LangChain4j and propose its inclusion. Based on the provided file structure, you'll be focusing on creating a new module similar to the existing ones (e.g., `langchain4j-open-ai`, `langchain4j-ollama`, etc.). Here's a breakdown of the process, referencing the structure you've provided:

**Key Steps and Considerations**

1.  **Understand the Abstractions and SPI:** LangChain4j, like its Python counterpart, is built around core abstractions. You need to understand these to implement your integration correctly. The core abstractions you _must_ implement are:

    - **`ChatLanguageModel` / `StreamingChatLanguageModel`:** For conversational models (like ChatGPT, Gemini). Implement `ChatLanguageModel` for synchronous responses, and `StreamingChatLanguageModel` if the model supports streaming responses token by token.
    - **`LanguageModel` / `StreamingLanguageModel`:** For models with a simpler text-in, text-out interface (less common these days).
    - **`EmbeddingModel`:** If the model provider offers embedding capabilities.
    - **`ModerationModel`:** If the model provider offers content moderation.
    - **`ScoringModel`:** If the model provider offers scoring/ranking capabilities.
    - **Builder Factories:** You'll also need to create builder factories (SPIs) for each model type you implement. These are how users will construct your model classes. See examples like `AzureOpenAiChatModelBuilderFactory`. These are registered using the Java ServiceLoader mechanism (the `META-INF/services` files).

2.  **Choose a Module Structure (and Repository):**

    - **Community Repo (Preferred for new integrations):** Start your integration in the [`langchain4j-community`](https://github.com/langchain4j/langchain4j-community) repository. This is the recommended approach for new contributions. It allows for easier initial review and iteration before considering a move to the core `langchain4j` repository. Clone this repo, don't fork the main `langchain4j` repo directly.
    - **Main `langchain4j` Repo (For Core Integrations):** If your integration is with a very widely used and well-established model provider (like OpenAI, Google, etc.), _and_ you are confident in its stability and long-term maintenance, you _might_ propose it for the main repo. However, start in `langchain4j-community` first.
    - **Module Naming:** Follow the pattern: `langchain4j-{provider-name}` (e.g., `langchain4j-my-llm`).
    - **Directory Structure:** Create a directory structure mirroring the existing modules (see `langchain4j-open-ai` or `langchain4j-ollama` as good examples):
      ```
      langchain4j-{provider-name}/
          pom.xml  (Your module's Maven build file)
          src/
              main/
                  java/
                      dev/
                          langchain4j/
                              model/
                                  {providername}/  (e.g., myllm)
                                      {ProviderName}ChatModel.java  (Your implementation)
                                      internal/ (API client and related classes)
                                      spi/      (Builder factory for your model)
                                          {ProviderName}ChatModelBuilderFactory.java
                  resources/
                      META-INF/
                          services/
                              (Files to register your builder factory, see examples)
              test/
                  java/
                      dev/
                          langchain4j/
                              model/
                                  {providername}/
                                      {ProviderName}ChatModelIT.java (Integration tests)
      ```

3.  **Implement the API Client:**

    - **Official SDK (Preferred):** If the LLM provider has an official Java SDK, use it. This is usually the best approach for stability, performance, and access to all features. See `langchain4j-bedrock` for an example using an official SDK.
    - **HTTP Client (If no SDK):** If there's no official SDK, use the JDK's built-in `java.net.http.HttpClient` (available since Java 11). This minimizes external dependencies. Avoid adding new dependencies unless absolutely necessary. See `http-clients/langchain4j-http-client-jdk` for how LangChain4j wraps this. Avoid using the older `okhttp3` directly if possible, prefer `langchain4j-http-client-jdk` (or `langchain4j-http-client-spring-restclient` if building a Spring Boot starter).
    - **JSON Handling:** Use Jackson for JSON serialization/deserialization, as it's already a dependency.
    - **Error Handling:** Make sure to handle HTTP errors (non-2xx responses) appropriately. Throw a `dev.langchain4j.exception.HttpException` for these.
    - **Request/Response Logging:** Implement logging for requests and responses (see `langchain4j-anthropic` for a complete example). This is _very_ helpful for debugging.

4.  **Implement the Model Interface(s):**

    - Implement `ChatLanguageModel`, `StreamingChatLanguageModel`, `EmbeddingModel`, etc., as appropriate, based on the provider's capabilities.
    - Use the `Builder` pattern for your model classes to allow for flexible configuration.
    - Make sure your implementation handles request/response mapping and error handling correctly.
    - Implement `TokenCountEstimator` if possible, so the `TokenWindowChatMemory` can calculate the token usage.
      Implement `DimensionAwareEmbeddingModel` to report the output dimension from the embedding model.

5.  **Write Tests:**

    - **Unit Tests:** Create unit tests for any complex logic, utility methods, and request/response mappers.
    - **Integration Tests (ITs):** Create integration tests (e.g., `MyLlmChatModelIT.java`) that interact with the _real_ LLM provider's API. These are _crucial_ for ensuring your integration works correctly.
      - Use environment variables (e.g., `MYLLM_API_KEY`) to store API keys and other secrets. Do _not_ hardcode them.
      - Use `@EnabledIfEnvironmentVariable` to skip the tests if the required environment variables are not set.
      - Extend `AbstractChatModelIT`, `AbstractStreamingChatModelIT`, `AbstractEmbeddingModelIT`, and/or `AbstractScoringModelIT` to get a set of basic tests.
      - Test all relevant features of the model (e.g., text generation, streaming, different parameters, tool use, JSON mode).
      - Add test for concurrent requests if possible.
      - Consider adding a test for the `Tokenizer` interface (see examples in `langchain4j-core`).
      - Add `@RetryingTest` if model response is inconsistent

6.  **Add to BOM (Bill of Materials):** Add your new module to `langchain4j-bom/pom.xml`. This helps users manage dependencies.

7.  **Documentation:**

    - **Update `README.md`:** Add your integration to the list of supported models and embedding stores.
    - **Create Markdown Documentation:** Create Markdown files in the `docs/docs/integrations/` directory, following the structure of existing integrations. You'll need:
      - A main file (e.g., `my-llm.md`).
      - An entry in `docs/docs/integrations/language-models/index.md` and in `docs/sidebars.js`.
      - An entry in `_category_.json` files in `docs/docs/integrations/language-models` and `docs/docs/integrations/embedding-stores`
    - **Examples (Highly Recommended):** Create a simple example in the [`langchain4j-examples`](https://github.com/langchain4j/langchain4j-examples) repository. This is _very_ helpful for users.

8.  **General Guidelines (from CONTRIBUTING.md):**

    - **Java 17:** Maintain compatibility with Java 17.
    - **Minimal Dependencies:** Avoid adding new dependencies if possible. If necessary, try to use libraries already present. Run `mvn dependency:analyze` to check.
    - **Backwards Compatibility:** Avoid breaking changes. If necessary, deprecate old methods/fields instead of removing them.
    - **Naming Conventions:** Follow existing naming conventions.
    - **No Lombok:** Avoid using Lombok in new code; remove it from existing code if you touch it.
    - **Javadoc:** Add Javadoc where needed.
    - **Code Style:** Run `make lint` and `make format` before committing.
    - **Large Features:** Discuss large features with maintainers (@langchain4j) before implementation.

9.  **Open a Pull Request (Draft First):**

    - Open a draft PR in the `langchain4j-community` repository.
    - Fill out all sections of the PR template.
    - Once the PR is reviewed and approved, you will be asked to finalize it (add documentation, examples, etc.).

**Example Code Snippets (Illustrative)**

```java
// MyLlmChatModel.java (in the appropriate package)
public class MyLlmChatModel implements ChatLanguageModel {

    private final MyLlmClient client; // Your custom client
    private final String modelName;

    @Builder
    public MyLlmChatModel(String baseUrl, String apiKey, String modelName, Duration timeout) {
        this.client = new MyLlmClient(baseUrl, apiKey, timeout); // Your custom client
        this.modelName = modelName;
    }

    @Override
    public Response<AiMessage> generate(List<ChatMessage> messages) {
        // 1. Convert Langchain4j messages to MyLLM's request format
        // 2. Call client.chat(...)
        // 3. Convert MyLLM's response to LangChain4j's Response<AiMessage>
        // 4. Handle errors (throw HttpException)
        return null; // TODO: Implement
    }

    // ... other methods, builder, etc. ...
}


// MyLlmClient.java (in a suitable package, e.g., dev.langchain4j.model.myllm.internal)
class MyLlmClient {

    // ... implementation using java.net.http.HttpClient ...
}

// MyLlmChatModelBuilderFactory.java (in a suitable package, e.g., dev.langchain4j.model.myllm.spi)
public class MyLlmChatModelBuilderFactory implements Supplier<MyLlmChatModel.Builder> {

    @Override
    public MyLlmChatModel.Builder get() {
        return MyLlmChatModel.builder();
    }
}

// META-INF/services/dev.langchain4j.model.chat.spi.ChatLanguageModelBuilderFactory (resource file)
// Add a line with the fully qualified name of your factory:
// dev.langchain4j.model.myllm.spi.MyLlmChatModelBuilderFactory
```

**Key Points and Common Mistakes**

- **Thorough Testing:** Integration tests are absolutely essential. Test with real API calls.
- **Error Handling:** Handle HTTP errors (non-2xx responses) from the LLM provider's API.
- **Token Usage:** If the LLM provider gives you token usage information, include it in the `Response`.
- **Finish Reason:** If the LLM provider gives you a finish reason (e.g., "stop", "length"), include it in the `Response`.
- **Consistency:** Maintain consistency with existing LangChain4j modules in terms of naming, structure, and coding style.
- **Documentation:** Clear, concise, and accurate documentation is critical. Follow the patterns you see in existing modules.
- **SPI Registration:** Remember to create the `src/main/resources/META-INF/services/` files to register your model implementation as a service.

This comprehensive guide, combined with the provided file structure and examples, should give you a strong foundation for contributing your new language model integration to LangChain4j. Remember to start in the `langchain4j-community` repository for initial development and review. Good luck!

{{< /details >}}

## The verdict

Honestly, this is really good! It follows the advice in the [contributing guidelines](https://github.com/langchain4j/langchain4j/blob/main/CONTRIBUTING.md).
But since it has access to the whole code base, it understands pretty well the various steps to follow, the classes to implement, etc.

A few nits though: for example, it confirms we shouldn't use Lombok for creating builders, but the example code shows a `@Builder` annotation from Lombok, because it's still used in several modules. Or there's this reference to the `make` tool, although the project doesn't use it at all. The code suggests implement the `generate()` methods, but newer models should now implement the new `chat()` method instead, but Gemini can't really know about this, as this is fairly new and not many models implement those interfaces for now.

But other than that, it's excellent!

Gemini created a contributing guide by looking at almost 2 million tokens of code and documentation.
But this doesn't end here, you can continue asking other questions, to get more insight into particular aspects of the development of a new module, and Gemini would continue the discussion, guiding you and helping you in your task. I found that quite impressive.

## Let's continue the conversation with the code base and documentation

As I was interested in creating a new embedding store for Firestore, I then added in the context the [documentation](https://cloud.google.com/firestore/docs/vector-search) of the Java SDK for Firestore. And asked the following question:

> I would also like to create a new embedding store for the Google Cloud Firestore database.
> What are the steps to create a new LangChain4j embedding store module?

Let's see what it suggested:

{{< details summary="Click to reveal the detailed answer" >}}

Okay, here's a breakdown of how to create a new LangChain4j embedding store module for Google Cloud Firestore, along with the key steps and considerations, mirroring the structure of existing modules like `langchain4j-milvus`.

**Project Structure**

Your project structure should follow the established pattern. I'll create a simplified version based on the most relevant parts from the provided file listing. The full structure would be much larger (like the main `langchain4j` project), but this captures the essentials:

```
langchain4j/
└── langchain4j-embedding-store-google-firestore/  (or similar name)
    ├── pom.xml                                     (Your module's Maven build file)
    └── src/
        └── main/
            └── java/
                └── dev/
                    └── langchain4j/
                        └── store/
                            └── embedding/
                                └── google/
                                    └── firestore/
                                        └── GoogleFirestoreEmbeddingStore.java  (Main class)
                                        └── (Any other supporting classes, like request/response objects)
        └── test/
            └── java/
                └── dev/
                    └── langchain4j/
                        └── store/
                            └── embedding/
                                └── google/
                                    └── firestore/
                                        └── GoogleFirestoreEmbeddingStoreIT.java (Integration test)
```

**Steps to Create the Module**

1.  **Project Setup (Maven Module):**

    - Create a new directory named `langchain4j-embedding-store-google-firestore` (or a similar, descriptive name) within the `langchain4j` parent directory.
    - Create a `pom.xml` file inside this new directory. This file will define your module as a Maven project and specify its dependencies. Use `langchain4j-milvus/pom.xml` as a guide, but adapt it:
      - **Parent:** Set the parent to `langchain4j-parent`, as shown in your example.
      - **ArtifactId:** Use `langchain4j-embedding-store-google-firestore`.
      - **Name and Description:** Update these appropriately.
      - **Dependencies:** Include `langchain4j-core` as a compile-time dependency. Add the Google Cloud Firestore Java client library as a dependency:
        ```xml
        <dependency>
            <groupId>com.google.cloud</groupId>
            <artifactId>google-cloud-firestore</artifactId>
            <version>YOUR_VERSION_HERE</version> <!-- Lookup the latest version -->
        </dependency>
        ```
        Add any other necessary dependencies, such as logging (SLF4J), Lombok (if desired, but try to avoid in new code), etc. _Minimize dependencies as much as possible._
      - **Test Dependencies:** Include JUnit, AssertJ, and any mocking libraries (like Mockito) in the `test` scope.
      - **Licenses:** Ensure your module has the correct Apache 2.0 license information in the POM.

2.  **Implement `EmbeddingStore<TextSegment>`:**

    - Create `GoogleFirestoreEmbeddingStore.java` in the `dev.langchain4j.store.embedding.google.firestore` package.
    - Implement the `EmbeddingStore<TextSegment>` interface from `langchain4j-core`. This is the _crucial_ part. You'll need to implement the following methods, mapping them to Firestore operations:
      - `add(Embedding embedding)`: Adds a single embedding to the store, generating a unique ID.
      - `add(String id, Embedding embedding)`: Adds an embedding with a specified ID.
      - `add(Embedding embedding, TextSegment textSegment)`: Adds an embedding with associated text and metadata.
      - `addAll(List<Embedding> embeddings)`: Adds multiple embeddings.
      - `addAll(List<String> ids, List<Embedding> embeddings, List<TextSegment> textSegments)`: Adds multiple embeddings with associated IDs and text segments.
      - `removeAll(Collection<String> ids)`: Delete embeddings by id
      - `removeAll()`: Deletes everything
      - `removeAll(Filter filter)`: Deletes records using the condition filter
      - `search(EmbeddingSearchRequest request)`: Find related embeddings
      - `findRelevant(Embedding referenceEmbedding, int maxResults, double minScore)`: Finds relevant embeddings.
    - **Considerations for Firestore Implementation:**
      - **Data Model:** How will you store the embeddings (as float arrays) and associated data (text, metadata)? Firestore uses a NoSQL document model. You'll likely store each `TextSegment` and its `Embedding` as a document in a collection.
      - **Metadata:** Firestore supports storing metadata as document fields. You'll need a way to map `TextSegment` metadata (which is a `Map<String, String>`) to Firestore document fields. You have a few options here, mirroring what existing modules do:
        - **Individual Columns (Preferred):** Each metadata key becomes a separate field in the document. This is efficient for querying but requires knowing the metadata keys in advance. The Mariadb integration uses this approach with `MetadataColumDefinition`.
        - **Single JSON Field:** Store all metadata as a single JSON string. This is flexible but less efficient for filtering. The Chroma integration uses this.
        - **Mixed Approach:** Common metadata fields (like "source" or "document_id") could be separate fields, and a catch-all "metadata" field could store the rest as JSON.
      - **Vector Search:** Firestore now has native Vector Search, which is excellent! You'll use this for the `findRelevant` method. The key will be understanding how to map LangChain4j's `EmbeddingSearchRequest` (which includes `maxResults` and `minScore`) to the appropriate Firestore vector search query.
      - **Filtering:** Implement filtering based on metadata using Firestore's query capabilities. LangChain4j's `Filter` interface needs to be translated into a Firestore query. Look at existing implementations like `ChromaMetadataFilterMapper` for inspiration, but adapt it to Firestore's query syntax.
      - **Error Handling:** Wrap Firestore exceptions in `RuntimeException` or a more specific custom exception.
      - **Configuration:** Use a `Builder` pattern (like `OpenAiChatModel` does) to allow users to configure:
        - Firestore project ID, database, collection name
        - Credentials (API key, service account)
        - Timeout settings
        - Maximum number of results (`maxResults`)
        - Minimum relevance score (`minScore`)
        - Field names for text, embedding, and metadata (if configurable)
        - Possibly options for automatically creating the collection/indexes.
      - **Indexing:** You _must_ create the necessary index in Firestore for vector search to work. The documentation you provided explains how to do this with the `gcloud` CLI. The code should, ideally, at least _check_ if the index exists. It _could_ even attempt to create it, but this would require more permissions.
      - **Concurrency:** if there is any concurrency, the code should be thread-safe.

- **Implement `GoogleFirestoreEmbeddingModel`:** You should also implement the `EmbeddingModel` interface, by adapting the google API to the langchain4j interface.

3.  **Create SPI Builder Factory:**

    - Create a `GoogleFirestoreEmbeddingStoreBuilderFactory` class that implements `Supplier<GoogleFirestoreEmbeddingStore.Builder>`.
    - Create a file named `META-INF/services/dev.langchain4j.spi.store.embedding.EmbeddingStoreFactory` in `src/main/resources`.
    - Add a single line to this file containing the fully qualified name of your factory class (e.g., `dev.langchain4j.store.embedding.google.firestore.GoogleFirestoreEmbeddingStoreBuilderFactory`).

4.  **Write Integration Tests:**

    - Create `GoogleFirestoreEmbeddingStoreIT.java` (and potentially `...WithFilteringIT.java`, `...WithRemovalIT.java`, etc., mirroring the existing modules).
    - Extend `EmbeddingStoreIT` (or `EmbeddingStoreWithFilteringIT`, etc.) to inherit a basic set of tests.
    - Implement the abstract methods (like `embeddingStore()`) to provide instances of your store and a compatible embedding model.
    - Add tests specific to Google Cloud Firestore features and limitations.
    - Use `@EnabledIfEnvironmentVariable` to conditionally run the tests only when the necessary environment variables (credentials) are set. See `OllamaChatModelIT` for an example.

5.  **Add to BOM (Bill of Materials):** Add your new module to `langchain4j-bom/pom.xml` to manage its version consistently.

6.  **Documentation:**

    - Add the new model in all the `index.md` files
    - Write a guide in `docs/docs/integrations/embedding-stores`
    - Create a README file

**Code Example (Conceptual)**

```java
// In your GoogleFirestoreEmbeddingStore.java
package dev.langchain4j.store.embedding.google.firestore;

import dev.langchain4j.data.embedding.Embedding;
import dev.langchain4j.data.segment.TextSegment;
import dev.langchain4j.model.embedding.EmbeddingModel;
import dev.langchain4j.store.embedding.EmbeddingMatch;
import dev.langchain4j.store.embedding.EmbeddingStore;
import lombok.Builder;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.List;

// ... other imports ...

public class GoogleFirestoreEmbeddingStore implements EmbeddingStore<TextSegment> {

    private static final Logger log = LoggerFactory.getLogger(GoogleFirestoreEmbeddingStore.class);

    // ... (fields for Firestore client, collection name, etc.) ...

    @Builder
    public GoogleFirestoreEmbeddingStore(...) {
        // ... (initialize Firestore client, etc.) ...
    }

    @Override
    public String add(Embedding embedding) {
        // ... implementation ...
    }

    @Override
    public void add(String id, Embedding embedding) {
        // ... implementation ...
    }

    @Override
    public String add(Embedding embedding, TextSegment textSegment) {
        // ... implementation ...
    }

    @Override
    public List<String> addAll(List<Embedding> embeddings) {
        // ... implementation ...
    }

    @Override
    public void addAll(List<String> ids, List<Embedding> embeddings, List<TextSegment> embedded) {
        // ... implementation ...
    }

    @Override
    public List<EmbeddingMatch<TextSegment>> findRelevant(Embedding referenceEmbedding, int maxResults, double minScore) {
        // ... implementation using Firestore vector search ...
        // ... map Firestore results to EmbeddingMatch objects ...
    }

    // ... other methods ...
}

// In a separate file: GoogleFirestoreEmbeddingStoreBuilderFactory.java
package dev.langchain4j.store.embedding.google.firestore;

import dev.langchain4j.model.embedding.EmbeddingModel;
import dev.langchain4j.spi.store.embedding.EmbeddingStoreFactory;

public class GoogleFirestoreEmbeddingStoreBuilderFactory implements EmbeddingStoreFactory {
    @Override
    public GoogleFirestoreEmbeddingStore.Builder get() {
       return GoogleFirestoreEmbeddingStore.builder();
    }
}
```

**Key Improvements and Considerations from the examples:**

- **Error Handling:** Wrap Firestore API calls in `try-catch` blocks and throw `RuntimeException` (or a more specific custom exception) to handle potential errors.
- **Logging:** Use SLF4J (`log.debug()`, `log.info()`, `log.warn()`, `log.error()`) for logging. This is crucial for debugging and monitoring.
- **Configuration:** The `Builder` should allow configuration of all necessary parameters (endpoint, credentials, collection name, timeouts, etc.). Use `ensureNotNull` and `ensureNotBlank` to validate.
- **Dependency Management:** The `pom.xml` should correctly specify the Google Cloud Firestore client library as a dependency.
- **Testcontainers:** Consider using Testcontainers for integration tests to spin up a Firestore emulator. This will make your tests more reliable and portable. (See examples in the provided code, such as for `CassandraEmbeddingStoreDockerIT`).
- **Metadata:** Implement proper handling of metadata, including mapping it to/from Firestore document fields. Decide on your strategy (separate fields vs. JSON).
- **Filtering:** Implement filtering based on metadata using Firestore's query capabilities. You will likely need a helper class like `ChromaMetadataFilterMapper` to translate `Filter` objects into Firestore queries.
- **Service Provider Interface (SPI):** The `spi` package and `META-INF/services` file are _critical_ for LangChain4j to discover your implementation. This is how `AiServices` (and other parts of the framework) dynamically load components. Without this, your module won't be usable.
- **Return type**: The `findRelevant` method should take a {@link dev.langchain4j.store.embedding.EmbeddingSearchRequest} and return a {@link dev.langchain4j.store.embedding.EmbeddingSearchResult}. This would ensure that we have consistency through all embedding stores and allow advanced filtering and reranking features.
- **Interface segregation**: Introduce a `EmbeddingStoreWithFiltering` interface, that extends `EmbeddingStore` and adds a `removeAll(Filter filter)` method.
- **Metadata handling:** Implement the `MetadataHandler` interface, or extend one of its base classes if it's a good fit.
- **Support Vector Search API in different database modes:** Support vector search in the different modes of Cosmos DB, implementing the search in each of them.
- **Implement the `close()` method:** You should close the connection to Firestore in the `close()` method.
- **Test your embedding store against the `EmbeddingStoreWithFilteringIT` and `EmbeddingStoreWithRemovalIT`:** The provided `langchain4j-core` contains those abstract test classes that you can use to test your embedding store.
- **Add documentation:** Create Markdown files in the `docs/docs/integrations/embedding-stores` directory, following the structure of existing integrations.
- **Add an example:** to the [examples repository](https://github.com/langchain4j/langchain4j-examples).

By following these steps and adapting the provided example code, you can create a robust and well-integrated
LangChain4j module for Google Cloud Firestore.

{{</details>}}

## Second verdict

**Again, it's pretty spot on and acurate!**
Still a mention to Lombok, or a strange reference to Cosmos DB, but I generally like how it advises me to look at existing modules, telling me that this particular one may be a good inspiration to get my implementation right.

I've never implemented an embedding store so far, and I think newer models should implement a `search()` method instead of `findRelevant()`.
So I asked how to implement this method, using the documentation of the Firestore Java SDK, and a minute later, it suggested a concrete implementation.
I won't copy the output again, as I don't want to make this article too long (it already is).
I haven't tried this implementation, but the code and explanations seemed pretty convincing, so when I get some time, I'll try to see if it's correct.

## Conclusion

**Only Gemini proposes a 2 million token context window**. And I'm glad it does, because the LangChain4j projects is close to that limit!
With models with smaller windows, I would have had to be way more selective, and send in the prompt just the right types of artifacts (ie. just the LLM modules, or just the embedding store implementations). Thanks to the huge window, I was able to feed the whole repository in its entirety!

**Does it mean it's the end to writing proper tutorials or how-to guides? Certainly not.**
But I find that very interesting that I'm able to have this kind of highly detailed conversation with the LLM, without having to understand all the tiny little details of the underlying project, as the model is able to grok it for me, and distills just the right level of information for me to do the task I asked about.

What's very interesting is that **I can continue the conversation** to go in various directions, or **zoom on some specific aspects**, which may not necessarily be covered by existing tutorials or guides. **It's as if I was pair programming with the founder of the project.**

# A Generative AI Agent with a real declarative workflow


In my [previous article]({{< ref "/posts/2025/01/27/an-ai-agent-to-generate-short-scifi-stories" >}}), I detailed how to build an AI-powered short story generation **agent** using Java, [LangChain4j](https://docs.langchain4j.dev/), Gemini, and Imagen 3, deployed on Cloud Run jobs.

This approach involved writing **explicit** Java code to orchestrate the entire workflow, defining each step programmatically. This follow-up article explores an alternative, **declarative** approach using [Google Cloud Workflows](https://cloud.google.com/workflows).

I've [written extensively on Workflows]({{< ref "/tags/workflows" >}}) in the past, so for those AI agents that exhibit a very explicit plan and orchestration, I believe Workflows is also a great approach for such declarative AI agents.

## From imperative to declarative: defining the workflow

The Java-based agent employed an imperative style, where the code explicitly defined the sequence of operations. Each step, from story conception to image selection, was a method call within the `ExplicitStoryGeneratorAgent` class (you can check the [code of this class](https://github.com/glaforge/short-genai-stories/blob/main/fictionStoryAgent/src/main/java/storygen/ExplicitStoryGeneratorAgent.java)). This provided fine-grained control and allowed for parallelization.

[Cloud Workflows](https://cloud.google.com/workflows) offers a declarative approach. Instead of writing code, you define the workflow in a YAML file. This file specifies the steps, their inputs and outputs, and the order in which they should be executed. You can also easily create loops (sequential or parallel), and you can implement _human in the loop_ callbacks if needed. The workflow engine then interprets this definition and executes the steps accordingly.

> YAML can be a fair bit more cumbersome to write, compared to using a programming language, but non-developers could get a workflow definition rolling, without having to fire an IDE to code. But for a Java developer, it's certainly simpler to write code, with the help of their favorite programming environment.

In this article, I've created a simplified variant: I removed the _LLM-as-judge_ step that picked the best images. And I've created pictures for the whole story, not for each chapter. So it's not exactly the same agent workflow as in the preivous article. But I don't want you to drown in too much YAML!

The workflow:

- creates the story with **Gemini 2**,
- creates a prompt (for the whole story, not for each chapter),
- generates images with **Imagen 3**,
- saves the result in [Cloud Firestore](https://cloud.google.com/firestore)

Let's have a look at the full YAML definition, and read the comments explaining what each step does:

```yaml
main:
  params: [input]
  steps:

    # Let's define the Gemini and Image models we want to use:
    - setup:
      assign:
        - GEMINI_MODEL: ${"projects/" + sys.get_env("GOOGLE_CLOUD_PROJECT_ID") +
            "/locations/us-central1/publishers/google/models/gemini-2.0-flash-exp"}
        - IMAGEN_MODEL: ${"projects/" + sys.get_env("GOOGLE_CLOUD_PROJECT_ID") +
            "/locations/us-central1/publishers/google/models/imagen-3.0-generate-002"}

    # We call Gemini to generate the story
    - generate_story:
      call: googleapis.aiplatform.v1.projects.locations.endpoints.generateContent
      args:
        model: ${GEMINI_MODEL}
        region: 'us-central1'
        body:
          contents:
            role: user
            parts:  # Let's write a sci-fi story!
              - text: "Write a short science-fiction story"
          generationConfig:
            temperature: 2.0
            responseMimeType: application/json
            # Use a JSON schema to define the format of the output
            responseSchema:
              type: OBJECT
              properties:
                title:
                  type: STRING
                  description: The title of the short story
                content:
                  type: STRING
                  description: The body of the story
              required: ['title', 'content']
          # You can define system instructions
          systemInstruction:
            parts:
              - text: >
                  You are a creative fiction author,
                  and your role is to write stories.
                  You write a story as requested by the user.

                  A story always has a title,
                  and is made of 5 long chapters.
                  Each chapter has a title, is split into paragraphs,
                  and is at least 20 sentences long.
      result: short_story

     # Assign the story, title, content into some variables
    - get_story:
      assign:
        - story_output: ${json.decode(short_story.candidates[0].content.parts[0].text)}
        - title: ${story_output.title}
        - content: ${story_output.content}

    # Let's call Gemini again, but for creating a prompt for Imagen
    - generate_image_prompt:
      call: googleapis.aiplatform.v1.projects.locations.endpoints.generateContent
      args:
        model: ${GEMINI_MODEL}
        region: 'us-central1'
        body:
          contents:
            role: user
            parts:
              - text: ${content}
          systemInstruction:
            parts:
                - text: |
                  You are an expert artist who masters crafting great
                  prompts for image generation models, to illustrate
                  short stories.
                  When given a short story, reply with a concise
                  prompt that could be used to create an illustration
                  with the Imagen 3 model.
                  Don't use any flags like those used with MidJourney.
                  Just answer with the short concise text prompt.

                  Your answer MUST start with "A cartoon of ",
                  as we want to use cartoon or comics illustrations.
                  The user gives you the following image prompt
                  for the chapter to illustrate:
      result: image_prompt

    # Retrieve the prompt from Gemini's output
    - assign_prompt:
      assign:
        - prompt: ${image_prompt.candidates[0].content.parts[0].text}

    # Time to generate the images
    - image_generation:
      call: googleapis.aiplatform.v1.projects.locations.endpoints.predict
      args:
        endpoint: ${IMAGEN_MODEL}
        region: us-central1
        body:
          instances:
            - prompt: ${prompt}
          parameters: # Store images in Google Cloud Storage
            storageUri: 'gs://short-scifi-stories-generated-images'
      result: images

    # Utility step to create the picture data for Firestore
    - prepare_images_uri_list:
      steps:
        - create_empty_list:
          assign:
            - uris: []
            - uris_for_firestore: []
        - loop_over_images:
          for:
            value: img_object
            in: ${images.predictions}
            steps:
              - append_uri:
                assign:
                  - uris: ${list.concat(uris, img_object.gcsUri)}
                  - stringUriMap:
                      stringValue: ${img_object.gcsUri}
                  - uris_for_firestore: ${list.concat(uris_for_firestore, stringUriMap)}

    # Let's prepare the final output to return
    # as the result of the workflow execution
    - prepare_result:
      assign:
        - final_result:
          title: ${title}
          content: ${content}
          prompt: ${prompt}
          images: ${uris}
          createdAt: ${sys.now()}

    # Finally, let's save the story in Firestore
    - save_to_firestore:
      call: googleapis.firestore.v1.projects.databases.documents.createDocument
      args:
        collectionId: short-story
        parent: ${"projects/" + sys.get_env("GOOGLE_CLOUD_PROJECT_ID") + "/databases/(default)/documents"}
        query:
          documentId: ${uuid.generate()}
        body:
          fields:
            title:
              stringValue: ${final_result.title}
            content:
              stringValue: ${final_result.content}
            prompt:
              stringValue: ${final_result.prompt}
            images:
              arrayValue:
                values: ${uris_for_firestore}
            createdAt:
              timestampValue: ${time.format(final_result.createdAt,"GMT")}

    # Return the data
    - return_output:
      return: ${final_result}
```

This YAML file defines the entire story generation process. It calls the Gemini and Imagen APIs, extracts the necessary information from the responses, and saves the final result to Firestore. No Java code is required to manage the flow of execution.

## Key differences and trade-offs

Let's zoom in on the pros and cons of both approaches.

### Imperative / programming approach:

- **Pros**:
  - Fine-grained control over the workflow.
  - Explicit parallelization for performance optimization.
  - Familiar programming and debugging tools.
  - Cloud Run jobs is fully managed and scaled by Google Cloud.
  - Job execution can be scheduled by Cloud Scheduler.
- **Cons**:
  - You need to be familiar with a programming language & environment.
  - It can potentially be challenging to maintain as the workflow evolves.
  - The approach used required being familiar with running & scheduling containers as jobs.

### Declarative / workflow based approach:

- **Pros**:
  - Pretty easy-to-understand workflow definitions.
  - Workflows offers a visualisation of the steps (also during execution).
  - Parallelization can be defined explicitly (with the `parallel` keyword on iterations or step branches).
  - Simplified maintenance and updates. Just need to update the YAML in the console.
  - Workflows is scalable and reliable out of the box without extra effort.
  - Workflow execution can be scheduled by Cloud Scheduler.
- **Cons**:
  - YAML authoring can be painful, if you're not familiar with the APIs you call.
  - Parallelization is declarative but might be limited depending on the workflow definition and Google Cloud Workflows capabilities. You would have more control with a programming language.
  - There's no emulator to run workflows locally, so you might have to create copies and work on these, to not affect the production workflow.
  - Debugging relies on workflow execution logs, which might be less intuitive than traditional debugging.

## Choosing the right approach

It depends! :sweat_smile:

Of course, the choice between these approaches depends on the specific project requirements. If fine-grained control and explicit parallelization are critical, the imperative programming approach might be preferable.

However, for simpler workflows where ease of development and maintainability are critical, Cloud Workflows offers an interesting alternative. You can easily make a tweak to the workflow directly from the Google Cloud console if needed.

In the case of this story generation agent, the declarative approach sounds like a good fit, but the YAML authoring can be a bit painful at times, as you have to look up the various payload schemas for the APIs to invoke, to be able to make the service calls. But that's definitely a plus as well, in the sense that pretty much all the products and services offered on Google Cloud Platform can easily be called via REST endpoints, and Workflows excels at that.

## Conclusion

Explicit declarative planning helps AI agents stay focused, and ensures a high level of predictability.
My experience with agents which plan their own actions has been mixed, as sometimes the LLM hallucinates function calls, or calls functions with bogus parameters.
In the previous [previous article]({{< ref "/posts/2025/01/27/an-ai-agent-to-generate-short-scifi-stories" >}}), I used an imperative programming approach, but in this article today, I developed a simplified equivalent with a declarative workflow definition.

[Google Cloud Workflows](https://cloud.google.com/workflows) offers a powerful and convenient way to build and manage declarative AI agents — and obviously any other kind of process that needs to call APIs. By defining the workflow declaratively, you can focus on the logic of your agent rather than the details of execution. While it might not be suitable for every use case, it's definitely a valuable tool to consider when building AI-powered applications on Google Cloud!

# An AI agent to generate short sci-fi stories


This project demonstrates how to build a fully automated short story generator using Java, [LangChain4j](https://docs.langchain4j.dev/), Google Cloud's **Gemini** and **Imagen 3** models, and a serverless deployment on [Cloud Run](http://cloud.run/).

Every night at midnight UTC, a new story is created, complete with AI-generated illustrations, and published via Firebase Hosting.
So if you want to read a new story every day, head over to:

## → [short-ai-story.web.app](https://short-ai-story.web.app/) ←

The code of this agent is available on Github. So don't hesitate to **check out the code**:

## → [github.com/glaforge/short-genai-stories](https://github.com/glaforge/short-genai-stories) ←

Let's have a closer look at the architecture and workflow of this automated storytelling machine.

## The agent: the storyteller's brain

At the heart of the system lies the `ExplicitStoryGeneratorAgent`, a Java class orchestrating the entire story generation process. This agent follows a clear, multi-step workflow:

* **Story conception (Gemini)**: The agent first calls the Gemini large language model (LLM) to generate the core story elements: a title, five chapters each with title and content.
* **Image prompt engineering (Gemini)**: For each chapter's content, the agent again leverages Gemini to craft tailored image generation prompts. This ensures that the image prompts are relevant to the specific content of each chapter.
* **Illustration generation (Imagen 3)**: Using the generated prompts, the agent calls Imagen 3 to produce a set of image candidates (four by default) for each chapter.
* **Image selection (Gemini, self-reflection)**: In a unique _"self-reflection"_ step, the agent presents the generated images back to Gemini, asking the LLM to select the image that best visually represents the chapter's narrative. This crucial step ensures that the illustrations truly complement the story.
* **Persistence (Firestore)**: Once the story, chapter titles, content, and selected images are finalized, the agent stores them in a Firestore database (a NoSQL document database). This makes retrieving complete data relatively straightforward from the web frontend, thanks to the [Firebase](https://firebase.google.com/) framework.

For the more visual people among us, this diagram illustrates the steps above:

![Agent workflow diagram](/img/short-ai-stories/agent-workflow.png)

**Note:** The critique step where Gemini is asked to judge the best image isn't really necessary, to be honest. Imagen generates images that adhere very much to the given prompt. So either of them would seem suitable to illustrate each chapter. But it was interesting to implement a _self-reflection_ step in this workflow.

## Digression: Explicit vs. Autonomous Agent Workflows

This project utilizes an _explicit workflow agent_, where the story generation process is meticulously defined and controlled by the Java code. This approach contrasts with fully _autonomous agents_, which rely on the LLM to plan and execute the workflow dynamically.

Let's explore the key differences and trade-offs between these two approaches:

### Explicit workflow agent (code-driven planning):

* **Predictable execution**: The Java code dictates the exact sequence of steps, ensuring a highly predictable and reliable workflow. Each stage, from story conception to image selection, is explicitly programmed, leaving no room for unexpected deviations.
* **Improved performance through parallelization**: With explicit control, tasks that can be executed concurrently (such as generating images for different chapters or judging the best image for each chapter) can be easily parallelized. This significantly reduces the overall execution time.
* **Easier debugging and maintenance**: The clear, structured code makes debugging and maintenance straightforward. The flow of execution is transparent to the developer, and any errors can be readily identified and addressed.
* **Limited flexibility**: The explicit nature of the workflow could be seen as offering less flexibility. Indeed, the code needs to be updated to handle changes of the workflow. However, it's not necessarily worse than endlessly tweaking prompts to coerce an LLM to plan correctly the needed workflow changes.

### Autonomous agent (LLM-driven planning):

* **Dynamic workflow**: Autonomous agents use the LLM's capabilities to plan and execute the workflow. This allows for greater flexibility and adaptability to different story generation requirements. The LLM can theoretically decide which steps to take, in which order, and how many times.
* **Potential for hallucinations and errors**: Relying on the LLM for planning introduces the risk of hallucinations and incorrect function calls. The LLM might generate nonsensical steps, omit crucial actions, provide incorrect parameters to functions, or execute functions in an illogical order. This can lead to unpredictable results and make it harder to catch potential errors. Even with perfect prompts, LLMs might make mistakes in function calling. This is actually the problem I encountered when trying this approach first.
* **Debugging challenges**: Debugging autonomous agents can be more complex. The dynamic nature of the workflow makes it harder to trace the execution path and identify the source of errors. Troubleshooting often involves analyzing the logs of the LLM and the tools it requested to call, which can be challenging to interpret at times.
* **Less control over execution**: With autonomous agents, developers cede some control over the execution flow to the LLM. While this offers flexibility, it also means less fine-grained control over performance optimization. Parallelization opportunities, for example, might not be readily apparent or easily exploitable. Currently, when receiving paralell function call requests, LangChain4j doesn't yet offer the possibility to request their paralellization.

The autonomous approach would have looked like the following diagram:

![Autonomous agent diagram](/img/short-ai-stories/autonomous-approach.png)

With this approach, the main agent generates the story, then would call first the prompt creation tool, then the generation image tool, and would finish with the tool to pick up the best image. However, in my experience, in spite of a good amount of prompt engineering tweaks, I couldn't get this to work reliably. I tried with different versions of Gemini (1.5 Flash, 1.5 Pro, and 2.O Flash experimental, from worst to best outcome), but sometimes, for example, it would request to judge images before they had been generated, or the URLs of the images would be hallucinated instead of coming from the outcome of the judge. So I prefered moving to a more explicit approach.

I invite you to read this great article from Anthropic about [building effective agents](https://www.anthropic.com/research/building-effective-agents) which also makes the distiction between _agents_ (fully autonomous planning agents) and _workflows_ (the more explicit approach with code driving the execution planning). They also recommend to stick to _workflows_ when the logic of the agent is very clear upfront: when you can draw a workflow on a sheet of paper, that's surely because you do need a workflow.

### Choosing the right approach:

The choice between explicit and autonomous workflows depends on the specific requirements of the project. Explicit workflows are best suited for applications where predictability, reliability, and performance are paramount.

Autonomous agents are more appropriate when flexibility, adaptability, and dynamic planning are prioritized, even at the cost of potential errors and increased debugging complexity.

This project prioritizes the former over the latter, which explains why an explicit agent is preferred for this use case. In other words, it's better to have a predictable solution, which then can be easily parallelized to reduce latency, than a non-predictable solution that is slower.

## A closer look at the code

As you'll be exploring the [code base](https://github.com/glaforge/short-genai-stories), I'd like to highlight a few points.

The `ExplicitStoryGeneratorAgent` class uses a structured and predictable approach to orchestrating the LLM. Its core logic resides within the `main()` method, outlining a clear, step-by-step workflow:

```java
// 1️⃣ let's prepare the story
Story story = prepareStory("a science-fiction novel");

// 2️⃣ iterate over each chapter in parallel
List<Story.Chapter> newChaptersWithImages = story.chapters.stream()
    .parallel()
    .map(chapter -> {
        // 3️⃣ prepare an impage prompt for each chapter
        String imagePrompt = prepareImagePromptForChapter(chapter);

        // 4️⃣ generate up to 4 images per chapter
        List<String> imagesForChapter = generateImages(imagePrompt);

        // 5️⃣ judge the best image for this chapter
        String bestImage = pickBestImageForChapter(
            chapter.chapterContent, imagesForChapter);

        return new Story.Chapter(
            chapter.chapterTitle,
            chapter.chapterContent,
            bestImage);
    }).toList();

Story newStoryWithImages =
    new Story(story.title, newChaptersWithImages);
// 6️⃣ save the story to Firestore
saveToFirestore(newStoryWithImages);
```

Story generation depends on _structured output_: The agent uses Gemini to generate the story's title and five chapters, each with a title and content. Crucially, it leverages Java `record`s and `responseSchema` to ensure type safety and consistent outputs. You'll notice the use of `@Description` annotations to ensure the LLM really understands what each field corresponds to:

```java
record Story(
    @Description("The title of the story")
    String title,
    @Description("The chapters of the story")
    List<Chapter> chapters) {
    record Chapter(
        @Description("The title of the chapter")
        String chapterTitle,
        @Description("The content of the chapter")
        String chapterContent,
        @Description("The Google Cloud Storage URI of the image...")
        String gcsURI) {
    }
}
```

To configure the model generation to use structured outputs, here's how the schema of this output is defined:

```java
var chatModel = VertexAiGeminiChatModel.builder()
    .project(GCP_PROJECT_ID)
    .location(GCP_LOCATION)
    .modelName(CHAT_MODEL_NAME)
    .temperature(1.5f)
    .responseSchema(Schema.newBuilder()
        .setType(Type.OBJECT)
        .putProperties("title", Schema.newBuilder()
            .setDescription("The title of the story")
            .setType(Type.STRING)
            .build())
        .putProperties("chapters", Schema.newBuilder()
            .setDescription("The list of 5 chapters")
            .setType(Type.ARRAY)
            .setItems(Schema.newBuilder()
                .setDescription(
                    "A chapter with a title, and its content")
                .setType(Type.OBJECT)
                .putProperties("chapterTitle", Schema.newBuilder()
                    .setType(Type.STRING)
                    .setDescription("The title of the chapter")
                    .build())
                .putProperties("chapterContent", Schema.newBuilder()
                    .setType(Type.STRING)
                    .setDescription("The content of the chapter, " +
                        "made of 20 sentences")
                    .build())
                .addAllRequired(
                    List.of("chapterTitle", "chapterContent"))
                .build())
            .build())
        .addAllRequired(List.of("title", "chapters"))
        .build())
    .build();
```

It's possible to simplify the schema creation by taking advantage of a helper class. This schema could have been simplified to:

```java
    // ...
    .responseSchema(SchemaHelper.fromClass(Story.class))
    // ...
```

To instruct the LLM at each step, I tend to use system instructions for setting the role and goal for the LLM, but I use user messages to give the more variable part, like the chapter's content, or the image prompt. Here's an example:

```java
Response<AiMessage> response = chatModel.generate(
    SystemMessage.from("""
        You are a creative fiction author, and your role is to write stories.
        You write a story as requested by the user.

        A story always has a title, and is made of 5 long chapters.
        Each chapter has a title, is split into paragraphs, \
        and is at least 20 sentences long.
        """),
    UserMessage.from(storyType)
);
```

The `storyType` variable in the user message contains the type of story to generate, like `"a science-fiction story"`.
It's currently set in stone, but you could parameterize this to generate fantasy novels, love stories, etc.

The _self-reflection_ step, where the LLM judges which is the best illustration for a chapter is taking advantage of Gemini's multimodal capabilities.
Indeed, Gemini receives the instruction of picking the best image out of a few, and it is given the text of the request (and the URLs of the pictures), as well as inline references to those images (ie. the Google Cloud Storage URI, pointing at the location of the pictures). Thus, this is a multimodal request, as both text and images are passed in the prompt:

```java
List<String> imagesForChapter = generateImages(imagePrompt);
String bestImage = pickBestImageForChapter(chapter.chapterContent, imagesForChapter);

// Inside pickBestImageForChapter we have:
List<ChatMessage> messages = new ArrayList<>();
messages.add(SystemMessage.from("...prompt to select best image..."));
messages.add(UserMessage.from("...chapter content..."));
imagesForChapter.forEach(imageUrl -> {
    // Send each URL as text and as image to the model
    messages.add(UserMessage.from(imageUrl + "\n"));
    messages.add(UserMessage.from(ImageContent.from(imageUrl)));
});

Response<AiMessage> response = chatModel.generate(messages);
// ... parse best image from response
```

## Building the application

The project employs a standard Java development workflow using Maven for dependency management and building:

* **Dependencies**: The `pom.xml` file defines the project's dependencies, including LangChain4j (for LLM orchestration), the Google Cloud Firestore library (for data persistence), and Google Cloud's Gemini and Imagen libraries.
* **Packaging**: The Maven build process packages the application into a JAR, and its dependencies by its side. I followed the approach explained in that [article](https://medium.com/holisticon-consultants/dont-build-fat-jars-for-docker-applications-6252a5571248): to build a JAR with its dependencies on the side, instead of a _shaded / fat_ JAR. One benefit I see is that the dependencies are one container layer, while the application itself is another, so it should make Docker building layer faster, as the dependencies don't change often, and that dependency layer would be cached.
* **Containerization (Docker)**: A `Dockerfile` is used to containerize the application. The container image includes the executable JAR and dependencies, as well as the Java runtime environment. I used Azul's [Zulu distroless Java 21](https://hub.docker.com/layers/azul/zulu-openjdk-distroless/21-latest/images/sha256-986ca559b15738378f4a67a563c117159136c5eff705b91ba68f0fe8883246ef?context=explore) base image. The container is finally built thanks to Cloud Build.

## Deployment and automation

To automate story generation and deployment, the project leverages several Google Cloud services:
* **Cloud Build**: Cloud Build automates the process of building the Docker container image. The provided `justfile` contains commands and recipes to build and submit the container image (I covered `just` in a [previous article](https://glaforge.dev/posts/2023/06/07/just-a-handy-command-line-tool/), a nifty little tool to parameterize and run common commands for the project). I simply followed the tutorial in the Cloud Build documentation to [submit a build via the CLI](https://cloud.google.com/build/docs/running-builds/submit-build-via-cli-api) (the `gcloud` CLI SDK), after having done some IAM setup as explained [here](https://cloud.google.com/build/docs/build-push-docker-image) to be able to push the built image in [Artifact Registry](https://cloud.google.com/artifact-registry/docs).
* **Cloud Run jobs**: The application runs as a Cloud Run job. Contrary to Cloud Run services, where incoming HTTP requests trigger the service, here, jobs are triggered and run to completion. The Cloud Run job allows for serverless execution of the story generation agent. I followed this guide to [create jobs](https://cloud.google.com/run/docs/create-jobs#gcloud). Don't forget to set up the [required environment variables](https://cloud.google.com/run/docs/configuring/jobs/environment-variables).
* **Cloud Scheduler**: Cloud Scheduler triggers the Cloud Run job every day at midnight UTC. This automation ensures that a new story is generated and published daily. To configure this, this page explains how to set [scheduled triggers](https://cloud.google.com/run/docs/execute/jobs-on-schedule#command-line).
* **Firebase Hosting**: Firebase Hosting serves the static assets of the website (HTML, CSS, JavaScript) that displays the stories. Firebase also provides easy access to the Firestore database where the stories are stored, at the last stage of our agentic workflow.

## Further possible improvements

I'm not in the business of selling novels, so I won't really spend much more time improving this application. However, I noticed a few areas where this project could be improved.

### More creativity

When reading the short stories, you'll notice a certain lack of creativity. Somehow, the stories often happen around the years 2340, the action takes places on Xylos, and some characters appear very frequently, like Aris Thorne. Similarly, some words or concepts appear all the time, like the words _echoes_, _obsidian_, _crimson_, etc. Maybe the model has seen such novels, with such personas, locations, time period, in its training. I've seen online some people getting the [same kind of stories](https://www.semanticpen.com/tools/ai-generated-superhero-origin-story-generator/female-superhero-origin-story--e894532b-b775-4fc8-82d4-e0afcb31afad), and even a [book](https://www.amazon.com/Veins-Starlight-Forbidden-Astral-Weavers-ebook/dp/B0DPKY5C4R) with the same characters or location.

I think it'd be interesting to explore how to make the stories more diverse and varied. For example by adding more steps in the workflow to work on character creation, on different narrative arcs, on environment definitions. For science-ficiton only, there are tons of [types of sci-fi stories](https://www.rachelagreco.com/30-types-of-science-fiction-every-sci-fi-lover-should-know/). My friend, Philippe Charrière, worked on [how to generate random RPG character names with LLMs](https://k33g.hashnode.dev/how-to-generate-random-rpg-character-names-with-an-llm). He shared plenty of ideas on how to guide LLMs to get more creative with personas.

### Character definition for illustration consistency

Speaking of character creation, if you look at the illustrations, you'll see that the characters often don't have the same style or appearance. Indeed, I don't give Imagen the whole context of the story when I let Gemini create the image prompts. A possible area of improvement could be to work on proper character definitions (face characteristics, attire, etc.), and ensure that the information is passed through to Imagen. The same would apply for the setting, like the planet, the spaceship details, and more.

### Chapter legibility

Each story is split into 5 chapters, of about 20 sentences or so. I tried to make Gemini to generate paragraphs, to improve legibility. However, in spite of a bit of time spent on tweaking the prompts, I failed to coerce it to create paragraphs to delineate the key sections of the chapters. When prompting can't solve this, an extra LLM call loop can take the chapter's content and make it more readable.

## Conclusion

The key take away of this experimetnation, is that **when you can describe your AI agent's plan of action with an explicit and predictable workflow, you should definitely follow that route, and avoid giving the LLM the freedom to handle the planning alone**. LLM autonomous planning works much better in more unpredictable cases, where steps can't be foreseen. Be sure to use the right approach!

Again, Gemini and Imagen were up to the task for this new project and gave great stories and illustrations, even if the creativity could be improved. And I'll keep using [LangChain4j](https://docs.langchain4j.dev/) as my Swiss-army knife for all my Generative AI projects, as it works reliably, and offers rich capabilities.

Knowing that I would build a _workflow_, I also explored the use of my beloved [Google Cloud Workflows](https://cloud.google.com/workflows) which I've [written a lot about](https://glaforge.dev/tags/workflows/). I'll likely write another (shorter) article where I'll show how to create such GenAI workflows with it, stay tuned.

This project was also a good opportunity for me to use Cloud Run jobs. I love Cloud Run for all my serverless, auto-scaled, fully-managed, HTTP services, but I hadn't used a Cloud Run _job_ so far. For such _batch_ kind of tasks, this is the right tool for the _job_ (pun intended)! There's also [Google Cloud Batch](https://cloud.google.com/batch) but it's more for heavier computation kind of workloads.

So what's next? Checkout the website to [read a short story every day](https://short-ai-story.web.app/), and explore the [code base](https://github.com/glaforge/short-genai-stories) to better understand how stories are baked. If you want to replicate this application, and haven't yet tried Google Cloud, feel free to use the [$300 of credits for new users](https://cloud.google.com/free).
# Analyzing trends and topics from Bluesky's Firehose with generative AI


First article of the year, so let me start by wishing you all, my dear readers, a very happy new year!
And what is the subject of this new piece of content?
For a while, I've been interested in analyzing trends and topics in social media streams.
I recently joined Bluesky (you can follow me at [@glaforge.dev](https://bsky.app/profile/glaforge.dev)),
and contrarily to X, it's possible to access its Firehose
(the stream of all the messages sent by its users) pretty easily, and even for free.
So let's see what we can learn from the firehose!

Without further ado, here's the end goal!

![](/img/bluesky/bluesky-visualization.png)

## Bluesky's Firehose — a stream of social messages

The underlying protocol used by Bluesky is the [AT Protocol](https://atproto.com/).
There's an API to access Bluesky's streams via this protocol, but it's a bit cumbersome to use.
In order to reduce the quantity of data sent via the AT protocol over its "relay" network,
the Bluesky team introduced [JetStream](https://docs.bsky.app/blog/jetstream),
to relay all the messages as well, via WebSockets, in JSON format, for a fraction of the size of the AT protocol payloads.
You can also read about how they [shrinked the payloads by 99%](https://jazco.dev/2024/09/24/jetstream/)!

The [JetStream Github repository](https://github.com/bluesky-social/jetstream) shares the endpoints you can use to access the firehose,
and gives some details about the various types of payloads (new messages, likes, shares, etc.)
It also mentioned a nice little tool called [websocat](https://github.com/vi/websocat)
which is a command line tool to connect to WebSockets — very handy to analyze the payloads.

To better understand the JSON message formats, I used websocat, as well as Simon Willison's client-side
[online tool](https://simonwillison.net/2024/Nov/20/bluesky-websocket-firehose/)
to access the JetStream, and see the flows of messages.

## A bird's eye view of the project

Before diving into the code, and showing how to fetch the Bluesky posts,
I'd like to give you a high level overview of what we're going to implement.

![](/img/bluesky/bluesky-jetstream-trends.png)

> I used [Napkin.ai](https://www.napkin.ai/) to generate this diagram!
> Go check out this tool. You can paste your article, and for a given paragraph, it can suggest nice diagrams to represent them.

The key steps towards a topic visualization of the stream are:
1. **Data acquisition** — The first step is to subscribe to the firehose via WebSockets to gather enough data points to make it interesting to extract trends from them.
2. **Embedding messages** — In order to compare users' posts, the text of the posts should be transformed into vector embeddings via an embedding model, which represents posts into a multidimensional space in which distances can be calculated (text whose vector is closer to another one is usually semantically similar).
3. **Clustering messages** — Now that we have all the vector embeddings, a clustering algorithm is used to create groups of messages that are close to each other in vector space, and form a cluster of data points on the same topic.
4. **Generating a summary of clusters' messages** — The clustering algorithm grouped messages into different clusters. However, at that point, we don't know what all those grouped messages are about. That's where a generative AI model is called to make sense of those messages, to get a short description of them.
5. **Preparing the data for visualization** — Armed with the clusters of posts and their descriptions, the data for the visualization is prepared.
6. **Visualizing the trends** — The last step is to visualize those clusters of messages with a nice visualization. For that purpose, I decided to present the groups of messages as bubbles (the more posts in a bubble, bigger the bubble is).

## Let's get coding!

In the article, I'll show only key snippets, sometimes simplifying the code a little bit, but you'll be able to checkout all the code in this [Github repository](https://github.com/glaforge/bluesky-topic-analysis).

As usual, the code will be in Java, and I'm going to use my favorite Generative AI framework: [LangChain4j](https://docs.langchain4j.dev/).
For the large language model, my choice went for [Gemini](https://deepmind.google/technologies/gemini/),
and for the embedding model, I'm calculating vectors thanks to Google Cloud Vertex AI [embedding models](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings).
Clusters of messages will be created with the [Apache Commons Math](https://commons.apache.org/proper/commons-math/userguide/ml.html) library.
The visualization will be implemented in JavaScript with the [D3.js](https://d3js.org/) library.

### Acquiring Bluesky messages via WebSocket

Let's kick off the project by establishing a real-time connection to the Bluesky firehose using WebSockets, thanks to JDK 11's HTTP client.
This allows us to receive a constant stream of public posts as they happen.
The `liveMessages()` method manages the WebSocket connection and filters incoming messages based on language:

```java
httpClient.newWebSocketBuilder().buildAsync(
        URI.create(JETSTREAM_WS_ENDPOINT),
        new WebSocket.Listener() {
    @Override
    public CompletionStage<?> onText(WebSocket webSocket,
                                    CharSequence data,
                                    boolean last) {
        // ... process incoming message ...
    }
});
```

The `onText()` method within the `WebSocket.Listener` is our gateway to the firehose.
Each incoming message, received as a JSON string, needs to be parsed into a usable Java object.
Here's where Google's `Gson` library and Java `record`s come into play.
We've defined a set of nested Java records that mirror the Bluesky message structure:

```java
record Message(Commit commit, String did) {
  record Commit(Record record, String cid) {
    record Record(String text, List<String> langs, Date createdAt) {}
  }
}
```

These records give us a strongly typed way to access message data.
The Message record holds the actual post content (`text`), a list of languages (`langs`),
and the creation timestamp (`createdAt`), nested within `Commit` and `Record` records.
We use Gson to deserialize the JSON strings into these records:

```java
Message message = GSON.fromJson(String.valueOf(text), Message.class);
```

### Calculating vector embeddings for all the messages

To analyze the semantic similarity between posts, we convert each post's text into a numerical vector representation, or embedding.
This is achieved using a Vertex AI embedding model, via LangChain4j's [Vertex AI module](https://docs.langchain4j.dev/integrations/embedding-models/google-vertex-ai/):

```java
EmbeddingModel embeddingModel = VertexAiEmbeddingModel.builder()
    .project(System.getenv("GCP_PROJECT_ID"))
    .location(System.getenv("GCP_LOCATION"))
    .endpoint(System.getenv("GCP_VERTEXAI_ENDPOINT"))
    .modelName("text-embedding-005")
    .publisher("google")
    .build();
```

We're using `text-embedding-005` which is a good embedding model and understands multiple spoken languages
(which is important for analyzing posts coming from a hundred different spoken languages or so).

As embedding all messages takes a while, we're batching the calculation in parallel:

```java
List<TextSegment> allSegments = allMessages.stream()
    .map(message -> TextSegment.from(message.commit().record().text()))
    .toList();

List<Embedding> allEmbeddings =
    IntStream.range(0, numberOfParallelBatches)
        .parallel()
        .mapToObj(i -> embeddingModel.embedAll(allSegments...)
        .flatMap(List::stream)
        .toList();
```

### Creating clusters of posts

With embeddings in hand, we can now group similar posts together using the [DBSCAN](https://en.wikipedia.org/wiki/DBSCAN)
clustering algorithm (Density-based spatial clustering of applications with noise) :

```java
var clusters = new DBSCANClusterer<ClusterableEmbeddedMessage>(
        MAXIMUM_NEIGHBORHOOD_RADIUS, MINIMUM_POINTS_PER_CLUSTER)
    .cluster(clusterableEmbeddedMessages);
```

For 10k posts, using a minimum of 10 points per cluster sounds about right.
As a rule of thumb, I got good visualizations with one cluster point per 1k messages
(ie. 10 points per cluser for 10k messages, 20 points per cluster for 20k messages).

The maximum neighborhood radius at 0.5 also looked like a good value.
I tried smaller and bigger values, but either the cluster are too specific and narrow with low values,
or too broad and generalist with higher values.

It's important to check for yourself the _hyperparameters_ of the algorithms you chose for your use case.
Some values might be better than others, and they are very much use-case dependant.
There's no magic numbers, you have to experiment to find the right mix for you!

Using a different embedding model (like `text-multilingual-embedding-002`), reducing the dimensionality to 128 dimensions,
I had to use a max neighborhood radius of 0.2 instead, to get a good number of clusters.

### Generating a description for clusters of messages

At this point, we have topic clusters. But they're just bags of numbers without a real meaning for us, human beings.
What we need is a way to make sense of those clusters, to know what topic they cover.

We configure the Vertex AI Gemini model, thanks to LangChain4j's [Gemini module](https://docs.langchain4j.dev/integrations/language-models/google-vertex-ai-gemini), with a max number of tokens, to avoid situations where a topic description is too long:

```java
ChatLanguageModel chatModel = VertexAiGeminiChatModel.builder()
    .project(System.getenv("GCP_PROJECT_ID"))
    .location(System.getenv("GCP_LOCATION"))
//  .modelName("gemini-2.0-flash-exp")
    .modelName("gemini-1.5-flash-002")
    .maxOutputTokens(25)
    .build();
```

You can use both the latest Gemini 1.5 Flash, or the new 2.0 Flash experimental model.
If you're hitting quota limits, as 2.0 is currently only in preview, 1.5 will give great results too.

To make the clusters more understandable, we call Gemini to generate a concise summary for each cluster,
passing all the messages contained in that cluster:

```java
Response<AiMessage> modelResponse = chatModel.generate(
    SystemMessage.from("""
        Summarize the following list of social media messages in one
        simple description. Don't give a full sentence saying the
        social messages are about a topic, just give the topic
        directly in 10 words or less, without mentioning the
        messages are social media posts or reactions.
        """),
    UserMessage.from(appendedMessages)
);
```

When I was running this code on January 1st, I was seeing topics like `New Year's greetings and well wishes` or
`Happy New Year 2025 wishes and hopeful sentiments for the year`.
But some categories of topics often come back, like a big cluster of emojis expressing various expressions,
or people sharing video links on YouTube, or pictures from Instagram.
I also saw some interesting trends as they came up, like weather alerts for snow storms,
or someone famous receiving congratulations for announcing some anniversary.
There are also repeated posts tagging people to request funding for some cause.
Funnily, in the morning, I was often seeing people sharing in how many steps
they solved the [Wordle](https://www.nytimes.com/games/wordle/index.html) word puzzle!

I filtered the messages to analyze only English messages for the purpose of this demo,
but there are a bunch of users setting their language as English, but posting in another language.
However it's not really a problem for Gemini which happily handles more than a hundred spoken languages.

### Preparing the data for visualization

The cluster summaries and their sizes (number of posts) are then formatted as JSON data, for ingestion by D3.js:

```javascript
const data = {
  name: "Bluesky topic clusters",
  children: [
    {name: "Summary of Cluster 1", value: 396},
    // ... other clusters
  ]
};
```

This JSON structure is ideal for consumption by D3.js, which we'll use for visualization.
The `FirehoseConsumer` class writes this JSON data to the `newdata.js` file,
which is integrated in the static web assets and loaded by D3.

### Visualizing the data with D3.js

Finally, the `visualisation.js` script uses D3.js to create an interactive bubble chart.
Each bubble represents a cluster, with its surface area corresponding to the number of posts in that cluster.
The color of the circles is also dynamically generated:

```java
const colorScale = d3.scaleQuantize()
    .domain([0, maxValue])
    .range(colorPalette);
    //.. later, in the circle
    .attr("fill",
          d => d.children == null ? colorScale(d.r) : "#fefef0")
```

What's more interesting in this part of the project is how the visualization is created.
I was inspired by the circle packing visualization seen in this [article](https://observablehq.com/@d3/pack/2),
which uses D3.js's [circle packing layout method](https://d3js.org/d3-hierarchy/pack).
I borrowed heavily from this example, and tweaked it for my needs, and to my liking.

```java
const pack = d3.pack()
    .size([width - margin * 2, height - margin * 2])
    .padding(4);

const root = pack(d3.hierarchy(data)
    .sum(d => d.value)
    .sort((a, b) => b.value - a.value));
```

The tricky part, as well, was how to render and layout the text of the topics, along with the number of posts per cluster, inside each circle.
I got it working by appending a custom div, as a _foreign object_ in the SVG document, and by tweaking the positioning:

```javascript
node.filter(d => !d.children)
    .append("foreignObject")
    .attr("x", d => -0.8 * d.r) // center horizontally
    .attr("y", d => -1.1*d.r) // center vertically, manually adjusted
    .attr("width", d => 1.6 * d.r)
    .attr("height", d => 2 * d.r)
    .append("xhtml:div")
    .classed("foreignDiv", true)
    .style("font-size", d => d.r / 5.3 + "px") // dynamic font sizing
    .html(d =>
        "<span style='font-size: " + (d.r / 2.5) + "px; color: "
        + d3.color(colorScale(d.r)).darker(1) + ";'>"
        + format(d.value)
        + "</span>"
        + d.data.name
        + "<br/>"
    );
```

Lots of hard-coded values to make it look nice!

To put everything together: an HTML file imports D3.js, our `newdata.js` file containing the cluster definitions,
the `visualization.js` file creates the bubble chart, plus some CSS in `styles.css`.
And when running the Java class, the `newdata.js` is generated and updated in the `static` web asset folder.

## Experiments, and what else to explore

### No live demo available

Interesting topic visualizations happen when you have collected enough messages to analyze.
Gathering about 10 thousand posts seemed to offer good results, but in spite of the 10+ million users on Bluesky,
you still need about 4 or 5 minutes to store that many messages.
Without mentioning the time it takes to calculate the embeddings (about 30 seconds in parallel),
and the clustering algorithm (about 1 minute and a half with a runtime complexity of `n*log(n)`).
So this is not ideal for a _real-time_ analysis of the current trending topics.
That's why I haven't posted a demo application online, as it's too slow to wait for the result to appear on screen.

What might be interesting to explore is somehow a live updating view that would be re-calculated every couple of minutes or so,
over a sliding window of messages, but the clustering duration is still a problem.
However, it's also something that could quickly become costly, considering the number of embedding calculations and generative summaries to generate each time.

### Different embedding models

Before parallelizing / batching the vector embedding calculations (which still take half a minute),
I also tried a non-cloud hosted embedding model, like a quantized version of the
[all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) embedding model, which can run locally without a big GPU.
I used it in some other projects with success, but for this clustering exercise, I found the result of poor quality, as if it wasn't knowledgeable enough to discern different topics.

I paid attention to restricting the messages to only English messages, as I knew that that small model was more at ease with English, but that didn't really help.
Ideally, I'd like to find a fast embedding model with good classification capabilities.
But read on, for another idea on speeding up the clustering part of the equation.

### Different clustering algorithms

DBSCAN isn't super fast, with a `n*log(n)` runtime complexity.

Apache Commons Math also offers a [KMeans++](https://en.wikipedia.org/wiki/K-means%2B%2B) implementation that is faster (with a more linear runtime)
but the `k` hyperparameter to specify is always giving a fixed number of clusters.
One one hand, it's nice to have a more predictable visualization (neither too few, nor too many bubbles with small text to display),
on the other hand, the fact the number of clusters si set in stone, leads the clusters to be too generic and too broad,
and there's always one cluster that contains everything that couldn't be clustered in meaningful groups.

In spite of its runtime complexity, I like DBSCAN for the fact it creates quite diverse but acurate clusters,
as it figures itself how many clusters to create, depending on the various topics it'll come across.

There's another library that I'd like to try some day, that's [Smile](https://haifengl.github.io/clustering.html).
It supports even more clustering algorithms than Apache Commons Math.

Something interesting going on for Smile is also its [dimensionality reduction algorithms](https://haifengl.github.io/manifold.html#t-sne)
(that they call _manifold learning_) like [t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) and
[UMAP](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction#Uniform_manifold_approximation_and_projection).

Why am I mentioning dimensionality reduction?
For one, it's super handy for visualizing the clusters in 2D or 3D.
But another idea I wanted to try was that if the reduction is fast enough,
maybe applying the clustering algorithm on lower-dimensioned data would be much faster.
The _projection_ (reducing the dimensionality) before clustering approach is also the one this [project from HuggingFace](https://github.com/huggingface/text-clustering)
followed to cluster the [Cosmopedia](https://huggingface.co/datasets/HuggingFaceTB/cosmopedia) dataset.

Indeed, Vertex AI embeddings generate vectors of 768 dimensions.
That said, some of the Vertex AI embeddings are [_Matryoshka_ embeddings](https://huggingface.co/blog/matryoshka),
so we could also calculate clusters on truncated vectors, without losing too much accuracy, without even doing dimenstionality reduction!
Both `text-embedding-005` and `text-multilingual-embedding-002` support reducing the vector dimension, so it's worth trying.
You just need to set `outputDimensionality(128)` on the embedding model builder to reduce the dimensions down to 128.
Then the clustering time can be go down to 15 seconds instead of 80 seconds like with full 768-dimension vectors.

### What else to try?

* In this experiment, I analyzed text, but users post hashtags, pictures, links, on their profiles.
It might be interesting to look at what is trending in terms of hashtags, or analyze the sentiment of messages related to such a hashtag.
* Looking at links, maybe it'd be interesting to also see what is shared, which news article is more popular...
* Regarding pictures, we could perhaps see which animals are more trendy? And do some fun analysis of favorite animals in different countries...
* Another interesting analysis could be to cluster user profiles, to find users posting on the same topics.
* I'd like to think more about how to make this application more lively, and make users explore indvidual posts contained in each clusters.

Many more things to try out and explore!

## Summary

The generated visualization offers an intuitive and engaging way to explore the **trending topics on Bluesky**.
And **generative AI** tools like **Gemini** and **Vertex AI** are here to help creating such data explorations.

This project combines the power of **real-time data streaming**, **AI-driven analysis**, and (not-yet-interactive) **visualization** to provide a valuable tool for understanding the ever-evolving conversations on Bluesky.
It sets the stage for more sophisticated analysis, such as tracking topic evolution over time, sentiment analysis within clusters, and identification of key influencers within specific discussions.

As always, this project also confirmed that **Java** and **[LangChain4j](https://docs.langchain4j.dev/)** are my two best buddies to explore topics with generative AI approaches (no need for Python!)
And I was happy to use [D3.js](https://d3js.org/) again for visualization purposes.
It's not easy to master, but it's a super powerful library!
I'm also glad that [Gemini Code Assist](https://cloud.google.com/products/gemini/code-assist?e=0&hl=en) helped me work with D3.js, to develop and enhance the visualization.

Finally, of course, the **Gemini chat model** and **Vertex AI embedding model** were perfect for the task, giving high quality embedding vectors, and clear synthetic summaries of social media posts.

Don't hesitate to [check out the code](https://github.com/glaforge/bluesky-topic-analysis) and play with this project!

# Let's think with Gemini Flash 2.0's experimental thinking mode and LangChain4j


Yesterday, Google released yet another cool Gemini model update, with **Gemini 2.0 Flash [thinking mode](https://ai.google.dev/gemini-api/docs/thinking-mode)**.
Integrating natively and transparently some [chain of thought](https://www.promptingguide.ai/techniques/cot) techniques,
the model is able to take some more thinking time, and automatically decomposes a complex task into smaller steps, and explores various paths in its thinking process.
Thanks to this approach, Gemini 2.0 Flash is able to solve more complex problems than Gemini 1.5 Pro or the recent Gemini 2.0 Flash experiment.

**And of course, you can already use Gemini 2.0 Flash Thinking with [LangChain4j](https://docs.langchain4j.dev/)!**

So let's _delve_ into some examples together!

## Solving a riddle

I found some [riddles online](https://parade.com/947956/parade/riddles/) and thought I would try one with both the new Gemini 2.0 Flash model,
and the new thinking flavor as well, in order to contrast their way of working, and the outcome.

```java
var model = GoogleAiGeminiChatModel.builder()
        .apiKey(System.getenv("GOOGLE_AI_GEMINI_API_KEY"))
        .modelName("gemini-2.0-flash-exp")
        .build();

String response = model.generate("""
        The day before yesterday I was 21, and next year I will be 24.
        When is my birthday?
        """);
```

Gemini replies with:

```
This is a classic riddle! Here's how to solve it:

* **"The day before yesterday I was 21"** means yesterday you were 22.
* **"Next year I will be 24"** means you are currently 23.
* If you were 22 yesterday and 23 today, your birthday must be **today**.

Therefore, your birthday is **today**.
```

The answer is good, it's today, but it doesn't really tell exactly which date is the birthday.

Now let's update the model name to use the new thinking mode:

```java
var model = GoogleAiGeminiChatModel.builder()
        .apiKey(System.getenv("GOOGLE_AI_GEMINI_API_KEY"))
        .modelName("gemini-2.0-flash-thinking-exp-1219")
        .build();

String response = model.generate("""
        The day before yesterday I was 21, and next year I will be 24.
        When is my birthday?
        """);
```

Gemini advanced thinking process shows up:

```
Here's a thinking process to solve this riddle:

1. **Analyze the core statements:**
    * "The day before yesterday I was 21."
    * "Next year I will be 24."

2. **Break down the time references:**
Identify the different points in time being referenced.
    * "The day before yesterday" refers to a past date.
    * "Yesterday" refers to the day after "the day before yesterday".
    * "Today" is the present day.
    * "Tomorrow" is the day after today.
    * "Next year" refers to the year after the current year.

3. **Assign ages to the time references:**  Based on the statements,
assign ages to the person at these different time points.
    * The day before yesterday: 21 years old.
    * Yesterday: Since the person's age changes by one each birthday,
     yesterday they were either still 21 or had just turned 22.
    * Today: Continuing the progression, today they are either 22
      or 23.
    * Next year: 24 years old.

4. **Focus on the age jump:**  The key is the jump in age from
"today" to "next year." To go from being 22 or 23 today to being 24
next year *definitively* means their birthday must fall *between*
now and next year.

5. **Work backward from "next year":** If they will be 24 next year,
they must turn 24 sometime within that year. This means they are
currently 23 *or* they are still 23 and about to turn 24 soon.

6. **Work forward from "the day before yesterday":**
If they were 21 the day before yesterday, then yesterday they
turned 22. This means today they are 22.

7. **Reconcile the information:** We have two possibilities for the
current age: 22 (from the first statement) and potentially 23
(considering the jump to 24 next year). The only way both statements
can be true is if the birthday is *very* soon.

8. **Consider the implications of the age progression:**
    * If today they are 22, and next year they will be 24,
      the birthday must be *before* the end of the current year.
    * Since they were 21 the day before yesterday, they must have
      turned 22 *yesterday*.

9. **Determine the date:**  If they turned 22 yesterday,
and the statement refers to "next year I will be 24," this can only
happen if today is the *last day* of the year, and their birthday
is *today*.

10. **Verify the solution:** Let's check if this works:
    * If today is December 31st:
        * The day before yesterday (December 29th) they were 21.
        * Yesterday (December 30th) they turned 22.
        * Today (December 31st) they are 22.
        * Next year (after December 31st),
          they will turn 23 and then 24. This works!

11. **Formalize the answer:** The birthday is on December 31st.

This is a classic riddle that plays on how we perceive time.
Here's how to solve it:

* **"The day before yesterday I was 21"**:
  This means yesterday you were 22.
* **"Next year I will be 24"**: This means you are currently 23.

For both of these statements to be true,
today must be **January 1st**.

Let's break it down:

* **January 1st:** You are 23.
* **December 31st (yesterday):** You were 22.
* **December 30th (the day before yesterday):** You were 21.
* **Sometime later this year (your birthday):** You will turn 24.

Therefore, your birthday is on **December 31st**.
```

Now, thanks to this advanced reasoning approach, it's able to tell me the exact date of the birthday.

I've also tried the model's reasoning capabilities on coding problems (puzzles like Advent of Code ones),
and it's really doing a great job at solving most of them!

## Multimodal reasoning

Remember that Gemini is a **multimodal** model?
That means it can accept other _modalities_ like images, in addition to text.

So let's have a look at another example, with a word game from the
[Reader's digest](https://www.rd.com/article/visual-brain-teasers-and-puzzles/).
Only one of the rows is an anagram of a five-letter English word...

![](/img/gemini/word-puzzle.jpg)

This time, it's a word game, but the information is inside an image.
So we need to pass both the image, and the problem statement.

```java
var model = GoogleAiGeminiChatModel.builder()
        .apiKey(System.getenv("GOOGLE_AI_GEMINI_API_KEY"))
        .modelName("gemini-2.0-flash-thinking-exp-1219")
        .build();

Response<AiMessage> response = model.generate(UserMessage.from(
        ImageContent.from(
            new String(Base64.getEncoder().encode(readBytes(FILE_URI))),
            "image/png"),
        TextContent.from("""
            Only one of the rows in the picture is an anagram of a
            five-letter English word. Do you know which one it is?
            """)
));
```

If I ask that puzzle to Gemini 2.0 Flash (by changing the model name used above), it'll tell me (quickly) that:

```
Certainly!
The anagram in the image is **O L C R E**,
which unscrambled is **COLOR**.
```

Gemini 2.0 Flash is at the very top of the LLM [leaderboard](https://lmarena.ai/?leaderboard)
but it gets the answer wrong. Notice that `COLOR` is not an anagram of `OLCRE` at all.

Now let's see what the _thinking_ model says:

```
The user wants me to find the row that is an anagram of a five-letter
English word. I need to go through each row and see if I can
rearrange the letters to form a valid five-letter word.

Row 1: L E G T N - Could be GENTL but need 5 letters. Could be GLENT,
but is not a common word.
Row 2: O L C R E - Could be CLORE, COLER, RECOL. RECOL is the most
promising one.
Row 3: T C O H E - Could be ECHOT.
Row 4: L U D I B - Could be BUILD.
Row 5: M E U D Q - No obvious combination.
Row 6: H I N W L - Could be WHILN.
Row 7: W E S O L - Could be LOWES, OWELS, SOWEL, WOLES.

From the analysis, RECOL seems to be a valid word and has 5 letters.
Let me double check other possibilities.
Row 1: L E G T N -  TENGLE? No.
Row 3: T C O H E -  Could be CHETO, but not a common word.
Row 4: L U D I B -  Could be BLUID, but not a common word.
Row 6: H I N W L -  Could be WHILE.

Out of the possible options, WHILE and RECOL are valid five-letter
words. Let me re-examine the instruction "Only one of the rows in
the picture is an anagram of a five-letter English word."

Row 1: L E G T N - No obvious five-letter word.
Row 2: O L C R E - CLORE, COLER, RECOL
Row 3: T C O H E - ECHOT
Row 4: L U D I B - BUILD
Row 5: M E U D Q - No obvious five-letter word.
Row 6: H I N W L - WHILE
Row 7: W E S O L - LOWES, OWELS, SOWEL, WOLES

There seems to be more than one. Let me re-check the letter counts.
 All rows have 5 letters.

Rechecking my anagram findings:
Row 2: O L C R E -  Could form RECOL
Row 3: T C O H E - Could form ECHOT
Row 4: L U D I B - Could form BUILD
Row 6: H I N W L - Could form WHILE
Row 7: W E S O L - Could form LOWES

Let me think again. The instruction says *only one*. I might be making
a mistake in identifying a valid word.

Re-examining:
Row 1: L E G T N - No common five-letter word.
Row 2: O L C R E - RECOL
Row 3: T C O H E - ECHOT
Row 4: L U D I B - BUILD
Row 5: M E U D Q - No common five-letter word.
Row 6: H I N W L - WHILE
Row 7: W E S O L - LOWES

Perhaps some of these are not valid English words.
Let me verify the words.
RECOL -  Yes, it's a valid word.
ECHOT - No, ECHO is a word, ECHOT is not.
BUILD - Yes, it's a valid word.
WHILE - Yes, it's a valid word.
LOWES - Yes, it's a valid word.

I am still finding more than one valid word. Let me go through each
row very carefully again.

Row 1: L E G T N - No obvious 5-letter word
Row 2: O L C R E - Could be CLORE, COLER, RECOL.
Row 3: T C O H E - Could be CHOTE. No such word.
Row 4: L U D I B - Could be BUILD.
Row 5: M E U D Q - No obvious 5-letter word.
Row 6: H I N W L - Could be WHILE.
Row 7: W E S O L - Could be LOWES.

Let me verify the validity of each potential word.
RECOL - Valid English word.
BUILD - Valid English word.
WHILE - Valid English word.
LOWES - Valid English word (name of a store).

I am still struggling to find only one. Perhaps I am overlooking
something simple. Let me reread the question carefully.
"Only one of the rows in the picture is an anagram of a five-letter
English word."

Let me try rearranging the letters systematically for each row.

Row 1: L E G T N -  No five letter word.
Row 2: O L C R E -  RECOL
Row 3: T C O H E - No five letter word.
Row 4: L U D I B -  BUILD
Row 5: M E U D Q - No five letter word.
Row 6: H I N W L -  WHILE
Row 7: W E S O L -  LOWES

I am still identifying multiple valid words. Could there be a
constraint I am missing? The hints are just crops, so they don't
add new information.

Let me consider uncommon words.

Row 2: O L C R E -  Could be ORCEL.
Row 3: T C O H E -
Row 7: W E S O L - Could be OLWES.

I am still finding multiple possibilities. The question states
*only one*. This implies that my initial assessment of multiple
possibilities is incorrect. Let me re-examine each row with more
scrutiny for common five-letter words.

Row 1: L E G T N - No.
Row 2: O L C R E - RECOL.
Row 3: T C O H E - No.
Row 4: L U D I B - BUILD.
Row 5: M E U D Q - No.
Row 6: H I N W L - WHILE.
Row 7: W E S O L - LOWES.

I have identified four potential candidates. There must be something
I am not considering. Is there a specific type of five-letter word?
No constraint mentioned.

Let me check my understanding of anagram. An anagram is a
rearrangement of letters to form a new word.

Perhaps some of the words I identified are not standard English words.

RECOL - Yes, it is.
BUILD - Yes, it is.
WHILE - Yes, it is.
LOWES - Yes, it is.

I am still at a loss. The instruction is very clear: "Only one of the
rows... is an anagram of a five-letter English word."

Let me try a different approach. Assume only one is correct
and try to disprove the others.

If Row 2 (O L C R E - RECOL) is the answer, then none of the others
should form a valid five-letter word.
Row 4 (L U D I B) - BUILD is a valid word. This contradicts the
"only one" rule.

If Row 4 (L U D I B - BUILD) is the answer, then none of the others
should form a valid five-letter word.
Row 2 (O L C R E) - RECOL is a valid word. This contradicts the
"only one" rule.

If Row 6 (H I N W L - WHILE) is the answer, then none of the others
should form a valid five-letter word.
Row 2 (O L C R E) - RECOL is a valid word. This contradicts the
"only one" rule.

If Row 7 (W E S O L - LOWES) is the answer, then none of the others
should form a valid five-letter word.
Row 2 (O L C R E) - RECOL is a valid word. This contradicts the
"only one" rule.

There must be something very obvious I am missing.

Let me read the rows aloud and see if something jumps out.
L E G T N
O L C R E
T C O H E
L U D I B
M E U D Q
H I N W L
W E S O L

Is it possible that some of the letter combinations seem like a word
but aren't actually?

Let's focus on making sure each identified word is definitively
correct.

RECOL - Define: To collect again. Yes, it's a valid word.
BUILD - Define: To construct. Yes, it's a valid word.
WHILE - Define: A period of time. Yes, it's a valid word.
LOWES -  While primarily known as a store name, it can be
a plural noun.
However, the question is about anagrams of five-letter words.

Let's go back to each row and try to form words methodically.

Row 1: L E G T N -  Tingle, Longe, Glent. None are common five-letter
words.
Row 2: O L C R E -  Clore, Coler, Lorec, Recol. RECOL is a valid word.
Row 3: T C O H E -  Chote, Cothe, EchoT. None are common five-letter
words.
Row 4: L U D I B -  Bluid, Build. BUILD is a valid word.
Row 5: M E U D Q - No valid word.
Row 6: H I N W L -  Whiln, While. WHILE is a valid word.
Row 7: W E S O L -  Lowes, Owels, Sowle, Woles. LOWES is a valid word.

The problem states *only one*. This is the key.
There must be something about one of these words that makes it
the correct answer over the others.

Could it be about the commonality of the word?  While all are valid,
some are more frequently used.

RECOL - Less common.
BUILD - Very common.
WHILE - Very common.
LOWES - Common (as a store name).

Could there be a nuance in the definition or usage?

Let me consider if the capitalization or the "RD" at the bottom has
any relevance (unlikely for an anagram puzzle).

The crops are there to help see better, so the visual aspect
is important.

Let me look at the letters themselves and see if there's a pattern
or something I've missed.

Maybe one of the identified words isn't as standard as the others
in a pure linguistic sense.

Consider "LOWES". It's primarily a proper noun. Is the puzzle looking
for common nouns or verbs?  The question says "a five-letter English
word," which is quite broad.

Let me revisit the less common words I dismissed earlier.

Row 1: L E G T N - GLENT (a small secluded valley).
Row 3: T C O H E -  None.
Row 6: H I N W L -  WHILN (the pod or husk of seeds).

If GLENT is considered, we have another possibility.
If WHILN is considered, another possibility.

The constraint "only one" is crucial.

Let's assume, for a moment, that the answer is indeed one of the ones
I identified and I need to find a reason to exclude the others.

Could the structure of the letter arrangement provide a clue?
No obvious pattern.

Let me focus on the most common five-letter words from my list:
BUILD and WHILE. If one of these is the answer, why isn't the other?

Perhaps there's a very simple word I'm overlooking in one of the rows.

Row 3: T C O H E -  THROE.

THROE is a valid five-letter word.

Now my list is: RECOL, BUILD, WHILE, LOWES, THROE.
Still more than one.

I am stuck on the "only one" constraint. What could make one row
uniquely solvable?

Could it be about pronunciation or homophones?
Unlikely for an anagram.

Let me go back to the instructions and the image.
There are no additional instructions.

Is it possible there's a very obscure five-letter English word?

Let's review each row and try all possible combinations.
This will be tedious, but the "only one" constraint suggests
a unique solution.

Row 1: L E G T N -  ELTNG, ELNTG, ETLNG, ETNLG, ENLTG, ENTLG...
This is not efficient.

Let me rely on my vocabulary for common words first.

Consider the possibility that one of the words I identified isn't
a standard English word in the context of this puzzle.

Could "LOWES" as a store name not count? But the letters
can form the word.

Let's try working backward from the assumption that only one row
is correct. If I pick a row, can I definitively say the others
don't form any five-letter words?

If Row 2 (O L C R E) is the answer (RECOL), then the others cannot
form a valid five-letter word. But Row 4 (BUILD), Row 6 (WHILE),
and Row 7 (LOWES) do.

There must be a constraint I am not understanding
or a word I am misinterpreting.

Could it be about the frequency of letter usage in the
English language? Unlikely.

Let me consider common knowledge or general vocabulary.

Perhaps one of the letter sets can *only* form one five-letter word,
while others can form multiple.

Row 2: O L C R E - RECOL, CLORE, COLER.
Row 4: L U D I B - BUILD. Only one common word.
Row 6: H I N W L - WHILE. Only one common word.
Row 7: W E S O L - LOWES, OWELS, SOWLE, WOLES.

This is a potential lead. Row 4 and Row 6 seem to have a single,
very common five-letter word.

Let me double-check Row 4 (L U D I B). Are there other common
five-letter words?  BLUID is not common.

Let me double-check Row 6 (H I N W L). Are there other common
five-letter words? WHILN is less common.

The wording "anagram of a five-letter English word" is precise.

Could it be that some of the words I found are plurals or other forms
that don't fit the strict definition?  No, RECOL, BUILD, WHILE
are base forms.

Let me consider the visual arrangement again.
Is there any hidden message or pattern?  The lines separate the rows.

The "RD" in the corner is likely just a watermark.

The color is uniform.

Back to the anagrams. The "only one" is the key.

If I had to pick one, which row is *unambiguously*
a single five-letter English word?

Row 4: L U D I B - BUILD. It's hard to make another common
five-letter word from these letters.

Let's confirm this. Consider permutations.
BLUID is the only other plausible one, and it's not common.

Could the answer be BUILD based on this uniqueness?

Let me test this hypothesis against the other rows.

Row 2: O L C R E - RECOL, CLORE, COLER. Multiple options.
Row 6: H I N W L - WHILE. WHILN is another possibility,
though less common.
Row 7: W E S O L - LOWES, OWELS, etc. Multiple options.

This line of reasoning seems promising.
The "only one" could refer to the row that forms *only one*
common five-letter English word.

If this is the case, Row 4 (L U D I B - BUILD)
fits this criterion best.


Solution: The row that is an anagram of a five-letter English word
is **LUDIB**, which can be rearranged to form the word **BUILD**.

While some other rows can form five-letter words (such as RECOL
from OLCRE, WHILE from HINWL, and LOWES from WESOL), the question
states that "only one of the rows... is an anagram of a five-letter
English word."  Considering the commonality and unambiguous nature
of the resulting word, "BUILD" from "LUDIB" stands out as the most
likely single correct answer. Other rows could potentially form
multiple valid five-letter words, making "LUDIB" unique in its most
obvious and common anagram.
```

That's a pretty long answer, but it's correct!

The answer actually concatenates both the long thinking process, and at the end, the simpler answer deduced from that thinking process.
With a version of the API endpoint that distinguishes clearly both thinking and answer parts, and with an update to the LangChain4j framework,
we'll make it configurable to return or not the thinking steps, in case you want to just return the final answer.

## Thinking about it...

This is very interesting to see the thinking process the model follows when reasoning about the problem.
Compared to some competing model which hides its thoughts, Gemini shares everything it went through.
And it does it faster!

You would likely not use a reasoning model for each and every question you could ask an LLM, obviously.
However, for solving advanced problems that require a deeper thought process, this is definitely the way to go!

And of course, I'm happy that [LangChain4j](https://docs.langchain4j.dev/) lets me play with this new model out of the box!
If you don't feel like coding right away in Java, you can also play with the model in [Google AI Studio](https://aistudio.google.com/app/prompts/new_chat).

# Detecting objects with Gemini 2.0 and LangChain4j


Hot on the heels of the [announcement of Gemini 2.0](https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/),
I played with the new experimental model both from within [Google AI Studio](https://aistudio.google.com/app/prompts/new_chat),
and with [LangChain4j](https://docs.langchain4j.dev/).

Google released Gemini 2.0 Flash, with new modalities, including interleaving images, audio, text, video, both in input and output.
Even a live bidirectional speech-to-speech mode, which is really exciting!

When experimenting with AI Studio, what attracted my attention was AI Studio's new [starter apps](https://aistudio.google.com/starter-apps) section.
There are 3 examples (including links to Github projects showing how they were implemented):

- **spatial understanding** — get Gemini to recognize objects in pictures, and give you bounding boxes for those objects
- **video analyzer** — to summarize, describe scenes, extract texts and objects from videos
- **map explorer** — an integration with Google Maps to explore the world

The first one, on detecting objects, reminded me of an old demo of mine I had developed with Gemini 1.0 Pro Vision to recognise the cards of the Skyjo card game
(a fun little card game I've been playing a lot with my youngest daughter):

![](/img/gemini/skyjo-ai-studio.png)

If you look at the screenshot above, you'll see some prompt suggestions to get bounding boxes around detected objects.
You'll notice that the model seems pretty capable at recnogising the numbers on those cards.
And with some bits of prompt engineering, it ignores cards facing down (attribute a value of 0 for those cards).
In the end, you can sum up all the points, and have the current score for your cards.

Back in the day, Gemini 1.0 was making quite a few mistakes when detecting and recognising the values of the cards,
in particular when the cards were tilted, or upside down.
But Gemini 2.0 Flash has greatly improved, and is much more capable.

So I decided to see:

- if LangChain4j works well with Gemini 2.0 Flash,
- and if I can craft a prompt that detects my cards flawlessly.

And I'm glad to report that for all the photos I had taken of my games (14 pictures), I managed to score a 100% score of recognition.
Of course, LangChain4j is happy to call Gemini 2 without a problem (although we'll have to update the framework with the new modalities when a Java SDK is made available)

## Let's code!

I'll skip some of the boilerplate code to iterate over all my test pictures, properly labeled with the card values.
But you can have a look at this [gist](https://gist.github.com/glaforge/d6e845c673a5441823efc800d2d6bbf6) with all the code.

First, let's create some Java `record`s to represent the cards, their bounding box, and number labels:

```java
record Card(
    int label,
    BoundingBox boundingBox
) {
    record BoundingBox(int x1, int y1, int x2, int y2) {}
}
```

We'll use GSON for marshalling/unmarshalling those card details.

```java
var model = VertexAiGeminiChatModel.builder()
    .project(System.getenv("PROJECT_ID"))
    .location(System.getenv("LOCATION"))
    .modelName("gemini-2.0-flash-exp")
    .responseMimeType("application/json")
    .responseSchema(SchemaHelper.fromClass(Card[].class))
    .temperature(0.1f)
    .build();
```

Notice that we're using the new model: `gemini-2.0-flash-exp` (it's labeled _experimental_ for now).
And also pay attention to the response MIME type, which is JSON, and the fact we're defining a response schema:
We instruct Gemini to return a valid JSON object whose schema corresponds to the `record`s we've just defined.

Next, let's load all the cards pictures and details (our sample dataset):

```java
var cardsExamples = processImageFiles
        Path.of("skyjo-counter/samples"));
```

Now we can iterate over all the cards, to check that Gemini 2 recognises all of them:

```java
for (CardsExample example : cardsExamples) {
    System.out.println("File: " + example.imageFile());
    // ...
}
```

Let's look at the convoluted prompt I came up with to ensure to recognise all my sample pictures:

```java
Response<AiMessage> response =
  model.generate(
    SystemMessage.from("""
      Detect playing cards with numbers, with no more than 12 items.
      Output a JSON list of cards, where each entry contains the 2D
      bounding box in `boundingBox` and the `label` is the big number
      displayed in the center of the card.
      If you see the text "SKYJO" on the card, use 0 as the label
      in `label`.
      Ignore the small numbers in the corners of the cards.
      Ignore cards with text written on them.
      Be careful when reading the numbers, as sometimes some cards
      are tilted, cut, or upside down.
      """),
  UserMessage.from(
    ImageContent.from(example.imageFile().toUri()),
      TextContent.from("""
        Detect the cards of this image.
        """)
  ));
```

We give Gemini some system instructions to pay attention to the (maximum 12) cards numbers,
to return bounding boxes around the detected cards, and to give the big number at the center of the cards as the label.
There are some extra instructions for cards upside down, to ignore the small numbers in the corners, or to pay attention to the fact some cards may be cut, tilted, etc.
This prompt may not necessarily perfect, but at least it worked for all my pictures!

Then, as user message, we pass both the picture, and the request to detect the cards in the picture.

Last step, let's parse the JSON returned structure with GSON
(I could have used LangChain4j's `AiServices` for a cleaner and more type-safe approach),
and we're counting the points.
If the sum of points isn't correct, we display the cards that have been recognised, for troubleshooting purpose.

Let's check the output:

```
File: skyjo-counter/samples/-1 -1 -2 0 3 0 4.jpg
 ==> Your points: 3
File: skyjo-counter/samples/1 4 1 -1 3 0 0 3 3 3.jpg
 ==> Your points: 17
File: skyjo-counter/samples/3 9 3 4 5 2 4 5.jpg
 ==> Your points: 35
File: skyjo-counter/samples/3 5 2 4 5.jpg
 ==> Your points: 19
File: skyjo-counter/samples/-1 4.jpg
 ==> Your points: 3
File: skyjo-counter/samples/1 0 2.jpg
 ==> Your points: 3
File: skyjo-counter/samples/1 0 3 4 0 3 1 -1 2.jpg
 ==> Your points: 13
File: skyjo-counter/samples/4 4 1 2 0 2 1 2 3.jpg
 ==> Your points: 19
File: skyjo-counter/samples/0 -1 -1 -2 0 0 0 0 -1.jpg
 ==> Your points: -5
File: skyjo-counter/samples/4 1 -2 2 4 2 3 3 0 5.jpg
 ==> Your points: 22
File: skyjo-counter/samples/4 3 0 -2 -1 -1 2 1 3.jpg
 ==> Your points: 9
File: skyjo-counter/samples/6 1 2 6 1 3.jpg
 ==> Your points: 19
File: skyjo-counter/samples/3 3 5 2 5.jpg
 ==> Your points: 18
File: skyjo-counter/samples/1 -2 5 2 -1 8 0.jpg
 ==> Your points: 13
```

The picture file names contain the values of the cards, so it was easy to check for the ground truth!
And if we sum up those numbers, we should come up with the same number of points.

## Now what?

Well, first of all, I'm happy that LangChain4j works with Gemini 2.0!
Secondly, that the quality of object detection keeps on progressing nicely.
Thirdly, I might have to update my old demo, to make it a PWA app that could run on mobile, so that I don't have to count the sum of the card numbers in my head, because I'm lazy!

# Semantic code search for Programming Idioms with LangChain4j and Vertex AI embedding models


_By Guillaume Laforge & Valentin Deleplace_

The [Programming Idioms](https://programming-idioms.org/coverage) community website created by [Valentin](https://www.linkedin.com/in/deleplacevalentin/) lets developers share typical implementations in various programming languages for usual tasks like printing the famous “Hello World!” message, counting the characters in a string, sorting collections, or formatting dates, to name a few. And many more: there are currently 350 idioms, covering 32 programming languages. It’s a nice way to discover how various languages implement such common tasks!

The website features a typical keyword-based search feature, which is able to search through idiom descriptions, source code, comments, and tags. However, we (Guillaume & Valentin) were curious to see if we could enhance the search with a more semantic focus, taking advantage of Vertex AI **embedding models**, and their ability to **search through code from natural language queries**. With a semantic search, you’re not limited to results that match some keywords from a query, but you’ll get results even when using synonyms, or descriptions of what the code is doing.

Embedding models take a string in input, and generate a multidimensional floating point vector representation of that string. What’s interesting with those vectors is that input strings whose vectors are close to each other (for instance via a [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) calculation) are generally close to each other semantically speaking as well. This is why you can create **semantic searches**: you can search for semantically similar strings, even if they don’t share the same keywords and use synonyms instead. You can explore Guillaume’s article “[The power of embeddings: How numbers unlock the meaning of data](https://glaforge.dev/posts/2024/07/02/the-power-of-embeddings-how-numbers-unlock-the-meaning-of-data/)” to learn more about embedding models.

In the code shown in this article, we’ll be coding in Java, and we will be using the [LangChain4j](https://docs.langchain4j.dev/) open source framework. You can view the [full source code in this gist](https://gist.github.com/glaforge/4e45fa4222dd803d6d8bbf2b9335e90d), and below, we’ll highlight the key elements of this program.

We’ll be using the latest version of Google Cloud Vertex AI embedding models: `text-embedding-005`. Why is it important? Because this new version supports a new [task type](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings): `CODE_RETRIEVAL_QUERY`.

With this embedding model, there are different task types that optimize the embedding of text for different purposes, like for document retrieval, question & answering, fact verification… and now for code retrieval queries. **With this code retrieval query task type, you can search for code snippets with natural language**! This will come in handy for us when we want to do natural language semantic search throughout our programming idioms!

Before implementing our smart code search, if you want to learn more about the new task types of our embedding models, please go check this video:

_New "task type" embedding from the DeepMind team improves RAG search quality_
{{< youtube BgfSCTdlvAA >}}

## Let’s collect the idioms

The [Programming Idioms](https://programming-idioms.org/) website exposes a simple REST API. An endpoint allows you to get all the idioms in one HTTP GET call, but you can also access individual idioms via another GET request:

- https://programming-idioms.org/api/idioms/all — Lists all the idioms
- https://programming-idioms.org/api/idiom/202 — A single idiom identified by its ID

Idioms contain various fields like their title, description, keywords, and provide one or more implementations in various programming languages.

For example, the “Sum of squares” idiom starts like this:

```json
{
  Id: 202,
  OrigId: 0,
  Title: "Sum of squares",
  LeadParagraph: "Calculate the sum of squares _s of _data, an array of floating point values.",
  ExtraKeywords: "reduce",
  Author: "Bart",
  CreationDate: "2019-09-28T20:37:11.726064Z",
  LastEditor: "programming-idioms.org",
  EditSummary: "New Java implementation by user [reilas]",
  LastEditedImplID: 6839,
  OriginalAttributionURL: "",
  Picture: "",
  ImageURL: "",
  ImageWidth: 0,
  ImageHeight: 0,
  ImageAlt: "",
  Version: 40,
  VersionDate: "2024-11-08T22:54:02.691646Z",
  Implementations:
  [
    {
      Id: 3466,
      OrigId: -1,
      Author: "Bart",
      CreationDate: "2019-09-28T20:37:11.726064Z",
      LastEditor: "programming-idioms.org",
      LanguageName: "Pascal",
      CodeBlock: "var
  data: array of double;
...
  s := SumOfSquares(data);
...",
      OriginalAttributionURL: "",
      DemoURL: "",
      DocumentationURL: "",
      AuthorComment: "",
      Version: 2,
      VersionDate: "2021-12-07T10:07:15.952746Z",
      Rating: 0,
      Checked: false,
      ImportsBlock: "uses math;",
      PictureURL: "",
      Protected: false
    },
    …
  ]
}
```

What’s interesting for us, for a semantic code search engine, are the following idiom fields:

- `Id` — the unique ID of the idiom
- `Title` — that describes the idiom in a short way
- `LeadParagraph` — which is a more detailed definition of the idiom
- ExtraKeywords — words related to the idiom, for search

And for the implementations, the fields:

- `Id` — the unique ID of the idiom implementation
- `CodeBlock` — which contains the source code of the implemented idiom
- `LanguageName` — which says which programming language was used for that implementation
- AuthorComment — a small explanation about the implementation

We can represent those two notions, idiom & implementations, as Java records:

```java
record Idiom(
    @SerializedName("Id")
    long id,
    @SerializedName("Title")
    String title,
    @SerializedName("LeadParagraph")
    String description,
    @SerializedName("ExtraKeywords")
    String keywords,
    @SerializedName("Implementations")
    Implementation[] implementations
) {
    record Implementation(
        @SerializedName("Id")
        long id,
        @SerializedName("LanguageName")
        String language,
        @SerializedName("CodeBlock")
        String code,
        @SerializedName("AuthorComment")
        String comment

    ) {
    }
}
```

The annotations are here to map between the JSON key names and the Java record field names.

We load all the idioms from the website, and we create `TextSegment`s, which is the class used by [LangChain4j](https://docs.langchain4j.dev/) to pass to the embedding model for creating vectors.

```java
Idiom[] idioms = loadIdioms();

for (Idiom idiom : idioms) {
    System.out.println("-> " + idiom.title);

    for (var implementation : idiom.implementations) {
        var implementation = idiom.implementations[j];
        if (implementation.code != null &&
               !implementation.code.isBlank()) {
            allCodeSegments.add(new TextSegment(
                implementation.code,
                new Metadata()
                    .put("idiomId", idiom.id)
                    .put("title", idiom.title)
                    .put("description", idiom.description)
                    .put("titleAndDescription",
                        idiom.title + ": " + idiom.description)
                    .put("keywords", idiom.keywords)
                    .put("implementationId", implementation.id)
                    .put("language", implementation.language)
            ));
        }
    }
}
```

Notice that we also add some metadata. Not only do we embed the code snippets, but we also add some extra information like the title, description, keywords, or programming language. This will be useful for showing the results found during the semantic search.

We create a metadata field that concatenates the title and description of the idiom, as this is useful meta-information that the embedding model can use when calculating the vector embeddings. The `text-embedding-005` model pays attention to that information, and this will influence the calculations and enrich the semantic context of the vector embedding.

## Calculating embedding vectors

To compute those embeddings, we configure and use the `text-embedding-005` embedding model offered by Vertex AI. We define two instances of the model, with two distinct task types:

```java
private static final VertexAiEmbeddingModel EMBEDDING_MODEL =
    VertexAiEmbeddingModel.builder()
        .project(System.getenv("GCP_PROJECT_ID"))
        .location(System.getenv("GCP_LOCATION"))
        .modelName("text-embedding-005")
        .publisher("google")
        .taskType(VertexAiEmbeddingModel.TaskType.RETRIEVAL_DOCUMENT)
        .titleMetadataKey("titleAndDescription")
        .maxSegmentsPerBatch(150)
        .build();

private static final VertexAiEmbeddingModel EMBEDDING_MODEL_FOR_RETRIEVAL =
    VertexAiEmbeddingModel.builder()
        .project(System.getenv("GCP_PROJECT_ID"))
        .location(System.getenv("GCP_LOCATION"))
        .modelName("text-embedding-005")
        .publisher("google")
        .taskType(VertexAiEmbeddingModel.TaskType.CODE_RETRIEVAL_QUERY)
        .titleMetadataKey("titleAndDescription")
        .build();
```

We use the `EMBEDDING_MODEL` with a `RETRIEVAL_DOCUMENT` task type for the calculation of the vector embedding, but we use the `EMBEDDING_MODEL_FOR_RETRIEVAL` instance one, with a `CODE_RETRIEVAL_QUERY` task type for the retrieval.

The [documentation on task types](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/task-types#benefits_of_task_types) explains that it helps optimize the vector embedding calculation for different types of tasks. And this is what allows us to compare natural language queries like `"calculating string length"` with the actual code that computes the length of a string. Task types put the questions and answers closer in the embedding space.

We calculate all the embeddings in batch with:

```java
InMemoryEmbeddingStore<TextSegment> embeddingStore =
    new InMemoryEmbeddingStore<>();
List<Embedding> allEmbeddings =
    EMBEDDING_MODEL.embedAll(allCodeSegments).content();
embeddingStore.addAll(allEmbeddings, allCodeSegments);
embeddingStore.serializeToFile(filePath);
```

## Embedding the query and searching

With vector databases, when doing a search, we compare a vector embedding of what we’re searching for, with all the vector embeddings stored. So now that we have all our code snippets embedded, we need to compare an embedding of a user query to all those snippets. The in-memory embedding store can calculate cosine similarities between vectors for us.

Simplifying the code from the [gist](https://gist.github.com/glaforge/4e45fa4222dd803d6d8bbf2b9335e90d) a little, what we do here is to calculate the embedding for the user query, and prepare an embedding search request:

```java
Embedding queryEmbedding =
    EMBEDDING_MODEL_FOR_RETRIEVAL.embed(question)
        .content();

var searchRequestBuilder =
    EmbeddingSearchRequest.builder()
        .maxResults(5)
        .minScore(0.8)
        .queryEmbedding(queryEmbedding)
        .build();

EmbeddingSearchResult<TextSegment> searchResult =
    embeddingStore.search(searchRequest);
```

We chose to return only the 5 best search results, whose minimal score is above 0.8 (the score is a value between 0 and 1, with 1 being the highest). Then, we can iterate over the hits, and display the results for this search with some formatting:

```java
searchResult.matches().forEach(match -> {
    TextSegment matchedSegment = match.embedded();

    System.out.format("""
            ——— %s ——— (score: %4.5f) —————————
            Title: %s

            Description: %s

            Code:
            %s

            """,
        matchedSegment.metadata().getString("language"),
        match.score(),
        matchedSegment.metadata().getString("title"),
        matchedSegment.metadata().getString("description"),
        matchedSegment.text()
    );
});
```

We can try different queries:

- How can I make an HTTP POST request?
- How to count the characters in a string?
- How to use the LibXML parser in Perl?

For example, for the first query, the top results look interesting, with some good scores:

```
——— Java ——— (score: 0.85341) —————————
Title: Make HTTP POST request

Description: Make a HTTP request with method POST to the URL u

Code:
String s = HttpClient.newHttpClient().send(HttpRequest.newBuilder()
                        .uri(URI.create(u))
                        .POST(HttpRequest.BodyPublishers.ofString(content))
                        .build(), HttpResponse.BodyHandlers.ofString())
                .body();

——— D ——— (score: 0.84189) —————————
Title: Make HTTP POST request

Description: Make a HTTP request with method POST to the URL u

Code:
auto response = post(u, content);

——— Go ——— (score: 0.84010) —————————
Title: Make HTTP POST request

Description: Make a HTTP request with method POST to the URL u

Code:
response, err := http.Post(u, contentType, body)

——— Go ——— (score: 0.83938) —————————
Title: Make HTTP POST request

Description: Make a HTTP request with method POST to the URL u

Code:
response, err := http.PostForm(u, formValues)

——— Lisp ——— (score: 0.83770) —————————
Title: Make HTTP POST request

Description: Make a HTTP request with method POST to the URL u

Code:
(dex:post u)
```

Our search implementation found the right idioms and implementations.

## Restricting the search with metadata filtering

Now if we try to be more specific, like our question that asks explicitly to search for a specific programming language like Perl, the search would yield results in all programming languages. But the user wanted only Perl examples! Instead, to have better and more precise results, we can take advantage of LangChain4j’s [metadata filtering](https://docs.langchain4j.dev/integrations/embedding-stores/).

You remember that we added various metadata information to our embedded text segments? We included the programming language used in the code snippet in a language metadata field. With metadata filtering, we can focus the search only on a subset of vector embeddings whose language metadata field matches the programming language we’re interested in.

Let’s update our search query as follows:

```java
var searchRequestBuilder = EmbeddingSearchRequest.builder()
    .maxResults(5)
    .minScore(0.8)
    .queryEmbedding(queryEmbedding)
    .filter(new IsEqualTo("language",
        programmingLanguageRecognised))
    .build();
```

We added a `filter()` method, that checks that the language is equal to some value. But then, it means we have to know up-front that the user wants results just for one specific programming language. We could have some kind of UI element that users have to fill to select the programming language. But in our search query, we had a user providing the programming language directly in that query: `"How to use the LibXML parser in Perl?"`

In such a situation, we can’t rely on a UI component or CLI parameter, we have to guess the programming language requested from the query string itself. This is where Gemini can come to the rescue, with a little bit of prompting, we can ask the generative model to tell us if a programming language is present in the query, and which one.

First, let’s have a look at the programming languages offered by Programming Idioms:

```java
private static final List<String> KNOWN_PROGRAMMING_LANGUAGES =
    List.of("UNKNOWN",
        "Go", "Rust", "Python", "Perl", "Ruby", "Java", "JS",
        "C#", "Dart", "Pascal", "PHP", "C++", "Haskell", "D",
        "Lua", "Clojure", "Fortran", "Elixir", "Kotlin",
        "Erlang", "C", "Lisp", "VB", "Groovy", "Ada", "Scala",
        "Scheme", "Smalltalk", "Obj-C", "Cobol", "Prolog", "Caml"
);
```

We added an `UNKNOWN` value, when the language is not specified or recognised.

Now we configure a Gemini 1.5 Flash model, specifying a response schema to restrict the model’s answer to a value contained in the language enumeration of possible programming languages:

```java
private static final ChatLanguageModel GEMINI_MODEL =
    VertexAiGeminiChatModel.builder()
        .project(System.getenv("GCP_PROJECT_ID"))
        .location(System.getenv("GCP_LOCATION"))
        .modelName("gemini-1.5-flash-002")
        .responseSchema(Schema.newBuilder()
            .setType(Type.STRING)
            .addAllEnum(KNOWN_PROGRAMMING_LANGUAGES)
            .build())
        .build();
```

Let’s prompt Gemini to find the programming language in the user query (if present):

```java
String programmingLanguageRecognised =
    GEMINI_MODEL.generate(
        SystemMessage.from("""
            Your role is to classify the user message to decide
            if it is a question about a particular programming
            language or not.
            If you don't know, or if the programming language
            is not specified, reply with `UNKNOWN`, otherwise
            reply with just the name of the programming
            language recognized among the following list:
            """ + KNOWN_PROGRAMMING_LANGUAGES),
        UserMessage.from(question)
    ).content().text();
```

Gemini will either reply with `UNKNOWN` if no programming language was mentioned, or with the language it has recognized.

Now, when making a search for an idiom in a particular language, only implementations in that language are returned, giving much better results, in line with the expectations of the user.

## Possible further improvements

Where can we go from there? We can make the search a little bit snappier, or further enhance the quality of the search results.

Let’s talk first about the search speed. Searching through the in-memory vector database is pretty fast, and only requires a couple dozen milliseconds. After all, it’s all in memory, and there’s not millions of records in the database. But what takes more time are the round trips to the cloud hosted embedding models and for the generative model calls.

Depending on the cloud region you use, and from where you call the program, an embedding request can take up to a second and a half, and the Gemini call less than a second. So making a request to Gemini to guess the programming language, then calling the embedding model to embed the query for comparison with the in-memory database, would be roughly two and a half seconds long if done serially. Since both operations are unrelated, we can call them in parallel using an executor service with two threads:

```java
List<Future<Object>> futures;
try (var executorService = Executors.newFixedThreadPool(2)) {
    futures = executorService.invokeAll(List.of(
        () -> recognizeProgrammingLanguage(question),
        () -> embedQuery(question)
    ));
}
String programmingLanguageRecognised = (String) futures.get(0).get();
Embedding queryEmbedding = (Embedding) futures.get(1).get();
```

With this trick, the embedding and programming language guessing takes as much time as the longest of both tasks. Usually, it seems the embedding is the longest. So we shave a second of wait time for the user. It’s a win!

The other aspect we could improve further is the quality of search results. We already improved it by applying two techniques: using a code retrieval task type with our embedding model, and also the programming language filtering to avoid returning languages the user isn’t interested in.

However, there’s another approach we haven’t explored (this could be the topic for another article) which is to combine the existing keyword-based search provided by the Programming Idioms website, with our semantic search. This is what is called **hybrid search**: combining the results of two or more searches, to give better results, applying techniques like [Reciprocal Rank Fusion](https://medium.com/@devalshah1619/mathematical-intuition-behind-reciprocal-rank-fusion-rrf-explained-in-2-mins-002df0cc5e2a) to merge results.

Embedding and generative models understand text pretty well, but can struggle with acronyms, product names, etc, that they haven’t seen much (if at all) in their training set. But keyword-based searches excel at that. So by combining the best of both worlds, our little website search box could tackle more queries, and give the best answers to our users.

## Summary

This article explored semantic code search for programming idioms using Vertex AI [embedding models](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings) and the [LangChain4j](https://docs.langchain4j.dev/) framework. We aimed to enable natural language queries for code examples, going beyond keyword-based searches. Key learnings included:

- **Embedding models** represented text as multidimensional vectors, capturing semantic similarities.
- **Vertex AI's text-embedding-005** model, particularly the `CODE_RETRIEVAL_QUERY` task type, was optimized for code-related searches.
- **LangChain4j** provided a framework for building LLM applications in Java.
- **Gemini**, a generative AI model, could be used to infer the programming language from a user's query, improving search accuracy.
- **Parallel processing** enhanced search speed by concurrently executing embedding and language recognition tasks.
- **Metadata filtering** allowed for more precise searches based on attributes like the programming language name.
- **Hybrid search**, combining semantic and keyword-based approaches, could further improve search quality.

Overall, the article demonstrated how we could build a fast and intelligent programming idiom search engine that understands natural language queries and retrieves contextually relevant code examples.

# Redacting sensitive information when using Generative AI models


As we are making our apps smarter with the help of Large Language Models, we must keep in mind that we are often dealing with potentially sensitive information coming from our users. In particular, in the context of chatbots, our application users have the ability to input any text in the conversation.

Personally Identifiable Information (PII) should be dealt with the highest level of attention, because we care about our users, we don't want to leak their personal details, and we must comply with all sorts of laws or regulations. In a word, we are [responsible AI](https://cloud.google.com/responsible-ai) developers.

In this article, we'll learn about the Google Cloud [Data Loss Prevention](https://cloud.google.com/security/products/dlp) (DLP) API. It's a very powerful and rich service, which allows you to identify, classify, filter, redact any PII like names, passport numbers, bank account numbers, and more.

Today, with DLP, our goal is to redact the PII information sent by our user, before sending the user's message to our LLM.

In a nutshell (in pseudo-code), instead of doing:

```java
String userMessage = "...";
String response = model.generate(userMessage);
```

We want to add an instruction in the middle to redact the personally identifiable information before sending it to the LLM, so we need to to insert a method in between:

```java
String userMessage = "...";
String redactedMessage = redact(userMessage);
String response = model.generate(redactedMessage);
```

We'll simply redact the user message, but remember that there are other areas where you can apply good practices when handling user information. For example, when you store data, when you log interactions, etc.

## Meet our user!

Our user, let's call her Alicia, is a bit talkative, and shares way too much information that she should. Let's imagine that she is travelling, and lost her wallet, and needs some money to be wired in a rush. Maybe she could send a message to our travel application that looks as follows:

```java
String userMessage = """
    My name is Alicia Bob.
    My number is +33612345678, can you call me please?
    Please wire some $$$ on FR7630001007941234567890185
    You can check my passport if needed, it's 78TH67845.
    """;
```

Woh! In one message she gave her name, her phone number, her bank account (IBAN), and even her passport number! But our application doesn't necessarily need all those details!

In our code, we're sending that information to our Gemini model, using [LangChain4j](https://docs.langchain4j.dev/):

```java
var model = VertexAiGeminiChatModel.builder()
    .project(System.getenv("GCP_PROJECT_ID"))
    .location(System.getenv("GCP_LOCATION"))
    .modelName("gemini-1.5-flash-002")
    .build();

String redactedMessage = redact(userMessage);

System.out.println(redactedMessage);

String response = model.generate(redactedMessage);
```

Our mission, if we accept it, is to implement the `redact()` method that will remove all the PII information from that request.

## Redacting this \[REDACTED\] message!

First, let's have a look at all the code of our `redact()` method, and we'll explain bits and pieces further down.
You can also look at this [gist](https://gist.github.com/glaforge/c7d7188aa3ff01a0f691b1e474ec0260) on Github with all the code as well.

```java
public static String redact(String userMessage) {
  try (var dlp = DlpServiceClient.create()) {
    var item = ContentItem.newBuilder().setValue(userMessage).build();
    var inspectConfigbuilder = InspectConfig.newBuilder();
    var redactConfig = DeidentifyConfig.newBuilder();
    var infoTypeTransfBuilder = InfoTypeTransformations.newBuilder();

    Stream.of("PERSON_NAME", "PHONE_NUMBER", "PASSPORT", "IBAN_CODE")
      .forEach(toRedact -> {
          var infoType = InfoType.newBuilder()
            .setName(toRedact)
            .build();
          inspectConfigbuilder.addInfoTypes(infoType);

          var replaceValueConfig =
            ReplaceValueConfig.newBuilder()
              .setNewValue(Value.newBuilder()
              .setStringValue("[" + toRedact + "]").build())
              .build();

          var primitiveTransformation =
            PrimitiveTransformation.newBuilder()
              .setReplaceConfig(replaceValueConfig).build();

          var infoTypeTransformation =
            InfoTypeTransformations.InfoTypeTransformation.newBuilder()
              .addInfoTypes(infoType)
              .setPrimitiveTransformation(primitiveTransformation)
              .build();

          infoTypeTransfBuilder
            .addTransformations(infoTypeTransformation);
        });

    redactConfig.setInfoTypeTransformations(
      infoTypeTransfBuilder);

    DeidentifyContentRequest request =
      DeidentifyContentRequest.newBuilder()
        .setParent(
            LocationName.of(System.getenv("GCP_PROJECT_ID"), "global")
            .toString())
        .setItem(item)
        .setDeidentifyConfig(redactConfig)
        .setInspectConfig(inspectConfigbuilder)
        .build();

    DeidentifyContentResponse response =
      dlp.deidentifyContent(request);

    return response.getItem().getValue();
  } catch (IOException e) {
    throw new RuntimeException("Failed to redact message.", e);
  }
}
```

As you can see, the DLP API is quite a bit verbose, but it's really super powerful, and is capable of more than just redacting PII information.

First of all, we need to create a client for the DLP service (which is `AutoCloseable`, hence the `try` with resources pattern):

```java
try (var dlp = DlpServiceClient.create()) { ... } catch (...) {...}
```

We create a `ContentItem` from our user message:

```java
var item = ContentItem.newBuilder()
    .setValue(userMessage)
    .build();
```

Then we'll create some `InfoType`s which represent the different kinds of identifiable information we're interested in:

```java
Stream.of("PERSON_NAME", "PHONE_NUMBER", "PASSPORT", "IBAN_CODE")
    .forEach(toRedact -> {
        var infoType = InfoType.newBuilder().setName(toRedact).build();
        inspectConfigbuilder.addInfoTypes(infoType);
```

Here, we care only for the person's name, phone number, passport, and IBAN codes. But there are a ton of [other details we can redact](https://cloud.google.com/sensitive-data-protection/docs/infotypes-reference).

The next few instructions will associate a text transformation rule to transform the PII information into some redacted format. We could have used just something like `[REDACTED]` but we are going to reuse the name of the info type: `[PERSON_NAME]`, `[PHONE_NUMBER]`, `[PASSPORT]`, and `[IBAN_CODE]`:

```java
var replaceValueConfig =
    ReplaceValueConfig.newBuilder()
        .setNewValue(Value.newBuilder()
            .setStringValue("[" + toRedact + "]").build())
        .build();

var primitiveTransformation =
    PrimitiveTransformation.newBuilder()
        .setReplaceConfig(replaceValueConfig).build();

var infoTypeTransformation =
    InfoTypeTransformations.InfoTypeTransformation.newBuilder()
        .addInfoTypes(infoType)
        .setPrimitiveTransformation(primitiveTransformation)
        .build();
```

We add all those text transformations to the information type transformation builder, and then it's time to actually make the request to the DLP service:

```java
DeidentifyContentRequest request =
    DeidentifyContentRequest.newBuilder()
        .setParent(
            LocationName.of(System.getenv("GCP_PROJECT_ID"), "global")
              .toString())
        .setItem(item)
        .setDeidentifyConfig(redactConfig)
        .setInspectConfig(inspectConfigbuilder)
        .build();

DeidentifyContentResponse response = dlp.deidentifyContent(request);

return response.getItem().getValue();
```

We wire everything together by creating a `DeidentifyContentRequest` instance with our user message (the item) and all PII identification and transformation configuration. We configured the DLP service by passing our Google Cloud project ID, after having [enabled the API](https://console.cloud.google.com/apis/library/dlp.googleapis.com). We call the DLP service with `dlp.deidentifyContent(request)` and finally we can get the redacted value with `response.getItem().getValue()`.

So what does our original user message look like now, once redaction is applied? Let's see:

```
My name is [PERSON_NAME] [PERSON_NAME].
My number is [PHONE_NUMBER], can you call me please?
Please wire some $$$ on [IBAN_CODE]
You can check my passport if needed, it's [PASSPORT].
```

No more personally identifiable information left!


## Summary

Our user's trust is one of the most important things we must care about. Not only for compliance purposes but also simply because it's the right thing to do. There are so many hackers out there trying to get access to such information, for nefarious reasons. Let's not offer them an extra chance to harm our users.

In this article and sample code, we've seen that the [Google Cloud DLP API](https://cloud.google.com/security/products/dlp?hl=en) is able to redact information, but it can be used in a myriad of ways, for example to analyze data at rest as well, or you can deidentify / reidentify information as well. Be sure to check out what this service is capable of doing. We focused on just a few PII details, but DLP supports a [huge number of identifiable information](https://cloud.google.com/sensitive-data-protection/docs/infotypes-reference).

There's a big [list of snippets](https://cloud.google.com/sensitive-data-protection/docs/samples/?hl=en) of code that you can have a look at to see what you can do with the DLP API. There are [SDKs](https://cloud.google.com/sensitive-data-protection/docs/libraries) for various programming languages, if you use another language than Java. And check out the [documentation](https://cloud.google.com/sensitive-data-protection/docs/sensitive-data-protection-overview)!

You can apply this technique to filter user input before sending it to a generative model, but you can also apply it in output as well, when/if you log user messages, or store data in databases or other places.

And remember, be mindful of your user's data!

# Data extraction: The many ways to get LLMs to spit JSON content


Data extraction from unstructured text is a very important task where LLMs shine, as they understand human languages well. Rumor has it that 80% of the worldwide knowledge and data comes in the form of unstructured text (vs 20% for data stored in databases, spreadsheets, JSON/XML, etc.) Let’s see how we can get access to that trove of information thanks to LLMs.

In this article, we’ll have a look at different techniques to make LLMs generate JSON output and extract data from text. This applies to most LLMs and frameworks, but for illustration purposes, we’ll use [Gemini](https://deepmind.google/technologies/gemini/) and [LangChain4j](https://docs.langchain4j.dev/) in Java.

We’ll explore the following approaches:

- prompting
- function calling
- structured output with a JSON mode
- structured output with a JSON response schema

## Let’s get started

Your mission, if you accept it, is to extract the name and age from the biography of a person:

```
Anna is a 23 year old artist based in Brooklyn, New York. She
was born and raised in the suburbs of Chicago, where she developed a
love for art at a young age. She attended the School of the Art
Institute of Chicago, where she studied painting and drawing. After
graduating, she moved to New York City to pursue her art career.
Anna's work is inspired by her personal experiences and observations
of the world around her. She often uses bright colors and bold lines
to create vibrant and energetic paintings. Her work has been exhibited
in galleries and museums in New York City and Chicago.
```

From that text, we want to extract the following JSON snippet:

```json
{
  "name": "Anna",
  "age": 23
}
```

## Let’s just ask politely\!

The first approach is to simply craft a user message, via prompting, that requests the response to be returned as JSON. A simple prompt suffice:

```
Return the name and age of the person described in the biography below.
Give the name and age in the form of a JSON object following this
structure: `{"name": "Jon Doe", "age": 36}`
Only return JSON, without any explanation,
without surrounding markdown code markup.

Here is the biography:

Anna is a 23 year old artist based in Brooklyn, New York. She
was born and raised in the suburbs of Chicago, where she developed a
love for art at a young age. She attended the School of the Art
Institute of Chicago, where she studied painting and drawing. After
graduating, she moved to New York City to pursue her art career.
Anna's work is inspired by her personal experiences and observations
of the world around her. She often uses bright colors and bold lines
to create vibrant and energetic paintings. Her work has been exhibited
in galleries and museums in New York City and Chicago.

JSON:
```

Sometimes, LLMs don’t always follow precisely the instructions. So you have to nudge them a little bit by requesting them to really output only JSON, as sometimes they wrap their answers with messages like “Here is the name and age of the person…” or with extra Markdown code blocks. So you may have to further tweak the prompt.

Quick illustration with Gemini and LangChain4j:

```java
String biography = "Anna is a 23 year old artist…";

var model = VertexAiGeminiChatModel.builder()
    .project(System.getenv("PROJECT_ID"))
    .location(System.getenv("LOCATION"))
    .modelName("gemini-1.5-pro-002")
    .build();

String response = model.generate("""
    Return the name and age of the person described in the biography
    below. Give the name and age in the form of a JSON object
    following this structure: `{"name": "Jon Doe", "age": 36}`
    Only return JSON, without any explanation,
    without surrounding markdown code markup.

    Here is the biography:

    """ + biography + """

    JSON:
    """);

System.out.println(response);
// {"name": "Anna", "age": 23}
```

The output is a `String`, so you have to parse it with your favorite JSON parser, but the data has been successfully extracted into a JSON object.

Most LLMs support the notion of system instructions. Usually, LLMs obey a bit more closely to those instructions, than via user prompts. So you could also rewrite the example above by splitting the instructions inside system instructions, and put only the biography in the user prompt.

## Function calling to the rescue\!

Before the advent of JSON modes and response schemas (that we’ll review in the next sections) a more certain way to get JSON outputs was to take advantage of function calling. You have to encourage the LLM to request a function call to extract the information. Here’s the trick.

```json
{
  "name": "extractNameAndAgeFromBiography",
  "description": "extract the name and age of a person described in the biographical text given in input",
  "parameters": {
    "type": "object",
    "properties": {
      "name": {
        "type": "string"
      },
      "age": {
        "type": "integer"
      }
    },
    "required": ["name", "age"]
  }
}
```

You define a function whose signature looks like `extractNameAndAgeFromBiography(String name, int age)`, following the OpenAPI specification. You should add very precise descriptions for the function and its arguments. Here, I could have added more information about the parameters, but the names seemed self-explanatory to me. Then you can just pass the biography directly, and it should just work out of the box.

You can add system instructions to request the model to call that method to find the name and age of the person. But sometimes, some LLMs also allow you to force the LLM to request a call to a function.

What does it look like in Java with LangChain4j?

```java
var model = VertexAiGeminiChatModel.builder()
    .project(System.getenv("PROJECT_ID"))
    .location(System.getenv("LOCATION"))
    .modelName("gemini-1.5-pro-002")
    .toolCallingMode(ToolCallingMode.ANY)
    .allowedFunctionNames(List.of("extractNameAndAgeFromBiography"))
    .build();
```

I specified the tool calling mode: this `ANY` value instructs the model to call one of the methods defined in the allowed function names list. It is a forced call request. The model will have to request the call.

```java
Response<AiMessage> response = model.generate(
    List.of(
        SystemMessage.from("""
          Return the name and age of the person described by the user
          by calling the function `extractNameAndAgeFromBiography()`
          and passing the name and the age of the person recognized.
        """),
        UserMessage.from(biography)
    ),
    ToolSpecification.builder()
        .description("""
            extract the name and age of a person described
            in the biographical text given in input
        """)
        .name("extractNameAndAgeFromBiography")
        .parameters(
            JsonObjectSchema.builder()
                .addStringProperty("name")
                .addIntegerProperty("age")
                .required("name", "age")
                .build()
        )
        .build()
);
```

The `generate()` call is a bit more convoluted. With forced tool calling, the system message is not mandatory, but it can help ensure all parameters are passed as arguments. Look at how we defined the contract of the function `extractNameAndAgeFromBiography()` by creating an object with a string and integer properties.

Now we’ll extract the function call request. We don’t look at the text content, as the model returns a tool execution request instead:

```java
System.out.println(response
    .content()
    .toolExecutionRequests()
    .getFirst()
    .arguments());

// {"name":"Anna","age":23.0}
```

You can retrieve just the arguments, as a JSON string. It’s already following the JSON object structure we wished to obtain.

You might notice a minor annoyance here, though, which is the fact the age is not an integer, but a floating point number. I’m not entirely sure at this point why we don’t get an integer. I’ll have to dig a little deeper…

Let’s now have a look at the JSON mode and response schema approaches.

## JSON mode approach

Some LLMs started offering the ability to request the model to output valid JSON. It’s not necessarily 100% certain that it will follow your requested format (for example, some JSON object keys could sometimes be named differently) but it works most of the time.

With the JSON mode (sometimes called structured output, or constrained decoding), we come back to our first approach, by prompting the LLM to generate JSON. But this time, we don’t have to nudge the LLM as much, because it must always generate valid JSON in output. It won’t add any Markdown markup, or any commentary.

Let’s see how to use the JSON mode with Gemini and LangChain4j:

```java
var model = VertexAiGeminiChatModel.builder()
    .project(System.getenv("PROJECT_ID"))
    .location(System.getenv("LOCATION"))
    .modelName("gemini-1.5-pro-002")
    .responseMimeType("application/json")
    .build();
```

Notice how we set the response MIME type to application/json? That’s how we enable Gemini to always return valid JSON in output.

```java
Response<AiMessage> response = model.generate(
    List.of(
        SystemMessage.from("""
            Return the name and age of the person described in the
            biography below. Give the name and age in the form of
            a JSON object following this structure:
            `{"name": "Jon Doe", "age": 36}`
            """
        ),
        UserMessage.from(biography)
    )
);

System.out.println(response.content().text());
// {"name": "Anna", "age": 23}
```

We just needed to encourage Gemini to follow the JSON structure shown in the example in the system instruction. We don’t have to give further nudges to the model to not output Markdown code markup, or to prevent it from adding extra explanations.

This gives great results, but to go even further and ensure that the returned JSON document is compliant with the format you really wish to get, you can also define a JSON response schema. That’s what we’re gonna see next.

## Even better with JSON schema for structured output

In addition to the response MIME type, you can specify the JSON schema that the JSON response must comply with. Let’s complement the previous example, and add that schema definition:

```java
var model = VertexAiGeminiChatModel.builder()
    .project(System.getenv("PROJECT_ID"))
    .location(System.getenv("LOCATION"))
    .modelName("gemini-1.5-pro-002")
    .responseMimeType("application/json")
    .responseSchema(Schema.newBuilder()
        .setType(Type.OBJECT)
        .putProperties("name", Schema.newBuilder()
            .setType(Type.STRING)
            .setDescription(
                "The name of the person described in the biography")
            .build())
        .putProperties("age", Schema.newBuilder()
            .setType(Type.INTEGER)
            .setDescription(
                "The age of the person described in the biography")
            .build())
        .build())
        .addAllRequired(List.of("name", "age"))
    .build();
```

The response should be an object with a string name, and an integer age properties.

## Bonus points with type safe objects with LangChain4j

In our LangChain4j based examples, in Java, each time, the low-level APIs offered by the framework always responded with JSON strings. But as a Java developer, we’d prefer to manipulate real Java objects instead. Of course, you can take advantage of the unmarshalling capabilities of your favorite JSON library. But what if the framework provided a higher level abstraction and did all the work for you? That’s where we’ll use LangChain4j’s AI services.

First, let’s define a data structure to hold the name and age of our biographies, with a Java record:

```java
record Person(String name, int age) { }
```

The next step is to create a contract that the framework will implement for you. In input, a string biography, and in output, a Person record:

```java
interface PersonExtractor {
    @SystemMessage("""
        Your role is to extract the name and age
        of the person described in the biography.
        """)
    Person extractPerson(String biography);
}
```

Notice how we annotate the method with a system instruction that instructs the model what its role is.

We still need to instantiate our chat model:

```java
var model = VertexAiGeminiChatModel.builder()
    .project(System.getenv("PROJECT_ID"))
    .location(System.getenv("LOCATION"))
    .modelName("gemini-1.5-pro-002")
    .responseMimeType("application/json")
    .responseSchema(SchemaHelper.fromClass(Person.class))
    .build();
```

We specify again the response MIME type, and also the response schema. But we’re using a convenience method provided by the SchemaHelper class to derive a schema from a Java class (here, our Person record).

Now we can instantiate our person extractor contract as follows:

```java
PersonExtractor extractor =
    AiServices.create(PersonExtractor.class, model);
```

And finally, we can pass it the biography in input:

```java
Person person = extractor.extractPerson(bio);

System.out.println(person.name());  // Anna
System.out.println(person.age());   // 23
```

We have an instance of our Person record in output that is properly populated with the name and age of the person described in our biography\! That way, as Java developers, we manipulate a real Java object, in a type-safe manner\! Our application is enhanced by an LLM, but from a developer perspective, we manipulate interfaces and objects.

## Summary

Lots of articles, videos, or presentations often talk about the chatbot use case, when creating applications powered by large language models. However, data extraction is another very important and useful task where LLMs shine.

In this article, we saw different approaches to do data extraction: via prompting, function calling, or with a JSON mode or JSON schema. If your LLM supports the ability to set a response schema, that’s definitely the best way to get the JSON output you expect.

Also, if the LLM orchestration framework you use supports it, be sure to check if it’s able to return type-safe objects that you can manipulate with your programming language directly, without having to parse the JSON string yourself.

# Things you never dared to ask about LLMs


Along my learning journey about generative AI, lots of questions popped up in my mind.
I was very curious to learn how things worked under the hood in Large Language Models (at least having an intuition rather than knowing the maths in and out).
Sometimes, I would wonder about how tokens are created, or how hyperparameters influence text generation.

Before the [dotAI](https://www.dotai.io/) conference, I was invited to talk at the meetup organised by [DataStax](https://www.datastax.com/).
I presented about all those things you never dared to ask about LLMs, sharing both the questions I came up with while learning about generative AI, and the answers I found and discovered along the way.

Without further ado, here's the deck:

{{< speakerdeck 476be803290048d6935e585bf87d1e5f >}}

## Abstract

> ## Things you never dared to ask about LLMs
>
> Large Language Models (LLMs) have taken the world by storm, powering applications from chatbots to content generation.
> Yet, beneath the surface, these models remain enigmatic.
>
> This presentation will “delve” into the hidden corners of LLM technology that often leave developers scratching their heads.
> It’s time to ask those questions you’ve never dared ask about the mysteries underpinning LLMs.
>
> Here are some questions we’ll to answer:
>
> Do you wonder why LLMs spit tokens instead of words? Where do those tokens come from?
> * What’s the difference between a “foundation” / “pre-trained” model, and an “instruction-tuned” one?
> * We’re often tweaking (hyper)parameters like temperature, top-p, top-k, but do you know how they really affect how tokens are picked up?
> * Quantization makes models smaller, but what are all those number encodings like fp32, bfloat16, int8, etc?
> * LLMs are good at translation, right? Do you speak the Base64 language too?
>
> We’ll realize together that LLMs are far from perfect:
> * We’ve all heard about hallucinations, or should we say confabulations?
> * What is this reversal curse that makes LLMs ignore some facts from a different viewpoint?
> * You’d think that LLMs are deterministic at low temperature, but you’d be surprised by how the context influences LLMs’ answers…
>
> Buckle up, it’s time to dispel the magic of LLMs, and ask those questions we never dared to ask!

This talk wasn't recorded, but I hope to give this presentation again sometime soon, and hopefully, it'll be recorded then.
If that happens, I'll share the video recording once it's available.

## Illustrations: Imagen 3 to the rescure

For those who are curious about the cute little robots that appear in this presentation,
I've generated them with DeepMind's [Imagen 3](https://deepmind.google/technologies/imagen-3/) image generation model.

The quality of the output was really lovely, and I might have been a bit overboard with the number of generated robots in this deck.

I would start pretty much all my prompts with _"cartoon of a cute little robot..."_

For my Java developer friends, you can [generate images with Imagen via LangChain4j](https://glaforge.dev/posts/2024/10/01/ai-nktober-generating-ink-drawings-with-imagen/)
(as explained in that article where I generated black'n white ink drawings).
# Advanced RAG Techniques


**Retrieval Augmented Generation** (RAG) is a pattern to let you prompt a large language model (LLM) about your own data, via in-context learning by providing extracts of documents found in a vector database (or potentially other sources too).

Implementing RAG isn't very complicated, but the results you get are not necessarily up to your expectations. In the presentations below, I explore various **advanced techniques to improve the quality of the responses returned by your RAG system**:

Ingestion chunking techniques like:

- Embedding of sliding windows of sentences
- Hypothetical question embedding
- Contextual retrieval embedding (invented recently by Anthropic)
- Semantic chunking (created by Greg Kamradt)

Retrieval techniques, including:

- Query compression
- Hypothetical Document Embedding (HyDE)

And I also mention how an _agentic_ approach can help for more advanced and complex needs, with providing intermerdiary results, combined in a final response. **Agentic RAG** is a very important and promising approach that I'll certainly come back to in upcoming articles.

At Devoxx Belgium 2024, I gave a 50-minute session, and a 3-hour long deep dive with my friend [Cédrick Lunven](https://x.com/clunven) from Datastax (we used the great [Astra DB](https://www.datastax.com/products/datastax-astra) vector database in our demos). You'll find both decks and videos below.

## Code available on Github

All the code presented in those sessions is available in this [Github repository](https://github.com/datastaxdevs/conference-2024-devoxx/)

## RAG: from dumb implementation to serious results

### Abstract

> Embarking on your RAG journey may seem effortless, but achieving satisfying results often proves challenging. Inaccurate, incomplete, or outdated answers, suboptimal document retrieval, and poor text chunking can quickly dampen your initial enthusiasm.
>
> In this session, we'll leverage LangChain4j to elevate your RAG implementations. We'll explore:
>
> - Advanced Chunking Strategies: Optimize document segmentation for improved context and relevance.
> - Query Refinement Techniques: Expand and compress queries to enhance retrieval accuracy.
> - Metadata Filtering: Leverage metadata to pinpoint the most relevant documents.
> - Document Reranking: Reorder retrieved documents for optimal result presentation.
> - Data Lifecycle Management: Implement processes to maintain data freshness and relevance.
> - Evaluation and Presentation: Assess the effectiveness of your RAG pipeline and deliver results that meet user expectations.
>
> Join us as we transform your simplistic RAG experience from one of frustration to delight your users with meaningful and accurate answers.

### Presentation slide deck

{{< speakerdeck a2207c4bc9b9447da5a397107da19d0f >}}

### YouTube video recording

{{< youtube 6_wUUYKBdE0 >}}

## RAG: from dumb implementation to serious results

### Abstract

> It’s easy to get started with Retrieval Augmented Generation, but you’ll quickly be disappointed with the generated answers: inaccurate or incomplete, missing context or outdated information, bad text chunking strategy, not the best documents returned by your vector database, and the list goes on.
>
> After meeting thousands of developers across Europe, we’ve explored those pain points, and will share with you how to overcome them. As part of the team building a vector database we are aware of the different flavors of searches (semantic, meta-data, full text, multimodal) and embedding model choices. We have been implementing RAG pipelines across different projects and frameworks and are contributing to LangChain4j.
>
> In this deep-dive, we will examine various techniques using LangChain4j to bring your RAG to the next level: with semantic chunking, query expansion & compression, metadata filtering, document reranking, data lifecycle processes, and how to best evaluate and present the results to your users.

### Presentation slide deck

{{< speakerdeck 5f7120a2dbeb4ffd917102321231cbc0 >}}

### YouTube video recording

{{< youtube RN7thifOmkI >}}

# A Gemini and Gemma tokenizer in Java


It's always interesting to know _how the sausage is made_, don't you think?
That's why, a while ago, I looked at
[embedding model tokenization](https://glaforge.dev/posts/2024/02/05/visualize-palm-based-llm-tokens/),
and I implemented a little [visualization](https://tokens-lpj6s2duga-ew.a.run.app/) to see the tokens in a colorful manner.
Yet, I was still curious to see how Gemini would tokenize text...

Both LangChain4j Gemini modules (from
[Vertex AI](https://docs.langchain4j.dev/integrations/language-models/google-vertex-ai-gemini) and from
[Google AI Labs](https://docs.langchain4j.dev/integrations/language-models/google-ai-gemini))
can count the tokens included in a piece of text.
However, both do so by calling a REST API endpoint method called `countTokens`.
This is not ideal, as it requires a network hop to get the token counts, thus adding undesired extra latency.
Wouldn't it be nicer if we could count tokens locally instead?

Interestingly, both Gemini and the open-weights [Gemma](https://ai.google.dev/gemma)
models share the same tokenizer and token vocabulary.
Also, the tokenizer is based on [SentencePiece](https://github.com/google/sentencepiece),
which is a tokenizer/detokenizer implementing the byte-pair-encoding (BPE) and unigram language algorithms.

If you look at the [Gemma code on HuggingFace](https://huggingface.co/google/gemma-2-9b-it/tree/main),
you'll see a `tokenizer.json` file that you can open to see the available tokens in the vocabulary,
and a `tokenizer.model` file which is some kind of binary compressed variation.

Knowing that the list of tokens supported by Gemini and Gemma is available in those files, and how they are encoded,
I was curious to see if I could implement a Java tokenizer that could run locally, rather than calling a remote endpoint.

The `SentencePiece` implementation from Google is a C++ library, but I didn't really feel like wrapping it myself with JNI,
and fortunately, I discovered that the [DJL](https://djl.ai/) project had done the JNI wrapping job already.

So let's see how to tokenize text for Gemini and Gemma, in Java!

## Gemini and Gemma tokenization in Java with DJL

First of all, let's setup the dependency on DJL's `SentencePiece` module:

- From Maven:

```xml
<dependency>
    <groupId>ai.djl.sentencepiece</groupId>
    <artifactId>sentencepiece</artifactId>
    <version>0.30.0</version>
</dependency>
```

- From Gradle:

```groovy
implementation 'ai.djl.sentencepiece:sentencepiece:0.30.0'
```

I saved the `tokenizer.model` file locally.
Note that it's a 4MB file, as Gemini/Gemma have a very large vocabulary of around a quarter million of tokens!

Now, let's instantiate an `SpTokenizer` object that loads this vocabulary file, and tokenize some text:

```java
import ai.djl.sentencepiece.SpTokenizer;
// ...
Path model = Paths.get("src/test/resources/gemini/tokenizer.model");
byte[] modelFileBytes = Files.readAllBytes(model);

try (SpTokenizer tokenizer = new SpTokenizer(modelFileBytes)) {
    List<String> tokens = tokenizer.tokenize("""
    When integrating an LLM into your application to extend it and \
    make it smarter, it's important to be aware of the pitfalls and \
    best practices you need to follow to avoid some common problems \
    and integrate them successfully. This article will guide you \
    through some key best practices that I've come across.
    """);

    for (String token: tokens) {
        System.out.format("[%s]%n", token);
    }

    System.out.println("Token count: " + tokens.size());
}
```

When running this Java class, you'll see the following output:

```
[When]
[▁integrating]
[▁an]
[▁L]
[LM]
[▁into]
[▁your]
[▁application]
...

Token count: 61
```

## Next steps

Do we need next steps? Yes, why not!
My idea is to contribute a tokenizer module to LangChain4j,
so that the Vertex AI Gemini and the Google AI Gemini modules can both import it,
instead of relying on remote endpoint calls to count tokens.

# AI Inktober — Generating ink drawings with Imagen 3


Every year, in October, takes place the [Inktober challenge](https://inktober.com/):
every day of the month, you have to do a drawing representing the word of the day.
The list of _prompts_ this year is the following:

![Inktober 2024 prompts](/img/ainktober/prompts.png)

I participated to some of the daily challenges the past few years, but I never did all of them.
But this year, for the fun, I thought I could ask Google's
[Imagen 3](https://deepmind.google/technologies/imagen-3/) image model to draw for me!
(Or at least to draw something I could try to reproduce.)

Of course, the goal of the challenge is not to generate images with the help of an AI.
On the contrary, the idea is about the pleasure you can have drawing yourself, with your own hands!
However, I was curious to see how Imagen would perform on such a challenge.

So I fired up my favorite Java AI framework: [LangChain4j](https://docs.langchain4j.dev/),
as it supports Imagen 3, as image model.

> **Note:** Imagen 3 is generally available on Google Cloud's Vertex AI platform, but it's behind an _allow list_.
> So you have to [request access](https://docs.google.com/forms/d/1cqt9padvfMgqn23W5FMPTqh7bW1KLkEOsC5G6uC-uuM/viewform) to be able to use it.

You will need the following dependency:

- For Gradle users:

```groovy
implementation 'dev.langchain4j:langchain4j-vertex-ai:0.35.0'
```

- For Maven users:

```xml
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-vertex-ai</artifactId>
    <version>0.35.0</version>
</dependency>
```

Now let's have a look at the code:

```java
import dev.langchain4j.data.image.Image;
import dev.langchain4j.model.output.Response;
import dev.langchain4j.model.vertexai.VertexAiImageModel;

import java.nio.file.Path;

public class AInktober {
    public static void main(String[] args) {
        VertexAiImageModel imagenModel = VertexAiImageModel.builder()
            .endpoint(System.getenv("GCP_VERTEXAI_ENDPOINT"))
            .location(System.getenv("GCP_LOCATION"))
            .project(System.getenv("GCP_PROJECT_ID"))
            .publisher("google")
            .modelName("imagen-3.0-fast-generate-001")
            .aspectRatio(VertexAiImageModel.AspectRatio.SQUARE)
            .negativePrompt("watercolor, gray shades")
            .persistTo(Path.of("/tmp/imagen"))
            .build();

        String prompt = """
            A black and white ink drawing of a
            backpack, on a fully white background
            """;

        Response<Image> imageResponse = imagenModel.generate(prompt);
        System.out.println(imageResponse.content().url());
    }
}
```

- I have set up several environment variables containing my Google Cloud project details.
- I decided to use `imagen-3.0-fast-generate-001`, which generates images faster (and cheaper!) than `imagen-3.0-generate-001`
  at the cost of a slightly lower quality (but for ink drawings, that's not really visible).
- I went with square images, but you can use landscape, portrait, and wider variants too.
- I added a negative prompt, because some images looked a bit more like watercolor at times, but I wanted images more black and white.
- I persist all the generated images into a temporary folder.
- My prompt contains the first subject of the day, a _"backpack"_, and I specify that I want a black and white ink drawing,
  but I also added that I wanted a white background, as sometimes the background can be fully black, or some sepia shade.

So what does the first image look like?

![Inktober 2024's backpack](/img/ainktober/ainktober-01-backpack.png)

It definitely looks like an ink drawing of a backpack!

Don't worry, I won't post a new article each day for the new daily image prompt.
Instead, I'll share the other days on my usual social media channels (see the bottom of the blog to find them out.)

Be sure to checkout Imagen 3, it's pretty good!

# Lots of new cool Gemini stuff in LangChain4j 0.35.0


While [LangChain4j](https://docs.langchain4j.dev/) 0.34 introduced my
[new Google AI Gemini module](http://localhost:1313/posts/2024/09/05/new-gemini-model-in-langchain4j/),
a new 0.35.0 version is already here today, with some more cool stuff for Gemini and Google Cloud!

Let's have a look at what's in store!

## Gemini 1.5 Pro 002 and Gemini 1.5 Flash 002

This week, [Google announced](https://developers.googleblog.com/en/updated-production-ready-gemini-models-reduced-15-pro-pricing-increased-rate-limits-and-more/)
the release of the new versions of the Google 1.5 models:
* `google-1.5-pro-002`
* `google-1.5-flash-002`

Of course, both models are supported by LangChain4j!
The Google AI Gemini module also supports the `gemini-1.5-flash-8b-exp-0924` 8-billion parameter model.

Versions `002` come with:
* much improved math and reasoning capabilities \
  (7%-20% increase depending on the benchmark),
* 2x faster output, and 3x lower latency,
* and also roughly a 50% price cut!

## Google Cloud Storage document loader

When implementing Retrieval Augmented Generation (RAG), you must load the documents from somewhere.
You can feed the docs directly in the context, but LangChain4j comes with the notion of [document loaders](https://docs.langchain4j.dev/tutorials/rag#document-loader).
There are existing document loaders for the file system, for files at remote URLs, or source files stored in Github.

In this release, I've implemented a **Google Cloud Storage document loader**,
which lets you reference documents stored inside cloud storage buckets.

Create a GCS document loader with the new builder:

```java
var gcsLoader = GoogleCloudStorageDocumentLoader.builder()
    .project(System.getenv("GCP_PROJECT_ID"))
    .build();
```

Then you can load a single document, and parse it:

```java
Document document = gcsLoader.loadDocument(
    "BUCKET_NAME", "FILE_NAME.txt", new TextDocumentParser());
```

All the documents in a bucket:

```java
List<Document> documents = gcsLoader.loadDocuments(
    "BUCKET_NAME", new TextDocumentParser());
```

Or just the a list of files filtered with a _glob_ pattern:

```java
List<Document> documents = gcsLoader.loadDocuments(
    "BUCKET_NAME", "*.txt", new TextDocumentParser());
```

## Vertex AI Ranking API

When implementing Retrieval Augmented Generation (RAG), your vector database returns a certain number of results.
They are usually sorted by vector similarity.
But it's not necessarily because the vectors have the highest similarity, that they are necessarily the best matches to answer a user query.
In order to palliate this problem, there are ranking or reranking APIs and models that exist to order results according to how well they match the query.

The Vertex AI platform from Google Cloud offers a [ranking API](https://cloud.google.com/generative-ai-app-builder/docs/ranking)
for that purpose, a little known API that deserves more awareness.
I implemented a `ScoringModel` for this Vertex AI Ranking API:

```java
VertexAiScoringModel scoringModel = VertexAiScoringModel.builder()
    .projectId(System.getenv("GCP_PROJECT_ID"))
    .projectNumber(System.getenv("GCP_PROJECT_NUMBER"))
    .projectLocation(System.getenv("GCP_LOCATION"))
    .model("semantic-ranker-512")
    .build();

Response<List<Double>> score = scoringModel.scoreAll(Stream.of(
        "The sky appears blue due to a phenomenon called Rayleigh " +
        "scattering. Sunlight is comprised of all the colors of " +
        "the rainbow. Blue light has shorter wavelengths than other " +
        "colors, and is thus scattered more easily.",

        "A canvas stretched across the day,\n" +
        "Where sunlight learns to dance and play.\n" +
        "Blue, a hue of scattered light,\n" +
        "A gentle whisper, soft and bright."
        ).map(TextSegment::from).collect(Collectors.toList()),
    "Why is the sky blue?");

// [0.8199999928474426, 0.4300000071525574]
```

In the example above, a user asks _why the sky is blue_.
The Ranking API attempts to determine which of two excerpts best matches this question.
The first excerpt appears to be an explanation of this celestial phenomenon, while the second sounds more like a poem.
When scoring these text fragments, we observe that the first one has a higher value (0.82 vs. 0.43).

It is also possible to score just one piece of text with the `score(text, query)` and `score(segment, query)` methods.

Now what's interesting is that this LangChain4j notion of scoring models is also well integrated in the RAG pipeline:

```java
VertexAiScoringModel scoringModel = VertexAiScoringModel.builder()
    .projectId(System.getenv("GCP_PROJECT_ID"))
    .projectNumber(System.getenv("GCP_PROJECT_NUM"))
    .projectLocation(System.getenv("GCP_LOCATION"))
    .model("semantic-ranker-512")
    .build();

ContentAggregator contentAggregator =
    ReRankingContentAggregator.builder()
        .scoringModel(scoringModel)
        ...
        .build();

RetrievalAugmentor retrievalAugmentor =
    DefaultRetrievalAugmentor.builder()
        ...
        .contentAggregator(contentAggregator)
        .build();

return AiServices.builder(Assistant.class)
    .chatLanguageModel(...)
    .retrievalAugmentor(retrievalAugmentor)
    .build();
```

When creating the AI service, you specify the chat model to use.
Additionally, you can integrate a _retrieval augmentor_, which allows you to configure a _content aggregator_.
The content aggregator, in turn, can specify a _scoring model_.
This process involves three steps, but it enables you to leverage the ranking of semantic search results when implementing RAG.
This means you can prioritize the most relevant results based on their semantic similarity, not solely on their vector similarity.

## New parameters for the Vertex AI embedding models

Embedding models are critical for RAG, and LangChain4j has had support for the Google Cloud Vertex AI embedding models for a long time.
But there are a couple of new flags that have recently been introduced:

```java
EmbeddingModel embeddingModel = VertexAiEmbeddingModel.builder()
    .project(PROJECT_ID)
    .location("us-central1")
    .publisher("google")
    .modelName(MODEL_NAME)
    .autoTruncate(true)
    .outputDimensionality(512)
```

The `autoTruncate(true)` method automatically truncates text to embed to a maximum of 2048 tokens.
If your input is longer than this limit, you would get an error from the model.
With auto-truncation, no more error, but if your text is truncated, you might miss a bit of meaning from the part that was cut off.

The other new method is `outputDimensionality(512)`.
The Vertex AI embedding models usually default to 768-dimensional vectors.
However, our [latest embedding models](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings)
are [_Matryoshka_ embedding models](https://huggingface.co/blog/matryoshka),
which means that the most meaningful values in the vector comes first.
So when you do vector comparisons, you can make calculations quicker if you focus on the lowest dimensions,
and with this new method, you can just return vectors with less dimensions directly.

## Google AI embedding model

Speaking of embedding models, if you use the Google AI Gemini model instead of the Vertex AI flavor,
you can now also access our embedding models without relying on the Vertex AI models,
thanks to the new embedding model for Google AI:

```java
var embeddingModel = GoogleAiEmbeddingModel.builder()
    .apiKey(GOOGLE_AI_GEMINI_API_KEY)
    .modelName("embedding-001")
    .maxRetries(3)
    .logRequestsAndResponses(true)
    .titleMetadataKey("title")
    .taskType(GoogleAiEmbeddingModel.TaskType.RETRIEVAL_DOCUMENT)
    .outputDimensionality(512)
    .build();
```

This new embedding model is the same as the one coming from Vertex AI, and has the same feature set.

## Google AI Gemini token count estimation and tokenizer

The Google AI Gemini model implements the `TokenCountEstimator` interface,
which means you can use the `estimateTokenCount()` method to count tokens:

```java
var gemini = GoogleAiGeminiChatModel.builder()
    .apiKey(GOOGLE_AI_GEMINI_API_KEY)
    .modelName("gemini-1.5-flash")
    .build();

int countedTokens = gemini.estimateTokenCount(
    "What is the capital of France?");
```

There is also now a `GoogleAiGeminiTokenizer` class, implementing the misnamed `Tokenizer` interface
(misnamed because it's not tokenizing text, it's just counting tokens):

```java
var geminiTokenizer = GoogleAiGeminiTokenizer.builder()
    .apiKey(GOOGLE_AI_GEMINI_API_KEY)
    .modelName("gemini-1.5-flash")
    .build();

int count = tokenizer.estimateTokenCountInText("Hello world!");
```

Note that both the `estimateTokenCount()` method and the `GoogleAiGeminiTokenizer` call a remote API endpoint.
They don't use a tokenizer class to count the tokens, so those calls incur some network hops.

What's interesting with the `Tokenizer`s is that they can be used by document splitters to split documents according to the number of tokens, rather than by characters or other boundaries:

```java
DocumentSplitter splitter = DocumentSplitters.recursive(
    maxSegmentSizeInTokens,
    maxOverlapSizeInTokens,
    geminiTokenizer);
```

Currently, only the Google AI module implements this `Tokenizer` interface, but it can be used with the Vertex AI Gemini module as well.
But later down the road, I think I'll also implement it for the Vertex AI module.

## Chat listener support

Both the Google AI Gemini and the Vertex AI modules implement the new chat listener support.

* Vertex AI Gemini:

```java
VertexAiGeminiChatModel.builder()
    .project(System.getenv("GCP_PROJECT_ID"))
    .location(System.getenv("GCP_LOCATION"))
    .modelName("gemini-1.5-pro-002")
    .listeners(singletonList(listener))
    .build();
```

* Google AI Gemini:

```java
GoogleAiGeminiChatModel.builder()
    .apiKey(System.getenv("GEMINI_API_KEY"))
    .modelName("gemini-1.5-flash-002")
    .listeners(singletonList(listener))
    .build();
```

Let's have a look at the listener interface, which allows you to listen to model requests, responses, and errors:

```java
public interface ChatModelListener {
  default void onRequest(ChatModelRequestContext reqContext) {...}
  default void onResponse(ChatModelResponseContext respContext) {...}
  default void onError(ChatModelErrorContext errContext) {...}
}
```

The various `*Context` parameters contain various details about how the model was parameterized, what the prompt was, or what error was encountered.

It might be interesting to follow the recent [OpenTelemetry GenAI recommendations](https://opentelemetry.io/docs/specs/semconv/gen-ai/)
and implement a listener that directly plugs into your observability solution!

## Enum structured output

I'll finish the laundry list of features with the **enum** structured output.

The Gemini models have great support for structured output.
Not only can you ask for JSON outputs, but you can also specify a JSON schema so that the model follows that schema for generating its JSON response.
This is of utmost importance for deterministic parseable results that fit well with your strongly typed programming language.

Gemini lets you return arbitray JSON objects and arrays.
But for tasks like classification or sentiment analysis, it is also able to return a single enum value, rather than a JSON object that would have a property containing the value.

* Vertex AI Gemini:

```java
 VertexAiGeminiChatModel model = VertexAiGeminiChatModel.builder()
    .project(System.getenv("GCP_PROJECT_ID"))
    .location(System.getenv("GCP_LOCATION"))
    .modelName(GEMINI_1_5_PRO)
    .responseSchema(Schema.newBuilder()
        .setType(Type.STRING)
        .addAllEnum(Arrays.asList("POSITIVE", "NEUTRAL", "NEGATIVE"))
        .build())
    .build();

Response<AiMessage> response = model.generate(asList(
    SystemMessage.from(
        "Your role is to analyse the sentiment of user's messages"),
    UserMessage.from(
        "This is super exciting news, congratulations!")
));

System.out.println(response.content().text());
// POSITIVE
```

* Google AI Gemini:

```java
GoogleAiGeminiChatModel gemini = GoogleAiGeminiChatModel.builder()
    .apiKey(System.getenv("GEMINI_API_KEY"))
    .modelName("gemini-1.5-flash")
    .responseFormat(ResponseFormat.builder()
        .type(JSON)
        .jsonSchema(JsonSchema.builder()
            .rootElement(JsonObjectSchema.builder()
                .properties(new LinkedHashMap<String, JsonSchemaElement>() {{
                    put("sentiment", JsonEnumSchema.builder()
                        .enumValues("POSITIVE", "NEUTRAL", "NEGATIVE")
                        .build());
                }})
                .build())
            .build())
        .build())
    .build();

ChatResponse response = gemini.chat(ChatRequest.builder()
    .messages(
        SystemMessage.from(
            "Your role is to analyse the sentiment of user's messages"),
        UserMessage.from(
            "This is super exciting news, congratulations!"
        )
    )
    .build());

System.out.println(response.aiMessage().text());
// POSITIVE
```

This is particularly useful for all sorts of classification tasks!

## Documentation updates

As I often used to say when working on the Apache Groovy project:

> "A feature doesn't exist if it's not documented."
>
> — Guillaume Laforge

With that motto in mind, I thought it was high time that I expanded the documentation for the Gemini related pages of the LangChain4j documentation:

* [Google Cloud Storage document loader](https://docs.langchain4j.dev/integrations/document-loaders/google-cloud-storage)
* [Google Cloud Ranking API](https://docs.langchain4j.dev/integrations/scoring-reranking-models/vertex-ai)
* [Vertex AI embedding models](https://docs.langchain4j.dev/integrations/embedding-models/google-vertex-ai)
* [Google AI Gemini models](https://docs.langchain4j.dev/integrations/language-models/google-ai-gemini)
* [Google Cloud Vertex AI Gemini models](https://docs.langchain4j.dev/integrations/language-models/google-vertex-ai-gemini)

## Tell me what you use LangChain4j's Gemini support for!

I'm really curious about what you are developing with LangChain4j, and even more so, if you're using the various Gemini components.
Don't hesitate to reach out to me, via the social media platforms mentioned below!
I'm also interested in the features you'd like to see prioritized and implemented.
# Some advice and good practices when integrating an LLM in your application


When integrating an LLM into your applicaton to extend it and make it smarter, it's important to be aware of the pitfalls and best practices you need to follow to avoid some common problems and integrate them successfully. This article will guide you through some key best practices that I've come across.

## Understanding the Challenges of Implementing LLMs in Real-World Applications

One of the first challenges is that LLMs are constantly being improved. This means that the model you start using could change under the hood, and suddenly your application doesn't work as it did before. Your prompts might need adjustments to work with the newer version, or worse, they might even lead to unintended results!

Furthermore, you need to consider how to effectively manage your prompts, especially when your applications start to get more complex. Prompts can easily become convoluted and difficult to modify. Imagine having to comb through a hundred lines of code in your application to find a specific prompt just to tweak a single word. That's why **prompt externalization** (not keeping your prompts inside your source files) is going to be important, to easily find your prompts, and have a birds-eye view of all of them!

Keeping track of changes and ensuring that the LLM's behavior remains consistent throughout your development process is another challenge. How can you ensure that a particular feature still functions correctly after upgrading your prompts, or even changing model versions? You need to **version your prompts** (we'll cover that in more details in a moment). Think of your prompts like code — just like your software code, prompts should have version control for easy management. Versioning ensures that you can quickly revert to previous versions if necessary, while providing a helpful audit trail to see exactly what changes have occurred in your prompt management process.

## Prompt Engineering for Consistent and Effective LLM Applications

You've probably noticed that one of the main things that determines how well your application works with a Large Language Model (LLM) is the _prompt_ you use to guide it. Prompts act like a guidebook for the LLM, explaining what you expect from it and how it should format its response. You've likely heard about the importance of using good prompts, but how do you go about creating prompts that are reliable and adaptable in the long run?

Think of your prompts like code artifacts. Just as you version your code to keep track of changes and ensure consistency, you should also version your prompts. This allows you to:

- **Keep track of your prompt evolution:** You'll have a clear record of how your prompts have changed over time, which helps you understand the application's evolving behavior.
- **Create a helpful audit trail:** Having versions of your prompts will help you understand exactly how the application behaved at specific times. This is essential for debugging, diagnosing issues, or understanding how user feedback impacted your application.
- **Enable rollbacks:** If you encounter an issue or want to test different prompt versions, you can easily revert to a previous state to ensure that you can isolate problems, revert to previously working versions, or simply experiment with different phrasing.

But simply versioning prompts isn't enough. Imagine you need to make a change to one particular prompt in a massive LLM-powered application. It might involve a lot of tedious code-hunting. That's where **prompt externalization**, that we mentioned earlier, comes in! Externalizing prompts is all about taking them out of your code and treating them like a separate configuration file. This way, they are:

- **Easy to modify:** Changing your prompts becomes a breeze. Just go to your external prompt file, make the adjustments, and you're ready to go! No more scouring through complex code to find a single prompt in some string variables somewhere.
- **More flexible:** By using externalized prompts, you can easily experiment with different versions or phrasing without rewriting your entire application. This lets you quickly adapt your prompts in response to user feedback or changes in your model.
- **Easier to manage:** Keeping prompts in their own dedicated file makes it easy to maintain them, making sure that your prompts are consistent and up-to-date. This approach becomes increasingly valuable as your applications become more complex and you have a growing set of prompts to maintain.

There are open source projects, or open formats that have emerged recently, to externalize prompts.
For examples Firebase's [GenKit](https://firebase.google.com/docs/genkit) LLM framework came up with their [dotPrompt](https://firebase.google.com/docs/genkit/dotprompt) format,
which not only externalizes the prompt itself, but also the name of the model, its configuration (temperature, etc.)

## Model Versioning: Preventing Surprises

Now let's cover the importance of managing model versions, a critical aspect of ensuring that your LLM-powered application continues to work reliably.

Imagine that you've built a great application using a particular model, and you're proud of the results. However, what happens when the LLM provider releases an updated version? It might offer performance improvements, but the updates can also change how the model responds to your prompts, potentially leading to unexpected issues or even breaking your application.

To avoid these unexpected changes, the key principle is to **pin the specific version of the LLM model** that you use for your application. For example, when using Gemini 1.5 Pro, if you use the version `gemini-1.5-pro`, you're actually using the latest version of the model. Currently, it's `gemini-1.5-pro-001`. But if tomorrow Google releases `gemini-1.5-pro-002`, your application would suddenly start using that new version. So be very explicit in the model version.

Here's why this is essential:

- **Avoid Drifting Model Behavior:** The update to an LLM might come with subtle changes that can lead to a shift in the model's responses, and you may not always be able to anticipate these changes beforehand. This can lead to inconsistency, where a prompt that generated a certain output in one version of the model generates a completely different (and perhaps undesirable) output in a newer version.
- **Maintain Application Consistency:** To keep your application performing reliably, you want to control the LLM’s responses as much as possible, and pinning the model version ensures that you can do this. If you're using a specific model, the prompts that are part of your application work in the context of that model's specific training and behaviors. Pinning the version helps you avoid unexpected changes that may interfere with your prompts' effectiveness.
- **Simplify Auditing and Debugging:** In case of an unexpected issue or an unexplained change in your LLM's behavior, being able to easily trace back the specific model version that's running provides invaluable context for debugging and understanding why those changes occurred. It helps isolate issues to specific model versions, so you can resolve them quicker.

While using the latest and greatest LLM version might seem tempting for its improved capabilities, remember: **the consistent performance and reliability of your application should be a top priority.** By pinpointing the model version you use, you gain better control over its behavior and maintain a smooth and predictable experience for your users.

## Optimizing for Efficiency: The Power of Response Caching

Even with well-crafted prompts, pinned versions, generating responses from a Large Language Model (LLM) can still be expensive. This is where **response caching** comes in, offering a crucial way to improve both the performance and the cost-efficiency of your application.

Models like [Gemini](https://deepmind.google/technologies/gemini/) support [context caching](https://cloud.google.com/vertex-ai/generative-ai/docs/context-cache/context-cache-overview). Quoting the documentation:

> Use context caching to reduce the cost of requests that contain repeat content with high input token counts. Cached context items, such as a large amount of text, an audio file, or a video file, can be used in prompt requests to the Gemini API to generate output. Requests that use the same cache in the prompt also include text unique to each prompt. For example, each prompt request that composes a chat conversation might include the same context cache that references a video along with unique text that comprises each turn in the chat. The minimum size of a context cache is 32,768 tokens.

By **caching frequently used responses** or heavy multimodal documents, you avoid having to generate them over and over again, leading to a dramatic improvement in performance and a reduction in LLM usage costs. Imagine users frequently asking the same question, like “What are the benefits of using your app?". By caching the response to this question, you'll be able to provide users with a fast and efficient response without burdening the LLM each time.

But how do you actually implement caching? You can choose different strategies for your caching system, each with its own benefits:

- **Context Caching:** If your model, like Gemini, supports caching already, be sure to understand how it works, what can be cached or not, the pros and cons, or potential limitations.
- **Basic Caching:** Store LLM responses based on the exact input. If you encounter a query that you've already generated, you can provide a pre-cached response, saving on processing time. You could also do some minimal string modifications to normalize whitespace, put everything in lowercase, etc, to get the chance to cache very similar prompts.
- **Advanced Caching with Similarity Search:** Even with string normalization, you might find that users don't always ask the exact same question, but the query can still be extremely similar. Think of typos, minor word substitutions, synonyms, or variations in punctuation. Instead of treating every query as unique, consider **approximate nearest neighbor search** and **embedding vector similarity**. This approach helps you find queries that are nearly identical, even with minor variations. You can then leverage this functionality to serve the same cached response for queries that are semantically similar, increasing the effectiveness of your caching strategy and ensuring that you only compute distinct queries once. For vector similarity, make sure to test with different inputs, to find the right threshold to say that a new prompt is equivalent to an older cached prompt/response pair.

Caching responses not only speeds up your LLM-powered application, lowering the perceived latency, but also significantly cuts down on LLM usage costs, helping you keep your application running smoothly while maximizing cost-effectiveness.

## Building Safeguards: Ensuring Robustness with Guardrails

Let's shift our focus to building safety mechanisms. This is crucial for creating reliable, trustworthy applications. Enter the concept of **guardrails**, which are safety systems designed to protect your application and users from unexpected, unwanted, or even harmful outcomes.

Think of guardrails like a protective fence, ensuring that the LLM stays within safe boundaries while performing its tasks. Imagine if someone tried to make an inappropriate request, or worse, a request that could cause harm. This is where guardrails step in.

Guardrails serve two main purposes:

- **Input Validation:** Guardrails can examine the user input and determine whether it's acceptable for your application and whether it aligns with your intended use case. Imagine preventing your LLM from processing prompts with malicious language or data that could cause harm to users.
- **Output Filtering:** Guardrails are not only for examining the user's input but also for checking the outputs of the LLM. By analyzing the LLM's generated responses, you can filter out inappropriate content or responses that don't meet your requirements.

What are the three primary types of guardrails?

- **Model's safety settings:** Models have usually been fine tuned to avoid certain harmful content in both input and output. They also give you access to safety settings, with different harm categories and safety thresholds. You should test those settings and how they can be configured for your use case. For example, have a look at the available [safety filters](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters) for Gemini.
- **Static Guardrails:** These are predefined rules that are set before the LLM begins to process any input. These can be rules that dictate certain formatting for prompts, limitations on input length, or even basic checks for prohibited terms or requests. Static guardrails offer fast processing times, since the checks are performed beforehand on the input strings, in your own code.
- **Dynamic Guardrails:** These are flexible guardrails that work in conjunction with the LLM or the embedding model used for text classification, continuously adapting to changes in user input or the output of the model itself. They allow you to handle complex or unpredictable situations and perform nuanced checks to maintain the safety and integrity of your application. You might have a look at Google Cloud Natural Language Processing's [moderation endpoint](https://cloud.google.com/natural-language/docs/moderating-text), or the free [Perspective API](https://perspectiveapi.com/) used by newspapers.

When you implement guardrails, it's also critical to consider performance impact. You want to make sure that these safeguards don't add too much latency and delay user experience. That's where **parallel processing** can come into play! Instead of waiting for the guardrail check to finish before starting the LLM generation, consider launching both tasks in parallel, optimizing speed and efficiency without sacrificing safety. Then, if the guardrails raise a red flag, you can stop the response generation, and reply right away to the user that the input content was problematic. For the response, unless you have a streaming kind of guardrail system, you might have to wait for the whole response to be generated before evaluating it with the guardrail, in which case, you can't really do parallel processing.

Always remember: Guardrails should be continuously refined and updated as you identify new potential risks. Gathering feedback from users, giving them the ability to report a bad response is one approach. But you should also monitor your application LLM responses to do some vibe-checks at random to ensure your application is behaving correctly.

## Evaluating and Monitoring for Consistent Performance

Onto the most crucial aspects of any application, regardless of its technology, is **evaluation and monitoring**. This is essential for ensuring your LLM-powered application continues to function reliably and meets your expectations as it interacts with users in the real world.

Imagine you make an update to your application, or perhaps even a simple tweak to one of your prompts. Without proper monitoring, you won't know if those changes had unintended consequences. You could end up with an app that gives unexpected results, leads to user frustration, or even creates unforeseen safety issues. That's where a robust evaluation and monitoring framework comes into play!

Your LLM-powered app needs a systematic way to ensure that everything is running smoothly and effectively. You need to:

- **Establish Evaluation Metrics:** You need clear guidelines to judge the LLM's performance. Think of key metrics like accuracy, relevance, and coherence.

  - **Accuracy:** This measures how often the LLM generates correct and factually accurate responses. This is particularly crucial if your application is designed for providing reliable information or carrying out fact-based tasks.
  - **Relevance:** You need to make sure the LLM stays focused on the core issue. It should respond to your prompts in a meaningful and helpful way, instead of giving irrelevant or off-topic responses.
  - **Coherence:** You need to check if the LLM produces well-written and logical text. Coherent responses are easily understood by users and don't leave them feeling confused or disoriented.

- **Gather User Feedback:** It's essential to go beyond just numbers. Your application's performance shouldn't just be evaluated on your own terms. Get feedback from the users, gather data on how they are using the application, and check their satisfaction with the outputs of your application. You can even ask users to provide their opinions on specific generated answers, giving you valuable insights into what resonates with them and how you can improve. Consider using tools like "thumbs up" or "thumbs down" buttons, offering an easy way for users to indicate their sentiment towards the LLM's responses, or a way to report and explain what wasn't up to the level of their expectations.

- **Build a “Golden Responses” Dataset:** Create a collection of carefully chosen inputs and their desired, accurate responses. These “golden” examples act like benchmarks, helping you measure how closely the LLM matches your expected results for specific tasks. By periodically checking how your LLM performs against these golden examples, you can get a clear picture of potential issues and make necessary adjustments. You can use this set as a starting point to track potential regressions and make sure the LLM's behavior is aligned with your expectations.

- **Implement Continuous Monitoring:** Monitoring shouldn't be a one-time event. It's an ongoing process, like keeping a watchful eye on your application as it functions in the real world. By monitoring in real-time, you can detect anomalies, unexpected issues, or performance regressions promptly. It allows you to address these issues before they cause significant problems for your users. Maybe checkout the recent [OpenTelemetry guidelines for Gen AI](https://opentelemetry.io/docs/specs/semconv/gen-ai/) to observe how your system and LLM are performing live.

You can further improve your LLM-powered application by analyzing the user's requests and responses generated by the LLM, especially those flagged by users as problematic or unexpected. These can be added to your collection of golden responses, constantly refining the process of evaluation. This helps your application evolve based on real-world interactions.

## Addressing Data Privacy Concerns

Another important topic to keep in mind: **data privacy**. LLMs have access to a vast amount of text data, which makes them incredibly powerful. But this same power brings with it the responsibility of safeguarding sensitive information. If your application handles user data, you need to ensure that you're handling it with utmost care, protecting it from unauthorized access and ensuring that you comply with relevant privacy regulations.

Think of data privacy as a trust contract. You, as the developer, are entrusted with safeguarding the sensitive information of your users. It's your responsibility to implement measures that keep this data secure and prevent breaches or misuse.

Here are some key steps to address data privacy concerns in your LLM application:

- **Implement strong security measures:** Use robust encryption methods to secure your application and data. Employ security best practices such as access controls, secure storage, and secure communication channels.
- **Stay aligned with data privacy regulations:** Comply with relevant privacy regulations like GDPR, CCPA, and HIPAA. You might need to review your data handling policies and make necessary adjustments.
- **Ensure data anonymization:** When working with sensitive data, always strive to anonymize or pseudonymize it to the fullest extent possible. You can utilize techniques like differential privacy, aggregation, or removing identifying details to protect user information (with [Google Cloud Data Loss Prevention](https://cloud.google.com/security/products/dlp) API for example).
- **Be transparent with users:** Communicate clearly with your users about how you collect, use, and store their data. Offer users options to control their data, and provide mechanisms to update or delete their information if needed.

By prioritizing data privacy in your LLM application, you not only uphold ethical standards but also build trust with your users. Your users should be confident that their information is being handled with respect and care, encouraging long-term trust in your application.

## Tailoring LLMs for Specific Business Goals

Remember that LLMs are tools, and the success of your LLM application ultimately hinges on aligning its capabilities with your unique goals and your target audience. So, how do you get the most out of an LLM in your business?

**First, define your goals.** What specific tasks can an LLM help you accomplish? What pain points are you trying to solve? Once you understand the big picture, you can break down those goals into actionable tasks that the LLM can potentially assist with.

**Then, it's time to find the right LLM for the job.** Not all LLMs are created equal. Different models excel at specific tasks, have varying levels of language support, and even require different levels of computational resources. For example, if your business uses many different languages, you’ll want an LLM with multilingual support.

To select the best LLM for your needs, ask yourself:

- **What specific task does this LLM need to perform?** Different LLMs excel at different tasks like text generation, summarization, or translation.
- **How does the LLM's accuracy compare with the level of accuracy required for your application?** The model needs to generate results with the appropriate level of precision for your goals.
- **How much computational power does it need to run this LLM?** Consider your budget and available infrastructure when making this selection, when hosting the model on your own. A cloud hosted model might be better (and cheaper) depending on your usage patterns, and if you don't want the hassle to handle your own infrastructure and GPUs.
- **What language capabilities does the LLM offer?** Is the model good at the languages you need to use, or are there specific domains where the model is particularly strong? It's not just about spoken languages, with code as well, some models maybe better dealing with a particular programming language than another one.

You can often find models with specialized skills. You may find, for example, a model trained on scientific papers if your work requires the processing of highly technical content, or a model trained on a particular field, such as text of laws, to be highly effective in that domain.

Once you’ve chosen your LLM, the next step could be **fine-tuning**, where you’d tailor the model to your specific needs. It’s like customizing a tool to do the exact job you need it to do. For example, imagine your application is helping people book vacations. You can train the model on a massive amount of vacation-related text data so it can accurately understand and respond to vacation-specific questions, making your application highly relevant for its intended purpose. But fine-tuning is not necessarily for the faint of heart, and can be complicated to do right.

While choosing and fine-tuning are critical steps, **assessing potential risks is equally important.** Think about potential unintended consequences. LLMs, for example, might not always be factual or accurate in their responses. You'll need to find ways to manage those potential issues, often incorporating guardrails to mitigate potential harms or biases, or implementing techniques like Retrieval Augmented Generation to ground the model's responses on your own data and documents.

Ultimately, you'll want to make your application a tool that not only works reliably but also gives real value to your business. By understanding your business goals, choosing the right model, customizing it effectively, and understanding the potential risks, you’re on the right path to success!

## Looking Ahead: Emerging Trends and Future Directions

Remember that this field is constantly changing! New capabilities are emerging, and existing models are getting even smarter and more efficient. This is an exciting time to be working with LLMs because the possibilities feel endless!

While it's fantastic to get your application off the ground using the latest LLMs, it's equally important to be open to continuous improvement. What's great today may not be optimal in the future. The world of LLMs is one where ongoing development is key! Here are a few tips:

- **Embrace continuous learning.** You should always be seeking out information about the newest developments in the field, how LLMs are being enhanced, and the impact those changes could have on your applications. Look out for improvements to existing models, new LLM models coming out, and fresh research.
- **Think ahead.** What new features could you integrate in your application that take advantage of those advancements? Would your app benefit from a specific, task-oriented model that focuses on summarization, question answering, or code generation? Maybe there's a model out there that will significantly boost performance and help you offer a smoother, more feature-rich experience for your users!
- **Prepare for evolution.** Remember that LLMs aren’t static! Your app should be built with a framework for easy adaptation. Consider how you can adapt to model updates or new model releases in a structured way, perhaps by putting in place frameworks for incorporating new models seamlessly and managing prompt changes for various models, like [LangChain4j](https://docs.langchain4j.dev/) (if you're a Java developer) which offers higher-level abstractions and that allows you to switch models easily.

The landscape of LLMs is evolving rapidly. Stay up-to-date with the latest developments and ensure your applications can adapt, allowing you to unlock the full potential of LLMs for your business!

# New Gemini model in LangChain4j


A new version of [LangChain4j](https://docs.langchain4j.dev/), the super powerful LLM toolbox for Java developers, was released today.
In [0.34.0](https://github.com/langchain4j/langchain4j/releases), a new Gemini model has been added.
This time, this is not the Gemini flavor from Google Cloud Vertex AI, but the [Google AI](https://ai.google.dev/gemini-api/) variant.

It was a frequently requested feature by LangChain4j users,
so I took a stab at developing a new chat model for it, during my summer vacation break.

## Gemini, show me the code!

Let's dive into some code examples to see it in action!

But first, you'll need an API key.
So just follow the instructions to [obtain your Gemini API key](https://ai.google.dev/gemini-api/docs/api-key).
I've saved mine in the `GEMINI_AI_KEY` environment variable,
so that I don't have to hardcode it in my source files.

The code examples below have been compiled with Java 21.

I've imported the following libraries in my build tool:

- `dev.langchain4j:langchain4j-google-ai-gemini:0.34.0`
- `dev.langchain4j:langchain4j-core:0.34.0`
- `dev.langchain4j:langchain4j:0.34.0`

### Let's be polite and say hello

My mom always told me to be polite and to say hello:

```java
ChatLanguageModel gemini = GoogleAiGeminiChatModel.builder()
    .apiKey(System.getenv("GEMINI_AI_KEY"))
    .modelName("gemini-1.5-flash")
    .build();

String response = gemini.generate("Konnichiwa Gemini!");

System.out.println("Gemini> " + response);
// Gemini> Konnichiwa! It's nice to hear from you.
//         What can I do for you today?
```

### Don't you like strawberries?

In the first example, I used the usual `generate()` method to send my greeting to Gemini.
But LangChain4j 0.34 introduces some new signatures and classes to interact with an LLM:

- `ChatRequest`: a new class that contains your conversation messages,
  the tools this request can use, and a response format definition to decide
  what should be the shape of the output
- `ChatResponse`: this class holds the LLM's response, the token usage information,
  and the _finish_ reason (ie. if the response was cut, filtered, or was generated till the end)
- `ChatResponse chat(ChatRequest req)`: this new method is added to the LLM contract to interact with it.

```java
ChatLanguageModel gemini = GoogleAiGeminiChatModel.builder()
    .apiKey(System.getenv("GEMINI_AI_KEY"))
    .modelName("gemini-1.5-flash")
    .build();

ChatResponse chatResponse = gemini.chat(ChatRequest.builder()
    .messages(UserMessage.from(
        "How many R's are there in the word 'strawberry'?"))
    .build());

String response = chatResponse.aiMessage().text();

System.out.println("Gemini> " + response);
// Gemini> There are **three** R's in the word "strawberry".
```

### Let's roll the JSON dice!

Both Gemini 1.5 Flash and Pro allow you to specify that the output should be valid JSON.
It's sometimes called the **JSON mode**.

```java
ChatLanguageModel gemini = GoogleAiGeminiChatModel.builder()
    .apiKey(System.getenv("GEMINI_AI_KEY"))
    .modelName("gemini-1.5-flash")
    .responseMimeType("application/json")
    .build();

String roll = gemini.generate("Roll a 6-sided dice");

System.out.println(roll);
// {"roll": "3"}
```

Gemini will always reply with valid JSON structures.

Here, the JSON object key is not always `roll`, and is sometimes `die`, `dice_roll`, etc.
But you could tweak your prompt to ask for a specific key name.

Gemini follows the instructions very precisely, but it's not guaranteed 100% that it will really use the requested key name.
But fear not, there's an even more powerful solution, thanks to response formats!

### Let's cook something with our strawberries

You can configure Gemini to make it generate outputs that comply with a JSON schema.
It's sometimes called **controlled generation**, or **constrained decoding**.

Let's say we have a schema that represents recipes!
It's time to do something with our strawberries!

```java
ChatLanguageModel gemini = GoogleAiGeminiChatModel.builder()
    .apiKey(System.getenv("GEMINI_AI_KEY"))
    .modelName("gemini-1.5-flash")
    .responseSchema(JsonSchema.builder()
        .rootElement(JsonObjectSchema.builder()
            .properties(Map.of(
                "title", JSON_STRING_SCHEMA,
                "preparationTimeMinutes", JSON_INTEGER_SCHEMA,
                "ingredients", JsonArraySchema.builder()
                    .items(JSON_STRING_SCHEMA)
                    .build(),
                "steps", JsonArraySchema.builder()
                    .items(JSON_STRING_SCHEMA)
                    .build()
                ))
            .build())
        .build())
    .build();

String recipeResponse = gemini.generate(
    "Suggest a dessert recipe with strawberries");

System.out.println(recipeResponse);

/*
{"ingredients": ["1 pint fresh strawberries, hulled and sliced",
"1/2 cup sugar", "1/4 cup water", "1 tablespoon lemon juice",
"1/2 teaspoon vanilla extract", "1 cup heavy cream, whipped"],
"preparationTimeMinutes": 30, "steps": ["In a saucepan, combine
the sugar, water, and lemon juice. Bring to a boil over medium
heat, stirring until the sugar is dissolved.", "Reduce the heat
to low and simmer for 5 minutes, or until the syrup thickens
slightly.", "Remove from heat and stir in the vanilla extract.",
"Pour the syrup over the strawberries in a bowl and stir to coat.",
"Refrigerate for at least 30 minutes, or until chilled.",
"To serve, top the strawberries with whipped cream and enjoy!"],
"title": "Strawberry Shortcake"}
 */
```

Gemini strictly follows the specified JSON schema, and generates a JSON object that matches.

This is particularly important when you integrate LLMs in your application.
You want a deterministic format for the output that can easily be parsed and handled by your system.

### Tasty strawberries from Japan!

A few months back, I had the chance to visit Japan with my family,
and they have some really gorgeous and tasty strawberries there!
And don't get me started on strawberry daifukus (mochis with fruits inside) we had in Osaka!

But before tasting those lovely confections, we need to plan our trip to Japan.

In the previous example, you might have found that a bit painful to describe the JSON schema.
For the integration in a Java application, you might have some more complex data structures to represent,
so deriving the big schema to define them can be tedious.
Fortunately, there's a little trick to get the JSON schema for a Java class (or record, enum, etc.).

Let's define and describe our trip itinerary object:

```java
@Description("details of a trip itinerary")
record TripItinerary(
    String country,
    Integer numberOfPersons,
    Month month,
    @Description("key highlights when visiting the city")
    List<CityHighlights> cityHighlights
) {
    enum Month {
        JANUARY, FEBRUARY, MARCH, APRIL, MAY, JUNE, JULY,
        AUGUST, SEPTEMBER, OCTOBER, NOVEMBER, DECEMBER
    }

    record CityHighlights(
        String cityName,
        List<String> visitHighlights
    ) { }
}
```

The itinerary is represented by some records, enums, and lists,
and the `@Description` annotation can help the LLM to better understand what some elements might be about
(in particular when you have some cryptic field names, but here,
it's not strictly necessary as Gemini is smart enough to understand what each field is about)

Now let's ask for our Japan itinerary:

```java
ChatLanguageModel gemini = GoogleAiGeminiChatModel.builder()
    .apiKey(System.getenv("GEMINI_AI_KEY"))
    .modelName("gemini-1.5-flash")
    .temperature(2.0)
    .responseSchema(jsonSchemaFrom(TripItinerary.class).get())
    .build();
```

We derive the JSON schema from the `TripItinerary` class.
No need to tediously craft a JSON schema for it.

Let's see what Gemini suggests for our visit:

```java
Response<AiMessage> tripResponse = gemini.generate(
    SystemMessage.from("You are an expert trip planner"),
    UserMessage.from("""
        Suggest an itinerary for Japan.
        Cities visited: Tokyo, Kyoto, Osaka.
        Trip for a family of 4 persons.
        Provide key highlights for each city visited.
        """)
);
```

We tell Gemini to act as an expert trip planner, and we give some details about the travellers, the cities we'd like to visit.

So what's the JSON structured output for this Japan visit?

```java
System.out.println(tripResponse);
/*
{"cityHighlights": [{"cityName": "Tokyo", "visitHighlights":
["Explore the vibrant Shibuya Crossing and the iconic Shibuya
Scramble.", "Visit the Meiji Jingu Shrine, a serene oasis in
the heart of Tokyo.", "Experience the fascinating world of
technology at the Miraikan National Museum of Emerging Science
and Innovation.", "Enjoy a traditional tea ceremony at one of
Tokyo's many teahouses.", "Get lost in the eclectic streets
of Harajuku and admire the unique fashion styles.", "Embark
on a scenic boat trip on the Sumida River, passing by Tokyo
Skytree.", "Indulge in a delightful sushi dinner at a renowned
Tsukiji Fish Market.", "Discover the charm of Ueno Park, home
to museums, temples, and the Ueno Zoo."]}, {"cityName": "Kyoto",
"visitHighlights": ["Wander through the serene gardens of the
Golden Pavilion (Kinkaku-ji).", "Immerse yourselves in the rich
history of the Kiyomizu-dera Temple, famous for its wooden stage.",
"Explore the ancient Gion district, known for its traditional
wooden buildings and geisha houses.", "Stroll through the Fushimi
Inari Shrine, famous for its thousands of red torii gates.",
"Discover the treasures of the Nishiki Market, offering a diverse
selection of food and crafts.", "Experience a traditional geisha
performance at one of Kyoto's exclusive theaters.", "Learn the
art of calligraphy at a traditional workshop in the Gion district.",
"Relax in the serene atmosphere of the Ryoan-ji Zen Garden.",
"Witness the beauty of the Arashiyama Bamboo Grove."]},
{"cityName": "Osaka", "visitHighlights": ["Experience the vibrant
Dotonbori district, renowned for its neon lights, street food,
and entertainment.", "Explore the Osaka Castle, a historic
landmark and symbol of the city.", "Enjoy the breathtaking
panoramic views from the Abeno Harukas, Japan's tallest
skyscraper.", "Visit the Osaka Aquarium Kaiyukan, home to diverse
marine life from around the world.", "Stroll through the lively
Kuromon Market, known for its fresh seafood and local produce.",
"Take a scenic ride on the Osaka Ferris Wheel, offering views of
the cityscape.", "Indulge in the delicious okonomiyaki, Osaka's
signature dish.", "Experience the unique culture of the Sumiyoshi
Taisha Shrine, dedicated to the gods of seafaring."]}],
"country": "Japan", "month": "MARCH", "numberOfPersons": 4}
 */
```

Damn! It didn't even mention the most delicious daifukus we had in Osaka!

### Can I go outside without my umbrella in Osaka, tonight?

Speaking of visiting Osaka and those great daifukus, what's the weather like there?
It's been raining a lot in Paris today, so I'm curious if it's better in Osaka.

This new Gemini chat model works with LangChain4j's higher-level abstractions: `AiServices`,
to create some very powerful LLM based apps, like smart agents or RAG (Retrieval Augmented Generation).

We'll have a look at a great use case for LLMs: **data extraction from free-form text**.

Let's define and describe a weather forecast record:

```java
record WeatherForecast(
    @Description("minimum temperature")
    Integer minTemperature,
    @Description("maximum temperature")
    Integer maxTemperature,
    @Description("chances of rain")
    boolean rain
) { }
```

We'll also create an interface for our weather service contract:

```java
interface WeatherForecastAssistant {
    WeatherForecast extract(String forecast);
}
```

Let's configure Gemini, instantiate our weather assistant,
and extract the weather forecast from today's newspaper:

```java
ChatLanguageModel gemini = GoogleAiGeminiChatModel.builder()
    .apiKey(System.getenv("GEMINI_AI_KEY"))
    .modelName("gemini-1.5-flash")
    .build();

WeatherForecastAssistant forecastAssistant =
    AiServices.builder(WeatherForecastAssistant.class)
        .chatLanguageModel(gemini)
        .build();

WeatherForecast forecast = forecastAssistant.extract("""
    Morning: The day dawns bright and clear in Osaka, with crisp
    autumn air and sunny skies. Expect temperatures to hover
    around 18°C (64°F) as you head out for your morning stroll
    through Namba.
    Afternoon: The sun continues to shine as the city buzzes with
    activity. Temperatures climb to a comfortable 22°C (72°F).
    Enjoy a leisurely lunch at one of Osaka's many outdoor cafes,
    or take a boat ride on the Okawa River to soak in the beautiful
    scenery.
    Evening: As the day fades, expect clear skies and a slight chill
    in the air. Temperatures drop to 15°C (59°F). A cozy dinner at a
    traditional Izakaya will be the perfect way to end your day in
    Osaka.
    Overall: A beautiful autumn day in Osaka awaits, perfect for
    exploring the city's vibrant streets, enjoying the local cuisine,
    and soaking in the sights.
    Don't forget: Pack a light jacket for the evening and wear
    comfortable shoes for all the walking you'll be doing.
    """);

System.out.println("Gemini> " + forecast);
// Gemini> WeatherForecast[
//             minTemperature=15,
//             maxTemperature=22,
//             rain=false]
```

Awesome, no need for my umbrella!

What's great here is that we're dealing with a real type-safe Java object, not JSON strings like before.
So it integrates very well within our Java codebase!

### Time for a little coding quiz

Alright, after the touristic detour, let's get back to some math, and some coding.
LLMs are quite good at reasoning, in particular when you encourage them to think _step by step_.
But sometimes, they fall short, and can't really calcuate results.
They're language models, not calculators, right?

Gemini has the ability to create some Python scripts, and to execute them in a sandbox.
So how can we configure Gemini for solving a little math problem?

```java
ChatLanguageModel gemini = GoogleAiGeminiChatModel.builder()
    .apiKey(System.getenv("GEMINI_AI_KEY"))
    .modelName("gemini-1.5-flash")
    .allowCodeExecution(true)
    .includeCodeExecutionOutput(true)
    .build();
```

There are 2 builder methods:

- `allowCodeExecution(true)`: to let Gemini know it can do some Python coding
- `includeCodeExecutionOutput(true)`: if you want to see the actual Python script it came up with, and the output of its execution

Do you know off head how much is `fibonacci(22)` or `ackermann(3, 4)`?
Let's ask Gemini:

```java
Response<AiMessage> mathQuizz = gemini.generate(
    SystemMessage.from("""
        You are an expert mathematician.
        When asked a math problem or logic problem,
        you can solve it by creating a Python program,
        and execute it to return the result.
        """),
    UserMessage.from("""
        Implement the Fibonacci and Ackermann functions.
        What is the result of `fibonacci(22)` - ackermann(3, 4)?
        """)
);
```

Looks like Gemini is a Python and math wiz:

````
Code executed:
```python
def fibonacci(n):
    if n <= 1:
        return n
    else:
        return fibonacci(n-1) + fibonacci(n-2)

def ackermann(m, n):
    if m == 0:
        return n + 1
    elif n == 0:
        return ackermann(m - 1, 1)
    else:
        return ackermann(m - 1, ackermann(m, n - 1))

print(fibonacci(22) - ackermann(3, 4))
```
Output:
```
17586
```
The result of `fibonacci(22) - ackermann(3, 4)` is **17586**.

I implemented the Fibonacci and Ackermann functions in Python.
Then I called `fibonacci(22) - ackermann(3, 4)` and printed the result.
````

If you don't include the script code and output, you would receive only the end of the message:

```
The result of `fibonacci(22) - ackermann(3, 4)` is **17586**.

I implemented the Fibonacci and Ackermann functions in Python.
Then I called `fibonacci(22) - ackermann(3, 4)` and printed the result.
```

I didn't encounter any snake in Japan, but I'm happy Gemini can write some Python functions when needed!

### What about the weather in Tokyo?

Besides this Python code execution sandbox, the more traditional **function calling** mechanism works.
We heard about the weather in Osaka, now let's ask for Tokyo.

Let's define a _tool_ to retrieve structured weather forecasts:

```java
record WeatherForecast(
    String location,
    String forecast,
    int temperature) {}

class WeatherForecastService {
    @Tool("Get the weather forecast for a location")
    WeatherForecast getForecast(
        @P("Location to get the forecast for") String location) {
        if (location.equals("Paris")) {
            return new WeatherForecast("Paris", "sunny", 20);
        } else if (location.equals("London")) {
            return new WeatherForecast("London", "rainy", 15);
        } else if (location.equals("Tokyo")) {
            return new WeatherForecast("Tokyo", "warm", 32);
        } else {
            return new WeatherForecast("Unknown", "unknown", 0);
        }
    }
}
```

We need a weather forecast assistant as well, that we'll instantiate and configure with our tool, thanks to `AiServices`:

```java
interface WeatherAssistant {
    String chat(String userMessage);
}

WeatherForecastService weatherForecastService =
    new WeatherForecastService();

ChatLanguageModel gemini = GoogleAiGeminiChatModel.builder()
    .apiKey(System.getenv("GEMINI_AI_KEY"))
    .modelName("gemini-1.5-flash")
    .temperature(0.0)
    .build();

WeatherAssistant weatherAssistant =
    AiServices.builder(WeatherAssistant.class)
        .chatLanguageModel(gemini)
        .tools(weatherForecastService)
        .build();

String tokyoWeather = weatherAssistant.chat(
        "What is the weather forecast for Tokyo?");

System.out.println("Gemini> " + tokyoWeather);
// Gemini> The weather forecast for Tokyo is warm
//         with a temperature of 32 degrees.
```

I didn't expect such warm temperatures in Tokyo!
Well, of course, it's all fake, but you can imagine calling a real weather service.

The beauty of LangChain4j's `AiServices` is that it handles calling the service for you.
Usually, with function calling, the LLM just replies with a request that says _you_ should be calling a tool or API,
and give it back the tool/API's answer.
Here, with `AiServices`, it's all automatic and transparent.

### Of parrots pictures, text files, and multimodality

Let's finish our whirlwind tour of this Google AI Gemini model for LangChain4j
with an example that highlights **Gemini's multimodal capabilities**.

Gemini is a multimodal LLM: in input, in addition to text, it accepts pictures, videos, audio, PDF files, and text files.

Let's ask what Gemini thinks of the cute colorful parrot mascot of LangChain4j.

```java
// README.md markdown file from LangChain4j's project Github repos
String base64Text = b64encoder.encodeToString(readBytes(
  "https://github.com/langchain4j/langchain4j/blob/main/README.md"));

// PNG of the cute colorful parrot mascot of the LangChain4j project
String base64Img = b64encoder.encodeToString(readBytes(
  "https://avatars.githubusercontent.com/u/132277850?v=4"));

ChatLanguageModel gemini = GoogleAiGeminiChatModel.builder()
    .apiKey(System.getenv("GEMINI_AI_KEY"))
    .modelName("gemini-1.5-flash")
    .build();

Response<AiMessage> response = gemini.generate(
    UserMessage.from(
        TextFileContent.from(base64Text, "text/x-markdown"),
        ImageContent.from(base64Img, "image/png"),
        TextContent.from("""
            Do you think this logo fits well
            with the project description?
            """)
    )
);

System.out.println("Gemini> " + response);
/*
   Gemini> The logo of a parrot drinking tea doesn't seem like a
   good fit for a project description of a Java version of LangChain.
   It's not clear how the logo relates to the project's purpose or
   functionality. A logo that better reflects the project's technical
   nature, such as a stylized representation of code or a language
   model, would be more appropriate.
 */
```

Ah well, looks like LLM don't want to be compared to _stochastic parrots_,
so it thinks the parrot mascot doesn't represent the project well enough!

Sorry Gemini, I have to disagree, I really love this logo!

This example shows that you can craft an elaborate prompt that contains a text query,
an external text file (the description of the project in Markdown format),
and the picture of the parrot mascot.

## Let's wrap up — with beautiful 'furoshiki' fabric!

Throughout this journey through code examples, strawberries, daifukus, Japan itineraries and weather forecasts,
you learned about the brand new LangChain4j module for Google AI's Gemini API, and its capabilities.
I hope this article makes you want to try it out!

Before calling it a day or night (depending on your timezone), I'd like to mention some limitations,
as it's still early days for this new module:

- Currently, there's only a `ChatLanguageModel` available,
  but no `StreamingChatLanguageModel` class, so you won't get streamed responses yet.
- Gemini's content caching capability is not surfaced in this implementation,
  so you can't use caching to save some bucks or yens.
- For multimodality, you should pass the Base64 encoded bytes of the files, and not use URLs to reference those resources,
  as this module doesn't yet upload files to Gemini's file service (Gemini won't download from an external URL).

Hopefully, the community will adopt this module, work with it, provide feedback to help us improve it further!
Don't hesitate to reach out with questions or to report any problems you encounter.
And if you build something cool, please tell me too!

# A retryable JUnit 5 extension for flaky tests


As I work a lot with Large Language Models (LLMs), I often have to deal with flaky test cases,
because LLMs are not always consistent and deterministic in their responses.
Thus, sometimes, a test passes maybe a few times in a row, but then, once in a while, it fails.

Maybe some prompt tweaks will make the test pass more consistently, lowering the temperature too,
or using techniques like few-shot prompting will help the model better understand what it has to do.
But in some circumenstances, you can't find ways around those weird failures,
and the sole solution I found was to make a test _retryable_.

If a test fails, let's retry a few more times (2 or 3 times) till it passes.
But if it fails everytime in spite of the retries, then it'll just fail as expected.

I wrote JUnit _Rules_ in the past for such situations, but that was in the JUnit 4 days.
Now, I'm using JUnit 5, and although it's possible to make JUnit 4 tests run under JUnit 5,
I thought it was a great opportunity to try creating a JUnit 5 _extension_,
which is the more powerful mechanism that replaces JUnit 4 rules.

## It all starts with a failing test case

Let's say you have an hypothetical flaky test that fails a few times in a row:

```java
    private static int count = 1;
    @Test
    void test_custom_junit_retry_extension() {
        assertThat(count++).isEqualTo(4);
    }
```

The first 3 executions will see an assertion failure, but the 4th would succeed
as the counter is then equal to `4`.

I'd like to annotate this test method with a custom annotation that indicates the number of times I'm ready to retry that test:

```java
    private static int count = 1;
    @Test
    @ExtendWith(RetryExtension.class)
    @Retry(4)
    void test_custom_junit_retry_extension() {
        assertThat(count++).isEqualTo(4);
    }
```

This `@ExtendWith()` annotation indicates that I'm registering a JUnit 5 extension.
And `@Retry(4)` is a custom annotation that I've created.

Note that `@ExtendWith()` can be at the class-level, but it can also live at the method level.

Let's have a look at the `@Retry` annotation:

```java
import java.lang.annotation.Retention;
import java.lang.annotation.RetentionPolicy;

@Retention(RetentionPolicy.RUNTIME)
public @interface Retry {
    int value() default 3;
}
```

By default, I attempt the test 3 times, if no number is provided for the annotation value.

Now it's time to see how the extension code works:

```java
import org.junit.jupiter.api.extension.ExtensionContext;
import org.junit.jupiter.api.extension.TestExecutionExceptionHandler;

import java.util.concurrent.atomic.AtomicInteger;

public class RetryExtension implements TestExecutionExceptionHandler {

    private final AtomicInteger counter = new AtomicInteger(1);

    private void printError(Throwable e) {
        System.err.println(
            "Attempt test execution #" + counter.get() +
            " failed (" + e.getClass().getName() +
            "thrown):  " + e.getMessage());
    }

    @Override
    public void handleTestExecutionException(
        ExtensionContext extensionContext, Throwable throwable)
        throws Throwable {

        printError(throwable);

        extensionContext.getTestMethod().ifPresent(method -> {
            int maxExecutions =
                method.getAnnotation(Retry.class) != null ?
                method.getAnnotation(Retry.class).value() : 1;

            while (counter.incrementAndGet() <= maxExecutions) {
                try {
                    extensionContext.getExecutableInvoker().invoke(
                        method,
                        extensionContext.getRequiredTestInstance());
                    return;
                } catch (Throwable t) {
                    printError(t);

                    if (counter.get() >= maxExecutions) {
                        throw t;
                    }
                }
            }
        });
    }
}
```

Let's go through the code step by step:
* The extension has a counter to count the number of executions
* a `printError()` method is used to report the assertion failure or exception
* The class implements the `TestExecutionExceptionHandler` interface
* That interface requires the method `handleTestExecutionException()` to be implemented
* This method is invoked when a test throws some exception
* If an exception is thrown, let's see if the method is annotated with the `@Retry` annotation
* and let's retrieve the number of attempts demanded by the developer
* Then let's loop to do some more executions of the test method, until it passes or up to the number of attempts

## Missing standard JUnit 5 extension?

I thought a `@Retry` extension would be pretty common, and that it would be integrated in JUnit 5 directly.
Or at least, some library would provide common JUnit 5 extensions?
But my search didn't yield anything meaningful.
Did I overlook or miss something?

At least now, I have a solution to work around some flaky tests, thanks to this retryable extension!

## Going further

If you want to learn more about JUnit 5 extensions,
there were a few resources that helped me develop this extension.
First of all, two artciles from Baeldung on
[Migrating from JUnit 4 to JUnit 5](https://www.baeldung.com/junit-5-migration)
to understand the changes since JUnit 4, and this
[Guide to JUnit 5 Extensions](https://www.baeldung.com/junit-5-extensions).
And of course, the JUnit 5 documentation on
[extensions](https://junit.org/junit5/docs/current/user-guide/#extensions).

> ## Update
>
> I'm glad I shared this article on Twitter, because I immediately got a response!
> Thanks [@donal_tweets](https://x.com/donal_tweets)
> for your [answer](https://x.com/donal_tweets/status/1830260408462221622)!
>
> The [JUnit Pioneer](https://junit-pioneer.org/) library provides a JUnit 5 extension pack,
> which includes a powerful [retrying extension](https://junit-pioneer.org/docs/retrying-test/).
> Replace the usual `@Test` annotation with `@RetryingTest`.
> You can specify the number of attempts, the minimum number of successes, or some wait time before retries.
>
> There's also a [rerunner](https://github.com/artsok/rerunner-jupiter) extension that is quite similar.
>
> My friend [@aheritier](https://x.com/aheritier) also suggested that
> Maven Surefire can be configured to automatically
> [retry failing tests](https://maven.apache.org/surefire/maven-surefire-plugin/examples/rerun-failing-tests.html)
> a few times, thanks to a special flag:
> ```
> mvn -Dsurefire.rerunFailingTestsCount=2 test
> ```
> In my case, I don't want to retry all failing tests, but only a specific one that I know is flaky.
>
> For those who prefer Gradle over Maven, there's a Gradle plugin as well:
> [test-retry](https://github.com/gradle/test-retry-gradle-plugin).
> You can configure the behavior in your `build.gradle` file:
> ```groovy
> test {
>    retry {
>        maxRetries = 2
>        maxFailures = 20
>        failOnPassedAfterRetry = true
>    }
> }
> ```
>
> Someone also suggested me to use fuzzy assertions, but my test is very binary as it either fails or succeeds.
> There's no threshold, or value that would fit within some bounds.
# Let LLM suggest Instagram hashtags for your pictures


In this article, we'll explore another great task where Large Language Models shine: **entity and data extraction**.
LLMs are really useful beyond just mere chatbots (even smart ones using Retrieval Augmented Generation).

Let me tell you a little story of a handy application we could build, for wannabe Instagram influencers!

## Great Instagram hashtags, thanks to LLMs

When posting Instagram pictures, I often struggle with finding the right hashtags to engage with the community.
Large Language Models are pretty creative, and they've certainly seen a bunch of Instagram pictures with their descriptions.

So it's natural to try asking an AI like [Gemini](https://gemini.google.com/app) what it could suggest in terms of hashtags:

![Gemini Instagram Hashtag suggestion](/img/gemini/gemini-instagram-hashtags.png)

This is a picture taken in the port of Heraklion in Crete, a Greek island.
Here's the [conversation](https://g.co/gemini/share/476eb5dd974a) I had with Gemini, if you want to see all the tags it suggested.
I think you'll agree with me that those hashtags look pretty good.
Gemini was able to recognise where the picture was taken, as it had tags like `#heraklion`, `#crete`, `#greece`, `#greekisland`, etc.
In another attempt, it even told me the name of the fortress of the Venetian port, and suggested other tags along those lines.
We also have several tags typically found on Instagram, like `#travelgram`, `#instatravel`, and more specific tags like `#cretephotography`.

My developer mind started quickly spinning with ideas of an online tool to help users be more creative with their instagram tags.
Armed with my usual tools of trade: Java, and [LangChain4j](https://docs.langchain4j.dev/),
I tried to see how I could implement such a tool.

When you want to integrate an LLM into an application, it's important to be able to use more structured outputs than plain text.
And what's great with the Gemini 1.5 Flash model is that it can generate a JSON response,
and Gemini 1.5 Pro can even follow a specific JSON schema
(also called [controlled generation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/control-generated-output)).

## Let's implement an Instagram hashtag generator

First, let's see what the Gemini API responds with a plain prompt, without trying to return some JSON payload:

```java
var modelCreative = VertexAiGeminiChatModel.builder()
    .project(PROJECT_ID)
    .location(LOCATION)
    .modelName("gemini-1.5-flash")
    .build();

List<ChatMessage> messages = new ArrayList<>();
messages.add(SystemMessage.from("""
    You are an Instagram influencer and expert.
    You master the fine art of choosing the best creative hashtags
    to share users' best pictures, and to ensure engagement with
    the Instagram community is the highest possible.
    """));
messages.add(UserMessage.from(
    ImageContent.from(
      Paths.get("src/main/resources/travel-picture.jpg").toUri()),
    TextContent.from(
      "What are the best Instagram hashtags to describe that picture?")
));

Response<AiMessage> response = modelCreative.generate(messages);
String responseText = response.content().text();

System.out.println(responseText);
```

- First, we instantiate a Vertex AI Gemini chat model
- We prepare a list of messages: one system message to describe the task the LLM must achieve, and one compound message made of the picture and the request to generate hashtags for it. Gemini is a **multimodal** model that accepts text, but also images, audios, videos, and PDF files.
- Then we ask Gemini to generate a response, which we then print.

The Gemini LLM API will reply with a nice and creative response suggesting lots of great hashtags, along with some interesting explanations:

```
Here are some relevant hashtags for your picture:

**General Hashtags:**
#greece #greekislands #crete #creteisland #cretelife #holiday #travel
#vacay #instatravel #travelgram #beautifuldestinations
#travelphotography #photooftheday #instagood #igdaily #instapic

**Specific Hashtags:**
#heraklion #heraklioncrete #venetianharbour #harbourlife #boatlife
#boatday #greekboats #greekharbour #beautifulcrete #creteharbour
#cretevibes #greece_gram #crete_gram #greece_travel

**Trending Hashtags:**
#wanderlust #traveltuesday #instagood #travelgram
#beautifuldestinations #adventuretime

**Hashtags for Engagement:**
#explorecrete #cretelove #lovegreece #greecevibes #cretephoto
#creteexperience #discovercrete

Make sure to also use a mix of hashtags with different lengths and
popularity. You can also use location hashtags to target people in
your area.

For example, you could use hashtags like #heraklioncrete or
#creteharbour to target people who are interested in visiting that
specific location.

You should also consider using a mix of popular and less popular
hashtags. Popular hashtags will help your post reach a wider audience,
while less popular hashtags can help your post stand out from the
crowd.

**Tips for Choosing Hashtags:**

* Research relevant hashtags. Look at what other users are using and
see what's trending.
* Use a mix of general and specific hashtags.
* Don't use too many hashtags.
* Keep your hashtags relevant to your image.

By using a mix of relevant and engaging hashtags, you can increase
your chances of getting your post seen by a wider audience and improve
your engagement on Instagram.
```

Now, let's tweak this code to output the Instagram hashtags as a JSON array of hashtag strings.
With LangChain4j's Gemini integration, it's pretty trivial, we can specify that we want to return JSON payloads,
thanks to the `responseMimeType()` method:

```java
var modelCreative = VertexAiGeminiChatModel.builder()
    .project(PROJECT_ID)
    .location(LOCATION)
    .modelName("gemini-1.5-flash")
    .responseMimeType("application/json")
    .build();
```

Let's update the system instruction to be explicit about what the JSON should look like:

````java
List<ChatMessage> messages = new ArrayList<>();
messages.add(SystemMessage.from("""
    You are an Instagram influencer and expert.
    You master the fine art of choosing the best creative hashtags
    to share users' best pictures, and to ensure engagement with
    the Instagram community is the highest possible.

    Return a JSON array containing the hashtags as strings, for example:
    ```json
    ["#beach", "#island", "#traveltahiti"]
    ```
    """));
````

Now let's see the LLM's response:

```json
[
  "#greece",
  "#crete",
  "#heraklion",
  "#cretelife",
  "#mediterraneansea",
  "#creteisland",
  "#greecevacations",
  "#greekislands",
  "#cretetravel",
  "#heraklionport"
]
```

On one hand, it's nice that Gemini obeyed us and generated the request JSON array of hashtags.
However, notice that there are fewer hashtags, which are also a bit less creative.

## LLMs are less creative when constrained

It's not the first time I noticed that behavior with an LLM.
I tried this with other LLMs like ChatGPT.
It seems that LLMs are less creative when they are constrained to follow a stricter output.

And indeed, what actually trigged this article idea and example was this paper that I came across:
[Let Me Speak Freely? A Study on the Impact of
Format Restrictions on Performance of Large Language Models](https://arxiv.org/abs/2408.02442#)
which has been published on arXiv a few days ago,
which confirms my intuition that LLMs are less creative when using controlled generation:

> Structured generation, the process of producing content in standardized formats like JSON and XML,
> is widely utilized in real-world applications to extract key output information from large language models (LLMs).
> This study investigates whether such constraints on generation space impact LLMs' abilities,
> including reasoning and domain knowledge comprehension.
> Specifically, we evaluate LLMs' performance when restricted to adhere to structured formats
> versus generating free-form responses across various common tasks.
> Surprisingly, **we observe a significant decline in LLMs' reasoning abilities under format restrictions**.
> Furthermore, we find that stricter format constraints generally lead to greater performance degradation in reasoning tasks.

## A better solution with a two-step approach with entity extraction

Since LLMs are not as good when we control their generation, we can try a slighly smarter approach:

- Firstly, we can ask the LLM to give its usual plain-text creative answer,
- Secondly, we ask the LLM to actually extract all the hashtags from the previous response, using controlled gneration.

LLMs are great at various classical Natural Language Processing tasks like **entity extraction**.
And here, indeed, what we want is to just extract the hashtags from the plain-text response.

For such a task, controlled generation won't hinder the creativity, and will be acurate and extract correctly all the tags.
The aforementioned paper seemed to also hint at the fact that controlled generation can actually help with some tasks like classification.

Let's have a look at our improved approach.
We keep the first attempt from the beginning of this article, without using controlled generation,
but we'll use a different configuration for the second step:

```java
var modelExtraction = VertexAiGeminiChatModel.builder()
    .project(PROJECT_ID)
    .location(LOCATION)
    .modelName("gemini-1.5-pro")
    .responseSchema(SchemaHelper.fromClass(String[].class))
    .build();

List<ChatMessage> messagesForExtraction = new ArrayList<>();
messagesForExtraction.add(SystemMessage.from("""
    Your job is to extract Instagram hashtags from a given text, and
    return them as a JSON array of strings representing those hashtags.
    """));
messagesForExtraction.add(UserMessage.from("""
    Here is the text to extract Instagram hashtags from:

    """ + responseText));

Response<AiMessage> responseFromExtraction =
    modelExtraction.generate(messagesForExtraction);

String extractedTagsJson = responseFromExtraction.content().text();
System.out.println(extractedTagsJson);
```

- In this example, I used Gemini 1.5 Pro instead of Gemini 1.5 Flash to show you the use of the
  `responseSchema()` method which allows you to specify the exact shape of the JSON we want to retrieve.
  I could have used Gemini 1.5 Flash like before, but I have to give a bit more prompting help to specify the JSON schema.
- This time, we use a different system message to explain the task of hashtag extraction.
- And the user message reuses the creative response from the previous LLM call to extract hashtags from it.

So what's the output like?

```json
[
  "#greece",
  "#greekislands",
  "#crete",
  "#creteisland",
  "#cretelife",
  "#holiday",
  "#travel",
  "#vacay",
  "#instatravel",
  "#travelgram",
  "#beautifuldestinations",
  "#travelphotography",
  "#photooftheday",
  "#instagood",
  "#igdaily",
  "#instapic",
  "#heraklion",
  "#heraklioncrete",
  "#venetianharbour",
  "#harbourlife",
  "#boatlife",
  "#boatday",
  "#greekboats",
  "#greekharbour",
  "#beautifulcrete",
  "#creteharbour",
  "#cretevibes",
  "#greece_gram",
  "#crete_gram",
  "#greece_travel",
  "#wanderlust",
  "#traveltuesday",
  "#instagood",
  "#travelgram",
  "#beautifuldestinations",
  "#adventuretime",
  "#explorecrete",
  "#cretelove",
  "#lovegreece",
  "#greecevibes",
  "#cretephoto",
  "#creteexperience",
  "#discovercrete"
]
```

Excellent! It managed to extract all the tags of the creative response!

## Conclusion & discussion

Even if researchers found that LLMs may be less creative when constrained with controlled generation,
we can find workarounds to prevent suffering from this limitation, like we did with this two-step approach
by making two calls.
The first call is a creative one, while the second is the data extraction one.

One drawback of this approach, however, is that we had to make two calls to the LLM.
So this can be a bit more costly in terms of tokens generated.
And it also adds latency, because we have two calls instead of just one.
So you might have to balance cost & lantency with quality, depending on your use case.

But it's always great to have the choice!

# Gemini Nano running locally in your browser


Generative AI use cases are usually about running large language models somewhere in the cloud.
However, with the advent of smaller models and open models, you can run them locally on your machine,
with projects like [llama.cpp](https://github.com/ggerganov/llama.cpp) or [Ollama](https://ollama.com/).

And what about in the browser?
With [MediaPipe](https://github.com/google-ai-edge/mediapipe) and [TensorFlow.js](https://www.tensorflow.org/js),
you can train and run small neural networks for tons of fun and useful tasks
(like recognising hand movements through the webcam of your computer), and it's also possible to run
[Gemma](https://ai.google.dev/gemma/) 2B and even 7B models.

But there's something interesting cooking these days: **built-in language models in the browser**!

The Chrome developers are working on a new Web API to integrate LLMs in the browser,
and are experimenting with the [Gemini Nano](https://deepmind.google/technologies/gemini/nano/) model
(already integrated in some smartphones like Samsung Galaxy or Google Pixel phones)
inside [Chrome Canary](https://www.google.com/chrome/canary/).

## Getting started with Gemini Nano and Chrome Canary

I'm sure you want to experiment with that too? Let's see how to proceed:

- First of all, you'll need to download [Chrome Canary](https://www.google.com/chrome/canary/)

- In `chrome://flags`, you must **enable** two experiments:

  - `Prompt API for Gemini Nano` and
  - `Enables optimization guide on device`.

- You'll have to restart the browser, after having enabled those two flags.

It may take quite a bit of time to download Gemini Nano (as it's a small model, it takes only around 1.7GB of space, but you'll need about 20GB at installation time on your hard drive)
but the API will tell you if the model weights are not fully downloaded yet.

## Experimenting in the playground

Now it's time to play!
Let's see what this embedded Gemini Nano can do, in the [Prompt API playground](https://chrome.dev/prompt-api-playground/).
This is a simple form where you can send prompts to the model, and see its replies.

![](/img/gemini/nano-playground.png)

Looks like it's smart enough to know that no cat ever went on the moon!

## A bit of code

The [code of this demo](https://github.com/tomayac/prompt-api-playground) is available on Github.

Let's have a look at the key lines of the **Prompt API** usage.

To know if the browser supports the Prompt API, you'll need to check the existence of the new `ai` object on `window`:

```javascript
if (!window.ai) {
    ...
}
```

Then you'll have to create a **text session** with:

```javascript
const session = await window.ai.createTextSession();
```

Then you can either wait for the full response, or stream the tokens as they are generated.
Here, let's see the streaming scenario, and how to iterate over the streamed tokens:

```javascript
const stream = await session.promptStreaming(
    "What's the name of the first cat who stepped on the moon?"
);

for await (const chunk of stream) {
    var fullResponse = chunk.trim();
    // do something with the response, like appending it to a DOM node
}
```

If you're not streaming the response, you can also do as follows,
to get the response in one go once it's fully generated:

```javascript
const result = await session.prompt(
    "What's the name of the first cat who stepped on the moon?"
);
```

## But why running AI in the browser?

Maybe I should have started there, afterall?
Why would you want to run models locally in the browser, rather than using a cloud-hosted one?

As the [documentation](https://developer.chrome.com/docs/ai/built-in) outlines:

* For **privacy reasons**: you may want to do local processing of sensitive data, to avoid sending such information on the web.
* For **latency gains**: once the model is loaded in the browser (in about 3 seconds on my machine), the model responds super fast to all subsequent requests.
So you can have a very snappy experience, without the long roundtrip through the internet!
* For **lower costs**: since all the AI inference is done in the browser, it's not going to cost you anything on the server-side.
* For **offline usage**: as it runs in the browser, even if you lost your internet connection, your Web UI will continue to function with all its smart AI features.

## Interesting resources

* Checkout the [Prompt API playground](https://chrome.dev/prompt-api-playground/) to play with it (after having followed the instructions above).
* Have a look at the [sources](https://github.com/tomayac/prompt-api-playground) of the playground to learn how the demo is done.
* There's a nice [publication](https://medium.com/google-cloud/google-chrome-has-a-secret-ai-assistant-9accb95f1911) that shows how to use the Prompt API to summarize the content of the web page displayed in your browser.
* The HuggingFace people have an [extended article](https://huggingface.co/blog/Xenova/run-gemini-nano-in-your-browser) on how to run Gemini Nano in the browser, with some advanced details about the Prompt API.
* Read the pages that explains the [goals of the built-in AI](https://developer.chrome.com/docs/ai/built-in).
* It's interesting to glance through the [explainer](https://github.com/explainers-by-googlers/prompt-api/) of the Prompt API to understand how it's been designed.
* And the best resource for the end, the [user guide of the built-in AI early preview](https://docs.google.com/document/d/1VG8HIyz361zGduWgNG7R_R8Xkv0OOJ8b5C9QKeCjU0c/edit), which gives lots of details about the Prompt API.

## Summary

I've been focusing mostly on large language models in the cloud so far,
in particular [Gemini](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal#gemini-text-only-samples-java),
but I'm excited at the prospect of the interesting use cases that it can enable.

Imagine, for example, a travel itinerary application, that would store all the information of your trip locally (in IndexedDB or a WebAssembly-fied sqlite),
and you could ask offline all the questions you want about the journey? (basically, **RAG in the browser**!)
No need to hunt for a public wifi network or a local SIM card.

There are also many tasks some browser extension could handle:
* When preparing my podcast episode and show notes, I could ask Gemini Nano to make a 5-bullet-point summary of the article I'm reading.
* When reading the reviews for a product, I could get a sentiment analysis signal that tells me if customers are happy with that product.

We could also think of some hybrid scenarios, as both cloud-hosted and local-running models could complement each other.

I hope this Web API will become a standard and that other browsers support it too, and offer different models as well.
# Sentiment analysis with few-shot prompting


In a rencent article, we talked about
[text classification]({{<ref "posts/2024/07/11/text-classification-with-gemini-and-langchain4j/">}})
using [Gemini](https://deepmind.google/technologies/gemini/) and [LangChain4j](https://docs.langchain4j.dev/).

A typical example of text classification is the case of **sentiment analysis**.

In my LangChain4j-powered Gemini [workshop](https://github.com/glaforge/gemini-workshop-for-java-developers/),
I used this use case to illustrate the classification problem:

```java
ChatLanguageModel model = VertexAiGeminiChatModel.builder()
    .project(System.getenv("PROJECT_ID"))
    .location(System.getenv("LOCATION"))
    .modelName("gemini-1.5-flash-001")
    .maxOutputTokens(10)
    .maxRetries(3)
    .build();

PromptTemplate promptTemplate = PromptTemplate.from("""
    Analyze the sentiment of the text below.
    Respond only with one word to describe the sentiment.

    INPUT: This is fantastic news!
    OUTPUT: POSITIVE

    INPUT: Pi is roughly equal to 3.14
    OUTPUT: NEUTRAL

    INPUT: I really disliked the pizza. Who would use pineapples as a pizza topping?
    OUTPUT: NEGATIVE

    INPUT: {{text}}
    OUTPUT:
    """);

Prompt prompt = promptTemplate.apply(
    Map.of("text", "I love strawberries!"));

Response<AiMessage> response = model.generate(prompt.toUserMessage());

System.out.println(response.content().text());
```

I used a `PromptTemplate` to craft the prompt, with a `{{text}}` placeholder value to analyze the sentiment of that particular text.

Notice that I used the [few-shot prompting](https://learnprompting.org/docs/basics/few_shot) technique, with example inputs and outputs.

## Few-shot prompting with a list of messages

Somehow, I had the impression that this `INPUT/OUTPUT` notation was a bit of a _hack_
to encourage the LLM to believe this is an actual exchange between the user and the AI.

I believed it would be cleaner to use a real list of messages that alternate user and AI messages.
So I implemented this alternative approach, but haven't yet committed it to my workshop repository.

Meanwhile, as I was chatting with my colleague [Dan Dobrin](https://x.com/ddobrin),
he pointed me at this very recent blog [post](https://blog.langchain.dev/few-shot-prompting-to-improve-tool-calling-performance/)
from the LangChain people, who were investigating _few-shot prompting to improve tool-calling performance_.

What's interesting in their analysis was that overall, on this anecdata example,
it seems **LLMs do better with real user/AI messages than with a big string of inputs/outputs**.

Let's see how to implement the same approach, with a real exchange of messages:

```java
List<ChatMessage> fewShotPrompts = List.of(
    SystemMessage.from("""
        Analyze the sentiment of the text below.
        Respond only with one word to describe the sentiment.
        """),

    UserMessage.from("This is fantastic news!"),
    AiMessage.from("POSITIVE"),

    UserMessage.from("Pi is roughly equal to 3.14"),
    AiMessage.from("NEUTRAL"),

    UserMessage.from("I really disliked the pizza. " +
                     "Who would use pineapples as a pizza topping?"),
    AiMessage.from("NEGATIVE"),

    UserMessage.from("I love strawberries!")
);

response = model.generate(fewShotPrompts);

System.out.println(response.content().text());
```

This is not much more verbose than the previous approach, as it's still very readable.
And when pulling the few-shot data from an external database, it feels cleaner than concatenating a big string.

## More type-safe few-shot prompting with messages and AiServices

To further improve on the list of messages tactic, we can use LangChain4j's `AiServices` concept,
which is a higher-level abstraction than using the model and prompt templates directly.

```java
enum Sentiment { POSITIVE, NEUTRAL, NEGATIVE }

interface SentimentAnalysis {
    @SystemMessage("""
        Analyze the sentiment of the text below.
        Respond only with one word to describe the sentiment.
        """)
    Sentiment analyze(String text);
}

MessageWindowChatMemory memory =
    MessageWindowChatMemory.withMaxMessages(10);

memory.add(UserMessage.from("This is fantastic news!"));
memory.add(AiMessage.from(Sentiment.POSITIVE.name()));

memory.add(UserMessage.from("Pi is roughly equal to 3.14"));
memory.add(AiMessage.from(Sentiment.NEUTRAL.name()));

memory.add(UserMessage.from("I really disliked the pizza. " +
        "Who would use pineapples as a pizza topping?"));
memory.add(AiMessage.from(Sentiment.NEGATIVE.name()));

SentimentAnalysis analyzer =
    AiServices.builder(SentimentAnalysis.class)
        .chatLanguageModel(model)
        .chatMemory(memory)
        .build();

System.out.println(analyzer.analyze("I love strawberries!"));
```

This third and final approach may be a bit more verbose, and introduces a few more LangChain4j concepts
like system messages, chat memory, and the AI service itself, but it has the advantages of being:

- **more type-safe**, as we're using a `Sentiment` enum, which is easier to manipulate from code,
- cleaner, because we're **using system instructions** to instruct the model about what its job is.

We created:

- a Java `enum` to represent the possible values of the sentiment,
- a `SentimentAnalysis` interface with a clear signature: a text in input, a `Sentiment` enum value in output,
- a `@SystemMessage` instruction to describe the analysis task,
- a `ChatMemory` (here a `MessageWindowChatMemory`) to hold the few-shot examples.

Then we bind everything together, thanks to `AiServices`:
the analysis interface that LangChain4j will implement for us, the language model, and the chat memory.

Finally, users just have to call the `analyze()` method, passing the text to analyze.

I also like the fact that we are **coding against an interface**, and potentially later on,
developers **could swap the implementation** of the sentiment analyzer, and use a different approach.

## Conclusion

All three approaches are valid: a big string, a low-level list of messages, or an `AiServices` abstraction.
But I have a slight preference for the approach that is more type-safe and less _stringy_.

Just like LangChain4j provides a `TextClassification` class that leverages vector embeddings for text similarity,
we could investigate whether it would make sense to also add a few-shot prompting classificaction solution directly in the LangChain4j project.

# Analyzing video, audio and PDF files with Gemini and LangChain4j


Certain models like Gemini are **multimodal**.
This means that they accept more than just text as input.
Some models support text and images, but **Gemini goes further and also supports audio, video, and PDF files**.
So you can mix and match text prompts and different multimedia files or PDF documents.

Until LangChain4j 0.32, the models could only support text and images,
but since my [PR](https://github.com/langchain4j/langchain4j/pull/1464) got merged into the newly released
[0.33](https://github.com/langchain4j/langchain4j/releases/tag/0.33.0) version,
you can use all those files with the LangChain4j Gemini module!

Let's have a look!

## Getting the transcription of a podcast recording

Are you an avid podcast listener and want to read its transcription?
Or you want to publish that transcription as show-notes of your own podcast on your website?

You can ask Gemini for the transcription with the following code:

```java
var model = VertexAiGeminiChatModel.builder()
    .project(PROJECT_ID)
    .location(LOCATION)
    .modelName("gemini-1.5-pro")
    .build();

Response<AiMessage> response = model.generate(
    UserMessage.from(
        AudioContent.from(
            "https://storage.googleapis.com/cloud-samples-data/"
            + "generative-ai/audio/pixel.mp3"),
        TextContent.from(
            "Write a transcription of this audio file")
    )
);

System.out.println(response.content().text());
```

Above, we created an audio content object with the `AudioContent.from(...)` method.
This method can take a string which can be a direct URL to a file on the web,
it can be a Google Cloud Storage URL as well (like `gs://bucket/audio.mp3`).
It is possible to load a local file from your file system with `AudioContent.from(Paths.get("audio.mp3").toUri())`.
You can even pass the base 64 encoded content of the audio file and specify its mime type.

### What else could you do with audio files?

- If you're in a hurry and don't have time to listen to this one-hour episode,
  instead of asking for the whole transcript, you could change the prompt to ask for a summary.
  That way you know if it's worth spending an hour to listen to it all.

- Gemini also accepts several audio files in input, so if you are recording interviews of persons on a specific topic,
  you could ask Gemini to contrast the differences in those responses.

## Preparing YouTube video chaptering

Let's say you're a YouTuber, and you want to do your own video chaptering, instead of relying on the the automatic chapters.
How can you do that?

```java
var model = VertexAiGeminiChatModel.builder()
    .project(PROJECT_ID)
    .location(LOCATION)
    .modelName("gemini-1.5-flash")
    .build();

Response<AiMessage> response = model.generate(
    UserMessage.from(
        VideoContent.from(
            "https://storage.googleapis.com/cloud-samples-data/"
            + "generative-ai/video/behind_the_scenes_pixel.mp4"),
        TextContent.from(
            "Prepare chapters for this video file, "
            + "using the YouTube chapter notation")
    )
);

System.out.println(response.content().text());
```

For this video, the chapters generated look as follows:

```
00:00 Making a Film with a Blind Director
00:16 Adam Morse, Filmmaker
00:28 The Film Shoot
00:48 A Blind Man & His Girlfriend
01:15 Google Pixel Phone
01:33 Guided Frame
02:06 The Technical Crew
02:32 Visual Effects
02:45 Misconceptions About Blindness
03:20 Filmmaking with a Team
03:46 Google Accessibility
04:00 One Person's Perspective
04:29 Adam's Vision
05:03 A Beautiful Position
05:19 Google Logo
```

### What else could you do with videos?

- If a video of your meeting or your conference presentation has been recorded,
  you could use this approach to ask Gemini for a summary of the video, to get the various sections, to write the transcript.

- We often record videos of our family, our children, etc.
  It's not always easy to _search_ through those videos.
  You could ask Gemini to provide a summary of the video,
  that you would then index with some search engine, or just do some simple _grep_ search from the command-line.

## Asking questions about PDF documents

Let's have a look at one last example: PDF documents.

With LangChain4j, it's possible to use the Apache Tika-based document loader to get the text content of a PDF.
However, you loose some important semantic information, as the layout may be important,
or the figures may convey as well some critical details.

Fortunately, Gemini can ingest PDF documents directly, without an intermediate text transcription.

This allows you to ask questions about PDf documents, and since Gemini has a very large context window,
it's able to analyze very big documents, or several documents at the same time,
without having to implement your own RAG system (Retrieval Augmented Generation).

```java
var model = VertexAiGeminiChatModel.builder()
    .project(PROJECT_ID)
    .location(LOCATION)
    .modelName("gemini-1.5-flash")
    .build();

Response<AiMessage> response = model.generate(
    UserMessage.from(
        PdfFileContent.from(
            "https://proceedings.neurips.cc/paper_files/paper/2017"
            + "/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf"),
        TextContent.from(
            "Give a summary of this paper")
    )
);

System.out.println(response.content().text());
```

This example analyzes the famous _"Attention is all you need"_ paper that introduced the concept of _Transformer_ neural networks:

```
This paper proposes a novel neural network architecture called the
Transformer, which relies entirely on an attention mechanism and
dispenses with recurrence and convolutions. The Transformer
outperforms existing models on two machine translation tasks, WMT
2014 English-to-German and WMT 2014 English-to-French, while
requiring significantly less training time. The authors argue that
the Transformer's ability to learn global dependencies without
regard to their distance in the input or output sequences, as well
as its parallelizable nature, make it a promising approach for
sequence modeling and transduction problems. They also present an
analysis of the Transformer's different components and their effect
on performance. The paper concludes by discussing potential future
directions for research.
```

### What else could you do with PDF documents?

- You can implement some smart question answering solutions over your documents.

- Gemini can help make sense of differences between two versions of your PDF paper.

- Gemini allows you to ingest multiple files at the same time,
  so it is possible to pass the PDF of your dishwasher manual,
  at the same time as a tutorial showing how to repair it,
  and then ask the LLM to answer a question on how to fix it.

## Summary

Multimodality is a powerful feature of Gemini,
and now LangChain4j is equiped with the ability to send text, images, audio files, videos, and PDF documents,
potentially all at the same time, to create some innovative multimedia integrations.

# Text classification with Gemini and LangChain4j


Generative AI has potential applications far beyond chatbots and Retrieval Augmented Generation.
For example, a nice use case is: **text classification**.

I had the chance of meeting some customers and prospects who had the need for triaging incoming requests, or for labeling existing data.
In the first case, a government entity was tasked with routing citizen requests to access undisclosed information to the right governmental service that could grant or reject that access. In the second case, a company needed to sort out tons of existing internal documents that were not properly organized, and they wanted to quickly start better structuring this trove of information, by labelling each of these docs into different categories.

In both situations, the task was a **text classification** one: to put each request or document in a distinct pile, so they could more easily be sorted out, organized, and treated more rapidly.

Before generative AI, text classification would be handled by data scientists who would craft and train dedicated machine learning models for that purpose. But it is now also possible to do the same with the help of large language models.
That's what I'd like to explore with you in this article today.

As usual, I'll be using the [Gemini model](https://deepmind.google/technologies/gemini/),
and the [LangChain4j framework](https://docs.langchain4j.dev/) for implementing illustrative examples in Java.

## Text classification: putting a label on a document

Before diving into the code, let's step back a short moment to clarify what text classification is about.
When we classify documents, we put a label on them.

For example, in a bug tracker, we could automate adding labels on new tickets that say that the bug report is related to a certain component.
So we would put the name of the component as the label for that new ticket.

For routing incoming document access requests, we could put the label of the service that must treat the request, etc.

**Filtering** is also a text classification problem: we can filter the content of emails to state whether they are spam or not.
And we can also use LLMs to filter harmful content from users' inputs, and even classify the category of harm (hateful speech, harrasment, etc.)

## Zero-shot prompting: just ask the model!

What about just asking a large language model what it thinks the classification, or the label should be?
And indeed, LLMs are often very smart and can figure out the correct classification, without being trained specifically for that purpose.

Let's illustrate this with a very common type of text classification: **sentiment analysis**.

First, we can define an `enum` representing the various sentiments that can be recognized:

```java
enum Sentiment {
    POSITIVE, NEUTRAL, NEGATIVE
}
```

We create a `record` which will hold the result of the sentiment analysis:

```java
record SentimentClassification(
    Sentiment sentiment
) {}
```

We will also need an `interface` to represent the type-safe Java service that the developers integrating this LLM-backed solution will call to retrieve the sentiment of the text:

```java
interface SentimentClassifier {
    SentimentClassification classify(String text);
}
```

Notice that it takes in input an unstructured `String` text, but in output, you'll manipulate a strongly typed object, not just a mere string.

It's time to prepare our Gemini model:

```java
var model = VertexAiGeminiChatModel.builder()
    .project(PROJECT_ID)
    .location(LOCATION)
    .modelName("gemini-1.5-pro")
    .responseMimeType("application/json")
    .responseSchema(Schema.newBuilder()
        .setType(Type.OBJECT)
        .putProperties("sentiment",
            Schema.newBuilder()
                .setType(Type.STRING)
                .addAllEnum(Stream.of(Sentiment.values())
                    .map(Enum::name)
                    .collect(Collectors.toList()))
                .build())
        .build())
    .build();
```

We're taking advantage of the latest feature of Gemini and LangChain4j, which permits to specify that we want 100% valid JSON in output,
and even better than this, we want the generated JSON output to comply with a JSON schema!

Now we create the sentiment analysis service:

```java
SentimentClassifier sentimentClassifier =
    AiServices.create(SentimentClassifier.class, model);
```

And we call it to retrieve the sentiment of the text we want to analyze:

```java
SentimentClassification classification =
    sentimentClassifier.classify("I am happy!");
System.out.println(classification.sentiment()); // POSITIVE
```

We didn't even need to give Gemini examples, this is why it's called _zero-shot prompting_.
LLMs are usually smart enough to easily handle familiar classification tasks like sentiment analysis.

## Few-shot prompting: when the model needs a little help

A more common approach with LLMs for text classification is _few-shot prompting_.
As the name implies, it's a prompting technique.

You give the model a task (classifying text), and you show it examples of classifications,
with a clear input/output format, to force the LLM to reply with just the expected class.

```java
ChatLanguageModel model = VertexAiGeminiChatModel.builder()
    .project(PROJECT_ID)
    .location(LOCATION)
    .modelName("gemini-1.5-flash-001")
    .maxOutputTokens(10)
    .maxRetries(3)
    .build();

PromptTemplate promptTemplate = PromptTemplate.from("""
    Analyze the sentiment of the text below.
    Respond only with one word to describe the sentiment.

    INPUT: This is fantastic news!
    OUTPUT: POSITIVE

    INPUT: Pi is roughly equal to 3.14
    OUTPUT: NEUTRAL

    INPUT: I hate disliked the pizza. Who'd put pineapple toppings?
    OUTPUT: NEGATIVE

    INPUT: {{text}}
    OUTPUT:
    """);

Prompt prompt = promptTemplate.apply(
    Map.of("text", "I love strawberries!"));

Response<AiMessage> response = model.generate(prompt.toUserMessage());

System.out.println(response.content().text()); // POSITIVE
```

In the above approach, we use LangChain4j's `PromptTemplate`, with a placeholder value `{{text}}` that will contain the text to classify.
We don't use an `enum` value though, so we have to discriminate against a string in the end.
But we could also apply the same schema response handling as in our previous zero-shot example.

Let's rewrite this code a little bit differently, to _fake_ a conversation with the model.
The model will see an exchange between a user and itself, and will also follow the same syntax, and will reply with just one word: the sentiment.
We'll use system instructions, and alternating AI and user messages:

```java
List<ChatMessage> fewShotPrompts = List.of(
    SystemMessage.from("""
        Analyze the sentiment of the text below.
        Respond only with one word to describe the sentiment.
        """),

    UserMessage.from("This is fantastic news!"),
    AiMessage.from("POSITIVE"),

    UserMessage.from("Pi is roughly equal to 3.14"),
    AiMessage.from("NEUTRAL"),

    UserMessage.from("I hate disliked the pizza. " +
                     "Who'd put pineapple toppings?"),
    AiMessage.from("NEGATIVE"),

    UserMessage.from("I love strawberries!")
);

response = model.generate(fewShotPrompts);

System.out.println(response.content().text()); // POSITIVE
```

Same outcome, stawberries are yummy!

## Text classification with embedding models

In the two previous sections, we took advantage of LLMs' abilities to classify text on their own,
based on their intrinsic knowledge, or with the help of a few examples.
But there's another way we can investigate: **using embedding vectors** to compare texts.

Embedding vectors are mathematical representations of words/sentences/paragraphs, in the form of a vector of floating point values.
The way those vectors are calculated by _embedding models_ makes those vector close to each other
(in terms of distance) when they are semantically close.
You can have a look at my recent article
[introducing vector embeddings]({{<ref "posts/2024/07/02/the-power-of-embeddings-how-numbers-unlock-the-meaning-of-data/">}}).

LangChain4j provides a `TextClassifier` interface which allows to classify text, by comparing it to sets of other texts
that belong to a same class. So we give a map of possible labels, associated with lists of texts that belong to that category.

In particular, there's an `EmbeddingModelTextClassifier` that uses embedding models to compare the texts with the examples of each labels.
We can even tweak its internal algorithm to say whether we prefer if a text should be closer to the average of all the examples,
or if we prefer if it's closer to one of the examples (by default, it's half distance to the mean, and half distance to the closest example.)

So let's have a look at this solution.

Instead of doing sentiment analysis, we'll go with recipe classification: our goal will be to classify a recipe,
to know if it's an _appetizer_, a _main course_, or a _dessert_.

First, we need to define our labels, with an `enum`:

```java
enum DishType {
    APPETIZER, MAIN, DESSERT
}
```

Because we don't have a dataset of recipes, we'll use Gemini to generate sample recipes, for each label.
For that, we need to configure Gemini:

```java
private static final VertexAiGeminiChatModel CHAT_MODEL =
    VertexAiGeminiChatModel.builder()
        .project(PROJECT_ID)
        .location(LOCATION)
        .modelName("gemini-1.5-flash")
        .build();
```

We'll also configure an embedding model to calculate the vector embeddings:

```java
private static final VertexAiEmbeddingModel EMBEDDING_MODEL =
    VertexAiEmbeddingModel.builder()
        .project(PROJECT_ID)
        .location(LOCATION)
        .endpoint(ENDPOINT)
        .publisher("google")
        .modelName("text-embedding-004")
        .taskType(VertexAiEmbeddingModel.TaskType.CLASSIFICATION)
        .build();
```

Vertex AI's embedding models are capable of handling various tasks, including:

- **classification**,
- semantic similarity,
- clustering,
- question answering,
- fact verification,
- query or document retrieval.

Let's create a method to generate a recipe for a particular type of dish:

```java
private static String recipeOf(DishType type) {
    return CHAT_MODEL.generate(
        "Write a recipe for a %s dish"
            .formatted(type.name().toLowerCase()));
}
```

And we'll collect 3 examples of recipes for each type of dish:

```java
var examplesOfRecipes = Stream.of(DishType.values())
    .collect(
        Collectors.toMap(
            dishType -> dishType,
            dishType ->
                Stream.generate(() -> recipeOf(dishType))
                    .limit(3)
                    .toList()
        )
    );
```

That way, we have our dataset ready, and we'll prepare a text classifier:

```java
EmbeddingModelTextClassifier<DishType> recipeClassifier =
    new EmbeddingModelTextClassifier<>(EMBEDDING_MODEL,
                                       examplesOfRecipes);
```

It takes a little while to calculate the initial embedding vectors of all the samples, but now our classifier is ready!
Let's see if the following recipe is an _appertizer_, a _main course_, or a _dessert_:

```java
List<DishType> classifiedDishes = recipeClassifier.classify("""
    **Classic Moist Chocolate Cake**

    This recipe delivers a rich, moist chocolate cake that's
    perfect for any occasion.

    Ingredients:
    * 1 ¾ cups all-purpose flour
    * 2 cups granulated sugar
    * ¾ cup unsweetened cocoa powder
    * 1 ½ teaspoons baking powder
    * 1 ½ teaspoons baking soda
    * 1 teaspoon salt
    * 2 large eggs
    * 1 cup milk
    * ½ cup vegetable oil
    * 2 teaspoons vanilla extract
    * 1 cup boiling water

    Instructions:
    * Preheat oven to 350°F (175°C). Grease and flour two 9-inch
      round cake pans.
    * Combine dry ingredients: In a large bowl, whisk together flour,
      sugar, cocoa powder, baking powder, baking soda, and salt.
    * Add wet ingredients: Beat in eggs, milk, oil, and vanilla until
      combined.
    * Stir in boiling water: Carefully stir in boiling water. The
      batter will be thin.
    * Bake: Pour batter evenly into prepared pans. Bake for 30-35
      minutes, or until a toothpick inserted into the center comes
      out clean.
    * Cool: Let cakes cool in pans for 10 minutes before transferring
      to a wire rack to cool completely.
    """);

System.out.println("This recipe is of type: " + classifiedDishes);
// This recipe is of type: [DESSERT]
```

And voilà, we used the full power of embedding models to calculate text similarity to classify our chocolate cake recipe as a dessert!

## Conclusion

Large Language Models like Gemini are great at classifying text, thanks to their general knowledge of the world that they acquired during their training. But for more specialized use cases, we might need to guide the LLM to recognize labels, because the subject is very specific to our data. That's when few-shot prompting or embedding model-based classification helps.

If we have lots of samples for each label, using a few-shot prompting approach means we'll have to pass all those examples again and again in the context window of the LLM, which yields a high token count. So if you pay per tokens, it can become a bit expensive.

If we use the embedding model text classifier, it might take a while to compute all the embedding vectors, but we'll do it only once, and then we can just calculate the vector embedding for the text to classify, so it's just the tokens of the text to classify that is incurred.
If we have lots of samples, the classifier needs to do quite a few vector / matrix computations to calculate the distance to the samples, but it's usually quite fast (unless we really have hundreds or thousands of samples).

I hope this article showed you that Generative AI is useful beyond the usual chatbots and RAG use cases.
It's great at text classification as well.
And LangChain4j and Gemini are well suited for that use case, and you learned how to implement different approaches to do text classification.

# Latest Gemini features support in LangChain4j 0.32.0


[LangChain4j](https://docs.langchain4j.dev/) 0.32.0 was released yesterday,
including my [pull request](https://github.com/langchain4j/langchain4j/pull/1278)
with the support for lots of new Gemini features:

- **JSON output mode**, to force Gemini to reply using JSON, without any markup,
- **JSON schema**, to control and constrain the JSON output to comply with a schema,
- **Response grounding** with Google Search web results and with private data in Vertex AI datastores,
- Easier debugging, thanks to new builder methods to **log requests and responses**,
- **Function calling mode** (none, automatic, or a subset of functions),
- **Safety settings** to catch harmful prompts and responses.

Let's explore those new features together, thanks to some code examples!
And at the end of the article, if you make it through, you'll also discover **2 extra bonus points**.

## JSON output mode

Creating LLM-powered applications means working with text, as this is what LLMs return.
But to facilitate this integration between LLM responses and your code,
the text format of choice is usually JSON, as it's human-readable, and easy to parse programmatically.

However, LLMs are a bit chatty, and rather than sending you back a nice raw JSON document, instead, it replies with some extra sentence, and some markdown markup to wrap the piece of JSON.

Fortunately, Gemini 1.5 (Flash and Pro) allows you to specify the response MIME type.
Currently, only `application/json` is supported, but other formats may come later.

To do that, when instantiating the Gemini model, use the `responseMimeType()` builder method:

```java
var model = VertexAiGeminiChatModel.builder()
    .project(PROJECT_ID)
    .location(LOCATION)
    .modelName("gemini-1.5-flash")
    .responseMimeType("application/json")
    .build();

String response = model.generate("Roll a dice");

System.out.println(response);
```

No sentence, no markdown markup, nothing, just pure JSON:

```
{"roll": 3}
```

We didn't even need to say in the prompt we wanted to get a JSON response!

However, the JSON key of that document may vary from time to time, so you may still wish to be a bit more prescriptive in your prompt, and ask the model to return JSON explicitly, give it an example of the JSON output you expect, etc. That's the usual prompting approach...

But now there's more!

## JSON Schema output

This is quite unique in the LLM ecosystem, as I believe it's the only model out there that allows you to specify a JSON schema for constraining the JSON output.
This works for Gemini 1.5 Pro only, not with Gemini 1.5 Flash.

Let's have another look at our previous dice roll example, and let's update it to specify a JSON schema for the output generation:

```java
import static dev.langchain4j.model.vertexai.SchemaHelper.fromClass;
//...

record DiceRoll(int roll) {}

var model = VertexAiGeminiChatModel.builder()
    .project("genai-java-demos")
    .location("us-central1")
    .modelName("gemini-1.5-pro")
    .responseSchema(fromClass(DiceRoll.class))
    .build();

String response = model.generate("Roll a dice");

System.out.println(response);
```

The generated JSON document will always contain the `roll` key

```json
{ "roll": 5 }
```

In this example, we used a convenience method called `fromClass()` that creates a JSON schema that corresponds to a Java type (here a Java record).

But there's also another convenient method that lets us pass a JSON schema string, called `fromJsonSchema()`:

```java
var model = VertexAiGeminiChatModel.builder()
    .project("genai-java-demos")
    .location("us-central1")
    .modelName("gemini-1.5-pro")
    .responseSchema(fromJsonSchema("""
        {
            "type": "object",
            "properties": {
                "roll": {
                    "type": "integer"
                }
            }
        }
        """))
    .build();
```

It's also possible to construct a JSON schema programmatically:

```java
var model = VertexAiGeminiChatModel.builder()
    .project("genai-java-demos")
    .location("us-central1")
    .modelName("gemini-1.5-pro")
    .responseSchema(Schema.newBuilder()
        .setType(Type.OBJECT)
        .putProperties("roll",
            Schema.newBuilder()
                .setType(Type.INTEGER)
                .build())
        .build())
    .build();
```

Now you always get consistent JSON outputs!

## Response grounding with Google Search web results and Vertex AI datastores

Large Language Models are wonderful creative machines, but rather than benefiting from their high degree of creativity, we'd prefer having factual responses grounded on data and documents.

Gemini offers the ability to [ground responses](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-gemini):

- against Google Search web results,
- against Vertex AI search datastores.

### Use Google Search to ground responses

The training of an LLM ended at a certain date: its _cut-off_ date.
So it doesn't know about news that happened after that date.
But you can request Gemini to use Google Search to find more up-to-date information.

For example, if we ask Gemini about the current elections going on in France, it could reply with something like this:

```
There is no current national election happening in France right now.

The last major national election in France was the **Presidential
election in April and May 2022**, where Emmanuel Macron won a second
term.

There are, however, **local elections** happening regularly in
different regions of France.

To stay updated on French elections, you can check the website of
the **French Ministry of the Interior** or reputable news sources
like **The Guardian, BBC, CNN, or Le Monde**.
```

Now, let's enable the use of Google Search web result with the `useGoogleSearch(true)` method:

```java
var model = VertexAiGeminiChatModel.builder()
    .project(PROJECT_ID)
    .location(LOCATION)
    .modelName("gemini-1.5-flash")
    .useGoogleSearch(true)
    .build();

String response = model.generate(
    "What is the current election going on in France?");

System.out.println(response);
```

The answer will be much different, and indeed factual and up-to-date:

```
France held the first round of a parliamentary election on July 4,
2024. The second round will be on July 7, 2024. The election is
significant because it could result in the first far-right government
in France since World War II.  The National Rally, President Emmanuel
Macron’s centrist alliance, and the New Popular Front coalition are
the three major political blocs competing in the election. The
outcome of the election is highly uncertain, with the far-right
National Rally potentially gaining a parliamentary majority.  If the
National Rally wins a majority, Macron would be expected to appoint
Jordan Bardella, the party's president, as prime minister.
```

There's indeed a parliamentary election going on right now in France.
Those elections were decided only a month ago, thus past the cut-of-date of the knowledge of the model.

> For my French audience, don't forget to go voting next Sunday!

### Grounding with Vertex AI Search

The idea is that we want to ground responses on our own data.
This is particularly important when the knowledge required is actually private information, like our internal docs, or our customers' docs.

My colleague Mete wrote a great
[article explaining how to setup grounding with private data](https://atamel.dev/posts/2024/07-01_grounding_with_own_data_vertexai_search/).
Below, I'll assume that we created a Vertex AI search app with a datastore backed by a Google Cloud Storage bucket that contains a fictious document which is a car manual, about the _Cymbel Starlight_ car model! I'm taking the same example as in Mete's article.

This time, we specify the search location to point at the Vertex AI search datastore with `vertexSearchDatastore()`:

```java
var model = VertexAiGeminiChatModel.builder()
    .project(PROJECT_ID)
    .location(LOCATION)
    .modelName("gemini-1.5-flash")
    .vertexSearchDatastore(String.format(
            "projects/%s/locations/%s/collections/%s/dataStores/%s",
            PROJECT_ID, "global", "default_collection",
            "cymbal-datastore_1720169982142")
    )
    .build();

String response = model.generate(
    "What is the cargo capacity of Cymbal Starlight?");

System.out.println(response);
```

It's a fictious car that doesn't exist, but it's covered in that private document, and indeed, Gemini is now able to respond to that question:

```
The Cymbal Starlight 2024 has a cargo capacity of 13.5 cubic feet.
```

What's interesting as well is that the response returned by Gemini provides some context about the source document that helped it answer the user query (we'll see in the next section how to enable logging requests and responses):

```
  grounding_metadata {
    2: {
      1: {
        3: 66
      }
      2: 0x3f7deee0
    }
    5: {
      2: {
        1: "gs://genai-java-demos-documents/cymbal-starlight-2024.pdf"
        2: "cymbal-starlight-2024"
      }
    }
    6: {
      1: {
        3: 66
        4: "The Cymbal Starlight 2024 has a cargo capacity of 13.5 cubic feet."
      }
      2: "\000"
      3: {
        257772: 63
      }
    }
```

However, to be honest, I'm not quite sure what the numbers exactly mean, but this metadata mentions that the PDF uploaded in cloud storage is the one that was used to shape the answer of the LLM, and gives an excerpt of the sentence that was found in the document.

## Request and response logging

To better understand what's going on under the hood, you can enable request and response logging.
That way, you're able to see exactly what is sent to Gemini, and what Gemini replies.

To enable logging, there are two methods we can use:

- `logRequests(true)` to log the request sent to Gemini,
- `logResponse(true)` to log the response received from Gemini.

Let's see that in action:

```java
var model = VertexAiGeminiChatModel.builder()
    .project(PROJECT_ID)
    .location(LOCATION)
    .modelName("gemini-1.5-flash")
    .logRequests(true)
    .logResponses(true)
    .build();

String response = model.generate("Why is the sky blue?");

System.out.println(response);
```

Here's what's logged:

```
[main] DEBUG dev.langchain4j.model.vertexai.VertexAiGeminiChatModel -
 GEMINI (gemini-1.5-flash) request: InstructionAndContent {
 systemInstruction = null,
 contents = [role: "user"
parts {
  text: "Why is the sky blue?"
}
]
} tools: []


[main] DEBUG dev.langchain4j.model.vertexai.VertexAiGeminiChatModel -
 GEMINI (gemini-1.5-flash) response: candidates {
  content {
    role: "model"
    parts {
      text: "The sky appears blue due to a phenomenon called
      **Rayleigh scattering**. Here\'s a breakdown:\n\n* **Sunlight
      is made up of all colors of the rainbow.**  When sunlight enters
      the Earth\'s atmosphere, it encounters tiny particles like
      nitrogen and oxygen molecules.\n* **These particles scatter the
      sunlight in all directions.**  However, shorter wavelengths of
      light, like blue and violet, scatter more strongly than longer
      wavelengths, like red and orange.\n* **This preferential
      scattering of shorter wavelengths is called Rayleigh
      scattering.**
      As a result, we see more blue light scattered throughout the sky,
      making it appear blue.\n\n**Why is the sky not violet?**\n\nEven
      though violet light scatters even more strongly than blue, our
      eyes are more sensitive to blue light. This is why we perceive
      the sky as blue rather than violet.\n\n**Other factors that
      affect sky color:**\n\n* **Time of day:** The sky appears more
      red or orange at sunrise and sunset because the sunlight has to
      travel through more of the atmosphere, scattering away most of
      the blue light.\n* **Clouds:** Clouds are made up of larger water
      droplets or ice crystals, which scatter all wavelengths of light
      equally. This is why clouds appear white.\n* **Pollution:**
      Pollution particles can scatter light differently, sometimes
      making the sky appear hazy or even reddish.\n\nLet me know if
      you have any other questions about the sky! \n"
    }
  }
  finish_reason: STOP
  safety_ratings {
    category: HARM_CATEGORY_HATE_SPEECH
    probability: NEGLIGIBLE
    probability_score: 0.054802597
    severity: HARM_SEVERITY_NEGLIGIBLE
    severity_score: 0.03314852
  }
  safety_ratings {
    category: HARM_CATEGORY_DANGEROUS_CONTENT
    probability: NEGLIGIBLE
    probability_score: 0.100348406
    severity: HARM_SEVERITY_NEGLIGIBLE
    severity_score: 0.06359858
  }
  safety_ratings {
    category: HARM_CATEGORY_HARASSMENT
    probability: NEGLIGIBLE
    probability_score: 0.10837755
    severity: HARM_SEVERITY_NEGLIGIBLE
    severity_score: 0.021491764
  }
  safety_ratings {
    category: HARM_CATEGORY_SEXUALLY_EXPLICIT
    probability: NEGLIGIBLE
    probability_score: 0.10338596
    severity: HARM_SEVERITY_NEGLIGIBLE
    severity_score: 0.020410307
  }
}
usage_metadata {
  prompt_token_count: 6
  candidates_token_count: 288
  total_token_count: 294
}
```

Let me give you a bit more details about the logging. LangChain4j uses Slf4j by default for logging.
Request & Response logging is logged at `DEBUG` level. So we have to configure our logger and/or logger façace accordingly.

In my test project for this article, I configured the following `Maven` dependencies for `Slf4j` and the `Simple` logger:

```xml
<dependency>
    <groupId>org.slf4j</groupId>
    <artifactId>slf4j-api</artifactId>
    <version>2.0.13</version>
</dependency>
<dependency>
    <groupId>org.slf4j</groupId>
    <artifactId>slf4j-simple</artifactId>
    <version>2.0.13</version>
</dependency>
```

I created a properties file to configure the loggers: `src/main/resources/simplelogger.properties`, which contains the following configuration:

```
org.slf4j.simpleLogger.defaultLogLevel=debug
org.slf4j.simpleLogger.log.io.grpc.netty.shaded=info
```

I set the default logging level to be `debug`.
But there's also Netty, the networking library used under the hood by the Gemini Java SDK, that logs at debug level.
So I specified that the logging for this library should only be at `info` and above, otherwise the output is super chatty.

## Function calling mode

So far, when using Gemini for
[function calling](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling),
the model would decide on its own if a function would be useful to call, and which function to call.

But Gemini introduces the ability to
[control the function or tool choice](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling#tool-config).

There are 3 options:

- `AUTO` — The familiar and default mode, where Gemini decides on its own if a function call is necessary and which one should be made,
- `ANY` — Allows to specify a subset of functions from all those available, but also forces the model to pick up one of them (only supported by Gemini 1.5 Pro),
- `NONE` — Even if tools are defined and available, prevents Gemini to use any of those tools.

Let's have a look at this example:

```java
var model = VertexAiGeminiChatModel.builder()
    .project(PROJECT_ID)
    .location(LOCATION)
    .modelName("gemini-1.5-pro")
    .logRequests(true)
    .logResponses(true)
    .toolCallingMode(ToolCallingMode.ANY)
    .allowedFunctionNames(Arrays.asList("add"))
    .build();

ToolSpecification adder = ToolSpecification.builder()
    .description("adds two numbers")
    .name("add")
    .addParameter("a", JsonSchemaProperty.INTEGER)
    .addParameter("b", JsonSchemaProperty.INTEGER)
    .build();

UserMessage message = UserMessage.from("How much is 3 + 4?");
Response<AiMessage> answer = model.generate(asList(message), adder);

System.out.println(
    answer.content().toolExecutionRequests().getFirst());
```

We specify the `ToolCallingMode.ANY` mode, and we list the allowed function names of the functions that the model must pick in order to reply to the request (with the `allowedFunctionNames()` builder method).

We describe the tool that can be called. We create a message.
And when calling `generate()`, we pass the tool specification corresponding to the function we want to be called.

The output will show that the model replied with the mandatory tool execution request:

```
ToolExecutionRequest { id = null, name = "add",
                       arguments = "{"a":3.0,"b":4.0}" }
```

Now it's our turn to call the `add` function with the arguments.
And then send back the function execution result back to Gemini.

> **Warning**:
> Currently, it is not possible to use the `ANY` forced function calling mode when using LangChain4j's `AiServices` class.
>
> `AiServices` takes care of automatic function calling. But the process is a two-step request / response mechanism:
>
> - First, we ask the model the math question and pass the tool specification along.
> - The model replies with a `ToolExecutionRequest`.
> - Then `AiServices` makes the function call locally, and replies to the model with the function execution result. However, since the `ANY` calling mode is specified at the model level, the model still wants to reply with yet another tool execution request. Although at this point, the second call made to the model was _just_ to pass the function execution result, not to request another tool execution.
> - So `AiServices` enters an infite loop as the model requests a function execution again and again, not taking into account the execution result that it received.
>
> When using `AiServices`, it's better to let Gemini operate under the default `AUTO` tool mode.
> So it knows when it needs to request a tool execution, or if just needs to handle the tool execution response.
>
> If you want to use the `ANY` mode with `allowedFunctionNames()`, then don't use `AiServices`, and handle the function calls on your own in your code, to avoid such infite loop situations.

## Specify safety settings

In LLM-powered applications, where users can enter any kind of weird textual inputs,
you may want to limit harmful content that may be ingested.
To do so, you can specify some safety settings, for different categories of content, with different thresholds of acceptance:

```java
import static dev.langchain4j.model.vertexai.HarmCategory.*;
import static dev.langchain4j.model.vertexai.SafetyThreshold.*;
//...
var model = VertexAiGeminiChatModel.builder()
    .project(PROJECT_ID)
    .location(LOCATION)
    .modelName("gemini-1.5-flash")
    .safetySettings(Map.of(
        HARM_CATEGORY_DANGEROUS_CONTENT, BLOCK_LOW_AND_ABOVE,
        HARM_CATEGORY_SEXUALLY_EXPLICIT, BLOCK_MEDIUM_AND_ABOVE,
        HARM_CATEGORY_HARASSMENT, BLOCK_ONLY_HIGH,
        HARM_CATEGORY_HATE_SPEECH, BLOCK_MEDIUM_AND_ABOVE
    ))
    .build();
```

If you want to make your app safer for your end-users, and to avoid malicious or ill-disposed users, that's the way to go!

## Bonus point #1: Streaming responses with lambda functions

I'll round up the review of Gemini-focused features with one little addition I contributed to the project:
the ability to pass a lambda instead of a streaming content handler, when using a streaming model.

This is not Gemini-related, you can use it with any model!

More concretely, if you want to use Gemini or another model in streaming mode, to see the response being printed as it's generated by the model, you would usually write the following code:

```java
var model = VertexAiGeminiStreamingChatModel.builder()
    .project(PROJECT_ID)
    .location(LOCATION)
    .modelName("gemini-1.5-flash")
    .build();

model.generate("Why is the sky blue?", new StreamingResponseHandler<>() {
    @Override
    public void onNext(String aFewTokens) {
        System.out.print(aFewTokens);
    }

    @Override
    public void onError(Throwable throwable) {
        throw new RuntimeException(throwable);
    }
});
```

Using an anonymous inner class implementing the `StreamingResponseHandler` interface is quite verbose.
Fortunately, I contributed a couple static methods you can import, to make the code a little bit more concise:

```java
import static dev.langchain4j.model.LambdaStreamingResponseHandler.onNext;
import static dev.langchain4j.model.LambdaStreamingResponseHandler.onNextAndError;
//...

// onNext
model.generate("Why is the sky blue?",
    onNext(System.out::println));

// onNextAndError
model.generate("Why is the sky blue?",
    onNextAndError(
        System.out::println,
        ex -> { throw new RuntimeException(ex); }
));
```

Now you can stream your LLM output in a single instruction!

## Bonus point #2: Generating stunning images with Imagen v3

A second bonus point in this new LangChain4j release is the fact that the Vertex AI Image model now supports
[Imagen v3](https://deepmind.google/technologies/imagen-3/) (Google DeepMind's latest high-quality image generation model).

> **Warning:** To use the Imagen model, you'll still have to be allow-listed for now.
> You'll need to [fill this form](https://docs.google.com/forms/d/1cqt9padvfMgqn23W5FMPTqh7bW1KLkEOsC5G6uC-uuM/viewform)
> to request access to the model.

There are a few new parameters that are available that you can take advantage of when generating pictures.
Let's have a look at the following image generation code:

```java
var imagenModel = VertexAiImageModel.builder()
    .project(PROJECT)
    .location(LOCATION)
    .endpoint(ENDPOINT)
    .publisher("google")
    .modelName("imagen-3.0-generate-preview-0611")
    .aspectRatio(VertexAiImageModel.AspectRatio.LANDSCAPE)
    .mimeType(VertexAiImageModel.MimeType.JPEG)
    .compressionQuality(80)
    .watermark(true) // true by default with Imagen v3
    .withPersisting()
    .logRequests(true)
    .logResponses(true)
    .build();

String prompt = """
    An oil painting close-up, with heavy brush strokes full of
    paint, of two hands shaking together, a young one, and an
    old one conveying a sense of heartfelt thanks and connection
    between generations
    """;

Response<Image> imageResponse = imagenModel.generate(prompt);
System.out.println(imageResponse.content().url());
```

Let's see the resulting picture?

![](/img/gemini/imagen-v3-two-hands-shaking.jpg)

In the code above, you certainly noticed the new builder methods:

- `aspectRatio()` — not only square, but wide and narrow landscape and portrait modes are available,
- `mimeType()` — in addition to PNG, you can request JPEG image generation,
- `comressionQuality()` — when requesting JPEG, you can chose the level of compression for encoding the image,
- `watermark()` — to have all your generated images be watermarked with [SynthId](https://deepmind.google/technologies/synthid/),
- `logRequest()` / `logResponse()` — to see what is exchanged with the model, in and out,
- `persistToCloudStorage()` — to specify you want the image saved in a cloud storage bucket (not used in this example).

If you get a chance, and request access to Imagen v3, you'll notice really great quality improvements compared to v2!

## Conclusion

Lots of new Gemini related features in this
[release of LangChain4j](https://github.com/langchain4j/langchain4j/releases/tag/0.32.0)!
I hope this article helped you learn about them, and will make you want to use them in your projects.

If you want to go hands-on with Gemini with LangChain4j, don't forget to check out my self-paced codelab:
[Gemini codelabg for Java developers, using LangChain4j](https://glaforge.dev/posts/2024/03/27/gemini-codelab-for-java-developers/).

# The power of embeddings: How numbers unlock the meaning of data


## Prelude

> As I'm focusing a lot on Generative AI, I'm curious about how things work under the hood, to better understand what I'm using in my gen-ai powered projects.
> A topic I'd like to focus on more is: **vector embeddings**, to explain more clearly what they are, how they are calculated, and what you can do with them.
>
> A colleague of mine, [André](https://x.com/andreban), was showing me a [cool experiment](https://writer-m4n3dyfjhq-uc.a.run.app/)
> he's been working on, to help people prepare an interview, with the help of an AI, to shape the structure of the resulting final article to write.
>
> The idea is to provide: a topic, a target audience, and to describe the goals for the audience.
> Then, a large language model like [Gemini](https://deepmind.google/technologies/gemini/) prepares a list of questions (that you can update freely) on that topic.
> Next, it's your turn to fill in the blanks, answer those questions, and then the LLM generates an article,
> with a plan following those key questions and your provided answers.
> I cheated a bit, and asked [Gemini](https://gemini.google.com/) itself those questions, and honestly, I really liked how the resulting article came to be,
> and I wanted to share with you the outcome below.
>
> It's a great and simple introduction to vector embeddings!
> I like how AI can help organize information, shape the structure and the content for an article.
> **I'm not advocating for letting AI write all your articles**, far from that, but as an author,
> however, I like that it can help me avoid the blank page syndrome, avoid missing key elements in my dissertation, improve the quality of my written prose.
>
> Generative AI, in its creative aspect, and as your assistant, can be super useful! Use it as **a tool to help drive your creativity**!
> But **always use your critical sense to gauge the quality and factuality of the content**.

## Introduction: What are vector embeddings?

Imagine you have a vast library filled with books on every topic imaginable. Finding a specific book can be a daunting task, especially if you only know the general subject matter. Now imagine a magical system that can understand the meaning of each book and represent it as a unique code. This code, called a vector embedding, can then be used to quickly find the most relevant books based on your search query, even if you only have a vague idea of what you're looking for.

This is the power of vector embeddings. They are essentially numerical representations of complex data, like text, images, or audio, that capture the underlying meaning and relationships within the data. These numerical codes, arranged as vectors, allow computers to process and compare data in a way that mimics human understanding.

## From Text to Numbers: The Journey of Embedding Creation

Creating vector embeddings involves a multi-step process that transforms raw data into meaningful mathematical representations. The journey begins with **data preprocessing**, where the data is cleaned, normalized, and prepared for embedding generation. This might involve tasks like removing irrelevant information, standardizing data formats, and breaking text into individual words or subwords (tokenization).

Next comes the heart of the process: **embedding generation**. This step leverages various techniques and algorithms, such as Word2Vec, GloVe, BERT, and ResNet, to convert each data point into a high-dimensional vector. The specific algorithm chosen depends on the type of data being embedded (text, images, or audio) and the intended application.

For instance, Word2Vec uses a neural network to learn relationships between words by analyzing how they co-occur in large text corpora. This results in vector representations for words, where similar words have similar vectors, capturing semantic relationships. Similarly, for images, convolutional neural networks (CNNs) like ResNet can be used to extract features from images, resulting in vectors that represent the visual content.

## Vector Databases: The Power of Storing and Searching Embeddings

Once embeddings are generated, they need a dedicated storage system for efficient retrieval and comparison. This is where **vector databases** come into play. Unlike traditional databases designed for structured data, vector databases are optimized for storing and searching high-dimensional vector data.

Vector databases employ specialized indexing techniques, such as Annoy, HNSW, and Faiss, to create efficient data structures that allow for fast similarity search. This means that when a user submits a query (e.g., a search term, an image), the database can quickly find the most similar data points based on the similarity of their vector representations.

## Embeddings Empower Search: Finding the Needle in the Haystack

The combination of vector embeddings and vector databases revolutionizes search by enabling **semantic search**. This means that instead of relying solely on keyword matching, search engines can understand the meaning behind the data and find relevant results even if the query doesn't use exact keywords.

For example, imagine searching for "a picture of a dog with a hat." Traditional keyword-based search might struggle to find relevant images, as the search term might not match the image description. However, with vector embeddings, the search engine can understand the semantic meaning of the query and find images that contain both a dog and a hat, even if those words are not explicitly mentioned in the image description.

## Beyond Search: Expanding the Reach of Embeddings

Vector embeddings are not limited to search applications. They have become essential tools in a wide range of fields, including:

- **Retrieval Augmented Generation (RAG):** This technique combines the power of information retrieval and generative models to create more informative and relevant responses. Embeddings are used to find relevant information in large text corpora, which is then used to augment prompts for language models, resulting in more accurate and context-aware outputs.
- **Data Classification:** Embeddings enable the classification of data points into different categories based on their similarity. This finds application in areas like sentiment analysis, spam detection, object recognition, and music genre classification.
- **Anomaly Detection:** By representing data points as vectors, anomalies can be identified as data points that are significantly different from the majority. This technique is used in various fields, including network intrusion detection, fraud detection, and industrial sensor monitoring.

## Facing the Challenges and Shaping the Future

While vector embeddings have revolutionized data analysis, they still face some challenges. These include the difficulty of capturing polysemy (multiple meanings of a word), contextual dependence, and the challenge of interpreting the meaning behind the high-dimensional vector representations.

Despite these limitations, research continues to push the boundaries of vector embeddings. Researchers are exploring techniques like contextual embeddings, multilingual embeddings, knowledge graph integration, and explainable embeddings to overcome existing limitations and unlock the full potential of these powerful representations.

## Stepping into the World of Embeddings: Resources and Next Steps

For those interested in diving deeper into the world of vector embeddings, a wealth of resources is available. Online courses and tutorials on platforms like Coursera, Fast.ai, and Stanford's online learning platform provide a solid foundation in the underlying concepts and techniques.

Books like "Speech and Language Processing" by Jurafsky and Martin and "Deep Learning" by Goodfellow, Bengio, and Courville offer in-depth coverage of the field. Additionally, research papers and articles on platforms like arXiv and Medium offer insights into the latest advancements and applications.

To gain practical experience, explore Python libraries like Gensim, spaCy, and TensorFlow/PyTorch. These libraries provide tools for creating and working with embeddings, allowing you to build your own models and experiment with various applications.

The world of vector embeddings is constantly evolving, offering exciting opportunities for innovation and discovery. By understanding the power of these representations, you can unlock new possibilities for data analysis, information retrieval, and artificial intelligence applications.

# Functional builders in Java with Jilt


A few months ago, I shared an article about what I called Java
[functional builders]({{< ref "posts/2024/01/16/java-functional-builder-approach/" >}}),
inspired by an equivalent pattern found in Go.
The main idea was to have builders that looked like this example:

```java
LanguageModel languageModel = new LanguageModel(
    name("cool-model"),
    project("my-project"),
    temperature(0.5),
    description("This is a generative model")
);
```

Compared to the more tranditional builder approach:

- You're using the `new` keyword again to construct instances.
- There's no more `build()` method, which felt a bit verbose.

Compared to using constructors with tons of parameters:

- You have methods like in traditional builders, that say what each parameter is about (`name()`, `temperature()`...)
  a bit similar to named parameters in some programming languages.

The approach I followed was to take advantage of lambda functions under the hood:

```java
public static ModelOption temperature(Float temperature) {
    return model -> model.temperature = temperature;
}
```

However, there were a few downsides:

- Of course, it's not very conventional! So it can be a bit disturbing for people used to classical builders.
- I didn't make the distinction between required and optional parameters (they were all optional!)
- The internal fields were not `final`, and I felt they should be.

## Discovering Jilt

When searching on this topic, I found [Adam Ruka](https://x.com/adam_ruka)'s great annotation processor library:
[Jilt](https://github.com/skinny85/jilt).

One of the really cool features of Jilt is its staged builder concept,
which makes builders very type-safe, and forces you to call all the required property methods by chaining them.
I found this approach very elegant.

Adam heard about my functional builder approach, and decided to implement this new style of builder in Jilt.
There are a few differences with my implementation, but it palliates some of the downsides I mentioned.

Let's have a look at what functional builders looks like from a usage standpoint:

```java
LanguageModel languageModel = languageModel(
    name("cool-model"),
    project("my-project"),
    temperature(0.5),
    description("This is a generative model")
);
```

Compared to my approach, you're not using constructors (as annotation processors can't change existing classes),
so you have to use a static method instead. But otherwise, inside that method call,
you have the named-parameter-like methods you're used to use in builders.

Here, `name()`, `project()` and `temperature()` are mandatory, and you'd get a compilation error if you forgot one of them.
But `description()` is optional and can be ommitted.

Let's now look at the implementation:

```java
import org.jilt.Builder;
import org.jilt.BuilderStyle;
import org.jilt.Opt;

import static jilt.testing.LanguageModelBuilder.*;
import static jilt.testing.LanguageModelBuilder.Optional.description;
//...
LanguageModel languageModel = languageModel(
    name("cool-model"),
    project("my-project"),
    temperature(0.5),
    description("This is a generative model")
);
//...
@Builder(style = BuilderStyle.FUNCTIONAL)
public record LanguageModel(
    String name,
    String project,
    Double temperature,
    @Opt String description
) {}
```

I used a Java `record` but it could be a good old POJO.
You must annotate that class with the `@Builder` annotation.
The `style` parameter specifies that you want to use a _functional_ builder.
Notice the use of the `@Opt` annotation to say that a parameter is not required.

## Derived instance creation

Let me close this article with another neat trick offered by Jilt, which is how to build other instances from existing ones:

```java
@Builder(style = BuilderStyle.FUNCTIONAL, toBuilder = "derive")
public record LanguageModel(...) {}
//...
LanguageModel derivedModel = derive(languageModel, name("new-name"));
```

By adding the `toBuilder = "derive"` parameter to the annotation, you get the ability to create new instances
similar to the original one, but you can change both required and optional parameters, to derive a new instance.

## Time to try Jilt!

You can try functional builders in [Jilt 1.6](https://github.com/skinny85/jilt) which was just released a few days ago!

# Let's make Gemini Groovy!


The happy users of [Gemini Advanced](https://gemini.google.com/advanced),
the powerful AI web assistant powered by the Gemini model,
can execute some Python code, thanks to a built-in Python interpreter.
So, for math, logic, calculation questions, the assistant can let Gemini invent a Python script,
and execute it, to let users get a more accurate answer to their queries.

But wearing my [Apache Groovy](https://groovy-lang.org/) hat on,
I wondered if I could get Gemini to invoke some Groovy scripts as well, for advanced math questions!

## LangChain4j based approach

As usual, my tool of choice for any LLM problem is the powerful [LangChain4j](https://docs.langchain4j.dev/) framework!
Interestingly, there are already some code engine integrations,

- a [GraalVM Polyglot Truffle](https://www.graalvm.org/latest/reference-manual/polyglot-programming/) engine, that can execute Python and JavaScript code,
- a [Judge0](https://judge0.com/) engine that uses the Judge0 online code execution system, which also supports Groovy!

I haven't tried Judge0 yet, as I saw it was supporting Groovy 3 only, and not yet Groovy 4.
But for math or logic questions, Groovy 3 is just fine anyway.
Instead, I wanted to explore how to create my own Groovy interpreter!

In the following experiment, I'm going to use the [Gemini](https://deepmind.google/technologies/gemini/) model,
because it supports _function calling_, which means we can instruct the model that it can use some tools when needed.

Let's walk through this step by step.

First, I instantiate a Gemini chat model:

```java
var model = VertexAiGeminiChatModel.builder()
    .project("MY_GCP_PROJECT_ID")
    .location("us-central1")
    .modelName("gemini-1.5-flash-001")
    .maxRetries(1)
    .build();
```

Then, I create a tool that is able to run Groovy code, thanks to the `GroovyShell` evaluator:

```java
class GroovyInterpreter {
  @Tool("Execute a Groovy script and return the result of its execution.")
  public Map<String, String> executeGroovyScript(
    @P("The groovy script source code to execute") String groovyScript) {
    String script = groovyScript.replace("\\n", "\n");
    System.err.format("%n--> Executing the following Groovy script:%n%s%n", script);
    try {
      Object result = new GroovyShell().evaluate(script);
      return Map.of("result", result == null ? "null" : result.toString());
    } catch (Throwable e) {
      return Map.of("error", e.getMessage());
    }
  }
}
```

Notice the `@Tool` annotation that describes what this tool can do.
And the `@P` annotation which explains what the parameter is about.

I noticed that sometimes the raw script that Gemini suggested contained some `\n` strings,
instead of the plain newline characters, so I'm replacing them with newlines instead.

I return a map containing either a result (as a string), or an error message if one was encountered.

Now it's time to create our assistant contract, in the form of an interface,
but with a very carefully crafted system instruction:

```java
interface GroovyAssistant {
  @SystemMessage("""
    You are a problem solver equipped with the capability of \
    executing Groovy scripts.
    When you need to or you're asked to evaluate some math \
    function, some algorithm, or some code, use the \
    `executeGroovyScript` function, passing a Groovy script \
    that implements the function, the algorithm, or the code \
    that needs to be run.
    In the Groovy script, return a value. Don't print the result \
    to the console.
    Don't use semicolons in your Groovy scripts, it's not necessary.
    When reporting the result of the execution of a script, \
    be sure to show the content of that script.
    Call the `executeGroovyScript` function only once, \
    don't call it in a loop.
    """)
  String chat(String msg);
}
```

This complex system instruction above tells the model what its role is,
and that it should call the provided Groovy script execution function
whenever it encounters the need to calculate some function, or execute some logic.

I also instruct it to return values instead of printing results.

Funnily, Gemini is a pretty decent Groovy programmer,
but it insists on always adding semi-colons like in Java,
so for a more _idiomatic_ code style, I suggest it to get rid of them!

The final step is now to create our LangChain4j AI service with the following code:

```java
var assistant = AiServices.builder(GroovyAssistant.class)
    .chatLanguageModel(model)
    .chatMemory(MessageWindowChatMemory.withMaxMessages(20))
    .tools(new GroovyInterpreter())
    .build();
```

I combine the Gemini chat model, with a memory to keep track of users' requests,
and the Groovy interpreter tool I've just created.

Now let's see if Gemini is able to create and calculate a fibonacci function:

```java
System.out.println(
  assistant.chat(
    "Write a `fibonacci` function, and calculate `fibonacci(18)`"));
```

And the output is as follows:

> ```groovy
> def fibonacci(n) {
>   if (n <= 1) {
>     return n
>   } else {
>     return fibonacci(n - 1) + fibonacci(n - 2)
>   }
> }
> fibonacci(18)
> ```
>
> The result of executing the script is: 2584.

## Discussion

It took me a bit of time to find the right system instruction to get Groovy scripts that complied to my requirements.
However, I noticed sometimes some internal errors returned by the model, which I haven't fully understood
(and particularly why those happen at all)

On some occasions, I also noticed that LangChain4j keeps sending the same script for execution, in a loop.
Same thing: I still have to investigate why this rare behavior happens.

So this solution is a fun experiment, but I'd call it just that, an experiment, as it's not as rock-solid as I want it to be.
But if I manage to make it more bullet-proof, maybe I could contribute it back as a dedicated execution engine for LangChain4j!

## Full source code

Here's the full content of my experiment:

```java
import dev.langchain4j.agent.tool.P;
import dev.langchain4j.agent.tool.Tool;
import dev.langchain4j.memory.chat.MessageWindowChatMemory;
import dev.langchain4j.model.vertexai.VertexAiGeminiChatModel;
import dev.langchain4j.service.AiServices;
import dev.langchain4j.service.SystemMessage;
import groovy.lang.GroovyShell;
import java.util.Map;

public class GroovyCodeInterpreterAssistant {
  public static void main(String[] args) {
    var model = VertexAiGeminiChatModel.builder()
      .project("MY_GCP_PROJECT_ID")
      .location("us-central1")
      .modelName("gemini-1.5-flash-001")
      .maxRetries(1)
      .build();

    class GroovyInterpreter {
      @Tool("Execute a Groovy script and return the result of its execution.")
      public Map<String, String> executeGroovyScript(
          @P("The groovy script source code to execute")
          String groovyScript) {
        System.err.format("%n--> Raw Groovy script:%n%s%n", groovyScript);
        String script = groovyScript.replace("\\n", "\n");
        System.err.format("%n--> Executing:%n%s%n", script);
        try {
          Object result = new GroovyShell().evaluate(script);
          return Map.of("result", result == null ? "null" : result.toString());
        } catch (Throwable e) {
          return Map.of("error", e.getMessage());
        }
      }
    }

    interface GroovyAssistant {
      @SystemMessage("""
        You are a problem solver equipped with the capability of \
        executing Groovy scripts.
        When you need to or you're asked to evaluate some math \
        function, some algorithm, or some code, use the \
        `executeGroovyScript` function, passing a Groovy script \
        that implements the function, the algorithm, or the code \
        that needs to be run.
        In the Groovy script, return a value. Don't print the result \
        to the console.
        Don't use semicolons in your Groovy scripts, it's not necessary.
        When reporting the result of the execution of a script, \
        be sure to show the content of that script.
        Call the `executeGroovyScript` function only once, \
        don't call it in a loop.
        """)
      String chat(String msg);
    }

    var assistant = AiServices.builder(GroovyAssistant.class)
      .chatLanguageModel(model)
      .chatMemory(MessageWindowChatMemory.withMaxMessages(20))
      .tools(new GroovyInterpreter())
      .build();

    System.out.println(
      assistant.chat(
        "Write a `fibonacci` function, and calculate `fibonacci(18)`"));
  }
}
```

# Grounding Gemini with Web Search results in LangChain4j


The latest [release of LangChain4j](https://github.com/langchain4j/langchain4j/releases/tag/0.31.0) (version 0.31) added the capability of _grounding_ large language models with results from web searches.
There's an integration with
[Google Custom Search Engine](https://developers.google.com/custom-search/v1/overview),
and also [Tavily](https://tavily.com/).

The fact of _grounding_ an LLM's response with the results from a search engine
allows the LLM to find relevant information about the query from web searches,
which will likely include up-to-date information that the model won't have seen
during its training, past its cut-off date when the training ended.

> **Remark:** Gemini has a built-in [Google Web Search grounding](https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/overview#ground-public)
> capability, however, LangChain4j's Gemini integration doesn't yet surface this feature.
> I'm currently working on a pull request to support this.

## Asking questions to your website

An interesting use case for LLM web search grounding is for example if you want to search a particular website.
I was interested in asking questions related to articles that I have posted on my personal website and blog.
Let's see, step by step, how you can implement this.

### Creating a custom search engine

First of all, as I decided to use Google Custom Search, I created a new custom search engine.
I won't detail the steps involved in this process, as it's explained in the [documentation](https://developers.google.com/custom-search/docs/tutorial/creatingcse).
I created a custom search searching only the content on my website: [glaforge.dev](https://glaforge.dev).
But you can potentially search the whole internet if you wish, or just your company website, etc.

Google Custom Search gave me an API key, as well as a Custom Search ID (csi) for my newly created custom search engine.
You can test the custom search engine with that ID with this URL:
[https://programmablesearchengine.google.com/controlpanel/overview?cx=YOUR_CSI_HERE](https://programmablesearchengine.google.com/controlpanel/overview?cx=YOUR_CSI_HERE).
It gives you a Google Search-like interface where you can enter your queries.
There's also a widget that you can integrate in your website if you wish.

### Implementation

First of all, I configure the chat model I want to use.
I'm using the latest and fastest Gemini model: [Gemini 1.5 Flash](https://deepmind.google/technologies/gemini/flash/).
I've saved my Google Cloud project ID and locaction in environment variables.

```java
VertexAiGeminiChatModel model = VertexAiGeminiChatModel.builder()
    .project(System.getenv("PROJECT_ID"))
    .location(System.getenv("LOCATION"))
    .modelName("gemini-1.5-flash-001")
    .build();
```

Next, I configure my web search engine.
Here, I'm using Google Search, but it could be Tavily as well.
I also saved my API key and the ID of my custom web search in environment variables:

```java
WebSearchEngine webSearchEngine = GoogleCustomWebSearchEngine.builder()
    .apiKey(System.getenv("GOOGLE_CUSTOM_SEARCH_API_KEY"))
    .csi(System.getenv("GOOGLE_CUSTOM_SEARCH_CSI"))
//    .logRequests(true)
//    .logResponses(true)
    .build();
```

Note that you can log the requests and responses, for debugging purpose.

Next, I define a _content retriever_, this is a way to let LangChain4j know
that _content_ can be _retrieved_ from a particular tool or location:

```java
ContentRetriever contentRetriever = WebSearchContentRetriever.builder()
    .webSearchEngine(webSearchEngine)
    .maxResults(3)
    .build();
```

Now, I define the contract I want to use to interact with my Gemini model, by creating my own custom search `interface`:

```java
interface SearchWebsite {
    String search(String query);
}
```

This interface will be implemented by LangChain4j's `AiServices` system that binds several components together:
the chat language model (here, Gemini), and the web search content retriever I created above:

```java
SearchWebsite website = AiServices.builder(SearchWebsite.class)
    .chatLanguageModel(model)
    .contentRetriever(contentRetriever)
    .build();
```

Then I can ask my question to the LLM, which will find the relevant information in my blog:

```java
String response = website.search(
    "How can I call the Gemma model from LangChain4j?");

System.out.println("response = " + response);
```

If I comment out the line `contentRetriever(contentRetriever)`, Gemini does a best effort at answering my question,
but since there's nothing in its training data (before its cut-off date)
about how to call the [Gemma](https://blog.google/technology/developers/gemma-open-models/) model from LangChain4j,
it is not able to provide a useful answer.

But with the web search content retriever, Gemini is able to find the right material to ground its answer,
as the custom search returns my article on
[calling Gemma with Ollama, Testcontainers, and LangChain4j](https://glaforge.dev/posts/2024/04/04/calling-gemma-with-ollama-and-testcontainers/):

```
Based on the provided information, you can call the Gemma model from
LangChain4j using the following approach:

1. **Use Ollama:** The articles highlight Ollama as a tool for
interacting with Gemma. You would need to set up Ollama and ensure it
has access to the Gemma model.
2. **Integrate TestContainers:** TestContainers helps you manage
containerized environments for testing. You can use it to run Ollama
within a container alongside LangChain4j.
3. **Utilize LangChain4j:** LangChain4j provides the framework for
interacting with large language models. You would define your prompt,
send it to Ollama (which runs Gemma), and receive the response back
through LangChain4j.

**Example Steps:**

1. **Set up Ollama:** Install Ollama and configure it to use the
Gemma model.
2. **Create a Dockerfile:** Use a Dockerfile to define an image that
includes Ollama and any dependencies.
3. **Run Ollama in a container using TestContainers:** Start the
container using TestContainers and ensure it is accessible from your
LangChain4j code.
4. **Implement LangChain4j calls:** Use LangChain4j to construct your
prompt and send it to Ollama (which will pass it to Gemma).
5. **Receive and process the response:** Receive the generated response
from Gemma and process it as needed in your Java application.

**Note:** These steps provide a general approach. You will need to
refer to the documentation for Ollama, TestContainers, and LangChain4j
for specific implementation details.

This method leverages Ollama as an intermediary to access Gemma.
If you have access to Google's Gemini model directly, you might be
able to integrate it with LangChain4j without the Ollama step,
depending on the specific API or SDK offered by Google.
```

The LLM found that I have to use [Ollama](https://ollama.com/) and
[TestContainers](https://testcontainers.com/), as explained in my article.
This information wasn't part of my query, so it proves that it really found the info in the article.

## Discussion

The LLM based its answer on the _excerpts_ contained in the search results,
not the whole content of the article, so some aspects of this answer are not totally correct:
For instance, you don't have to _install_ Ollama or create your own _Dockerfile_.

To make the response perfect, I believe we would have to combine web search results
with Retrieval Augmented Generation, or pass the whole context of the article to the model,
so that it could provide a more thorough and factual answer.

For different queries that lead to shorter answers, the answer would probably be more to the point.

Another approach is to annotate our `String search(String query)` method with a `@SystemInstruction()`
with instructions that encourage the LLM to provide a shorter answer.
But it's difficult to find the right balance between too long and too short,
and of course without any sort of hallucinations!

For example, you can try with the following system instruction:

```java
interface SearchWebsite {
  @SystemMessage("""
    Provide a paragraph-long answer, not a long step by step explanation.
    Reply with "I don't know the answer" if the provided information isn't relevant.
    """)
  String search(String query);
}
```

I got the following response:

```
The provided information mentions using Gemma with Ollama,
TestContainers, and LangChain4j. You can use Ollama, a local
LLM server, and TestContainers, which provides lightweight,
disposable containers, to set up a testing environment.
Then, with LangChain4j, a Java library for interacting with LLMs,
you can call Gemma through the Ollama server.
```

Which is shorter and more factual, without being too short either!

## What's next?

In an upcoming article, I'll show you how to use Gemini's built-in Google Search grounding,
but first, I have to finish my pull request for the LangChain4j project!

Or I can explore how to reply more precisely to queries that lead to complex answers like the above,
maybe combinging a RAG approach to get the full context of the article found by the web search.

Also, the Tavily API seems to be able to return the raw content of the article,
so maybe it can help giving the LLM the full context of the article to base its answers on it.
So that may be worth comparing those two web search integrations too.

Stay tuned!

## Full sample code

For reference, here is the full sample (with the system instruction approach):

```java
import dev.langchain4j.model.vertexai.VertexAiGeminiChatModel;
import dev.langchain4j.rag.content.retriever.ContentRetriever;
import dev.langchain4j.rag.content.retriever.WebSearchContentRetriever;
import dev.langchain4j.service.AiServices;
import dev.langchain4j.service.SystemMessage;
import dev.langchain4j.web.search.WebSearchEngine;
import dev.langchain4j.web.search.google.customsearch.GoogleCustomWebSearchEngine;

public class GroundingWithSearch {
  public static void main(String[] args) {
    VertexAiGeminiChatModel model = VertexAiGeminiChatModel.builder()
      .project(System.getenv("PROJECT_ID"))
      .location(System.getenv("LOCATION"))
      .modelName("gemini-1.5-flash-001")
      .build();

    WebSearchEngine webSearchEngine = GoogleCustomWebSearchEngine.builder()
      .apiKey(System.getenv("GOOGLE_CUSTOM_SEARCH_API_KEY"))
      .csi(System.getenv("GOOGLE_CUSTOM_SEARCH_CSI"))
//    .logRequests(true)
//    .logResponses(true)
      .build();

    ContentRetriever contentRetriever = WebSearchContentRetriever.builder()
      .webSearchEngine(webSearchEngine)
      .maxResults(3)
      .build();

    interface SearchWebsite {
      @SystemMessage("""
        Provide a paragraph-long answer, not a long step by step explanation.
        Reply with "I don't know the answer" if the provided information isn't relevant.
        """)
      String search(String query);
    }

    SearchWebsite website = AiServices.builder(SearchWebsite.class)
      .chatLanguageModel(model)
      .contentRetriever(contentRetriever)
      .build();

    String response = website.search(
      "How can I call the Gemma model from LangChain4j?");

    System.out.println("response = " + response);
  }
}
```

# Gemini, Google's Large Language Model, for Java Developers


As a follow-up to my talk on [generative AI for Java developers]({{< ref "/talks/2023/11/13/gen-ai-with-palm-2-and-java" >}}), I've developed a new presentation that focuses more on
the [Gemini](https://deepmind.google/technologies/gemini/#introduction) large multimodal model by Google.

In this talk, we cover the multimodality capabilities of the model, as it's able to ingest code, PDF, audio, video, and is able to reason about them.
Another specificity of Gemini is its huge context window of up to 1 million tokens!
This opens interesting perspectives, especially in multimodal scenarios.

We also talk about the [Gemma](https://blog.google/technology/developers/gemma-open-models/) model, a small open-weights model in the Gemini family, which I covered recently about how to [run it locally thanks to Ollama and Testcontainers]({{< ref "/posts/2024/04/04/calling-gemma-with-ollama-and-testcontainers.md" >}}).

In that presentation, I'm showing some of my past Gemini-powered demos, as well as the code examples in my [Gemini workshop for Java developers]({{< ref "/posts/2024/03/27/gemini-codelab-for-java-developers.md" >}}), using [LangChain4j](https://docs.langchain4j.dev/).

{{< speakerdeck 202b1956e3b747afa85cbf5d1b40bf20 >}}

# Calling Gemma with Ollama, TestContainers, and LangChain4j


Lately, for my Generative AI powered Java apps,
I've used the [Gemini](https://deepmind.google/technologies/gemini/#introduction)
multimodal large language model from Google.
But there's also [Gemma](https://blog.google/technology/developers/gemma-open-models/),
its little sister model.

Gemma is a family of lightweight, state-of-the-art open models built from the same research
and technology used to create the Gemini models. Gemma is available in two sizes: 2B and 7B.
Its weights are freely available, and its small size means you can run it on your own, even on your laptop.
So I was curious to give it a run with [LangChain4j](https://docs.langchain4j.dev/).

## How to run Gemma

There are many ways to run Gemma: in the cloud,
via [Vertex AI](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/335)
with a click of a button,
or [GKE](https://cloud.google.com/kubernetes-engine/docs/tutorials/serve-gemma-gpu-vllm) with some GPUs,
but you can also run it locally with [Jlama](https://github.com/tjake/Jlama) or
[Gemma.cpp](https://github.com/google/gemma.cpp).

Another good option is to run Gemma with [Ollama](https://ollama.com/),
a tool that you install on your machine, and which lets you run small models,
like Llama 2, Mistral, and [many others](https://ollama.com/library).
They quickly added support for [Gemma](https://ollama.com/library/gemma) as well.

Once installed locally, you can run:

```bash
ollama run gemma:2b
ollama run gemma:7b
```

Cherry on the cake, the [LangChain4j]() library provides an
[Ollama module](https://docs.langchain4j.dev/integrations/language-models/ollama),
so you can plug Ollama supported models in your Java applications easily.

## Containerization

After a great discussion with my colleague [Dan Dobrin](https://twitter.com/ddobrin)
who had worked with Ollama and TestContainers
([#1](https://github.com/GoogleCloudPlatform/serverless-production-readiness-java-gcp/blob/main/sessions/next24/books-genai-vertex-langchain4j/src/test/java/services/OllamaContainerTest.java) and
[#2](https://github.com/GoogleCloudPlatform/serverless-production-readiness-java-gcp/blob/main/sessions/next24/books-genai-vertex-langchain4j/src/test/java/services/OllamaChatModelTest.java#L37))
in his [serverless production readiness workshop](https://github.com/GoogleCloudPlatform/serverless-production-readiness-java-gcp/tree/main), I decided to try the approach below.

Which brings us to the last piece of the puzzle:
Instead of having to install and run Ollama on my computer,
I decided to use Ollama within a container, handled by [TestContainers](https://testcontainers.com/).

TestContainers is not only useful for testing, but you can also use it for driving containers.
There's even a specific [OllamaContainer](https://java.testcontainers.org/modules/ollama/) you can take advantage of!

So here's the whole picture:
![](/img/gemini/gemma-ollama-testcontainers-langchain4j.png)

## Time to implement this approach!

You'll find the code in the Github
[repository](https://github.com/glaforge/gemini-workshop-for-java-developers/blob/main/app/src/main/java/gemini/workshop/CallGemma.java)
accompanying my recent [Gemini workshop](https://codelabs.developers.google.com/codelabs/gemini-java-developers)

Let's start with the easy part, interacting with an Ollama supported model with LangChain4j:

```java
OllamaContainer ollama = createGemmaOllamaContainer();
ollama.start();

ChatLanguageModel model = OllamaChatModel.builder()
    .baseUrl(String.format("http://%s:%d", ollama.getHost(), ollama.getFirstMappedPort()))
    .modelName("gemma:2b")
    .build();

String response = model.generate("Why is the sky blue?");

System.out.println(response);
```

- You run an Ollama test container.
- You create an Ollama chat model, by pointing at the address and port of the container.
- You specify the model you want to use.
- Then, you just need to call `model.generate(yourPrompt)` as usual.

Easy?
Now let's have a look at the trickier part, my local method that creates the Ollama container:

```java
// check if the custom Gemma Ollama image exists already
List<Image> listImagesCmd = DockerClientFactory.lazyClient()
    .listImagesCmd()
    .withImageNameFilter(TC_OLLAMA_GEMMA_2_B)
    .exec();

if (listImagesCmd.isEmpty()) {
    System.out.println("Creating a new Ollama container with Gemma 2B image...");
    OllamaContainer ollama = new OllamaContainer("ollama/ollama:0.1.26");
    ollama.start();
    ollama.execInContainer("ollama", "pull", "gemma:2b");
    ollama.commitToImage(TC_OLLAMA_GEMMA_2_B);
    return ollama;
} else {
    System.out.println("Using existing Ollama container with Gemma 2B image...");
    // Substitute the default Ollama image with our Gemma variant
    return new OllamaContainer(
        DockerImageName.parse(TC_OLLAMA_GEMMA_2_B)
            .asCompatibleSubstituteFor("ollama/ollama"));
}
```

You need to create a derived Ollama container that pulls in the Gemma model.
Either this image was already created beforehand, or if it doesn't exist yet, you create it.

Use the Docker Java client to check if the custom Gemma image exists.
If it doesn't exist, notice how TestContainers let you create an image derived from the base Ollama image,
pull the Gemma model, and then commit that image to your local Docker registry.

Otherwise, if the image already exists (ie. you created it in a previous run of the application),
you're just going to tell TestContainers that you want to substitute the default Ollama image
with your Gemma-powered variant.

## And voila!

You can **call Gemma locally on your laptop, in your Java apps, using LangChain4j**,
without having to install and run Ollama locally
(but of course, you need to have a Docker daemon running).

Big thanks to [Dan Dobrin](https://twitter.com/ddobrin) for the approach,
and to [Sergei](https://twitter.com/bsideup), [Eddú](https://twitter.com/EdduMelendez)
and [Oleg](https://twitter.com/shelajev) from TestContainers for the help and useful pointers.

# Gemini codelab for Java developers using LangChain4j


No need to be a Python developer to do Generative AI!
If you're a Java developer, you can take advantage of [LangChain4j](https://docs.langchain4j.dev/)
to implement some advanced LLM integrations in your Java applications.
And if you're interested in using
[Gemini](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/),
one of the best models available, I invite you to have a look at the following "codelab" that I worked on:

[Codelab — Gemini for Java Developers using LangChain4j](https://codelabs.developers.google.com/codelabs/gemini-java-developers)

In this workshop, you'll find various examples covering the following use cases, in _crescendo_ approach:

- Making your fist call to Gemini (streaming & non-streaming)
- Maintaining a conversation
- Taking advantage of multimodality by analysing images with your prompts
- Extracting structured information from unstructured text
- Using prompt templates
- Doing text classification with few-shot prompting
- Implementing Retrieval Augmented Generation to chat with your documentation
- How to do Function Calling to expand the LLM to interact with external APIs and services

You'll find all the [code samples on Github](https://github.com/glaforge/gemini-workshop-for-java-developers).

If you're attending Devoxx France, be sure to attend the
[Hands-on-Lab workshop](https://www.devoxx.fr/en/schedule/talk/?id=40285) with my colleagues
[Mete Atamel](https://twitter.com/meteatamel) and [Valentin Deleplace](https://twitter.com/val_deleplace)
who will guide you through this codelab.

# Visualize PaLM-based LLM tokens


As I was working on tweaking the Vertex AI text embedding model in [LangChain4j](https://github.com/langchain4j),
I wanted to better understand how the `textembedding-gecko`
[model](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/text-embeddings)
tokenizes the text, in particular when we implement the
[Retrieval Augmented Generation](https://arxiv.org/abs/2005.11401) approach.

The various PaLM-based models offer a `computeTokens` endpoint, which returns a list of tokens (encoded in Base 64)
and their respective IDs.

> **Note:** At the time of this writing, there's no equivalent endpoint for Gemini models.

So I decided to create a [small application](https://tokens-lpj6s2duga-ew.a.run.app/) that lets users:

- input some text,
- select a model,
- calculate the number of tokens,
- and visualize them with some nice pastel colors.

The available PaLM-based models are:

- `textembedding-gecko`
- `textembedding-gecko-multilingual`
- `text-bison`
- `text-unicorn`
- `chat-bison`
- `code-gecko`
- `code-bison`
- `codechat-bison`

You can [try the application](https://tokens-lpj6s2duga-ew.a.run.app/) online.

And also have a look at the [source code](https://github.com/glaforge/llm-text-tokenization) on Github.
It's a [Micronaut](https://micronaut.io/) application.
I serve the static assets as explained in my recent
[article](https://glaforge.dev/posts/2024/01/21/serving-static-assets-with-micronaut/).
I deployed the application on [Google Cloud Run](https://cloud.run/),
the easiest way to deploy a container, and let it auto-scale for you.
I did a source based deployment, as explained at the bottom
[here]({{< ref "posts/2022/10/24/build-deploy-java-17-apps-on-cloud-run-with-cloud-native-buildpacks-on-temurin.md" >}}).

And _voilà_ I can visualize my LLM tokens!

# Image generation with Imagen and LangChain4j


This week [LangChain4j](https://github.com/langchain4j "LangChain4j"), the LLM orchestration framework for Java developers, released version
[0.26.1](https://github.com/langchain4j/langchain4j/releases/tag/0.26.1 "0.26.1"), which contains my first significant contribution to the open source project:
**support for the Imagen image generation model**.

**Imagen** is a text-to-image diffusion model that was [announced](https://imagen.research.google/ "announced") last year.
And it recently upgraded to [Imagen v2](https://deepmind.google/technologies/imagen-2/ "Imagen v2"), with even higher quality graphics generation.
As I was curious to integrate it in some of my generative AI projects, I thought that would be a great first
[contribution](https://github.com/langchain4j/langchain4j/pull/456 "contribution") to LangChain4j.

> **Caution:** At the time of this writing, image generation is still only for allow-listed accounts.
>
> Furthermore, to run the snippets covered below, you should have an account on Google Cloud Platform,
> created a project, configured a billing account, enabled the Vertex AI API,
> and authenticated with the gcloud SDK and the command:
> `gcloud auth application-default login`.

Now let's dive in how to use Imagen v1 and v2 with LangChain4j in Java!

## Generate your first images

In the following examples, I'm using the following constants, to point at my project details, the endpoint, the region, etc:

```java
private static final String ENDPOINT = "us-central1-aiplatform.googleapis.com:443";
private static final String LOCATION = "us-central1";
private static final String PROJECT = "YOUR_PROJECT_ID";
private static final String PUBLISHER = "google";
```

First, we're going to create an instance of the model:

```java
VertexAiImageModel imagenModel = VertexAiImageModel.builder()
    .endpoint(ENDPOINT)
    .location(LOCATION)
    .project(PROJECT)
    .publisher(PUBLISHER)
    .modelName("imagegeneration@005")
    .maxRetries(2)
    .withPersisting()
    .build();
```

There are 2 models you can use:

- `imagegeneration@005` corresponds to Imagen 2
- `imagegeneration@002` is the previous version (Imagen 1)

In this article, we'll use both models. Why? Because currently Imagen 2 doesn't support image editing, so we'll have to use Imagen 1 for that purpose.

The configuration above uses `withPersisting()` to save the generated images in a temporary folder on your system.
If you don't persist the image files, the content of the image is avaiable as Base 64 encoded bytes in the `Image`s objects returned.
You can also specify `persistTo(somePath)` to specify a particular directory where you want the generated files to be saved.

Let's create our first image:

```java
Response<Image> imageResponse = imagenModel.generate(
    "watercolor of a colorful parrot drinking a cup of coffee");
```

The `Response` object wraps the created `Image`.
You can get the `Image` by calling `imageResponse.getContent()`.
And you can retrieve the URL of the image (if saved locally) with `imageResponse.getContent().url()`.
The Base 64 encoded bytes can be retrieved with `imageResponse.getContent().base64Data()`

Some other tweaks to the model configuration:

- Specify the **language** of the prompt: `language("ja")`
  (if the language is not officially supported, it's usually translated back to English anyway).
- Define a **negative prompt** with things you don't want to see in the picture: `negativePrompt("black feathers")`.
- Use a particular **seed** to always generate the same image with the same seed: `seed(1234L)`.

So if you want to generate a picture of a pizza with a prompt in Japanese, but you don't want to have pepperoni and pineapple,
you could configure your model and generate as follows:

```java
VertexAiImageModel imagenModel = VertexAiImageModel.builder()
        .endpoint(ENDPOINT)
        .location(LOCATION)
        .project(PROJECT)
        .publisher(PUBLISHER)
        .modelName("imagegeneration@005")
        .language("ja")
        .negativePrompt("pepperoni, pineapple")
        .maxRetries(2)
        .withPersisting()
        .build();

Response<Image> imageResponse = imagenModel.generate("ピザ"); // pizza
```

## Image editing with Imagen 1

With Imagen 1, you can [edit](https://cloud.google.com/vertex-ai/docs/generative-ai/image/edit-images?hl=en "edit") existing images:

- **mask-based editing:** you can specify a mask, a black & white image where the white parts are the corresponding parts of the original image that should be edited,
- **mask free editing:** where you just give a prompt and let the model figure out what should be edited on its own or following the prompt.

When generating and editing with Imagen 1, you can also configure the model to use a particular style (with Imagen 2, you just specify it in the prompt) with `sampleImageStyle(VertexAiImageModel.ImageStyle.photograph)`:

- `photograph`
- `digital_art`
- `landscape`
- `sketch`
- `watercolor`
- `cyberpunk`
- `pop_art`

When editing an image, you may wish to decide how strong or not the modification should be, with `.guidanceScale(100)`.
Usually, between 0 and 20 or so, it's lightly edited, between 20 and 100 it's getting more impactful edits, and 100 and above it's the maximum edition level.

Let's say I generated an image of a lush forrest (I'll use that as my original image):

```java
VertexAiImageModel model = VertexAiImageModel.builder()
        .endpoint(ENDPOINT)
        .location(LOCATION)
        .project(PROJECT)
        .publisher(PUBLISHER)
        .modelName("imagegeneration@002")
        .seed(19707L)
        .sampleImageStyle(VertexAiImageModel.ImageStyle.photograph)
        .guidanceScale(100)
        .maxRetries(4)
        .withPersisting()
        .build();

Response<Image> forestResp = model.generate("lush forest");
```

Now I want to edit my forrest to add a small red tree in the bottom of the image.
I'm loading a black and white mask image with a white square at the bottom.
And I pass the original image, the mask image, and the modification prompt, to the new `edit()` method:

```java
URI maskFileUri = getClass().getClassLoader().getResource("mask.png").toURI();

Response<Image> compositeResp = model.edit(
        forestResp.content(),              // original image to edit
        fromPath(Paths.get(maskFileUri)),  // the mask image
        "red trees"                        // the new prompt
);
```

![](/img/gemini/lush-forrest-red-tree.jpg)

Another kind of editing you can do is to upscale an existing image.
As far as I know, it's only supported for Imagen v1 for now, so we'll continue with that model.

In this example, we'll generate an image of 1024x1024 pixels, and we'll scale it to 4096x4096:

```java
VertexAiImageModel imagenModel = VertexAiImageModel.builder()
        .endpoint(ENDPOINT)
        .location(LOCATION)
        .project(PROJECT)
        .publisher(PUBLISHER)
        .modelName("imagegeneration@002")
        .sampleImageSize(1024)
        .withPersisting()
        .persistTo(defaultTempDirPath)
        .maxRetries(3)
        .build();

Response<Image> imageResponse =
        imagenModel.generate("A black bird looking itself in an antique mirror");

VertexAiImageModel imagenModelForUpscaling = VertexAiImageModel.builder()
        .endpoint(ENDPOINT)
        .location(LOCATION)
        .project(PROJECT)
        .publisher(PUBLISHER)
        .modelName("imagegeneration@002")
        .sampleImageSize(4096)
        .withPersisting()
        .persistTo(defaultTempDirPath)
        .maxRetries(3)
        .build();

Response<Image> upscaledImageResponse =
        imagenModelForUpscaling.edit(imageResponse.content(), "");
```

And now you have a much bigger image!

## Conclusion

That's about it for image generation and editing with Imagen in LangChain4j today!
Be sure to use LangChain4j v0.26.1 which contains that new integration.
And I'm looking forward to seeing the pictures you generate with it!
m

# Serving static assets with Micronaut


My go-to framework when developing Java apps or microservices is
[Micronaut](https://micronaut.io).
For the apps that should have a web frontend, I rarely use
[Micronaut Views](https://micronaut-projects.github.io/micronaut-views/latest/guide/)
and its templating support.
Instead, I prefer to just **serve static assets** from my resource folder,
and have some JavaScript framework (usually [Vue.js](https://vuejs.org/))
to populate my HTML content (often using
[Shoelace](https://shoelace.style/) for its nice Web Components).
However, the [static asset documentation](https://docs.micronaut.io/latest/guide/#staticResources)
is a bit light on explanations.
So, since I always forget how to configure Micronaut to serve static assets,
I thought that would be useful to document this here.

In `/src/main/resources/application.properties`, I'm adding the following:

```properties
micronaut.router.static-resources.default.paths=classpath:public
micronaut.router.static-resources.default.mapping=/**
micronaut.router.static-resources.default.enabled=true

micronaut.server.cors.enabled=true
```

* The first line says that my resources will live in `src/main/resources/public/`.
* The second line means the pattern will match recursively for sub-directories as well.
* The `enabled` flag is to activate static serviing (not strictly needed as it's supposed to be enabled by default).
* I also enabled CORS (cross-origin resource sharing).

Then in `src/main/resources/public/`, I'll have my `index.html` file,
my `css` and `js` folders.


# Light Mode Bookmarlet

A while ago, my friend Sylvain Wallez shared a little [bookmarlet](https://twitter.com/bluxte/status/1729912211882094701 "bookmarlet")  
on Twitter/X that transforms a dark mode site into light mode.  
I know the trend is towards dark mode, but for a lot of people with certain vision issues,  
for example with astigmatism like me, certain dark modes can very painful.

This site about [vision](https://www.allaboutvision.com/digital-eye-strain/is-dark-mode-better-for-eyes/ "vision")  
(and you'll find other similar references) mentions that:

> People who have myopia or **astigmatism** also may experience **halation** (from the word “halo”).  
> Halation occurs when light spreads past a certain boundary, creating a foggy or blurry appearance.

So for certain websites, often with a too strong contrast, I'm using the following bookmarklet trick.

Go to your bookmark manager, and save the following bookmarklet (I called mine "light mode"):

```javascript
javascript:(function(){document.documentElement.style.filter=document.documentElement.style.filter?%27%27:%27invert(100%)%20hue-rotate(180deg)%27})();
```

Now, to pretty print the above code and remove the URL encoded characters, to decypher what it does:

```javascript
(function () {
  document.documentElement.style.filter = document.documentElement.style.filter
    ? ""
    : "invert(100%) hue-rotate(180deg)";
})();
```

Two filters are going to be applied to your current web page:

- First, it will completely **invert** all the colors, like a negative photography
- Second, compared to Sylvain, I also add a **hue rotation** of 180 degrees

## Why the hue rotation

Because the color inversion is also going to shift the colors: a red will become blue, a yellow will be dark blue, a violet will turn pink, etc.  
With a hue rotation, we get back the right color, a red is still red, a blue is still blue, etc.  
The different however will be in the lightness, as a light blue becomes dark, and a dark green becomes light.  
But at least, it's a bit more faithful to the original images.

Here's a picture to highlight the differences.  
See how the rainbow picture is transformed:

![](/img/misc/invert-hue-roate.jpg)

## Possible improvements

Perhaps we could avoid applying the filter globally, or at least avoid to apply it somehow to the images, so that they are not affected by those filters.  
At least for now, that's good enough for me!
# Functional builder approach in Java


In Java, builders are a pretty classical pattern for creating complex objects with lots of attributes.
A nice aspect of builders is that they help reduce the number of constructors you need to create,
in particular when not all attributes are required to be set (or if they have default values).

However, I've always found builders a bit verbose with their `newBuilder()` / `build()` method combos,
especially when you work with deeply nested object graphs, leading to lines of code of builders of builders of...

As I was chatting about those builders with my colleague [Valentin](https://www.linkedin.com/in/deleplacevalentin/),
who is a Go developer, he told me about Golang's functional builder approach.
It's not a very common implementation practice for Java builders, but it's worth revisiting!

## First, the classical builder

Let's start with an example.
We want to create a builder for a class with a few attributes.
Not all attributes are mandatory, some may have some default values,
and we don't want to create as many constructors as possible combinations of attributes.

Let me introduce you to my `SomeModel` class:

```java
public class SomeModel {
    private String modelName;
    private Float temperature = 0.3f;
    private Integer maxOutputTokens = 100;
    // ... possibly many other attribtues

    private SomeModel(String modelName,
                      Float temperature,
                      Integer maxOutputTokens) {
        this.modelName = modelName;
        this.temperature = temperature;
        this.maxOutputTokens = maxOutputTokens;
    }
}
```

Creating tons of constructors for the various model configurations can be painful.
Furthermore, some attributes can have the same type, so from a user perspective, it's hard to know which value corresponds to which parameter type.
So creating a builder can reduce that toil.

We could write a static builder class inside `SomeModel` along the lines of:

```java
public class SomeModelBuilder {
    private String modelName;
    private Float temperature = 0.3f;
    private Integer maxOutputTokens = 100;

    public SomeModelBuilder modelName(String modelName) {
        this.modelName = modelName;
        return this;
    }

    public SomeModelBuilder temperature(Float temperature) {
        this.temperature = temperature;
        return this;
    }

    public SomeModelBuilder maxOutputTokens(Integer maxOutputTokens) {
        this.maxOutputTokens = maxOutputTokens;
        return this;
    }

    public SomeModel build() {
        return new SomeModel(modelName, temperature, maxOutputTokens);
    }
}
```

Inside `SomeModel` you would add a method to instantiate a builder:

```java
public static SomeModelBuilder newBuilder() {
    return new SomeModelBuilder();
}
```

Then, the user would create a model instance with the builder as follows:

```java
var model = SomeModel.newBuilder()
    .modelName("gemini")
    .temperature(0.2f)
    .maxOutputToken(300)
    .build();
```

Not too bad.
The are some variations to this approach, like passing the builder in the class' constructor,
using setter methods that return `this`, using or not using final fields, etc.
But they are mostly stylistic variations.

However, I was wondering about this idea of a functional builder...

## Existing functional approaches in Java

I haven't found much litterature on this theme.
There are 2 blog posts
([here](https://medium.com/beingprofessional/think-functional-advanced-builder-pattern-using-lambda-284714b85ed5)
and [there](https://www.innovect.com/advanced-builder-using-java-8-lambda))
that suggest an approach with lambda expressions and `Consumer`s,
but I find it even more unconventional than the approach I'm going to describe further in this article:

```java
SomeModel model = new SomeModelBuilder()
        .with($ -> {
            $.modelName = "Gemini";
            $.temperature = 0.4f;
        })
        .with($ -> $.maxOutputTokens = 100);
```

You can pass one or more lambdas in chained calls.
It's the end-user who controls how the model is built, not the implementor, so I feel it's less safe.
The use of the `$` sign is a bit of a syntactical hack to avoid repeating the name of the variable corresponding to the model.
Finally, there's still a builder class after all, and maybe we can find a way to get rid of it.

Let's see what Go has to offer instead, and if we can get some inspiration from it!

## The Go approach

My colleague [Valentin](https://www.linkedin.com/in/deleplacevalentin/) pointed me at Dave Cheney's
[article](https://dave.cheney.net/2014/10/17/functional-options-for-friendly-apis) on Go's functional option pattern.
There's also a [video](https://www.youtube.com/watch?v=24lFtGHWxAQ) available.

The idea is that the class' constructor takes function _options_ as a vararg paramter,
that are able to modify the instance that's being built.

Let's illustrate this with the following snippet.

We create a `struct` that represents our model object like in our Java example:

```go
package main

import "fmt"

type SomeModel struct {
    modelName string
    temperature float32
    maxOutputTokens int
}
```

We define a method to construct our model, which takes a vararg of options:

```go
func NewModel(options ...func(*SomeModel)) (*SomeModel) {
    m := SomeModel{"", 0.3, 100}

    for _, option := range options {
        option(&m)
    }

    return &m
}
```

Those options are actually functions that take a model object as parameter.

Now we can create utility methods that create such option functions,
and we pass the value for each field of the `struct` via the method parameter.
So we have a method for each structure field: model name, temperature and max output tokens:

```go
func modelName(name string) func(*SomeModel) {
    return func(m *SomeModel) {
        m.modelName = name
    }
}

func temperature(temp float32) func(*SomeModel) {
    return func(m *SomeModel) {
        m.temperature = temp
    }
}

func maxOutputTokens(max int) func(*SomeModel) {
    return func(m *SomeModel) {
        m.maxOutputTokens = max
    }
}
```

Next we can create the model in the following way, by calling the utility methods that return functions
that are able to modify the `struct`.

```go
func main() {
    m := NewModel(
        modelName("gemini"),
        temperature(0.5),
        maxOutputTokens(100))

    fmt.Println(m)
}
```

Notice there's not even a `NewBuilder()` or `Build()` method!

## Let's implement our functional builder in Java!

We can follow the same approach in Java.
Instead of Go functions, we'll use Java's lambdas.
Our lambdas will be converted into `Consumer`s of `SomeModel`.

So let's recreate our `SomeModel` class, with the same fields as before.
This time, however, the constructor won't be `private`, and it'll take a list of options
(lambda expressions that consume instances of `SomeModel`).
We'll iterate over all of them to execute them:

```java
import java.util.function.Consumer;

public class SomeModel {
    private String modelName;
    private Float temperature = 0.3f;
    private Integer maxOutputTokens = 100;

    public SomeModel(ModelOption... options) {
        for (Option option : options) {
            option.accept(this);
        }
    }
```

> **Update #1:** A neat [suggestion](https://gist.github.com/edeandrea/27ee1c61f05e640fc6fa1e19b8fb756e)
> by Eric Deandrea on Twitter to use streams to filter the null options,
> as I was not checking them with an extra `if` before calling `accept()` on the option:
>
> ```java
> Optional.ofNullable(options)
>    .map(Stream::of)
>    .orElseGet(Stream::empty)
>    .forEach(option -> option.accept(this))
> ```

And what is this `ModelOption` class? This is just a synonym for a `Consumer<SomeModel>`
(so not strictly needed, but can help with readability).
It's a nested interface:

```java
    public interface ModelOption extends Consumer<SomeModel> {}
```

Next, we create similar utility methods that will update the model instance:

```java
    public static ModelOption modelName(String modelName) {
        return model -> model.modelName = modelName;
    }

    public static ModelOption temperature(Float temperature) {
        return model -> model.temperature = temperature;
    }

    public static ModelOption maxOutputTokens(Integer maxOutputTokens) {
        return model -> model.maxOutputTokens = maxOutputTokens;
    }
}
```

Now, if we want to create a model, we'll be able to call the constructor as follows:

```java
import fn.builder.SomeModel;
import static fn.builder.SomeModel.*;
//...

SomeModel model = new SomeModel(
    modelName("gemini"),
    temperature(0.5f),
    maxOutputTokens(100)
);
```

Don't forget to use a `static import` to keep the syntax short.

## Discussion

A few advantages I see with this approach:

- I like the fact we're using a constructor to construct our model instances!
- And the constructor is super simple and short!
- It also means that the constructor won't change when there's going to be a new parameter to handle (better backward compatibility).
  On the other hand, with a traditional builder, the constructor could also take the builder itself as sole parameter.
- I'm also happy that I got rid of the verbose `newBuilder()` / `build()` combo.
  It feels like we don't really have a builder at play here.
- At first, I was wondering if I was opening the Pandora box, as I feared developers could provide their own lambda
  and potentially wreck havoc in my instance construction, but because of visibility rules,
  only my methods can modify the internals of the model class
- Although we're using a constructor, the fact of passing those method calls as parameters, it feels a bit like having
  [named arguments](https://www.groovy-lang.org/objectorientation.html#_named_parameters)
  like in languages like Python or Groovy (which can also
  [create builders for you](https://www.groovy-lang.org/metaprogramming.html#xform-Builder) via AST transformations).
  It also looks more like the classical builder too, which has that readability aspect.
- I can pass the arguments in whichever order I want.
- I can put validation rules both in each mutator method and in the constructor after all mutators have been called.

Potential tweaks:

- I used non-final fields, because I wanted to be able to define my default values for some fields at definition time
  rather than in the constructor, but we could certainly tweak this implementation a bit if needed.
  And anyway, only my mutator methods can alter those fields, so I guess it's fine.
- I was curious if I could use Java `enum`s for storing only my allowed mutators,
  but I haven't found an effective and concise way of implementing this.
  Java `enum`s don't work like Rust's, but there's an interesting article about this
  [here](https://www.reddit.com/r/java/comments/135i37c/rust_like_enums_in_java/) on how to implement sum types.
- I wondered also about a mix of `sealed` `interface`s and maybe `record`s, but similarly to `enum`s,
  I couldn't find a nice and short syntax that I was happy with.

In the cons:

- It's a bit unconventional, as I haven't seen this approach implemented in the wild.
  So maybe the approach suffers in terms of readability.
- The other concerns I have is with discoverability.
  When auto-completing code, an IDE like IntelliJ is smart enough to suggest the mutators methods can be used inside the constructor.
  But it's not that clear that such mutator methods exist.
  It's going to be important to document the constructor to say that those mutators exist.

## Feedback

I'd be curious to hear your thoughts on this.
Don't hesitate to interact with me on
[Mastodon](https://uwyn.net/@glaforge/111766219413506355),
[Twitter](https://twitter.com/glaforge/status/1747272263546905026), or
[BlueSky](https://bsky.app/profile/glaforge.bsky.social/post/3kj47jxwseg2m)

# URL slug or how to remove accents from strings in Java


In this article, we'll figure out how to create _slugs_.
Not the slobbery kind of little gastropods that crawls on the ground. Instead,
we'll see how to create the short hyphened text you can see in the URL of your web browser,
and that is often a **URL-friendly variation of the title of the article**.

> Interestingly, one of the most popular posts on my blog is an almost 20 year old article that explains
> how to [remove accents from a string]({{< ref "posts/2005/04/27/how-to-remove-accents-from-a-string" >}}).
> And indeed, in _slugs_ you would like to remove accents, among other things.

So what problem are we trying to solve today?
Let's say you have an article whose title is _"L'été, où est tu ?"_
(which translates to: _"Summer, where have you been?"_").
You want your blog to have a friendly URL that looks like the title,
but without the punctuation, or the accents (also called diacritical marks),
and you also want to replace spaces with hyphens.
The final URL should then be `https://myblog.com/l-ete-ou-est-tu`.

A naive approach would be to try to replace all the letters with diacritical marks with their non marked equivalents.
So don't try to replace _"é"_ with "e", etc. You'll likely miss some letters in some languages.
A better approach is to take advantage of **Unicode normalization**.

If you are interested, you can learn more about
[unicode normalization](https://unicode.org/reports/tr15/images/UAX15-NormFig4.jpg)
on the [Unicode.org](https://unicode.org/reports/tr15/) website.
But in a nutshell, some letters, like accented letters, are a combination of a base letter, and a diacritical mark.

Let's have a look at this image from the link above:

![](https://unicode.org/reports/tr15/images/UAX15-NormFig3.jpg)

The uppercase [angström](https://www.compart.com/en/unicode/U+212B) letter is comprised of
the _A uppercase letter_, and the _ring above_ diacritical mark.
The composed letter has a unicode value of `U+212B` but can be decomposed
into `U+0041` _(uppercase A)_ and `U+30A` _(ring above)_.

I'll spare you from the details of the various normalization forms.
But Java allows you to work with the normalized forms of letters thanks to the `java.text.Normalizer` class.
We'll also take advantage of Java's regex `Pattern` class to identify particular classes of characters.

> Be sure to check the Javadocs of the `Normalizer` and `Pattern` classes:
>
> - [Normalizer](https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/text/Normalizer.html)
> - [Pattern](https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/regex/Pattern.html)
>
> The former explains how to do string normalization, and the latter will give you the list of available character classes.

Let's have a look at the following Java snippet:

```java
import java.text.Normalizer;

String title = "L'été, où es tu ?"

Normalizer.normalize(title, Normalizer.Form.NFD)
          .toLowerCase()                  // "l'été, où es tu ?"
          .replaceAll("\\p{IsM}+", "")    // "l'ete, ou es tu ?"
		  .replaceAll("\\p{IsP}+", " ")   // "l ete  ou es tu  "
          .trim()                         // "l ete  ou es tu"
          .replaceAll("\\s+", "-")        // "l-ete-ou-es-tu"

```

My approach is usually the following:

- First, I normalize the text into the `NFD` form _(canonical decomposition)_, so base characters and diacritical marks are now separated,
- Then, I'm replacing all the uppercase letters with lowercase ones,
- Next, we use the `IsM` property which selects the the diacritical marks, and we remove them
- Simiarly, we look at the characters which are punctuation, with the `IsP` binary property, and replace them with spaces
- I usually trim the string at that point, as I don't want to have spaces at the beginning or end of the strings (when a punctuation mark is replace with a space in the previous step)
- Eventually, all the space characters are replaced with hyphens.

## Slugify

Recently, I came across a Java library that takes care of creating slugs: [Slugify](https://github.com/slugify/slugify)!

With Slugify, you can do a similar transformation as mine, with the following code:

```java
import com.github.slugify.Slugify;

Slugify slugify = Slugify.builder().build();
slugify.slugify("L'été, où es tu ?")    // "lete-ou-es-tu"
```

A small difference here is that the quote is removed, which leads to having the string `lete` instead of `l-ete`.
I find that a bit less readable at a glance, but Slugify has various knobs you can tweak to customize its output.

There's one particular thing I like about this library, it's its use of the
[ICU4J](https://unicode-org.github.io/icu/userguide/icu4j/) library, which supports **transliteration**
_([ICU](https://icu.unicode.org/) is a well known set of libraries for full unicode and globalization support.)_

The problem with our examples above is that they work well for language with latin-like alphabets.
But my examples keep characters like ideograms intact, and Slugify removes them by default.
If you want to have URLs that stay within the ASCII realm,
you can use [transliteration](https://en.wikipedia.org/wiki/Transliteration),
which can map text in one language into readable latin-like text that sounds like the original text.

So if I wanted to transliterate my string into ascii-friendly text, I could use Slugify's integration of ICU:

```java
import com.github.slugify.Slugify;

Slugify slugify = Slugify.builder()
        .transliterator(true)          // use transliteration
        .locale(Locale.ENGLISH)
        .build()
        
slugify.slugify("夏よ、どこにいるの？")  // "xiayo-dokoniiruno"
```

# Gemini Function Calling


A promising feature of the Gemini large language model released recently by [Google DeepMind](https://deepmind.google/),
is the support for [function calls](https://ai.google.dev/docs/function_calling).
It's a way to supplement the model, by letting it know an external functions or APIs can be called.
So you're not limited by the knowledge cut-off of the model: instead, in the flow of the conversation with the model,
you can pass a list of functions the model will know are available to get the information it needs,
to complete the generation of its answer.

For example, if you want to ask the model about the weather, it doesn't have the realtime information about the weather forecast.
But we can tell it that there's a function that can be called, to get the forecast for a given location.
Internally, the model will acknowledge it doesn't know the answer about the weather,
but it will request that you call an external function that you describe, using a specific set of parameters which correspond to the user's request.

Just days ago, I wrote about how to [get started with Gemini in Java]({{< ref "/posts/2023/12/13/get-started-with-gemini-in-java" >}}).
In that article, we explored how to use the hand-written Java SDK that is available to interact with Gemini from Java.
However, the Java SDK doesn't yet expose all the features of the model: in particular, function calling is missing.
But not all hope is lost! Because under the hood, the SDK relies on the generated protobuf classes library, which exposes everything!

> Soon, Gemini will be supported by [LangChain4j](https://github.com/langchain4j/langchain4j),
> and the Java SDK will also provide an easier way to take care of function calling.
> But in this article, I wanted to explore the use of the internal protobuf classes, to see how to best implement its support in the SDK.

Let's go step by step!

Instead of using the `GenerativeModel` API from the SDK, we'll go straight with the `PredictionServiceClient`:

```java
try (VertexAI vertexAI = new VertexAI(projectId, location)) {
  PredictionServiceClient client = vertexAI.getPredictionServiceClient();
  ...
}
```

We need to prepare a function declaration to describe the kind of functions that the LLM can ask us to call, and we'll wrap it in a `Tool`:

```java
FunctionDeclaration functionDeclaration = FunctionDeclaration.newBuilder()
    .setName("getCurrentWeather")
    .setDescription("Get the current weather in a given location")
    .setParameters(
        Schema.newBuilder()
            .setType(Type.OBJECT)
            .putProperties("location", Schema.newBuilder()
                .setType(Type.STRING)
                .setDescription("location")
                .build()
            )
            .addRequired("location")
            .build()
    )
    .build();

Tool tool = Tool.newBuilder()
    .addFunctionDeclarations(functionDeclaration)
    .build();
```

Functions are described using classes that represent a subset of the OpenAPI 3 specification.

> This is important to provide descriptions for the functions and its parameters,
> as the LLM will use that information to figure out which function to call, and which parameters should be passed.

Next, let's prepare a question asking about the weather in Paris, and configuring the text generation request with that prompt and the tool defined above:

```java
String resourceName = String.format(
    "projects/%s/locations/%s/publishers/google/models/%s",
    vertexAI.getProjectId(), vertexAI.getLocation(), modelName);

Content questionContent =
    ContentMaker.fromString("What's the weather in Paris?");

GenerateContentRequest questionContentRequest =
    GenerateContentRequest.newBuilder()
        .setEndpoint(resourceName)
        .setModel(resourceName)
        .addTools(tool)
        .addContents(questionContent)
        .build();

ResponseStream<GenerateContentResponse> responseStream =
    new ResponseStream<>(new ResponseStreamIteratorWithHistory<>(
        client
            .streamGenerateContentCallable()
            .call(questionContentRequest)
            .iterator())
);

GenerateContentResponse generateContentResponse =
    responseStream.stream().findFirst().get();
Content callResponseContent =
    generateContentResponse.getCandidates(0).getContent();
```

If you print the `callResponseContent` variable, you'll see that it contains a function call request,
suggesting that you should call the predefined function with the parameter of `Paris`:

```
role: "model"
parts {
  function_call {
    name: "getCurrentWeather"
    args {
      fields {
        key: "location"
        value {
          string_value: "Paris"
        }
      }
    }
  }
}
```

At that point, as the developer, it's your turn to work a little, and make the call to that function yourself!
Let's pretend I called an external Web Service that gives weather information, and that it returns some JSON payload that would look like so:

```json
{
  "weather": "sunny",
  "location": "Paris"
}
```

We need now to create a function response structure to pass that information back to the LLM:

```java
Content contentFnResp = Content.newBuilder()
    .addParts(Part.newBuilder()
        .setFunctionResponse(
            FunctionResponse.newBuilder()
                .setResponse(
                    Struct.newBuilder()
                        .putFields("weather",
                            Value.newBuilder().setStringValue("sunny").build())
                        .putFields("location",
                            Value.newBuilder().setStringValue("Paris").build())
                        .build()
                )
                .build()
        )
        .build())
    .build();
```

Then, since LLMs are actually stateless beasts, we need to give it the whole context of the conversation again,
passing the query, the function call response the model suggested us to make, as well as the response we got from the external weather service:

```java
GenerateContentRequest generateContentRequest = GenerateContentRequest.newBuilder()
    .setEndpoint(resourceName)
    .setModel(resourceName)
    .addContents(questionContent)
    .addContents(callResponseContent)
    .addContents(contentFnResp)
    .addTools(tool)
    .build();
```

And to finish, we'll invoke the `client` one last time with that whole dialog and information, and print a response out:

```java
responseStream = new ResponseStream<>(new ResponseStreamIteratorWithHistory<>(
    client
        .streamGenerateContentCallable()
        .call(generateContentRequest)
        .iterator())
);

for (GenerateContentResponse resp : responseStream) {
    System.out.println(ResponseHandler.getText(resp));
}
```

And happily, Gemini will reply to us that:

```
The weather in Paris is sunny.
```

What a lovely way to start the holiday season with a nice and sunny weather!

I wish you all happy year end festivities, and I look forward to seeing you next year.
Hopefully next month, I'll be able to show you some cool new SDK features or the LangChain4j integration!
Thanks for reading.

# Visualize and Inspect Workflows Executions


When using a service like Google Cloud [Workflows](https://cloud.google.com/workflows/),
in particular as your workflows get bigger, it can be difficult to understand what's going on under the hood.
With multiple branches, step jumps, iterations, and also parallel branches and iterations,
if your workflow fails during an execution, until now, you had to check the execution status,
or go deep through the logs to find more details about the failed step.

I have good news for you!
Workflows recently added some deeper introspection capability:
you can now [view the history of execution steps](https://cloud.google.com/workflows/docs/debug-steps).
From the Google Cloud console, you can see the lists of steps, and see the logical flow between them.
The usual workflow visualisation will also highlight in green the successful steps, and in red the failed one.
Of course, it is also possible to make a curl call to get the JSON of the
[list of executed steps](https://cloud.google.com/workflows/docs/debug-steps#list-entries).

Let's have a look!

In the console, when you click on an execution, in the `summary` tab,
you'll see not only the failed step, but also the nice workflow graph colored green and red:

![](/img/workflows-days/step-visu-1.png)

That way, you know which path the execution followed, in a visual manner.
But you can also see the actual list of steps executed, with more details, by clicking on the `steps` tab:

![](/img/workflows-days/step-visu-2.png)

From this table, the filter will let you further refine particular type of steps you'd like to investigate,
or visualise the steps of a subworkflow only, etc.

This is a nice improvement to the developer experience, and for your ops team,
to better understand what happens during your workflow executions!
Feel free to read more about this new capabability in the documentation about
[viewing the history of execution steps](https://cloud.google.com/workflows/docs/debug-steps).

# Hands on Codelabs to dabble with Large Language Models in Java


Hot on the heels of the [release of Gemini](https://glaforge.dev/posts/2023/12/13/get-started-with-gemini-in-java/),
I'd like to share a couple of resources I created to get your hands on large language models,
using [LangChain4J](https://github.com/langchain4j/), and the [PaLM 2](https://ai.google/discover/palm2/) model.
Later on, I'll also share with you articles and codelabs that take advantage of Gemini, of course.

The PaLM 2 model supports 2 modes:

- text generation,
- and chat.

In the 2 codelabs, you'll need to have created an account on Google Cloud, and created a project.
The codelabs will guide you through the steps to setup the environment,
and show you how to use the Google Cloud built-in shell and code editor, to develop in the cloud.

You should be a Java developer, as the examples are in Java, use the [LangChain4J](https://github.com/langchain4j/) project, and Maven for building the code.

### [Generative AI text generation in Java with PaLM and LangChain4J](https://codelabs.developers.google.com/codelabs/genai-text-gen-java-palm-langchain4j?hl=en#0)

In the first [codelab](https://codelabs.developers.google.com/codelabs/genai-text-gen-java-palm-langchain4j?hl=en#0)
you can explore:

- how to make your first call to PaLM for simple question/answer scenarios
- how to extract structured data out of unstructured text
- how to use prompts and prompt templates
- how to classify text, with an example on sentiment analysis

### [Generative AI powered chat with users and docs in Java with PaLM and LangChain4J](https://codelabs.developers.google.com/codelabs/genai-chat-java-palm-langchain4j?hl=en#0)

In the second [codelab](https://codelabs.developers.google.com/codelabs/genai-chat-java-palm-langchain4j?hl=en#0)
you'll use the chat model to learn:

- how to create your first chat with the PaLM model
- how to give your chatbot a personality, with an example with a chess player
- how to extract structured data out of unstructured text using LangChain4J's AiServices and its annotations
- how to implement Retrieval Augmented Generation (RAG) to answer questions about your own documentation

## Going further with Generative AI

If you're interested in going further with Generative AI, and learn more,
feel free to [join the Google Cloud Innovators program](https://goo.gle/generativeai).

Google Cloud Innovators is **free** and includes:

- live discussions, AMAs, and roadmap sessions to learn the latest directly from Googlers,
- the latest Google Cloud news right in your inbox,
- digital badge and video conference background,
- and more.

Go check what the [program offers](https://cloud.google.com/innovators?hl=en)!

# Get Started with Gemini in Java


Google announced today the availability of
[Gemini](https://cloud.google.com/blog/products/ai-machine-learning/gemini-support-on-vertex-ai),
its latest and more powerful Large Language Model.
Gemini is **multimodal**, which means it's able to consume not only text, but also images or videos.

I had the pleasure of working on the Java samples and help with the Java SDK, with wonderful engineer colleagues, and I'd like to share some examples of **what you can do with Gemini, using Java**!

First of all, you'll need to have an account on Google Cloud and created a project.
The Vertex AI API should be enabled, to be able to access the Generative AI services,
and in particular the Gemini large language model.
Be sure to check out the
[instructions](https://cloud.google.com/vertex-ai/docs/generative-ai/start/quickstarts/quickstart-multimodal?hl=en).

## Preparing your project build

To get started with some coding, you'll need to create a Gradle or a Maven build file
that requires the Google Cloud libraries BOM, and the `google-cloud-vertexai` library.
Here's an example with Maven:

```xml
...
<dependencyManagement>
    <dependencies>
        <dependency>
            <artifactId>libraries-bom</artifactId>
            <groupId>com.google.cloud</groupId>
            <scope>import</scope>
            <type>pom</type>
            <version>26.29.0</version>
        </dependency>
    </dependencies>
</dependencyManagement>

<dependencies>
    <dependency>
        <groupId>com.google.cloud</groupId>
        <artifactId>google-cloud-vertexai</artifactId>
    </dependency>
    ...
</dependencies>
...
```

## Your first queries

Now let's have a look at our first multimodal example, mixing text prompts and images:

```java
try (VertexAI vertexAI = new VertexAI(projectId, location)) {
    byte[] imageBytes = Base64.getDecoder().decode(dataImageBase64);

    GenerativeModel model = new GenerativeModel("gemini-pro-vision", vertexAI);
    GenerateContentResponse response = model.generateContent(
        ContentMaker.fromMultiModalData(
            "What is this image about?",
            PartMaker.fromMimeTypeAndData("image/jpg", imageBytes)
        ));

    System.out.println(ResponseHandler.getText(response));
}
```

You instantiate `VertexAI` with your Google Cloud project ID, and the region location of your choice.
To pass images to Gemini, you should either pass the bytes directly,
or you can pass a URI of an image stored in a cloud storage bucket (like `gs://my-bucket/my-img.jpg`).
You create an instance of the model. Here, I'm using `gemini-pro-vision`.
But later on, a `gemini-ultra-vision` model will also be available.
Let's ask the model to generate content with the `generateContent()` method,
by passing both a text prompt, and also an image.
The `ContentMaker` and `PartMaker` classes are helpers to further simplify
the creation of more advanced prompts that mix different modalities.
But you could also just pass a simple string as argument of the `generateContent()` method.
The `ResponseHandler` utility will retrieve all the text of the answer of the model.

Instead of getting the whole output once all the text is generated,
you can also adopt a streaming approach:

```java
model.generateContentStream("Why is the sky blue?")
    .stream()
    .forEach(System.out::print);
```

You can also iterate over the stream with a `for` loop:

```java
ResponseStream<GenerateContentResponse> responseStream =
    model.generateContentStream("Why is the sky blue?");

for (GenerateContentResponse responsePart: responseStream) {
    System.out.print(ResponseHandler.getText(responsePart));
}
```

## Let's chat!

Gemini is a multimodal model, and it's actually both a text generation model, but also a chat model.
So you can chat with Gemini, and ask a series of questions in context.
There's a handy `ChatSession` utility class which simplifies the handling of the conversation:

```java
try (VertexAI vertexAI = new VertexAI(projectId, location)) {
    GenerateContentResponse response;

    GenerativeModel model = new GenerativeModel(modelName, vertexAI);
    ChatSession chatSession = new ChatSession(model);

    response = chatSession.sendMessage("Hello.");
    System.out.println(ResponseHandler.getText(response));

    response = chatSession.sendMessage("What are all the colors in a rainbow?");
    System.out.println(ResponseHandler.getText(response));

    response = chatSession.sendMessage("Why does it appear when it rains?");
    System.out.println(ResponseHandler.getText(response));
}
```

This is convenient to use `ChatSession` as it takes care of keeping track
of past questions from the user, and answers from the assistant.

## Going further

This is just a few examples of the capabilities of Gemini. Be sure to check out some of the
[samples that are available on Github](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/main/vertexai/snippets/src/main/java/vertexai/gemini).
Read [more about Gemini and Generative AI](https://cloud.google.com/vertex-ai/docs/generative-ai/start/quickstarts/quickstart-multimodal?hl=en) in the Google Cloud documentation.

# Generative AI in practice: Concrete LLM use cases in Java, with the PaLM API


Large Language Models, available through easy to use APIs, bring powerful machine learning tools in the hands of developers.
Although Python is usually seen as the _lingua franca_ of everything ML, with LLM APIs and LLM orchestration frameworks, complex tasks become easier to implement for enterprise developers.

## Abstract

> Large language models (LLMs) are a powerful new technology that can be used for a variety of tasks, including generating text, translating languages, and writing different kinds of creative content. However, LLMs can be difficult to use, especially for developers who are not proficient in Python, the lingua franca for AI. So what about us Java developers? How can we make use of Generative AI?
>
> This presentation will go through how to use LLMs in Java without the need for Python. We will use the PaLM API, provided by Google Cloud’s Vertex AI services, to perform a variety of tasks, such as searching through documentation, generating kids stories, summarizing content, extracting keywords or entities, and more.
> In our journey through demos, we'll discover LangChain4J, a wonderful LLM orchetratore for Java developers that simplifies the implementation of advanced LLM use cases.

I had the chance to get this talk recorded at Devoxx Belgium:

{{< youtube ioTPfL9cd9k >}}

And you can check the slides here:

{{< speakerdeck be0c44ac898f4ce5b905a8389bb751e2 >}}

# Tech Watch #5 — November, 15, 2023


- Some friends shared this article from Uwe Friedrichsen, tilted [back to the future](https://www.ufried.com/blog/back_to_the_future/), that talks about this feeling of "déjà-vu", this impression that in IT we keep on reinventing the wheel. With references to mainframes, Uwe compared CICS to Lambda function scheduling, JCL to step functions, mainframe software development environments to the trendy platform engineering. There are two things I like about this article. First of all, it rings a bell with me, as we've seen the pendulum swing as we keep reinventing some patterns or rediscovering certain best practices, sometimes favoring an approach one day, and coming back to another approach the next day. But secondly, Uwe referenced Gunter Dueck who talked about spirals rather than a pendulum. I've had that same analogy in mind for years: rather than swinging on one side to the next and back, I always had this impression that we're circling and spiraling, but each time, even when passing on the same side, we've learned something along the way, and we're getting closer to an optimum, with a slightly different view angle, and hopefully with a better view and more modern practices. Last week at FooConf #2 in Helsinki, I was just talking with my friend [Venkat Subramaniam](https://agiledeveloper.com/aboutus.html) about this spiral visualisation, and I'm glad to see I'm not the only one thinking that IT is spiraling rather than swinging like a pendulum.

- [Automerge-repo, a batteries included toolkit for building local-first applications](https://automerge.org/blog/2023/11/06/automerge-repo/)\
  [Automerge](https://automerge.org/) is one of the most well-known CRDT algorithm (Conflict-Free Replicated Data Type) that allows you to implement collaborative applications (think Google Docs kind of collaboration, for example). With CRDT algorithms and data structures, concurrent changes on different devices can be merged automatically without requiring a central server, and without complex merge processes. However, having an algorithm and data structure is one thing, but to put the whole system in place is not necessarily easy. This new automerge-repo projects tries to solve this problem, by offering networking and storage adapters to facilitate the communication between the peers, or with a potential sync server.

- The WebAssembly Garbage Collection proposal (WasmGC) lands in the latest Chrome version. The [V8 team dives into the details about WasmGC](https://v8.dev/blog/wasm-gc-porting). It'll be particularly useful to better support garbage collected languages (like Java and friends) without having to ship a garbage collector in each wasm package.

- Although I'm not developing native apps for Macs, I spotted this article about an [open source implementation of Apple code signing and notarization](https://gregoryszorc.com/blog/2022/08/08/achieving-a-completely-open-source-implementation-of-apple-code-signing-and-notarization/), implemented in Rust, and that can run on non-Mac hardware. With this approach, when you're building native apps for the Mac, you can integrate that approach in your Linux-based CI/CD pipeline, without having a Mac box somewhere.

- [Document summarization is an area where large language models excel](https://medium.com/google-cloud/langchain-chain-types-large-document-summarization-using-langchain-and-google-cloud-vertex-ai-1650801899f6). There are different approaches to do so when your context window can't fit the whole document to summarize. In this article, different approaches are mentioned: stuffing (when it fits in the context window), Map/Reduce to split the content in sections that can be summarised and a summary of summary can be made, and the more sequential Refine method where we summarize what fits in memory, and then ask to refine that first summary with the details of the following sections, till we run out of content.

- Large Language Models face two big issues: one is hallucinations and how to mitigate them by grounding answers or finding ways to assess the response's factuality, and the other one is prompt injection, as a malignant attacker can misguide an LLM to do something else than what it was programmed for. The folks at Scott Logic developed a demo based on the idea of ImmersiveLabs' [online playground](https://prompting.ai.immersivelabs.com/) to experiment with prompt injection and techniques to circumvent them. There's also an [article](https://blog.scottlogic.com/2023/11/03/spy-logic.html) that talks about the project, and a [video](https://blog.scottlogic.com/2023/10/31/mitigating-prompt-injections.md.html) that shows it all in action.

- My good friend Ken Kousen dives into [the magic of AI Services with LangChain4J](https://kousenit.org/2023/11/06/the-magic-of-ai-services-with-langchain4j/). He has a nice blog post, and also a great accompanying [video](https://www.youtube.com/watch?v=Bx2OpE1nj34) on YouTube where he shows some of the powerful features of LangChain4J, in particular the AI service that allows you to decorate an interface with annotations to interact with your large language model and get plain Java types or objects in return.

- My colleague Romin Irani also [integrated LangChain4J and the PaLM 2 chat model](https://medium.com/google-cloud/integrating-langchain4j-and-palm-2-chat-bison-model-a684cefd67af), showing how to deploy a Google Cloud Function chatbot.

- Baeldung also gives in [introduction to LangChain4J](https://www.baeldung.com/java-langchain-basics) showing the basics of prompts, models, memory management, retrieval, chains, and agents.

- [LangChain4J using Redis](https://www.linkedin.com/pulse/langchain4j-using-redis-stephan-janssen-lobpe/): Stephan Janssen, the founder of Devoxx, is using [LangChain4J](https://github.com/langchain4j) inside the Devoxx CFP and schedule application. In this article on LinkedIn, he explains how he used Redis to store vector embeddings corresponding to the talks of the conference, to search for similar talks.

# Tech Watch #4 — October, 27, 2023


- The [State of AI report](https://www.stateof.ai/) is pretty interesting to read (even if long!). Among the major sections: research, industry, but also politics, safety, and some predictions. You'll find an executive summary in one slide, on slide #8. \
  \
  On #22, **emergent capabilities of LLMs** is covered and mentions Stanford's research that talks about the importance of more linear and continuous measures as otherwise capabilities sound like they emerge out of the blue. \
  \
  On #23, they talk about the **context length of LLMs being the new parameter count**, as models try to have bigger context windows. \
  \
  However, on slide #24, they also talk about researchers who showed that **in long context windows the content provided in the middle is more ignored** by LLMs compared to content at the beginning or end of the window. \
  So be sure to **put the important bits first or last**, but not lost in the middle. \
  \
  Slide #26 speaks about **smaller models trained with smaller curated datasets and can rival 50x bigger models**. \
  \
  Slide #28 wonders if we're **running out of human-generated data**, and thus, if we're going to have our LLMs trained on... LLM generated data!

- [3D visualisation of vector embeddings from Tensorflow](https://projector.tensorflow.org/) \
  As I'm working on a small application that would help visuliase vector embeddings, I was looking for existing apps or articles that show how vectors can be similar, and thus their semantic to be similar as well. And I came across this existing visualisation from the Tensorflow project, which uses the Word2Vec embedding approach. I like the fact you can use different 3D projections techniques like t-SNE or PCA, and you see related vectors closer in the 3D space, as their meaning is closer too.

- [A cron extension for PostgreSQL](https://www.citusdata.com/blog/2023/10/26/making-postgres-tick-new-features-in-pg-cron/)\
  pg_cron is an extension for the PostgreSQL database that adds scheduling capabilities. It can even be scheduled to run your procedures or other SQL queries every few seconds.

- [Protomaps](https://protomaps.com/) is a free and open source map of the world, deployable as a single static file on cloud storage (including Google Cloud Storage). You can use OpenStreetMap tiles, as it's distributed with a version of OSM. It's using an efficient and open archive format for pyramids of tile data, accessible via HTTP Range requests.

- [ArtistAssistApp](https://artistassistapp.com/) is an application which can tell you which oil or water color paints to use and mix to create similar looking colors for your painting, as you try to reproduce a photo. As a wannabe painter myself, I always struggle creating mixes that match real colors, and this tool is pretty clever to let you find the right mix (at least if you use some well-known paint brands). This also reminds me of [mixbox](https://scrtwpns.com/mixbox/) which simulates color mixing as real color pigments mix in real paint, and using such algorithm would greatly improve the real-life accuracy of color mixes in digital art painting applications.

- [Vectorizer](https://vectorizer.ai/) is an online tool to transform an image into an SVG file. As I'm playing a bit with Generative AI-based image generation, sometimes, the upscalers don't suffice, and you want to transform a nice generated image into a vectorial format (for example clipart-like illustrations), so they scale gracefully in slide decks or on websites.

# Tech Watch #3 — October, 20, 2023


- [Stop Using char in Java. And Code Points](https://horstmann.com/unblog/2023-10-03/index.html)\
  It's a can of worms, when you start messing with chars, code points, and you're likely going to get it wrong in the end. As much as possible, stay away from chars and code points, and instead, use as much as possible the String methods like `indexOf()` / `substring()`, and some regex when you really need to find grapheme clusters.

- Paul King shared his presentations on [Why use Groovy in 2023](https://speakerdeck.com/paulk/groovy-today) and an
  [update on the Groovy 5 roadmap](https://speakerdeck.com/paulk/groovy-roadmap)It's interesting to see how and where Groovy goes beyond what is offered by Java, sometimes thanks to its dynamic nature, sometimes because of its compile-time transformation capabilities. When Groovy adopts the latest Java features, there's always a twist to make things even groovier in Groovy!

- [The State of WebAssembly in 2023](https://blog.scottlogic.com/2023/10/18/the-state-of-webassembly-2023.html)\
  I often enjoy the articles from the folks at Scott Logic. This one is about a survey they ran on the topic of WebAssembly. Languages like Rust and JavaScript are seeing increased usage (for targeting wasm). Wasm is used a lot for web app development, but serverless seems to be he second most common use case, as well as for hosting plugin environments. The survey also mentions that threads, garbage collection and the new component model are the features developer are most interested in. For WASI, all the I/O related proposals like HTTP, filesystem support, sockets, are the ones developers want (although WASIX which covered this area received mixed reactions).

- [Tell your LLM to take a deep breath!](https://arstechnica.com/information-technology/2023/09/telling-ai-model-to-take-a-deep-breath-causes-math-scores-to-soar-in-study/)\
  We tend to humanize large language models via [anthropomorphism](https://en.wikipedia.org/wiki/Anthropomorphism), as much as we see human faces in anything like with [pareildolia](https://en.wikipedia.org/wiki/Pareidolia), although LLMs are neither sentients nor human. So it's pretty ironic that to get a better result in some logic problem solving, we need to tell the LLM to actually take a deep breath! Are they now able to breathe?

- [Wannabe security researcher asks Bard for vulnerabilities in cURL](https://hackerone.com/reports/2199174)\
  Large Language Models can be super creative, that's why we employ them to imagine new stories, create narratives, etc. And it seems wannabe security experts believe that what LLMs say is pure facts, probably what happened to this person that reported that they asked Bard to find a vulnerability in cURL! And Bard indeed managed to be creative enough to craft an hypothetical exploit, even explaining where a possible integer overflow could take place. Unfortunately, the generated exploit text contained many errors (wrong method signature, invented changelog, code that doesn't compile, etc.)

- [LLMs confabulate, they don't hallucinate](https://www.beren.io/2023-03-19-LLMs-confabulate-not-hallucinate/)\
  A few times, I've seen this mention on social networks about the fact we should say that LLM confabulate, instead of hallucinate. Confabulation is usually a brain disorder that makes people confidently tell things that may be true or not, in a convincing fashion (they don't even know it's false or a lie). Hallucination is more of a misinterpretation of the sensory input, like having the impression to see a pink elephant! The article linked above explains the rationale.

- Greg Kamradt tweets about the [use cases for multimodal vision+text LLMs](https://twitter.com/GregKamradt/status/1711772496159252981)\
  You'd think that you could just get a model that describes a picture as a text, and then mix that description with other text snippets. But models that really fully understand both images and texts are way more powerful than this. In this tweet, Greg distinguishes different scenarios: description, interpretation, recommendation, convertion, extraction, assistance and evaluatation. For example, we could imagine transforming an architecture diagram into a proper Terraform YAML file, or a UI mockup into a snippet of code that builds that UI for real. You You could show a picture of a dish, and ask for its recipe!

- [The Story of AI Graphics at JetBrains](https://blog.jetbrains.com/blog/2023/10/16/ai-graphics-at-jetbrains-story/)\
  I've always loved generative and procedural art, both for games and indeed for art. I really enjoyed this article which is going through the story of how they are generating their nice splash screens and animations for the JetBrains family of products. Neural networks at play here!

# Tech Watch #2 — Oct 06, 2023


-   [Generative AI exists because of the transformer\
    ](https://ig.ft.com/generative-ai/)I confess I rarely read the Financial Times, but they have a really neat articles with animations on how large language models work, thanks to the transformer neural network architecture, an architecture invented by Google in 2017. They talk about text vector embeddings, how the self-attention makes LLM understand the relationship between words and the surrounding context, and also doesn't forget to mention hallucinations, how "grounding" and RLHF (Reinforcement Learning with Human Feedback) can help mitigate them to some extent.

-   [Generative AI in practice: Concrete LLM use cases in Java, with the PaLM API](https://www.youtube.com/watch?v=ioTPfL9cd9k&t=7s) (video)\
    At Devoxx Belgium this week, the biggest theme of the conference was Generative AI and Large Language Models. The audience being mainly Java-focused, there was a very strong interest for Java developers to be able to take advantage of GenAI / LLMs in Java, instead of the ubiquitous Python. And all sessions along those lines were fully packed. The conference featured Microsoft's Java SemanticKernel, the open source LangChain4J project, or Spring's AI experimental module. The link above is the video of my presentation I did on using PaLM API but for the Java developer, using different approaches, and also with [LangChain4J](https://github.com/langchain4j/langchain4j).

-   [What "AI-Assistant for a Developer" is all about?](https://medium.com/google-cloud/what-ai-assistant-for-a-developer-is-all-about-723de644a449) and [An AI-assisted cloud? It's a thing now, and here are six ways it's already made my cloud experience better](https://seroter.com/2023/09/28/an-ai-assisted-cloud-its-a-thing-now-and-here-are-six-ways-its-already-made-my-cloud-experience-better/) are two articles from my colleagues Romin and Richard about how AI assistants will progressively make us, developers, more productive and stay in the flow.

-   [Heredoc notation in Dockerfiles\
    ](https://www.docker.com/blog/introduction-to-heredocs-in-dockerfiles/)Did you know you can use the "heredoc" notation in Dockerfiles, like <<EOF some script commands EOF, to run multiple commands like in a Bash file? It's just like writing RUN commands separated with &&, but in a nice script, and without creating extra layers. I think I'll start using this in my next Dockerfiles!

-   [The Absolute Minimum Every Software Developer Must Know About Unicode in 2023\
    ](https://tonsky.me/blog/unicode/)UTF-8 is pretty much ubiquitous nowadays, so we don't need to think about which encoding is used, but rather think about how to use UTF-8 properly. Unicode assigns a character (actually a code point) a number. Unicode is big, with more than 1 million code points. UTF-8 is an encoding: a way to store code points in memory, but the article mentions the other UTF encodings as well. But unicode is tricky as a characters with a diacritical mark, an emoji, etc, can be graphemes: the combination of several code points. And there are lots of tricky corner cases that stem from that (like the length of a string isn't trivial to calculate). A particular character (like a vowel with an accent) can be look alike another, but their composition of code points might differ, hence why there are different compositions and decompositions. So it's important to normalize strings when doing comparisons.

-   [Jq released version 1.7\
    ](https://github.com/jqlang/jq/releases)There's a new release of jq, the super handy command-line tool to explore and massage your JSON payloads! The new version uses decimal number literals to preserve precision. A new pick(stream) method to do projections (to filter just the stuff you're interested in), a debug() method to log some messages through stderr, and and abs() function, and plenty other little refinements and bug fixes.

-   [Goodbye integers. Hello UUIDv7!\
    ](https://buildkite.com/blog/goodbye-integers-hello-uuids)BuildKite's article delves into their choice of UUIDv7 for primary keys. The initially started with a combination of sequential primary keys for efficient indexing, but with a UUID as a secondary key for external use. But the characteristics of the 7th version of the UUID specification leads them to just use UUIDv7 instead. UUID eliminate the issue of coordination in distributed systems. Their random aspect makes them less guessable. But the drawback can be poor database index locality.


# Client-side consumption of a rate-limited API in Java


In the literature, you'll easily find information on how to rate-limit your API. I even talked about
[Web API rate limitation](https://speakerdeck.com/glaforge/the-never-ending-rest-api-design-debate-devoxx-france-2016?slide=80)
years ago at a conference, covering the usage of
[HTTP headers like X-RateLimit-\*](https://www.ietf.org/archive/id/draft-ietf-httpapi-ratelimit-headers-07.html).

Rate limiting is important to help your service cope with too much load, or also to implement a tiered pricing scheme
(the more you pay, the more requests you're allowed to make in a certain amount of time). There are useful libraries like
[Resilience4j](https://micronaut-projects.github.io/micronaut-ratelimiter/snapshot/guide/index.html)
that you can configure for Micronaut web controllers, or [Bucket4j](https://www.baeldung.com/spring-bucket4j)
for your Spring controllers.

Oddly, what is harder to find is information about how to consume APIs that are rate-limited.
Although there are usually way more consumers of rate-limited APIs, than producers of such APIs!

Today, I'd like to talk about this topic: how to consume APIs that are rate-limited.
And since I'm a Java developer, I'll focus on Java-based solutions.

The use case which led me to talk about this topic (on Twitter / X in particular,
with a [fruitful conversation](https://twitter.com/glaforge/status/1705933799635268050) with my followers)
is actually about a Java API which is an SDK for a Web API that is rate-limited.
I'll briefly cover consuming Web APIs, but will focus more on using the Java API instead.

## Consuming Web APIs

### Rate limit headers

Let's say we are calling a Web API that is rate-limited to 60 requests per minute.
We could call it 60 times in a second without hitting the limit then wait for a minute, or call it once every second.
Usually, a sliding time window is used to check that within that minute, no more than 60 requests have been made.

If the rate-limited API is well behaved and provides X-RateLimit headers, you can check what those headers say.
Taking the explanations from the IETF [draft](https://datatracker.ietf.org/doc/draft-ietf-httpapi-ratelimit-headers/):

> - **RateLimit-Limit**: containing the requests quota in the time window;
> - **RateLimit-Remaining**: containing the remaining requests quota in the current window;
> - **RateLimit-Reset**: containing the time remaining in the current window, specified in seconds.

Note that the draft mentions RateLimit-\* as headers, but often in the wild, I've seen those headers always prefixed with "X-" instead.
And sometimes, some APIs add a hyphen between Rate and Limit! So it's hard to create a general consumer class that could deal with
[all cases](https://stackoverflow.com/questions/16022624/examples-of-http-api-rate-limiting-http-response-headers).

Those headers inform you about the quota, how much is left, and when the quota should be back to its full capacity (if you don't consume more requests).
So you could certainly stage your requests accordingly --- we will talk about how to schedule your requests in Java in the second section.

Another thing to keep in mind is that the quota may be shared among API consumers.
Maybe you have several parallel threads that will call the API and consume the API quota.
So when you see the reset header, maybe the API will have been called by another thread already, leaving you with a smaller amount of requests left in the quota.

### Exponential backoff and jitter

The API that triggered my research actually doesn't provide any rate limitation headers.
So another approach is needed. A classical approach is to use an exponential backoff.
It was nicely [documented](https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/) on the AWS blog, a while ago.

The idea is that when you face an over quota error, you're going to retry the call after, for example, one second.
And if you're getting another error, you'll wait a little longer, by multiplying the interval by a constant, like doubling.
So at first, on the first error, you wait 1 second before retrying, next 2 seconds, then 4 seconds, etc.
You can use a fractional multiplier, of course.

But as explained in the article, if all clients fail at the same time, they will retry roughly at the same time as well, after one, two, four seconds.
So the idea is to add some randomness, the jitter, to more evenly spread out the retries, to avoid having new bursts of traffic at roughly the same moments.

There's another good article on Baeldung about
[exponential backoff and jitter using Resilience4J](https://www.baeldung.com/resilience4j-backoff-jitter) for your API consumers.

## Consuming a Java API

Back to my use case, the underlying Web API I'm using doesn't feature rate limitation headers.
And since there's a Java library that wraps that API anyway, I'd rather just use that Java API for convenience.
When a rate limit is hit, the API will throw an exception.
So I can catch that exception, and deal with it, maybe applying the same exponential backoff + jitter strategy.

However, I know the rate limit of the API.
So instead of eagerly calling the API as fast as possible, getting an exception, waiting a bit, and trying again...
I'd rather just call the API at the pace I'm allowed to use it.

Let's say I have a hypothetical API that takes a String as argument and returns a String:

```java
public  class  RateLimitedApi {
    public String call(String arg) {
        return arg.toUpperCase();
    }
}
```

### Sleeping a bit...

A first, but naive, idea would be to just add some pause after each call:

```java
for (int i = 0; i < 20; i++) {
    api.call("abc");
    Thread.sleep(100);
}
```

And instead of making the same call with the same argument, you could iterate over an array or list:

```java
for (String s : args) {
    api.call(s);
    Thread.sleep(100);
}
```

Well, it works, but the API call takes some time as well, so you may have to adjust the sleep time accordingly, so it's not really ideal.
The call could also be longer than the actual wait time really needed between two invocations.

### Scheduled execution

A better approach would be to use Java's scheduled executors, with a few threads, in case of long API execution times that overlap.

```java
try (var scheduler = Executors.newScheduledThreadPool(4)) {
    var scheduledCalls = scheduler.scheduleAtFixedRate(
        () -> api.call("abc"),
        0, 100, TimeUnit.MILLISECONDS);
}
```

Instead of calling the API with the same argument, how would you call it for a series of different values,
but then stop the scheduler once we're done with all the values?
You could take advantage of some kind of queue (here a ConcurrentLinkedDeque) to pop the arguments one at a time.
Once you've cleared all the elements of the queue, you shut down the scheduler altogether.

```java
var args = new ConcurrentLinkedDeque<>(
    List.of("a", "b", "c", "d", "e", "f", "g", "h", ..."x", "y", "z"));

try (var scheduler = Executors.newScheduledThreadPool(4)) {
    scheduler.scheduleAtFixedRate(() -> {
        if (!args.isEmpty()) {
                api.call(args.pop());
        } else {
                scheduler.shutdown();
        }
    }, 0, 100, TimeUnit.MILLISECONDS);
}
```

### One more in the Bucket4J!

In the introduction, I mentioned some great libraries like Resilience4J and Bucket4J.
Let's have a look at an approach using [Bucket4J](https://bucket4j.com/).

Scheduling is fine, to respect the rate limit, but you may perhaps want to get as many calls through as possible,
while still respecting the rate. So a different approach is necessary.

Bucket4J is based on the [token bucket algorithm](https://en.wikipedia.org/wiki/Token_bucket).
It offers a very rich and fine-grained set of rate limit definitions, if you want to allow bursts, or prefer a regular flow (like our schedule earlier).
Be sure to check out the [documentation](https://bucket4j.com/8.4.0/toc.html#quick-start-examples) for the details.

Let's see how to define my limited consumption rate of 10 per second:

```java
var args = List.of("a", "b", "c", "d", "e", ..."x", "y", "z");

var bucket = Bucket.builder()
    .addLimit(Bandwidth.simple(10, Duration.ofSeconds(1)))
    .build();

for (String arg : args) {
    bucket.asBlocking().consumeUninterruptibly(1);
    api.call(arg);
}
```

It's pretty explicit: I create a limit that corresponds to a bandwidth of 10 tokens per second.
With this simple strategy, the bucket is refilled greedily: every 100ms a new token will be available again.
But it's also possible to configure it differently, to say that you want to allow another 10 calls once every second.

Then I have a simple for loop to iterate over the list of arguments I must pass to the API,
but I introduce an instruction that blocks until a token is available --- ie. that I have the right to call the API again while respecting the rate limit.

Also beware of API calls that take a lot of time, as here we're using a blocking call that blocks the calling thread.
So if API calls take longer than the time a new token is available in the bucket, you'll end up calling the API much less frequently than the allowed rate limit.

However, with Bucket4J, the bucket can be used in a thread-safe manner, you can have several threads consuming from the same API,
using the same shared bucket, or you can make parallel calls with a single consumer as well, to use the quota to its maximum.

Let's use executors to parallelize our calls:

```java
try (ExecutorService executor = Executors.newFixedThreadPool(4)) {
    for (String arg : args) {
        bucket.asBlocking().consumeUninterruptibly(1);
        executor.submit(() -> api.call(arg));
    }
}
```

Be careful though, that doing so, your API calls are not necessarily following the exact same order as the order of the input collection.
In my case, I didn't care about the order of execution.

Last little tweak we could make since Java 21 was released recently, we could make use of virtual threads,
instead of threads! So let's push our example forward in the 21th century with this small change when creating our executor service:

```java
Executors.newVirtualThreadPerTaskExecutor()
```

So far, we have only called the API without taking care of the returned result.
We could update the examples above with an extra line to add the argument and result in a ConcurrentHashMap or to use the result immediately.
Or we could also explore one last solution, using CompletableFutures and/or ExecutorCompletionService.
But I'm not 100% satisfied with what I came up with so far.
So I might update this article if I find a convenient and elegant solution later on.

Time to wrap up!

## Summary

In this article, we explored the less covered topic of consuming a rate-limited API.
First, we discussed approaches for consuming Web APIs that are well-behaved, exposing rate limitation headers,
and those less well-behaved using an exponential backoff and jitter approach.
We then moved on to the case of Java APIs, doing a simple sleep to call the API at a cadence that respects the rate limit.
We also had a look at scheduled executions.
And we finished our journey with the help of the powerful Bucket4J library.

# Tech Watch #1 — Sept 29, 2023


Inspired my by super boss [Richard Seroter](https://twitter.com/rseroter) with his regular [daily reading list](https://seroter.com/2023/09/28/daily-reading-list-september-28-2023-171/), I decided to record and share my _tech watch_, every week (or so).
I always take notes of interesting articles I read for my own curiosity and to remember them when I need those references later on. But also to share them with [Les Cast Codeurs podcast](https://lescastcodeurs.com/)!
So I hope it'll be interesting to my readers too!

- [LLMs Demand Observability-Driven Development\
  ](https://www.honeycomb.io/llms-demand-observability-driven-development)A great tribune from [Charity Majors](https://twitter.com/mipsytipsy) on the importance of observability-driven development, in the wake of large language models. Developing LLM based solutions is typically not something you can do with a classical test-driven approach, as you only really get proper test data when you have it coming from production usage. Furthermore, LLMs are pretty much unpredictable and underterministic. But with observability in place, you can better understand why there's latency in some scenarios, why the LLM came to certain solutions, and this will help you improve as your learn along the way.

- [How LangChain rebuilt their LLM documentation chatbot\
  ](https://blog.langchain.dev/building-chat-langchain-2/)For example: the choice of docs to parse: indexing source code didn't yield great results. Citing sources lets users dive deeper into the documentation and double check the LLM didn't hallucinate. Quality evaluation is important, to assess at each step of the process the impact of each change, each tweaks of your prompts, each change in the docs that are ingested. Also, how do you handle reindexing the documents, when there are changes in a document, when there are new pages to be indexed, or that disappear, to keep track of what has to be updated in the stored vector embeddings in vector store. A great trick about how to rephrase questions: sometimes you ask a question, ask a refinement, but you don't formulate a whole new question, so you can actually ask the LLM to reformulate a full question based on the conversation context, so as to find more meaningful similar text embeddings in the vector database.

- [macOS containers\
  ](https://macoscontainers.org/)You can run all sorts of Linux flavors inside containers, on all platforms, and even Windows containers. But with the macOS containers projects, that you can install with Homebrew, you can also install and run macOS containers. It's still early days for the project, it seems, and there are limitated container support in macOS itself, but it sounds promising. Also, macOS containers only run on top of macOS  itself.

- [Using PostgreSQL for queuing\
  ](https://adriano.fyi/posts/2023-09-24-choose-postgres-queue-technology/)With our without extensions, I see a lot of articles mentioning using PostgreSQL for everything! With the pgVector extension, for example, you can use Postgres as a vector database for storing parsed documents for your LLM use cases. In this article, the author suggests taking advantage of its pub/sub (with notify/listen) and row locking capabilities to implement queuing, and thus replacing other dedicated queuing components in your architecture.

- [Use ControlNet with StableDiffusion's SDXL\
  ](https://stable-diffusion-art.com/controlnet-sdxl/)You've probably all seen some cool images with some subliminal text appear, or with weird squares or spirals shapes, on social networks. This tutorial explains how you can guide StableDiffusion's SDXL model with ControlNet to shape particular picture generations, or to create pictures in the style of other pictures.

- [Transformer.js\
  ](https://huggingface.co/docs/transformers.js/index)A JavaScript transformer implementation that allows to load HuggingFace models, and do predictions and other LLM tasks right in the browser.

- [JVector\
  ](https://github.com/jbellis/jvector/)An open source Java project for fast vector search, used in Astra DB's vector search. This project was mentioned in TheNewStack's [article](https://thenewstack.io/5-hard-problems-in-vector-search-and-how-cassandra-solves-them/) on how Astra DB solves 5 typical problems of vector search. So for those who want to embed an Java vector store in their LLM use cases, this might be an option to look into, besides Lucene, for example.

- [Mixing LLMs and a Knowledge Graphs\
  ](https://www.marktechpost.com/2023/09/19/llms-knowledge-graphs/)Inherently, knowledge graphs have structured information and relationships, that LLM based projects can take advantage of. The article discusses different approaches and patterns to bind them together, to reduce hallucination, enhance transparency & interpretability.

- [Tracing is better than logging!\
  ](https://andydote.co.uk/2023/09/19/tracing-is-better/)It's often hard to figure out from logs what happened when a problem occurred. It's slightly better with structured logging to do some querying though. But with tracing, you can see correlations between traces, as they are nested, and see all the attributes you can attach to those spans, without mentioning the fact you can more easily understand where time is spent rather than just have a point in time like with a log statement.

# Discovering LangChain4J, the Generative AI orchestration library for Java developers


As I started my journey with Generative AI and Large Language Models, I've been overwhelmed with the omnipresence of Python.
Tons of resources are available with Python front and center. However, I'm a Java developer
(with a penchant for [Apache Groovy](https://groovy-lang.org/), of course).
So what is there for me to create cool new Generative AI projects?

When I built my first experiment with the
[PaLM API](https://cloud.google.com/vertex-ai/docs/generative-ai/start/quickstarts/api-quickstart),
using the integration within the Google Cloud's Vertex AI offering,
I called the available [REST API](https://cloud.google.com/vertex-ai/docs/reference/rest),
from my [Micronaut](https://micronaut.io/) application.
I used Micronaut's built-in mechanism to marshal / unmarshal the REST API constructs to proper classes.
Pretty straightfoward.

You can learn more about this first app in my previous articles on
[generating kid stories](https://glaforge.dev/posts/2023/06/08/creating-kids-stories-with-generative-ai/)
and [how to get started with the PaLM API](https://glaforge.dev/posts/2023/05/30/getting-started-with-the-palm-api-in-the-java-ecosystem/)

But soon after, I discovered that the Vertex AI Java SDK, which covers all products and services of Vertex AI,
added support for the PaLM API thanks to a new
[prediction service client](https://cloud.google.com/vertex-ai/docs/generative-ai/text/test-text-prompts#generative-ai-test-text-prompt-java) class.
I was happy and decided to try it! So here's how making a simple call to the LLM looks like from Groovy:

```groovy
@Grab('com.google.cloud:google-cloud-aiplatform:3.24.0')
import com.google.cloud.aiplatform.v1beta1.*
import com.google.protobuf.Value
import com.google.protobuf.util.JsonFormat

String instance =
    '''{ "prompt": "Tell me more about Large Language Models"}'''
String parameters = '''{
  "temperature": 0.2,
  "maxOutputTokens": 256,
  "topP": 0.95,
  "topK": 40
}'''

String project = "my-llm-java-demos"
String location = "us-central1"
String publisher = "google"
String model = "text-bison"

def predictionServiceSettings =
    PredictionServiceSettings.newBuilder()
        .setEndpoint("${location}-aiplatform.googleapis.com:443")
        .build()

def predictionServiceClient =
    PredictionServiceClient.create(predictionServiceSettings)
def endpointName =
    EndpointName.ofProjectLocationPublisherModelName(project, location, publisher, model)

def instanceValue = Value.newBuilder()
JsonFormat.parser().merge(instance, instanceValue)
def instances = [instanceValue.build()]

def parameterValueBuilder = Value.newBuilder()
JsonFormat.parser().merge(parameters, parameterValueBuilder)
def parameterValue = parameterValueBuilder.build()

def resp = predictionServiceClient.predict(endpointName, instances, parameterValue)
// resp[0].content
println resp.predictionsList.first().structValue.fieldsMap['content'].stringValue 
```

You create a PredictionServiceSettings, then an EndpointName, and a PredictionServiceClient to call its `predict()` method. Not overly complicated to set up.

However, there are really two things that I really dislike about this API:

- Why are we parsing some JSON strings and creating some Protobuf structures? This isn't very developer friendly to me.
- And then, it also returns some generic Protobuf structure response, that I have to navigate through to find the relevant bits I'm interested in, instead of letting me call something like `resp[0].content`.

I'd rather have a proper set of Java classes that represent my prompt, my LLM settings, the response, etc. I was a bit disappointed and preferred the approach I took with REST marshalling / unmarshalling in my Micronaut application --- you can check the [code on Github](https://github.com/glaforge/bedtimestories).

![](https://avatars.githubusercontent.com/u/132277850?v=4)

## Here comes the delight, with LangChain4J!

If you're following the Generative AI field, you'll have come across the [LangChain](https://www.langchain.com/) project. It's a Python (and Javascript) orchestrator framework to connect various building blocks: large language models, document loaders, text splitters, output parsers, vector stores to store text embeddings, tools, and prompts.

With just a few lines of code, you're able to create some great integrations to implement your Generative AI use cases, like for example following the [Retrieval Augmented Generation](https://www.langchain.com/use-case/retrieval) pattern to create chat bots that talk with your documentation.

Remember that I'm a Java developer? I played a bit with the Python version of LangChain (I didn't try the Javascript/Typescript variant) but I wasn't at ease with Python, and I didn't want to learn a whole new ecosystem to implement my Generative AI ideas.

Fortunately, that's when I discovered the open source [LangChain4J](https://github.com/langchain4j) project! This is also an AI orchestrator framework, but for Java! It's very much inspired by the original LangChain project, but independent. So this is the perfect match for my programming language skills and Generative AI needs.

Now, let's compare our protobuf-_obstruse_ example from earlier, with an equivalent one based on LangChain4J (this time I used the chat model instead of the text model):

```groovy
@Grab('dev.langchain4j:langchain4j-vertex-ai:0.22.0')
import dev.langchain4j.model.vertexai.*

VertexAiChatModel vertexAiChatModel =
    VertexAiChatModel.builder()
        .endpoint("us-central1-aiplatform.googleapis.com:443")
        .project("my-llm-java-demos")
        .location("us-central1")
        .publisher("google")
        .modelName("chat-bison@001")
        .temperature(1.0)
        .maxOutputTokens(256)
        .topK(40)
        .topP(0.95)
        .maxRetries(3)
        .build()

def response = vertexAiChatModel.sendUserMessage(
        "What is the best Large Language Model?")

println response.text()
```

It's very declarative and straightforward! I define my endpoint and my model settings with one builder. And then I just send messages to that chat model with just strings. And the response is also a simple string.

LangChain4J has won my heart!

## What's next?

I didn't stop there, I also built another Generative AI use case: I created a project that lets me ask questions about some documentation (in my case, I wanted to query the Apache Groovy documentation.) I'll tell you more about that project in a forthcoming article, as we dive deeper in LangChain4J, to cover text embeddings, vector stores, and more.

I'll be covering this topic on Generative AI with Java at
[Devoxx Belgium](https://devoxx.be/talk/?id=4452) next week, and
[Devoxx Morocco](https://devoxx.ma/talk/?id=4901) the following one.

But you can have a look already at some of the [more advanced examples](https://github.com/langchain4j/langchain4j-examples/tree/main/other-examples/src/main/java), to see how you can calculate vector embeddings locally with the all-MiniLM-L6-v2 embedding model, and store the vectors in a convenient in-memory vector store ([link](http://all_minilm_l6_v2)), how to do text classification ([link](https://github.com/langchain4j/langchain4j-examples/blob/main/other-examples/src/main/java/embedding/classification/EmbeddingModelTextClassifierExample.java)), how to talk chat with your documents with conversational retrieval chains ([link](https://github.com/langchain4j/langchain4j-examples/blob/main/other-examples/src/main/java/ChatWithDocumentsExamples.java)).

LangChain4J is still young, but already pretty powerful, and offers integrations with VertexAI and OpenAI, with vector stores like [ChromaDB](https://www.trychroma.com/), [Pinecone](https://www.pinecone.io/) or [Weaviate](https://weaviate.io/) databases, and more.

Be sure to [checkout LangChain4J](https://github.com/langchain4j) if you want to build your next Generative AI use case with Java!

# Custom Environment Variables in Workflows


In addition to the built-in [environment variables available by default](https://cloud.google.com/workflows/docs/reference/environment-variables) in Google Cloud [Workflows](https://cloud.google.com/workflows) (like the project ID, the location, the workflow ID, etc.) it’s now possible to define your own [custom environment variables](https://cloud.google.com/workflows/docs/use-environment-variables)!

Why is it useful and important? It’s particularly handy when you want to read information that is dependent on the deployment of your workflow, like, for example, information about the environment you’re running in. Is my workflow running in development, staging, or production environment? Then you can read your custom `MY_ENVIRONMENT` variable, like you read the existing built-in environment variables. And you define such variables at deployment time.

In our [best practices articles](https://cloud.google.com/blog/topics/developers-practitioners/workflows-patterns-and-best-practices-part-3#:~:text=Plan%20for%20multi%2Denvironment%20orchestrations), and in the more detailed article on [multi-environment service orchestration](https://cloud.google.com/blog/topics/developers-practitioners/multi-environment-service-orchestrations), my colleague [Mete](https://atamel.dev/) and I had shared ways to implement such an approach. You have a workflow that orchestrates some API calls. But you want to have one single workflow definition that can run in different environments. There were a few approaches, each with pros and cons, to do that: by passing the API URLs as parameters of the workflow execution (but it doesn’t work for event-triggered workflows), by replacing some special text tokens before deployment, or even with some string replacement when deploying with Terraform.

But now, things are simpler! Let’s see how to **define custom environment variables** and how to **access them**.

## Calling an API endpoint in staging or in prod

With custom environment variables, you can now deploy the exact same workflow definition, but with different variables, using the `sys.get_env()` built-in function:


```bash
- call_a_service:
    call: http.get
    args:
      url: ${sys.get_env("SERVICE_URL"}
```


And on deployment, specify `SERVICE_URL` to point at the staging or the production URL of that service.

## Setting environment variables

Now that we’ve seen how to access an environment variable, let’s see how you can set it.

As explained in the documentation about [custom environment variables](https://cloud.google.com/workflows/docs/use-environment-variables), you can use different flags to define, update, delete those variables.

You can specify one or more variables with `--set-env-vars`:

```bash
gcloud workflows deploy WORKFLOW_NAME \
    --set-env-vars KEY1=VALUE1,KEY2=VALUE2
```


Use a file that contains all your custom environment variables (one `key:value` per line):


```bash
gcloud workflows deploy WORKFLOW_NAME \
    --env-vars-file FILE_PATH
```

You can also update vars with the `--update-env-vars` flag, remove some with `--remove-env-vars`, or delete them all with `--clear-env-vars`.

## Bonus tip: Use the `default()` built-in function in case the environment variable isn’t defined

In case the environment variable wasn’t defined at deployment time, you can use the `default()` value method to set a default value, like in this example

```yaml
- logEnv:
    call: sys.log
    args:
        text: ${default(sys.get_env("ENVIRONMENT"), "PRODUCTION")}
```

Here, we’re logging the value of the environment, but if the `ENVIRONMENT` custom environment variable isn’t defined, by default, the value will be `PRODUCTION`.

## Summary

With custom environment variables, you can parameterize your workflows to tackle different use cases. One of the most frequently used ones is to use those environment variables to distinguish between different environments, like prod or staging. But you can also use them to configure different parameters of your workflow, like defining some configurable limits (number of retries), different endpoints or parameters for the services you call. You define your workflow once, and customize the deployment with different environment variables.

# From Bird to Elephant: Starting a New Journey on Mastodon


{{< speakerdeck 365d3694bd674bfa85d812d8c2fd32f9 >}}

At Devoxx France and Devoxx Greece, I had the pleasure to talk about my new social media journey on [Mastodon](https://joinmastodon.org/).
After a quick introduction about Mastodon and the [Fediverse](https://fediverse.party/), I contrasted the key differences between Twitter and Mastodon.
Then I shared some advice on how to get started, how to chose an instance, or clients you can pick from.

I moved on to important tips to get the best experience on the platform, and ensure to gather a great following:
* introduce yourself with a detailed bio and first #introduction post
* create your profile before following others
* configure your account so it can be discoveredn and recommended to others
* contrary to Twitter, you can verify yourself, showing that you own the personal links you share

Once your account is ready, if you are migrating from Twitter, you might want to find who among your friends have also migrated, so you can follow them in the fediverse.
I advise people not to delete their Twitter account, to avoid someone to pick up their old handle and to impersonate them.

Another aspect I like about the Mastodon platform is that it seems to care deeply about accessibility, and about people's possible troubles.
Putting _alt_ tags for images is highly encouraged on Mastodon.
Or putting content warnings on text and images also helps prevent unwanted content to jump at your eyse unexpectedly.

In a second part of the presentation, I spoke about the various standards and APIs underlying the Fediverse and Mastodon:
* [ActivityPub](https://www.w3.org/TR/activitypub/) and [ActivityStream](https://www.w3.org/TR/activitystreams-core/)
* [JSON-LD](https://json-ld.org/)
* [WebFinger](https://webfinger.net/)
* [MicroFormats](http://microformats.org/)
* [HTTP Sigantures](https://oauth.net/http-signatures/) and [OAuth 2](https://oauth.net/2/)
I went through an exchange between a client and a server, mimicking the actual process when you send a message to another recipient.
This is basically how to implement a basic ActivityPub server, based on Eugen Rochko's great [post](https://blog.joinmastodon.org/2018/06/how-to-implement-a-basic-activitypub-server/) on the topic.

The third and final part of the presentation was a comcrete demo on how to implement your own bots on Mastodon.
I showed how to create a service (a [Micronaut](https://micronaut.io/) application) that [calculates the potential reach]({{< ref "/posts/2023/01/06/calculating-your-potential-reach-on-mastodon-with-google-cloud-workflows-orchestrating-the-mastodon-apis" >}}) of your posts.
You can play with the service [online](https://stootistics.web.app/) and give it your account to see how popular your recent posts are.
And there's even an account ([@getmyreach@tooters.org](https://tooters.org/@getmyreach)) you can ping on Mastodon to get back the most popular of your posts.
The code is available on [Github](https://github.com/glaforge/stootistics) if you want to check it out.

You can check the recording of the talk in English from Devoxx Greece:

{{< youtube DafHAmlzWUM >}}

And in French at Devoxx France:

{{< youtube _BaK9BNlUHg >}}


# Creating kids stories with Generative AI


Last week, I wrote about how to [get started with the PaLM API in the Java ecosystem]({{< ref "/posts/2023/05/30/getting-started-with-the-PaLM-API-in-the-java-ecosystem" >}}),
and particularly, how to overcome the lack of Java client libraries (at least for now) for the PaLM API, and how to properly authenticate.
However, what I didn't explain was what I was building! Let's fix that today, by telling you a story, a kid story!
Yes, I was using the trendy **Generative AI** approach to generate bedtime stories for kids.

Without further ado, let me introduce you to my little app: [bedtime stories](https://bed-time-stories.web.app/).

[![](/img/bedtime/bedtime-stories-ui.png)](https://bed-time-stories.web.app/)

> If you're interested in the source code, head over to the Github [repository](https://github.com/glaforge/bedtimestories):
> it's implemented in [Apache Groovy](https://groovy-lang.org/), developed with the [Micronaut](https://micronaut.io/) framework,
> designed with the [Shoelace](https://shoelace.style/) web components, and deployed on Google [Cloud Run](https://cloud.run/), the serverless container runtime.

## The concept

For a good story, we need 3 key ingredients:
* a **character** — the main protagonist of the story whose adventures are narrated, like a princess, an astronaut, a firefighter...
* a **setting** — where (and potentially when) the action takes place, like a beautiful kingdom, a faraway planet, a mysterious haunted house...
* a **plot** — a rough idea of what's going to happen in the story, like an evil darkness is menacing the kingdom, huge shooting stars are menacing the planet...

In the UI, there are a few options to pick from, by default, but you can actually customise them at will, or better, come up with your own characters, settings, and plots.
You can play that game with your kids: *"hey, who should be the hero of our story tonight?"*. They may have an idea, or even a favorite character!

Then, just click the `Generate` button, and after 20s or so, you'll have a story ready!

## Where Generative AI comes in

Of course, the whole story is created thanks to Generative AI.
I used the [PaLM API](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview#palm-api) for that,
within my Google Cloud project, using the [Vertex AI](https://cloud.google.com/vertex-ai/) suite of machine learning services.

For the characters, settings, and plots, I came up with a few ideas on my own.
But I felt like the choice was limited and would warrant some more creativity.
So I asked [Bard](http://bard.google.com/) (powered by the PaLM API as well) to help me!
It's all about the *art of prompting*, of asking the right question to your favorite generative AI:

> Here are a few characters of bedtime kid stories:
> - a funny little princess with a strong character
> - a young astronaut exploring space
> - a fearless firefighter
> - a cute little cat with a long and silky fur
> - a gentle dragon with a colorful skin
>
> Suggest a list of other possible characters:

And lo and behold, I got a dozen suggestions that I then integrated in my character picker. Same thing for the settings and plots.
Interestingly, not only Bard (or PaLM) would give me suggestions, but it also gave me explanations on why those characters, settings and plots made sense.
So Generative AI is also here to help in the process of crafting your application, or your own prompts.

## The story generator prompt

The crux of this story is the main prompt that makes the requests to generate the actual story.
I wanted to have a familiar pattern or structure for my generated stories.
You've probably heard about such common structures for narration, in 3 or 5 acts.
I came across this [website](https://bubblecow.com/blog/importance-of-structure) about the 5-act approach,
with an exposition phase, the rising action, the climax, the falling action, and the final denouement.
So when crafting my prompt, first I started by telling PaLM who it was (a story teller), but then I also explained what a 5-act story act looks like,
and finally, I asked it to generate a story for my particular chosen trio of character, setting, and plot.
Here's my final prompt:

> You are a creative and passionate story teller for kids.
> Kids love hearing about the stories you invent.
>
> Your stories are split into 5 acts:
> - Act 1 : Sets up the story providing any contextual background the reader needs, but most importantly it contains the inciting moment. This incident sets the story in motion. An incident forces the protagonist to react. It requires resolution, producing narrative tension.
> - Act 2 : On a simplistic level this is the obstacles that are placed in the way of the protagonists as they attempt to resolve the inciting incident.
> - Act 3 : This is the turning point of the story. It is the point of the highest tension. In many modern narratives, this is the big battle or showdown.
> - Act 4 : The falling action is that part of the story in which the main part (the climax) has finished and you're heading to the conclusion. This is the calm after the tension of the climax.
> - Act 5 : This is the resolution of the story where conflicts are resolved and loose ends tied up. This is the moment of emotional release for the reader.
>
> Generate a kid story in 5 acts, where the protagonist is ${character}, where the action takes place ${setting} and ${plot}.

The fact of asking PaLM to structure the story that way also influences its textual output.
Not only did it create those 5 key parts, but it also added some bold act labels in its output, which I could filter to then split my string story into 5 smaller chunks.

## Where to go from there?

I hope you enjoyed the journey so far, and that you got a chance to generate your own story and tell it to a happy kid!

However, for now at least, this is just a concept, so I'm not sure whether I'll be developing it much further, but I'd like to share possible ways to improve this application.

* As I explained, it's a story in 5 acts, so we could offer the story over 5 distinct pages that you would have to turn.
Vertex AI also features an image generation service (still in preview for now), so the **stories could also be decorated with AI generated pictures**!
(We can even ask PaLM to generate ideas of prompts for image generation.)
* Currently, PaLM can generate up-to 1024 characters of output, but it has 8KB in input.
We can't generate a super long story, but since it's split in 5 acts, that can all fit in the input context window,
we could try to pass PaLM the whole generated story, and ask it 5 times to generate 1KB characters for each section, thus **lengthening the whole story by a factor of 5**.
* To go even further, we could use the multilingual capabilities of large language models,
or at least just the Translate API, to offer **translations of the app and the stories** into different languages.
* We could also imagine the app being able to narrate the story itself, by taking advantage of **Text-to-Speech voice generation**!
However you might miss on the great bonding opportunity with your kids when you tell them a story,
but on the other hand, kids could entertain themselves when you're busy by generating random stories on their own.
* Maybe we could also **save stories** that pleased our kids (and reshare them with others),
as each generation, even with the same trio of character/setting/plot, can yield very diverse outcomes.

So there are plenty options possible offered by Generative AI!


# Just a handy command-line tool


When developing new projects on my laptop, I often run some commands over and over again.
Regardless of how far you've gone with your CI/CD pipelines, running commands locally without resorting to becoming a bash ninja can be pretty easy with... `just`!

> [`just`](https://just.systems/) is a handy way to save and run project-specific commands

It's a command-line tool that lets you define some commands to run (called recipes), in the form of a Makefile-inspired syntax.
It even allows you to define dependencies between the various tasks of your `justfile`.
It runs across all environments (Mac, Linux, Windows), and is quick to install.
It loads `.env` files in which you can define variables specific to your project (other developers can have the same `justfile` but have variables specific for their projects)

Without further ado, let's see it in action in my current project.

In my project, I have the following `justfile`:

```make
set dotenv-load

alias r := run
alias b := build
alias d := deploy

default: run

run:
    ./gradlew -t run

build:
    gcloud builds submit -t $CLOUD_REGION-docker.pkg.dev/$PROJECT_ID/containers/$CONTAINER_NAME:v1

deploy: build
     gcloud run deploy bedtimestories --image=$CLOUD_REGION-docker.pkg.dev/$PROJECT_ID/containers/$CONTAINER_NAME:v1
```

* The first instruction tells `just` to load an `.env` file.
* The (optional) alias lines allow me to define shorcuts for commands that I run very often
* There are three commands: `run`, `build`, and `deploy`:
    * `run` will run my application locally with `gradle`
    * `build` will containerize my app with my `Dockerfile` on Google Cloud Build
    * `deploy` depends on `build` and will deploy my container on Google Cloud Run

And now, I _just_ run: `just run`, `just deploy`, or their shortcuts: `just r` or `just d`.

You also noticed the dollar variables which are interpolated from my `.env` file which contains the following variables:

```bash
PROJECT_ID=some-project-id
CLOUD_REGION=us-central1
CONTAINER_NAME=some-container-name
```

It's `just` a new little handy tool in my toolbox!

Go check it out: [just.systems](https://just.systems/).
And have a look at the [cheat sheet](https://cheatography.com/linux-china/cheat-sheets/justfile/) for more examples and syntax.
# Getting started with the PaLM API in the Java ecosystem


Large Language Models (LLMs for short) are taking the world by storm,
and things like ChatGPT have become very popular and used by millions of users daily.
Google came up with its own chatbot called [Bard](https://bard.google.com/),
which is powered by its ground-breaking [PaLM 2](https://ai.google/discover/palm2/) model and API.
You can also find and use the PaLM API from withing Google Cloud as well
(as part of [Vertex AI Generative AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview) products)
and thus create your own applications based on that API.
However, if you look at the documentation, you'll only find Python tutorials or notebooks,
or also explanations on how to make cURL calls to the API.
But since I'm a Java (and Groovy) developer at heart, I was interested in seeing how to do this from the Java world.

## Micronaut + Groovy + Cloud Run

My use case was to create a simple application that generates bedtime kid stories, using the PaLM LLM.
I went ahead and decided to use [Micronaut](https://micronaut.io) for my framework,
and [Apache Groovy](https://groovy-lang.org) for my programming language.
I containerize and deploy my application on [Cloud Run](https://cloud.run) on Google cloud.
And I use the [Cloud Run integration for Firebase](https://cloud.google.com/run/docs/integrate/firebase-hosting)
to have a nice domain for my app, and to serve my static content from Firebase's CDN.
I won't cover these aspects too much in this article,
but I want to stress the important roadblock you might encounter: authentication.

## Let's get started!

First, you may not necessarily have access to the Generative AI services in Google Cloud.
For that, you'll need to [sign up](https://cloud.google.com/ai/generative-ai) to join the Trusted Tester Program.
But once you have access, you'll be able to use the PaLM API programmatically for your own apps.

When experimenting with prompts to the LLM, you'll notice the handy sliding panel
that shows you how to interact with the API from code. But you only have the choice between Python and cURL.
That said, the cURL command helps you figure out how to call the API via REST:

```bash
curl \
    -X POST \
    -H "Authorization: Bearer $(gcloud auth print-access-token)" \
    -H "Content-Type: application/json" \
    "https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/us-central1/publishers/google/models/${MODEL_ID}:predict" -d \
    $'{
    "instances": [
        {
        "content": "Write a kid story about an astronaut visiting another galaxy but facing problems with shooting stars"
        }
    ],
    "parameters": {
        "temperature": 0.5,
        "maxOutputTokens": 1000,
        "topP": 0.8,
        "topK": 40
    }
    }'
```

We have the JSON structure in input, and if you call that command,
you'll get an output similar to the following one:

```json
{
  "predictions": [
    {
      "safetyAttributes": {
        "scores": [
          0.10000000149011612
        ],
        "blocked": false,
        "categories": [
          "Violent"
        ]
      },
      "content": "Once upon a time, there was a young astronaut called..."
    }
  ]
}
```

Our Micronaut will have to marshall/unmarshall those input and output JSON documents.
But the tricky bit for me was authentication.
From the command-line, the embedded `gcloud` command makes use of an access token,
which grants you access to the PaLM API.
But from my Micronaut/Groovy code, I needed to find a way to authenticate as well.

## Preparing a low-level HTTP client call

Let's craft the appropriate REST endpoint URI:

```groovy
def uri = UriBuilder
        .of("/v1/projects/${projectId}/locations/us-central1/publishers/google/models/text-bison:predict")
        .scheme("https")
        .host("us-central1-aiplatform.googleapis.com")
        .build()
```

Currently, the API is only available in the `us-central1` region, so it's hard-coded.

Then we need to prepare the request:

```groovy
def request = HttpRequest
        .POST(uri, [
                instances: [
                  [ content: storyPrompt ]
                ],
                parameters: [
                    temperature: 0.6,
                    maxOutputTokens: 1000,
                    topP: 0.8,
                    topK: 40
                ]
        ])
        .bearerAuth(token)
        .accept(MediaType.APPLICATION_JSON_TYPE)
        .contentType(MediaType.APPLICATION_JSON_TYPE)
```

In a moment, we'll see how we can create the bearer `token` we use in the `bearerAuth()` call.
Here, we just send the prompt, with some parameters to say how creative we want the LLM answer to be.

Finally, we make the request:

```groovy
def predictionResponse = client.toBlocking()
        .exchange(request, PredictionResponse)
        .body()

return predictionResponse.predictions.first().content
```

I created some classes to unmarshall the resulting JSON:

```groovy
import com.fasterxml.jackson.annotation.JsonProperty
import io.micronaut.serde.annotation.Serdeable

@Serdeable
class PredictionResponse {
    @JsonProperty("predictions")
    List<Prediction> predictions
}

@Serdeable
class Prediction {
    @JsonProperty("safetyAttributes")
    SafetyAttributes safetyAttributes
    @JsonProperty("content")
    String content
}

@Serdeable
class SafetyAttributes {
}
```

## Authenticating

When running my application locally, no problem, but once deployed, I needed to have a fresh bearer token.
I created a dedicated service account, with the minimum needed permissions:

* `roles/aiplatform.user` to have the rights to call the PaLM API
* `roles/logging.logWriter` as your Cloud Run app needs to write some logs back to Cloud Logging

This [article](https://medium.com/google-cloud/generative-ai-palm-2-model-deployment-with-cloud-run-54e8a398b24b)
also nicely explains how to handle deployment to Cloud Run.

My Cloud Run service will be deployed with that service account.

Locally, on my laptop, I used the `GOOGLE_APPLICATION_CREDENTIALS" approach,
by exporting a JSON key, and point at it via an environment variable:

```bash
GOOGLE_APPLICATION_CREDENTIALS="exported-key.json"
```

You can learn more about local development with
[Application Default Credentials](https://cloud.google.com/docs/authentication/provide-credentials-adc#local-dev).

So locally, we use that exported key, and locally we use a generated token from the restricted service account.
And to generate that token, I had to use the
[google-auth-library-oauth2-http](https://github.com/googleapis/google-auth-library-java#google-auth-library-oauth2-http)

Here's the missing snippet to do so:

```groovy
def credentials = GoogleCredentials.applicationDefault
        .createScoped('https://www.googleapis.com/auth/cloud-platform')
credentials.refreshIfExpired()
def token = credentials.accessToken.tokenValue
```

To import that authentication library in my project, I defined its requirement in my `build.gradle` file:

```groovy
implementation('com.google.auth:google-auth-library-credentials:1.17.0')
```

## Voilà!

With the right authentication client library, I was able to create the beared token needed to authenticate
to the Vertex AI PaLM API, both locally on my laptop, and once deployed on Cloud Run as well.

Hopefully, when Google releases official Java client libraries,
it'll certainly be easier to interact with the PaLM API,
without having to create marshalling/unmarshalling code,
and will likely make it smoother to authenticate transparently.
So stay tuned!
# Exploring Open Location Code


![](/img/misc/eiffel-tower-plus-code.png)

When using Google Maps, you might have seen those strange little codes, as in the screenshot above.
This is a _plus code_, or to use the more official name, an **Open Location Code**.
It's a way to encode a location in a short and (somewhat) memorable form.

In countries like France, every house has an official address, so you can easily receive letters or get some parcel delivered. But there are countries where no such location system exists, so you have to resort to describing where you live (take this road, turn right after the red house, etc.)

Of coursse, you could use GPS coordinates, but that's not very convenient to share, and nobody could remember a precise address. So there have been several attemps at creating systems that represent any location in the world,
like [GeoHash](http://geohash.org/), [MapCode](https://www.mapcode.com/), and other proprietary systems like 3-words.

Out of curiosity, I wanted to play with this geo-encoding approach, and decided to spend a few minutes playing with the available Java library (available on [Maven Central](https://central.sonatype.com/artifact/com.google.openlocationcode/openlocationcode/1.0.4)), but using [Apache Groovy](https://groovy-lang.org/).

You'll find more links on the topic at the end of this article.

## Playing with plus codes in Groovy

Here's a little script that shows the library in action:

```groovy
@Grab("com.google.openlocationcode:openlocationcode:1.0.4")
import com.google.openlocationcode.OpenLocationCode

// Eiffel Tower
def (lat, lon) = [48.8584, 2.29447]

def eiffelTowerPlusCode = OpenLocationCode.encode(lat, lon)
println "Eiffel Tower +code: ${eiffelTowerPlusCode}"

def decoded = OpenLocationCode.decode('8FW4V75V+9Q')
println "Original coord: ${decoded.centerLatitude}, ${decoded.centerLongitude}"
```
(You can play and run the above script in the [Groovy Web Console](https://gwc-experiment.appspot.com/?g=groovy_4_0&gist=4176e0ad13b396001c92ab5cd584b3d8))

## More information

* The official [Open Location Code website](https://maps.google.com/pluscodes/)
* The project [open-location-code project on Github](https://github.com/google/open-location-code) that provides implementations of the algorithm in various programming languages
* A [comparison](https://github.com/google/open-location-code/wiki/Evaluation-of-Location-Encoding-Systems) of different geocoding / geohashing systems
* The French wikipedia [page on Open Location Code](https://fr.wikipedia.org/wiki/Open_Location_Code) shows visually how the world map is cut in smaller boxes, as you zoom in, and takes the example of the Eiffel Tower like in my script above
* For reference, the English wikipedia [page](https://en.wikipedia.org/wiki/Open_Location_Code), but it's a little less detailed and visual
# cURL's --json flag


As cURL was celebrating its [25th birthday](https://daniel.haxx.se/blog/2023/03/20/twenty-five-years-of-curl/), I was reading Daniel Stenberg's story behind the project, and discovered a neat little feature I hadn't heard of before: the `--json` flag! Daniel even [blogged](https://daniel.haxx.se/blog/2022/02/02/curl-dash-dash-json/) about it when it landed in cURL 7.82.0 last year.

So what's so cool about it? If you're like me, you're used to post some JSON data with the following verbose approach:

```bash
curl --data '{"msg": "hello"}' \
    --header "Content-Type: application/json" \
    --header "Accept: application/json" \
    https://example.com
```

You have to pass the data, and also pass headers to specify the content-type.
You can make it slightly shorter with the one-letter flags:

```bash
curl -d '{"msg": "hello"}' \
    -H "Content-Type: application/json" \
    -H "Accept: application/json" \
    https://example.com
```

But with the recent addition of this flag, it's much shorter, as you don't have to specify the mime types:

```bash
curl --json '{"msg": "hello"}' https://example.com
```

It's available since version 7.82.0, and on my Mac laptop, I have version 7.86.0.

For reference, here's the excerpt of the manual that gives the details about the `--json` flag:

```
--json <data>
    (HTTP) Sends the specified JSON data in a POST request to the
    HTTP server. --json works as a shortcut for passing on these
    three options:

    --data [arg]
    --header "Content-Type: application/json"
    --header "Accept: application/json"

    There is no verification that the passed in data is actual
    JSON or that the syntax is correct.

    If you start the data with the letter @, the rest should be a
    file name to read the data from, or a single dash (-) if you
    want curl to read the data from stdin. Posting data from a file
    named 'foobar' would thus be done with --json @foobar and to
    instead read the data from stdin, use --json @-.

    If this option is used more than once on the same command line,
    the additional data pieces will be concatenated to the previous
    before sending.

    The headers this option sets can be overridden with --header
    as usual.

    --json can be used several times in a command line

    Examples:

    curl --json '{ "drink": "coffe" }' https://example.com
    curl --json '{ "drink":' --json ' "coffe" }' https://example.com
    curl --json @prepared https://example.com
    curl --json @- https://example.com < json.txt
```
# Tip: Visualize output in the Groovy Console


For some scripting tasks, my favorite go-to tool is the **Groovy Console**,
and writing code with [Apache Groovy](https://groovy-lang.org/).
Usually, you just spill some `println` calls all over the place to display some textual information.
But there's a little known secret. Not really secret though,
as it's properly [documented](http://docs.groovy-lang.org/2.4.1/html/documentation/tools-groovyconsole.html#GroovyConsole-Visualizingscriptoutputresults).
It's possible to display images (like `BufferedImage` or its parent `java.awt.Image`)
or all sorts of rich components (from the `Swing` UI toolkit, like `JPanel`, `JLabel`, etc.)

For example, to display an image in the output pane of my Groovy Console, I can load it up via an `ImageIcon`:

```groovy
import javax.swing.*

def url = "https://pbs.twimg.com/profile_images/1590794600867893271/ttqX3njd_400x400.jpg".toURL()
new ImageIcon(url)
```

For that purpose, you'll have to ensure that the `View > Visualize Script Results` is enabled, as shown in the picture below:

![](/img/misc/groovy-console-visualize-output.png)

As mentioned in the [documentation](http://docs.groovy-lang.org/2.4.1/html/documentation/tools-groovyconsole.html#GroovyConsole-Visualizingscriptoutputresults), you could for example display maps or lists as nice Swing `JTable`.
Or for some data visualisation, you could also used any Java libraries that output images or that can be embeded in Swing components,
like the venerable JFreeChart library (ie. here's a StackOverflow question that shows that JFreeChart charts can be embedded in Swing components like `JPanel`).

# Some custom VS Code settings


I regularly use both [IntelliJ IDEA](https://www.jetbrains.com/idea/) and [Visual Studio Code](https://code.visualstudio.com/) as my environments for developing.
But like all tools, we often need to personalise them to our liking, to feel at ease, or to be more productive.
As we read code more than we write, there are certain settings in your favorite editor to improve your reading experience. Today, I'll share of the tweaks I've made to my VS Code settings.

You can edit some of the settings by opening the UI of the settings dialog box, but you can also edit the `JSON` file in which those settings are saved. On a Mac, for example, the `settings.json` file is stored in `~/Library/Application Support/Code/User/`.

Here are my current custom settings, compared to the default configuration:

```json
{
    "security.workspace.trust.untrustedFiles": "open",
    "window.title": "${folderPath} ${separator} ${activeEditorShort}",
    "breadcrumbs.enabled": true,
    "workbench.colorCustomizations": {
        "[Default Dark+]": {
            "editor.lineHighlightBackground": "#404020FF",
            "editorLineNumber.activeForeground": "#ffff00",
        },
        "[Default Light+]": {
            "editor.lineHighlightBackground": "#FFEEEE",
            "editorLineNumber.activeForeground": "#ff0000",
        }
    },
    "workbench.tree.renderIndentGuides": "always",
    "workbench.tree.indent": 10,
    "editor.fontSize": 12,
    "editor.fontFamily": "Fira Code",
    "editor.fontLigatures": true,
    "editor.formatOnPaste": true,
    "editor.guides.bracketPairs": true,
    "files.trimTrailingWhitespace": true,
    "editor.mouseWheelZoom": true
}
```

Let's go through them:

* `security.workspace.trust.untrustedFiles` — allows to open a file not part of the project without warning
* `window.title` — for a custom window title, with the root of the project, and the name of the current opened file
* `breadcrumbs.enabled` — to display a breadcrumbe to see where I'm located in the file tree, and inside the file's structure itself
* `editor.lineHighlightBackground` and `editorLineNumber.activeForeground` — I've customised the colors of the current line the cursor is on, as well as the line number in the gutter, to make it stand out more on my dark background
* `workbench.tree.renderIndentGuides` and `workbench.tree.indent` — adds the little vertical bars in the file explorer, to visually see the current level or depth in the directory structure, and specifies how far apart they should be
* `editor.fontSize` — customize the default font size (but it may already be 12 by default)
* `editor.fontFamily` and `editor.fontLigatures` — I'm using Fire Code for my coding font, and I enable the ligatures to have nice looking operators
* `editor.formatOnPaste` — to automatically format the code that you pase, without having to manually reident it
* `editor.guides.bracketPairs` — for drawing a little vertical line that highlights the current scope of the block my cursor is in
* `files.trimTrailingWhitespace` — I like to trim the trailing whitespace at the end of a line automatically (to avoid some dummy commit because of a remaining space, for instance)
* `editor.mouseWheelZoom` — to allow mousewheel zoom in and out to increase / decrease font size


# New blog location


I started blogging 20 years ago, in April 2003. My first blog engine was a PHP CMS, called [Nucleus](http://nucleuscms.org/). I was hosting it on my ISP, at free.fr.

Then in 2011, I wrote my own blog engine, called [Bloogaey](https://github.com/glaforge/bloogaey), which was written in [Groovy](https://groovy-lang.org/), using my little [Gaelyk](http://gaelyk.appspot.com/) web framework, and running on [App Engine](https://cloud.google.com/appengine).

As it became a bit painful to properly format my blog posts, and evolve my blog engine, I decided I should move to something that is more static, with a static site generator that eats Markdown files: I chose the [Hugo](https://gohugo.io/) static site generator that I used in some previous projects. And I'm now hosting the content of my blog in [Github Pages](https://github.com/glaforge/glaforge.github.io), under the [glaforge.dev](https://glaforge.dev/) custom domain name.

## <https://glaforge.dev/>

I'll stop blogging on the old website, and will write my new articles on that new URL.

I'll try to redirect all the links back to this new location, and also update the RSS feed for those who are subscribed via Feedburner. But if you want to update your feed reader manually, here's the new URL for the feed: <https://glaforge.dev/index.xml>

[![](/img/misc/glaforge-dev-screenshot.png)](https://glaforge.dev/)
# Google Cloud Workflows API automation, patterns, and best practices


* Workflows at a glance, benefits, key features, use cases
* UI interface in Google Cloud console
* Deep dive into the Workflows syntax
* Workflows connectors
* Demos
* Patterns and best practices

{{< speakerdeck 9957977f37554ccdacf91f0859592bae >}}


# Calculating your potential reach on Mastodon with Google Cloud Workflows orchestrating the Mastodon APIs


With the turmoil around Twitter, like many, I’ve decided to look into [Mastodon](https://joinmastodon.org/). 
My friend [Geert](https://uwyn.net/@gbevin) is running his own Mastodon server, 
and welcomed me on his instance at: [uwyn.net/@glaforge](https://uwyn.net/@glaforge). 

With Twitter, you can access your [analytics](https://analytics.twitter.com/about) to know how your tweets are doing, how many views you’re getting. 
Working in developer relations, it’s always interesting to get some insights into those numbers to figure out if what you’re sharing is interesting for your community. 
But for various (actually good) reasons, Mastodon doesn’t offer such detailed analytics. 
However, I wanted to see what the [Mastodon APIs](https://docs.joinmastodon.org/api/) offered. 

## How to calculate your potential reach

Your _“toots”_ (ie. your posts on Mastodon) can be “boosted” (equivalent of a retweet on Twitter). 
Also, each actor on Mastodon has a certain **number of followers**. 
So potentially, one of your toots can reach all your followers, as well as all the followers of the actors who reshare your toot. 

So the maximum potential reach of one of your posts would correspond to the following equation:

```
potential_reach = 
    me.followers_count + 
    ∑ ( boosters[i].followers_count )
```

Let’s play with the Mastodon APIs to compute your reach

Fortunately, the Mastodon APIs allow you to get those numbers, albeit not with a single API call. 
Let’s have a look at the interesting endpoints to get the potential reach of my most recent posts.


First of all, I’ll look up my account on the Mastodon instance that hosts me:

```
GET https://uwyn.net/api/v1/accounts/lookup?acct=glaforge
```

I pass my account name as a query parameter to the /accounts/lookup endpoint.

In return, I get a JSON document that contains various details about my account and me 
(I’ll just show some of the interesting fields, not the whole payload):

```json
{
    id: "109314675907601286",
    username: "glaforge",
    acct: "glaforge",
    display_name: "Guillaume Laforge",
    ...
    note: "...",
    url: "https://uwyn.net/@glaforge",
    ...
    followers_count: 878,
    fields: [...]
}
```

I get two important pieces of information here: the followers_count gives me, you guessed it, 
the number of followers my account has, thus the potential number of persons that can see my toots. 
Also the id of my account, which I’ll need for some further API calls further down.

To get the most recent statuses I’ve posted, I’ll indeed need that account id for crafting the new URL I’ll call:

```
GET https://uwyn.net/api/v1/accounts/109314675907601286/statuses
```

This call will return a list of statuses (again, snipped less interesting part of the payload):

```json
[
    …
    {
        id: "109620174916140649",
        created_at: "2023-01-02T14:52:06.044Z",
        …
        replies_count: 2,
        reblogs_count: 6,
        favourites_count: 6,
        …
        edited_at: null,
        content: "...",
        reblog: null,
        …
    },
    …
]
```

In each status object, you can see the number of replies, the number of times the post was reshared or favorited, 
or whether it’s a reshared toot itself. So what’s interesting here is the reblogs_count number. 

However, you don’t get more details about who reshared your toot. 
So we’ll need some extra calls to figure that out!

So for each of your posts, you’ll have to call the following endpoint to know more about those “reblogs”:

```
GET https://uwyn.net/api/v1/statuses/109620174916140649/reblogged_by
```

This time, you’ll get a list of all the persons who reshared your post:

```json
[
    {
        id: "123456789",
        username: "...",
        acct: "...",
        display_name: "...",
        ...
        followers_count: 7,
        ...
    },
    ...
]
```

And as you can see the details of those persons also have the followers_count field, 
that tells the number of people that follow them. 

So now, we have all the numbers we need to calculate the potential reach of our toots: 
your own number of followers, and the number of followers of all those who reshared! 
It doesn’t mean that your toots will actually be viewed that many times, 
as one doesn’t necessarily read each and every toots on their timelines, 
but at least, that’s an approximation of the maximum reach you can get.

## Automating the potential reach calculation with Web API orchestration

Initially I played with both cURL and a little Apache Groovy [script](https://gwc-experiment.appspot.com/?g=groovy_4_0&codez=eJx1kl9PwjAUxd_3KRqeNjUtoAlsCTHGhAfjg0F8MoaUcQczY3dp78DF-N0tLRv_xp66c-85t_216bpARWypEDcV_9aY8xvPW0DCdms2Yjls2YtZvmelKkD5gcfMZzsIkT5UZpo6K6JCR0KU2yrnOZCQRSo2PaFJUqlBi143vB_2hmE4fOiH_cEg7HZsRiGVhsXUJJkYO94qU_ghf5_PCT8mr37AyYiB14x-Q02gxphluAWljf8QxmUcY5kTT-ryzP6zx4h1m4Sx3KBKCc68iZFLq7eZJjDPcHlmUU487rcGp08bUDWyW9YRrraExWxeHcNwA56UktUlk5PANjJNagPm2e5pdJnOY9MCMbFflraTYn9cl2s_2J9IAZUqZ5_2CSQ1vOiU5Z2r1mlR2125nj206BirqxCSzJwyPgRdOZqzFEiQU7qzyXjVOtVQvxLhfXneP1NZD_M) 
to better understand the Mastodon APIs to figure out how to chain them to get to the expected result. 
Then I decided to automate that series of Web API calls using an API orchestrator: [Google Cloud Workflows](https://cloud.google.com/workflows).


To recap, we need to:
* Get the details of your account
* Get the recent posts for that account
* Get all the followers count for each person who reshared each post

Let’s have a look at this piece by piece:

```yaml
main:
    params: [input]
    steps:
    - account_server_vars:
        assign:
        - account: ${input.account}
        - server: ${input.server}
        - prefix: ${"https://" + server + "/api/v1"}
        - impact_map: {}
```

First, the workflow takes an account and server arguments, in my case that is glaforge and uwyn.net. 
And I’m defining a variable with the base path of the Mastodon API, and a dictionary to hold the data for each toot.

```yaml
- find_account_id:
    call: http.get
    args:
        url: ${prefix + "/accounts/lookup"}
        query:
            acct: ${account}
    result: account_id_lookup
- account_id_var:
    assign:
    - account_id: ${account_id_lookup.body.id}
    - followers_count: ${account_id_lookup.body.followers_count}
```

Above, I’m doing an account lookup, to get the id of the account, but also the followers count.

```yaml
- get_statuses:
    call: http.get
    args:
        url: ${prefix + "/accounts/" + account_id + "/statuses"}
        query:
            limit: 100
            exclude_reblogs: true
    result: statuses
```

We get the list of most recent toots. 


Now things get more interesting, as we need to iterate over all the statuses. We’ll do so in parallel, to save some time:

```yaml
- iterate_statuses:
    parallel:
        shared: [impact_map]
        for:
            value: status
            in: ${statuses.body}
```

To parallelize the per-status calls, we just need to state it’s parallel, 
and that the variable we’ll keep our data in is a shared variable that needs to be accessed in parallel. 
Next, we define the steps for each parallel iteration:

```yaml
steps:
- counter_var:
    assign:
    - impact: ${followers_count}
- fetch_reblogs:
    call: http.get
    args:
        url: ${prefix + "/statuses/" + status.id + "/reblogged_by"}
    result: reblogs
```

Above, we get the list of people who reshared our post. And for each of these accounts, 
we’re incrementing our impact counter with the number of their followers. 
It’s another loop, but that doesn’t need to be done in parallel, as we’re not calling any API:

```yaml
- iterate_reblogs:
    for:
        value: reblog
        in: ${reblogs.body}
        steps:
        - increment_reblog:
            assign: 
            - impact: ${impact + reblog.followers_count}
- update_impact_map:
    assign:
    - impact_map[status.url]: ${impact}
```

And we finish the workflow by returning the data:

```yaml
- returnOutput:
        return:
            id: ${account_id}
            account: ${account}
            server: ${server}
            followers: ${followers_count}
            impact: ${impact_map}
```

This will return an output similar to this:

```json
{
  "account": "glaforge",
  "followers": 878,
  "id": "109314675907601286",
  "impact": {
    "https://uwyn.net/@glaforge/109422399389341013": 945,
    "https://uwyn.net/@glaforge/109462120695384207": 1523,
    "https://uwyn.net/@glaforge/109494881278500194": 121385,
    "https://uwyn.net/@glaforge/109495686235916646": 878,
    "https://uwyn.net/@glaforge/109516968335141401": 1002,
    "https://uwyn.net/@glaforge/109523829424569844": 878,
    "https://uwyn.net/@glaforge/109528949144442301": 896,
    "https://uwyn.net/@glaforge/109620174916140649": 1662,
    "https://uwyn.net/@glaforge/109621803885287542": 1523,
    ...
  },
  "server": "uwyn.net"
}
```

With this little workflow, I can check how my toots are doing on this new social media! As next steps, 
you might want to check out how to get started with API orchestration with Google Cloud Workflows, 
[in the cloud console](https://cloud.google.com/workflows/docs/create-workflow-console), 
or [from the command-line](https://cloud.google.com/workflows/docs/create-workflow-gcloud). 
And to go further, potentially, it might be interesting to 
[schedule a workflow execution]({{< ref "/posts/2022/02/09/schedule-a-workflow-execution" >}}) 
with [Cloud Scheduler](https://cloud.google.com/scheduler). 
We could also imagine storing those stats in a database (perhaps [BigQuery](https://cloud.google.com/bigquery) for some analytics, 
or simply [Firestore](https://cloud.google.com/firestore) 
or [CloudSQL](https://cloud.google.com/sql)), to see how your impact evolves over time.


# Workflows patterns and best practices — Part 3


This is a three-part series of posts, in which we summarize Workflows and service orchestration patterns. In this third and final post, we talk about managing workflow life cycles and the benefits of using Firestore with Workflows. 

### Use subworkflows and Terraform to manage workflow definitions

If you're not careful, the workflow definitions you create with YAML or JSON can get out of hand pretty quickly. While it is possible to use subworkflows to define snippets of a workflow that can be reused from multiple workflows, Workflows does not support importing these subworkflows. Thankfully, there are other tools, such as Terraform, that can help.

In our [Deploying multi-YAML Workflows definitions with Terraform](https://cloud.google.com/blog/topics/developers-practitioners/deploying-multi-yaml-workflows-definitions-terraform) post, we showed how to use Terraform to define a workflow and import it into a Terraform configuration file. We further showed how to also import a subworkflow in the same workflow definition. This makes it easier to manage workflows and subworkflow definitions.

When you're defining a workflow, make sure you have a strategy to define and reuse subworkflows with Terraform or some other tool.

### GitOps your service orchestrations

[GitOps](https://opengitops.dev/) takes DevOps best practices used for application development (such as version control and CI/CD) and applies them to infrastructure automation. Service orchestrations, which have their own definition files and deployment cycles, can benefit from a GitOps approach as well.

In our [GitOps your service orchestrations](https://cloud.google.com/blog/topics/developers-practitioners/gitsops-service-orchestration) post, we showed how to use Cloud Build to manage an automated and staged rollout of workflow changes with tests along the way to minimize risk.

![/img/workflows-patterns/GitOps_Blog_1.max-800x800.max-800x800.png](/img/workflows-patterns/GitOps_Blog_1.max-800x800.max-800x800.png)

### Plan for multi-environment orchestrations

While GitOps helps to manage the deployment lifecycle of a workflow, sometimes you need to make changes to the workflow before deploying to different environments. That means you need to design workflows with multiple environments in mind. For example, instead of hardcoding the URLs called from the workflow, replace the URLs with staging and production URLs depending on where the workflow is being deployed.

In our [Multi-environment service orchestrations](https://cloud.google.com/blog/topics/developers-practitioners/multi-environment-service-orchestrations) post, we showed three different ways of replacing URLs in a workflow: passing URLs as runtime arguments, using Cloud Build to deploy multiple versions, and using Terraform to deploy multiple versions.

![/img/workflows-patterns/GOB2_-_2.max-700x700.max-700x700.png](/img/workflows-patterns/GOB2_-_2.max-700x700.max-700x700.png)

### Manage external state with Firestore

You define workflows YAML/JSON as the recipe and then execute it with optional runtime arguments as an individual isolated instance of that recipe. Sometimes, you need to store some state (typically a key/value pair) in a step from one workflow execution and later read that state in another step from another workflow execution. There's no intrinsic key/value store in Workflows. However, you can use Firestore to store and read key/value pairs from Workflows.

In our [Workflows state management with Firestore](https://medium.com/google-cloud/worklows-state-management-with-firestore-99237f08c5c5) post and its associated [sample](https://github.com/GoogleCloudPlatform/workflows-demos/tree/master/state-management-firestore), we showed a couple of subworkflows to put and get key/value pairs from Workflows with Firestore. This pattern is very useful when you need to manage some state in your workflow. 

### Workflows for reliable work and Firestore for reactive UI

You can count on Workflows to perform some long-running work reliably and as an admin, check the status of the workflow and the current running step using the Google Cloud console or the Workflows API. However, how do you keep end users up to date about the status of the workflow? To have this kind of reactive UI, you can have your workflow write its status to a Firestore document and have Firestore notify connected end users in real time.

At Google I/O, we demonstrated this pattern with two examples. In the [expense report application](https://github.com/GoogleCloudPlatform/smart-expenses), the UI updates the status of the approval process both for the employee and the manager. In the [translation application using callbacks](https://github.com/GoogleCloudPlatform/workflows-demos/tree/master/callback-translation), Firestore is used to show the status of an ongoing translation.

{{< youtube "l3aMs00ziYA" >}}

* * * * *

This wraps up our three-part series. For questions or feedback, or if you want to share your own best practices and patterns, feel free to reach out to us on Twitter @[meteatamel](https://twitter.com/meteatamel) and @[glaforge](https://twitter.com/glaforge).
# Turning a Website Into a Desktop Application


Probably like most of you, my dear readers, I have too many browser windows open,
with tons of tabs for each window. But there are always apps I come back to very often,
like my email (professional & personal), my calendar, my chat app, or even social media
sites like Mastodon or Twitter. You can switch from window to window with `CTRL/CMD-Tab`,
but you also have to move between tabs potentially. But for the most common webapps or
websites I’m using, I wanted to have a dedicated desktop application.


Initially, I was on the lookout for a Mac specific approach, as I’ve been a macOS users
for many years. So I found some Mac-specific apps that can handle that. This website mentions
[5 approaches for macOS](https://www.makeuseof.com/tag/website-desktop-mac-app/), including
free, freemium, non-free apps, like Fluid, Applicationize (creating a Chrome extension),
Web2Desk, or Unite. However, some of them create big hundred-mega wrappers. Another approach
on Macs was using Automator, to create a pop-up window, but that’s just a pop-up, not a real app.
There are also some promising open source projects like [Tauri](https://tauri.app/)
and [Nativefier](https://github.com/nativefier/nativefier) which seem promising.

Fortunately, there’s a cool feature from Chrome, that should work across all OSses,
and not just macOS. So if you’re on Linux or Windows, please read on.
The websites you’ll turn into applications don’t even need to be PWAs (Progressive Web Apps).

Here’s how to proceed:

First, navigate to your website you want to transform into an application with your Chrome browser.

Click on the triple dots in the top right corner, then `More Tools`, and finally `Create Shorctut`:

![](/img/chrome-to-app/web2app-01-create-shortcut.png)

It will then let you customise the name of the application.
It’ll reuse the favicon of the website as icon for the application.
But be sure to check `Open as window` to create a standalone application:

![](/img/chrome-to-app/web2app-02-open-as-window.png)

Then you’ll be able to open the website as a standalone application:

![](/img/chrome-to-app/web2app-03-standalone-app.png)

I was curious if a similar feature existed with other browsers like Firefox.
For the little fox, the only thing I could find was the ability to open Firefox in kiosk mode,
in full-screen. But I wanted a window I could dimension however I wanted, not necessarily full-screen.
I hope that Firefox will add that capability at some point.
But for now, I’m happy to have this solution with Chrome!


# Workflows patterns and best practices — Part 2


This is part 2 of a three-part series of posts, in which we summarize Workflows and service orchestration patterns. You can apply these patterns to better take advantage of Workflows and service orchestration on Google Cloud.

In the [first post]({{< ref "posts/2022/11/22/workflows-patterns-and-best-practices-part-1" >}}), we introduced some general tips and tricks, as well as patterns for event-driven orchestrations, parallel steps, and connectors. This second post covers more advanced patterns.  

Let's dive in!

## Design for resiliency with retries and the saga pattern

It's easy to put together a workflow that chains a series of services,  especially if you assume that those services will never fail. This is a common distributed systems fallacy, however, because of course a service will fail at some point. The workflow step calling that service will fail, and then the whole workflow will fail. This is not what you want to see in a resilient architecture. Thankfully, Workflows has building blocks to handle both transient and permanent service failures. 

In our post on [Implementing the saga pattern in Workflows](https://cloud.google.com/blog/topics/developers-practitioners/implementing-saga-pattern-workflows) (and its associated e-commerce [sample](https://github.com/GoogleCloudPlatform/workflows-demos/tree/master/retries-and-saga)), we talked about how you can apply the saga pattern and take compensation steps to undo one or more previous steps with the `try/except` block for permanent service failures. 

![https://storage.googleapis.com/gweb-cloudblog-publish/images/image3_2_1Fl6i9t.max-1400x1400.png](https://storage.googleapis.com/gweb-cloudblog-publish/images/image3_2_1Fl6i9t.max-1400x1400.png)

_Saga pattern implementation_

We also showed how to handle transient service failures by adding the default HTTP retry policy with the `try/retry` block of Workflows. If you have non-idempotent steps, you need to adjust the retry policy to `default_retry_non_idempotent`. In most cases, you need a custom retry policy with a longer backoff, because the default one waits at most ~8 seconds.  When eventual consistency over a longer time period is more important than fast failure, consider a longer retry policy over several minutes or even hours with a large multiplier is much more likely to succeed during temporary outages. 

Don't take network calls for granted. Make sure you design your orchestration with resiliency in mind using retries and the saga pattern.

## Wait for HTTP and event callbacks instead of polling

Sometimes, your orchestration might need to wait for a long-running job or an asynchronous event in another system before it can continue with the rest of the steps. The workflow can ask for that input by polling an endpoint or a queue, but this requires complicated polling logic, wasted polling cycles and most likely higher latency. A better approach is to use Workflows [callbacks](https://cloud.google.com/workflows/docs/creating-callback-endpoints) to wait for HTTP calls or events.  

In our [Introducing Workflows callbacks](https://cloud.google.com/blog/topics/developers-practitioners/introducing-workflows-callbacks) post, we showed a workflow that waits for human input for automated machine learning translations. Similarly, the [Smarter applications with Document AI, Workflows and Cloud Functions](https://cloud.google.com/blog/topics/developers-practitioners/smarter-applications-document-ai-workflows-and-cloud-functions) post shows a document processing workflow that waits for human approval of expense reports with a callback. 

![/img/workflows-patterns/architecture-diagram_6rwVYEP.max-1500x1500.png](/img/workflows-patterns/architecture-diagram_6rwVYEP.max-1500x1500.png)

_Smarter applications with Document AI, Workflows and Cloud Functions_

While both of these posts are focused on waiting for *HTTP callbacks*, in [Creating Workflows that pause and wait for events](https://medium.com/google-cloud/creating-workflows-that-pause-and-wait-for-events-4da201741f2a) post, we showed how a workflow can also wait for Pub/Sub and Cloud Storage events. You can even use Google Sheets as a quick and simple frontend for human approvals as we showed in the [Workflows that pause and wait for human approvals from Google Sheets](https://medium.com/google-cloud/workflows-that-pause-and-wait-for-human-approvals-from-google-sheets-53673ced2a81) post. 

When designing a workflow, consider waiting for HTTP calls and events, rather than polling.  

## Orchestrate long-running batch jobs

If you need to execute long-running jobs, Google Cloud has services such as [Batch](https://cloud.google.com/batch) and [Cloud Run jobs](https://cloud.google.com/run/docs/create-jobs) that can help. While these services are great for completing  long-running jobs on Compute Engine instances and containers, you still need to create and manage the Batch and Cloud Run job service. One pattern that works really well is to use Workflows to manage these services running batch jobs. 

In the [Taking screenshots of web pages with Cloud Run jobs, Workflows, and Eventarc](https://cloud.google.com/blog/topics/developers-practitioners/taking-screenshots-web-pages-cloud-run-jobs-workflows-and-eventarc) post, we showed how Cloud Run jobs take screenshots of web pages and Workflows creates and manages parallel Cloud Run jobs tasks. Similarly, in the [Batch - prime number generator](https://github.com/GoogleCloudPlatform/batch-samples/tree/main/primegen) sample, we showed how to run prime number generator containers in parallel on Compute Engine instances using Google Batch. The lifecycle of the Batch job is managed by Workflows.

![/img/workflows-patterns/image1_2.max-2200x2200.png](/img/workflows-patterns/image1_2.max-2200x2200.png)

_Take screenshots of webpages with Cloud Run jobs, Workflows and Eventarc_

Use the right services for long-running batch jobs and use Workflows to manage their life cycles.

## Treat serverful workloads as serverless with Workflows

Sometimes, you really need a server due to some serverless limitation. For example, you might need to run on GPUs or execute a long-running process that lasts weeks or months. In those cases, Compute Engine can provide you with customized virtual machines (VM), but you're stuck with managing those VMs yourself. 

In this kind of IT automation scenario, you can use Workflows to create VMs with the customizations you need, run the workloads for however long you need (Workflows executions can last up to one year), and return the result in the end.  This pattern enables you to use servers but manage them as if they were serverless services using Workflows.

In our [Long-running containers with Workflows and Compute Engine](https://cloud.google.com/blog/topics/developers-practitioners/long-running-containers-workflows-and-compute-engine) post, we showed how to use Workflows to spin up a VM, start a prime number generator on the VM, run it for however long you want, and return the result.

Next time you need to spin up a VM, treat it like a serverless service with Workflows. 

## Run command-line tools with Workflows and Cloud Build

We often use command-line tools such as `gcloud` to manage Google Cloud resources or `kubectl` to manage Kubernetes clusters. Wouldn't it be nice if we could call these tools from Workflows and orchestrate management of resources?

In the [Executing commands (gcloud, kubectl) from Workflows](https://medium.com/google-cloud/executing-commands-gcloud-kubectl-from-workflows-ad6b85eaf39c) post, we showed how to use Cloud Build to run these tools and how to create and call that Cloud Build step from Workflows using the Cloud Build connector. 

Keep in mind that this pattern is not limited to `gcloud` and `kubectl`. Any tool you can run in a container can potentially be a target for Workflows with the help of Cloud Build.

Integrate command-line tools into your workflows when needed by calling a Cloud Build step from Workflows.

* * * * *

This second part series covered a lot of ground, but there's still more to cover! We'll wrap up the series in our [third and final post]({{< ref "posts/2022/12/06/workflows-patterns-and-best-practices-part-3" >}}), which describes how to manage the lifecycle of workflow definitions and the benefits of using Firestore. Stay tuned! For questions or feedback, feel free to reach out to us on Twitter @[meteatamel](https://twitter.com/meteatamel) and @[glaforge](https://twitter.com/glaforge).

[](https://cloud.google.com/blog/topics/developers-practitioners/workflows-patterns-and-best-practices-part-1)
# Workflows patterns and best practices — Part 1


For the last couple of years, we've been using [Workflows](https://cloud.google.com/workflows), Google Cloud's service orchestrator, to bring order to our serverless microservices architectures. As we used and gained more experience with Workflows and service orchestration, we shared what he had learned in conference talks, blog posts, samples, and tutorials. Along the way, some common patterns and best practices emerged. 

To help you take better advantage of Workflows and service orchestration on Google Cloud, we've summarized these proven patterns and best practices in a three-part series of blog posts.

Let's get started with Part 1!

## Make a conscious choice on the communication style upfront

Choosing a communication style is more of a task than a pattern, but it is an important one to complete before even considering service orchestration. 

When you have multiple services, you need to decide how these services will communicate. The options are:

-   **Direct** service-to-service communication
-   Indirect **event-driven** communication (also known as choreography)
-   A central **orchestrator** (e.g. Workflows) directing the communication

There's no right or wrong, only pros and cons. Direct service-to-service communication is easy to implement but creates tight coupling between services. Events enable loosely coupled services at the expense of harder monitoring and debugging when something goes wrong. An orchestrator, while less flexible, brings order to communication without the tight coupling of direct service-to-service communication and the chaos of events in choreographed architectures.

In our [Orchestrating the Pic-a-Daily serverless app with Workflows](https://cloud.google.com/blog/topics/developers-practitioners/orchestrating-pic-daily-serverless-app-workflows) post, we explained how we transformed an event-driven application into an orchestrated application and the benefits of doing so. In [Choosing the right orchestrator in Google Cloud](https://cloud.google.com/blog/topics/developers-practitioners/choosing-right-orchestrator-google-cloud), we talked about which service is best suited for different orchestration needs (scheduled, service, and data). 

As you design your architecture, make a conscious choice on the communication style with pros and cons in mind, and if you choose to use orchestration, be sure to use the right orchestrator for the task. 

## Keep these tips and tricks for Workflows in mind

Once you decide to use Workflows for service orchestration, you'll realize that Workflows has its own strengths and idiosyncrasies. Here are some general tips and tricks that we found useful as we used Workflows:

-   **Avoid hard-coding URLs** for more portable workflows across environments.
-   **Use substeps** to collect a common series of steps in one logical unit.
-   **Wrap string expressions** to avoid parsing problems.
-   **Replace logic-less services with declarative API calls** to avoid boilerplate code.
-   **Store what you need, free what you can** to keep memory consumption under control.
-   **Use subworkflows and call external workflows** to increase reuse.

Check our [post on Workflows tips and tricks](https://glaforge.appspot.com/article/workflows-tips-n-tricks) for a more detailed explanation of these points. 

### Consider event-driven orchestration

The choice on the communication style is not all or nothing. You can and should combine different styles when it makes sense. For example, there is a common pattern where services that are closely related are managed by an orchestrator like Workflows but that orchestration is triggered by an event from a service like Eventarc. Similarly, we see architectures where the end of an orchestration is a Pub/Sub message to some other orchestration or service. 

In our [Introducing Eventarc triggers for Workflows](https://cloud.google.com/blog/topics/developers-practitioners/introducing-eventarc-triggers-workflows) post, we showed how easy it is to route events to Workflows using Eventarc. In the [Build an event-driven orchestration with Eventarc and Workflows](https://youtu.be/2SI12QE-2DU) video and its associated [codelab](https://codelabs.developers.google.com/codelabs/cloud-event-driven-orchestration?hl=en#8) and [sample](https://github.com/GoogleCloudPlatform/eventarc-samples/tree/main/processing-pipelines/image-v3), we showed how to design an image processing pipeline where the services are managed by Workflows but the orchestration is triggered in a loosely coupled way by a Cloud Storage event via Eventarc:

{{< youtube "2SI12QE-2DU" >}}

Mix communication styles to get the best of both worlds: use orchestration when you need tight coupling between services but loose coupling with other orchestrations via events.

## Use connectors when you can

Workflows has a rich set of [connectors](https://cloud.google.com/workflows/docs/connectors) to call other Google Cloud services. They handle the formatting of requests for you, providing methods and arguments so that you don't need to get deep into the gory details of a Google Cloud API. More importantly, connectors enable a workflow to transparently wait for long-running Cloud API calls. This saves you from the tedious work of iterating and waiting for calls to complete; connectors take care of this for you! 

In our [Introducing new connectors for Workflows](https://cloud.google.com/workflows/docs/connectors) post, we showed you how Compute Engine connector simplified creating and stopping a virtual machine. 

Whenever you want to call a Google Cloud API from Workflows, check to see if there's a connector for it. You'll be glad that you did and you can always request a new connector [here](https://docs.google.com/forms/d/e/1FAIpQLScdDRwFHcFuy28hvjGq0XCBMyiVuhHGq2c-7Gy_no1ZuqKAOg/viewform?resourcekey=0-0BRW58uzC8wnVntuOiM7AQ), if there's no connector.

## Parallelize when you can

When we talk about Workflows, we often talk about steps executed one after another sequentially. While Workflows is fast enough to run steps sequentially with no noticeable delay, not all steps need to run sequentially. Independent steps can actually run in parallel, and in some cases this can provide a significant speed up for workflow executions.

In the [Introducing Parallel Steps for Workflows](https://cloud.google.com/blog/topics/developers-practitioners/introducing-parallel-steps-workflows-speed-up-workflow-executions-by-running-steps-concurrently) post and its associated video, we showed how running BigQuery jobs from Workflows in parallel can speed up the workflow execution by five times. The more independent steps you have, the more you can run those steps in parallel and the faster your workflow execution will be, especially with long-running tasks like BigQuery jobs.

{{< youtube "C1Reg1u1MXY" >}}

Try to keep your steps independent and make sure to take advantage of parallel steps when you can.

* * * * *

This initial list of patterns and tips will help you get started taking better advantage of Workflows. We cover more advanced patterns in [part 2]({{< ref "posts/2022/11/28/workflows-patterns-and-best-practices-part-2" >}}) of this series. For questions or feedback, feel free to reach out to us on Twitter @[meteatamel](https://twitter.com/meteatamel) and @[glaforge](https://twitter.com/glaforge).

[](https://cloud.google.com/blog/topics/developers-practitioners/orchestrating-pic-daily-serverless-app-workflows)
# APIs, we have a Problem JSON


When designing a web API, not only do you have to think about the happy path when everything is alright, 
but you also have to handle all the error cases: Is the payload received correct? Is there a typo in a field? 
Do you need more context about the problem that occured? 

There’s only a limited set of status codes that can convey the kind of error you’re getting, 
but sometimes you need to explain more clearly what the error is about.

In the past, the APIs I was designing used to follow a common JSON structure for my error messages: a simple JSON object, 
usually with a `message` field, and sometimes with extra info like a custom error `code`, or a `details` field that contained a longer explanation in plain English. 
However, it was my own convention, and it’s not necessarily one that is used by others, or understood by tools that interact with my API. 

So that’s why today, for reporting problems with my web APIs, I tend to use **Problem JSON**. This is actually an RFC ([RFC-7807](https://datatracker.ietf.org/doc/html/rfc7807)) 
whose title is “Problem Details for HTTP APIs”. Exactly what I needed, a specification for my error messages!

First of all, it’s a JSON content-type. Your API should specify the content-type with:

```http
Content-Type: application/problem+json
```

Content-types that end with `+json` are basically treated as `application/json`.

Now, an example payload from the specification looks like:

```http
HTTP/1.1 403 Forbidden
Content-Type: application/problem+json
Content-Language: en

{
   "type": "https://example.com/probs/out-of-credit",
   "title": "You do not have enough credit.",
   "detail": "Your current balance is 30, but that costs 50.",
   "instance": "/account/12345/msgs/abc",
   "balance": 30,
   "accounts": ["/account/12345", "/account/67890"]
}
```

There are some standard fields like:
* **type**: a URI reference that uniquely identifies the problem type
* **title**: a short readable error statement
* **status**: the original HTTP status code from the origin server
* **detail**: a longer text explanation of the issue
* **instance**: a URI that points to the resource that has issues

Then, in the example above, you also have custom fields: `balance` and `accounts`, which are specific to your application, 
and not part of the specification. Which means you can expand the Problem JSON payload to include details that are specific to your application.

Note: Although I’m only covering JSON APIs, the RFC also suggests an `application/problem+xml` alternative for the XML APIs.

## Icing on the cake: built-in support in Micronaut

My framework of choice these days for all my apps is [Micronaut](https://micronaut.io/), as it’s super fast and memory efficient. 
And it’s only recently that I realized there was actually a [Micronaut extension for Problem JSON](https://micronaut-projects.github.io/micronaut-problem-json/2.5.2/guide/index.html)!
So instead of returning a custom JSON payload manually, I can use the built-in integration.

Here’s an example from the Problem JSON Micronaut extension:

```java
@Controller("/product")
public class ProductController {
  @Get
  @Status(HttpStatus.OK)
  public void index() {
    throw Problem.builder()
            .withType(URI.create("https://example.org/out-of-stock"))
            .withTitle("Out of Stock")
            .withStatus(new HttpStatusType(HttpStatus.BAD_REQUEST))
            .withDetail("Item B00027Y5QG is no longer available")
            .with("product", "B00027Y5QG")
            .build();
  }
}
```

Which will return a JSON error as follows:

```json
{
    "status": 400,
    "title": "Out of Stock",
    "detail": "Item B00027Y5QG is no longer available",
    "type": "https://example.org/out-of-stock",
    "parameters": {"product": "B00027Y5QG"}
}
```

Now, I’m happy that I can use some official standard for giving more details about the errors returned by my APIs!



# Workflows Tips and Tricks


Here are some general tips and tricks that we found useful as we used Google Cloud [Workflows](https://cloud.google.com/workflows):

## Avoid hard-coding URLs

Since Workflows is all about calling APIs and service URLs, it's important to have some clean way to handle those URLs. 
You can hard-code them in your workflow definition, but the problem is that your workflow can become harder to maintain. 
In particular, what happens when you work with multiple environments? 
You have to duplicate your YAML definitions and use different URLs for the prod vs staging vs dev environments. 
It is error-prone and quickly becomes painful to make modifications to essentially the same workflow in multiple files. 
To avoid hard-coding those URLs, there are a few approaches.

The first one is to externalize those URLs, and 
[pass them as workflow execution arguments](https://github.com/GoogleCloudPlatform/workflows-demos/tree/master/multi-env-deployment#option-1-use-urls-as-runtime-arguments). 
This is great for workflow executions that are launched via the CLI, via the various client libraries, or the REST & gRPC APIs. 
However, there's a limitation to this first approach, in the case of event-triggered workflows, where the invoker is Eventarc. 
In that case, that's Eventarc that decides which arguments to pass (ie. the event payload). 
There's no way to pass extra arguments in that case.

A safer approach is then to use some placeholder replacement techniques. 
Just use a tool that replaces some specific string tokens in your definition file, before deploying that updated definition. 
We explored that approach using some 
[Cloud Build steps that do some string replacement](https://github.com/GoogleCloudPlatform/workflows-demos/tree/master/multi-env-deployment#option-2-use-cloud-build-to-deploy-multiple-versions). 
You still have one single workflow definition file, but you deploy variants for the different environments. 
If you're using Terraform for provisioning your infrastructure, we've got you covered, you can also employ a 
[similar technique with Terraform](https://github.com/GoogleCloudPlatform/workflows-demos/tree/master/multi-env-deployment#option-3-use-terraform-to-deploy-multiple-versions).

There are also other possible approaches, like taking advantage of Secret Manager and the dedicated 
[workflow connector](https://cloud.google.com/workflows/docs/reference/googleapis/secretmanager/Overview), 
to store those URLs, and retrieve them. Or you can also 
[read some JSON file in a cloud storage bucket](https://github.com/GoogleCloudPlatform/workflows-demos/tree/master/gcs-read-write-json#load-environment-specific-variables-from-a-json-file-in-gcs), 
within which you would store those environment specific details.

## Take advantage of sub-steps

Apart from branching or looping, defining your steps is a pretty sequential process. One step happens after another. 
Steps are their own atomic operation. 
However, often, some steps really go hand-in-hand, like making an API call, logging its outcome, retrieving and assigning parts of the payload into some variables. 
You can actually regroup common steps into substeps. This becomes handy when you are branching from a set of steps to another set of steps, without having to point at the right atomic step.

```yaml
main:
    params:  [input]
    steps:
    - callWikipedia:
        steps:
        - checkSearchTermInInput:
            switch:
                - condition:  ${"searchTerm"  in  input}
                  assign:
                    - searchTerm:  ${input.searchTerm}
                  next:  readWikipedia
        - getCurrentTime:
            call:  http.get
            args:
                url: ...
            result:  currentDateTime
        - setFromCallResult:
            assign:
                - searchTerm:  ${currentDateTime.body.dayOfTheWeek}
        - readWikipedia:
            call:  http.get
            args:
                url:  https://en.wikipedia.org/w/api.php
                query:
                    action:  opensearch
                    search:  ${searchTerm}
            result:  wikiResult
    - returnOutput:
            return:  ${wikiResult.body[1]}
```

## Wrap expressions

The dollar/curly brace `${}` expressions are not part of the YAML specification, so what you put inside sometimes doesn't play well with YAML's expectations. 
For example, putting a colon inside a string inside an expression can be problematic, as the YAML parser believes the colon is the end of the YAML key, and the start of the right-hand-side. 
So to be safe, you can actually wrap your expressions within quotes, like: `'${...}'`

Expressions can span several lines, as well as the strings within that expression. 
That's handy for SQL queries for BigQuery, like in our [example](https://github.com/GoogleCloudPlatform/workflows-demos/tree/master/bigquery-parallel):

```yaml
query:  ${
 "SELECT TITLE, SUM(views)
    FROM `bigquery-samples.wikipedia_pageviews."  +  table  +  "`
    WHERE LENGTH(TITLE) > 10
    GROUP BY TITLE
    ORDER BY SUM(VIEWS) DESC
    LIMIT 100"
}
```

## Replace logic-less services with declarative API calls

In our [serverless workshop](https://github.com/GoogleCloudPlatform/serverless-photosharing-workshop/), in lab 1, 
we had a [function service](https://github.com/GoogleCloudPlatform/serverless-photosharing-workshop/blob/master/functions/image-analysis/nodejs/index.js#L19) 
that was making a call to the Cloud Vision API, checking a boolean attribute, then writing the result in Firestore. 
But the Vision API can be called declaratively from Workflows. 
The boolean check can be done with a switch conditional expression, and even writing to Firestore can be done via a declarative API call. 
When rewriting our application in [lab 6](https://github.com/GoogleCloudPlatform/serverless-photosharing-workshop/blob/master/workflows/workflows.yaml#L33) 
to use the orchestrated approach, we moved those logic-less calls into declarative API calls.

There are times where Workflows lack some built-in function that you would need, so you have no choice but fork into a function to do the job. 
But when you have pretty logic-less code that just makes some API calls, you'd better just write this declaratively using Workflows syntax.

It doesn't mean that everything, or as much as possible, should be done declaratively in a Workflow either. 
Workflows is not a hammer, and it's definitely not a programming language. 
So when there's real logic, you definitely need to call some service that represents that business logic.

## Store what you need, free what you can

Workflows keeps on granting more memory to workflow executions, but there are times, with big API response payloads, where you'd be happy to have even more memory. 
That's when sane memory management can be a good thing to do. 
You can be selective in what you store into variables: don't store too much, but store just the right payload part you really need.
Once you know you won't need the content of one of your variables, you can also reassign that variable to null, that should also free that memory. 
Also, in the first place, if the APIs allow you to filter the result more aggressively, you should also do that. 
Last but not least, if you're calling a service that returns a gigantic payload that can't fit in Workflows memory, 
you could always delegate that call to your own function that would take care of making the call on your behalf, and returning to you just the parts you're really interested in.

Don't forget to check the documentation on [quotas and limits](https://cloud.google.com/workflows/quotas) to know more about what's possible.

## Take advantage of sub-workflows and the ability to call external workflows

In your workflows, sometimes there are some steps that you might need to repeat. 
That's when [subworkflows](https://cloud.google.com/workflows/docs/reference/syntax/subworkflows) become handy. 
Sub-workflows are like sub-routines, procedures or methods. 
They are a way to make a set of steps reusable in several places of your workflow, potentially parameterized with different arguments. 
The sole downside maybe is that subworkflows are just local to your workflow definition, so they can't be reused in other workflows. 
In that case, you could actually create a dedicated reusable workflow, because you can also 
[call workflows from other workflows](https://cloud.google.com/workflows/docs/reference/googleapis/workflowexecutions/Overview)! The workflows connector for workflows is there to help.

## Summary

We've covered a few tips and tricks, and we've reviewed some useful advice on how to make the best use of Workflows. 
There are certainly others we're forgetting about. 
So feel free to share them with [@meteatamel](https://twitter.com/meteatamel) and [@glaforge](https://twitter.com/glaforge) over Twitter.

And don't forget to double check what's in the Workflows [documentation](https://cloud.google.com/workflows/docs). 
In particular, have a look at the built-in functions of the [standard library](https://cloud.google.com/workflows/docs/reference/stdlib/overview), 
at the [list of connectors](https://cloud.google.com/workflows/docs/reference/googleapis) that you can use, 
and perhaps even print the [syntax cheat sheet](https://cloud.google.com/workflows/docs/reference/syntax/syntax-cheat-sheet)!

Lastly, check out all the [samples](https://cloud.google.com/workflows/docs/samples) in the documentation portal, 
and all the [workflow demos](https://github.com/GoogleCloudPlatform/workflows-demos) Mete and I have built and open sourced over time.
# Retrieve YouTube views count with youtubeDL, JQ, and a Docker container


I wanted to track the number of views, and also likes, of some YouTube videos I was featured in. 
For example, when I present a talk at a conference, often the video becomes available at a later time, and I'm not the owner of the channel or video. 
At first, I wanted to use the [YouTube Data API](https://developers.google.com/youtube/v3), 
but I had the impression that I could only see the stats of videos or channels I own, 
however I think I might be wrong, and should probably revisit this approach later on.

My first intuition was to just scrape the web page of the video, but it's a gobbledygook of JavaScript, 
and I couldn't really find an easy way to consistently get the numbers in that sea of compressed JavaScript. 
That's when I remembered about the [youtube-dl project](https://youtube-dl.org/). 
Some people think of this project as a way to download videos to watch offline, but it's also a useful tool that offers lots of metadata about the videos. 
You can actually even use the project without downloading videos at all, but just fetching the metadata.

For example, if I want to get the video metadata, without downloading, I can launch the following command, after having installed the tool locally:

```bash
youtube-dl -j -s https://www.youtube.com/watch?v=xJi6pldZnsw
```

The `-s` flag is equivalent to `--simulate` which doesn't download anything on disk.

And the `-j` flag is the short version of `--dump-json` which returns a big JSON file with lots of metadata, including the view count, 
but also things like links to transcripts in various languages, chapters, creator, duration, episode number, and so on and so forth.

Now, I'm only interested in view counts, likes, dislikes. 
So I'm using [jq](https://stedolan.github.io/jq/) to filter the big JSON payload, and create a resulting JSON document with just the fields I want.

```bash
jq '{"id":.id,"title":.title,"views":.view_count,"likes":(.like_count // 0), "dislikes":(.dislike_count // 0)}'
```

This long command is creating a JSON structure as follows:

```json
{
 "id": "xJi6pldZnsw",
 "title": "Reuse old smartphones to monitor 3D prints, with WebRTC, WebSockets and Serverless by G. Laforge",
 "views": 172,
 "likes": 6,
 "dislikes": 0
}
```

The `.id`, `.title`, `.view_count`, etc, are searching for that particular key in the big JSON documentation. 
The `// 0` notation is to avoid null values and return 0 if there's no key or if the value associated with the key is null. 
So I always get a number --- although I noticed that sometimes, the likes are not always properly accounted for, but I haven't figured out why.

So far so good... but if you pass a URL of a video with a playlist, or if you pass a playlist URL, it will fetch all the metadata for all the videos. 
This is actually useful: you can even create your own playlists for the videos you want to track. 
There's one odd thing happening though when using youtube-dl with such URLs: it will output a JSON document per line for each video. 
It's not returning an array of those documents. So I found a nice trick with jq to always put the results within an array, whether you pass a URL for a single video, or a video with a playlist:

```bash
​​jq -n '[inputs]'
```

So I'm piping the `youtube-dl` command, the first and second `jq` commands.

Rather than installing those tools locally, I decided to containerize my magic commands.

Let me first show you the whole `Dockerfile`:

```Dockerfile
FROM ubuntu:latest
RUN apt-get update && apt-get -y install wget
    && wget https://yt-dl.org/latest/youtube-dl -O /usr/local/bin/youtube-dl
    && chmod a+rx /usr/local/bin/youtube-dl
    && apt-get -y install python3-pip jq 
    && pip3 install --upgrade youtube-dl
COPY ./launch-yt-dl.sh
RUN chmod +x /launch-yt-dl.sh
ENTRYPOINT ["./launch-yt-dl.sh"]
```

And also this bash script mentioned in the Dockerfile:

```bash
#!/bin/bash\
youtube-dl -j -s -- "$@" | jq '{"id":.id,"title":.title,"views":.view_count,"likes":(.like_count // 0), "dislikes":(.dislike_count // 0)}' | jq -n '[inputs]'
```

I went with the latest ubuntu image. I ran some apt-get commands to install wget to download the latest youtube-dl release, Python 3's pip to upgrade youtube-dl. 
There's no recent apt module for youtube-dl, hence why we have those steps together.

What's more interesting is why I don't have the youtube-dl and jq commands in the Dockerfile directly, but instead in a dedicated bash script. 
Initially I had an `ENTRYPOINT` that pointed at youtube-dl, so that arguments passed to the docker run command would be passed as arguments of that entrypoint. 
However, after those commands, I still have to pipe with my jq commands. And I couldn't find how to do so with `ENTRYPOINT` and `CMD`. 
When raising the problem on [twitter](https://twitter.com/glaforge/status/1584800385256280064), 
my friends [Guillaume Lours](https://twitter.com/glours/status/1584810960136683521) and [Christophe Furmaniak](https://twitter.com/cfurmaniak/status/1584845647647506432) pointed me in the right direction with this idea of passing through a script.

So I use the `$@` bash shortcut, which expands as arguments `$1 $2 $3`, etc. in case there are several videos passed as arguments. 
I have the jq pipes after that shortcut. 
But for my `ENTRYPOINT`, it's fine, the args are passed directly to it, and it's that intermediary script that weaves the args in my longer command.

Next, I just need to build my Docker container:

```bash
docker build . -t yt-video-stat
```

And then run it:

```bash
docker run --rm -it yt-video-stat "https://www.youtube.com/watch?v=xJi6pldZnsw"
```

And voila, I have the stats for the YouTube videos I'm interested in!
# Build and deploy Java 17 apps on Cloud Run with Cloud Native Buildpacks on Temurin


In this article, let's revisit the topic of deploying Java apps on [Cloud Run](https://cloud.run/). 
In particular, I'll deploy a [Micronaut](https://micronaut.io/) app, written with [Java 17](https://jdk.java.net/17/), and built with [Gradle](https://gradle.org/).

## With a custom Dockerfile

On Cloud Run, you deploy containerised applications, so you have to decide the way you want to build a container for your application. 
In a [previous article]({{< ref "/posts/2020/03/24/start-the-fun-with-java-14-and-micronaut-inside-serverless-containers-on-cloud-run.md" >}}), 
I showed an example of using your own Dockerfile, which would look as follows with an OpenJDK 17, and enabling preview features of the language:

```Dockerfile
FROM openjdk:17
WORKDIR /app
COPY ./ ./
RUN ./gradlew shadowJar
EXPOSE  8080
CMD ["java", "--enable-preview", "-jar", "build/libs/app-0.1-all.jar"]
```

To further improve on that Dockerfile, you could use a multistage Docker build to first build the app in one step with Gradle, and then run it in a second step. 
Also you might want to parameterize the command as the JAR file name is hard-coded.

To build the image, you can build it locally with Docker, and then push it to Container Registry, and then deploy it:

```bash
# gcloud auth configure-docker
# gcloud components install docker-credential-gcr

docker build . --tag gcr.io/YOUR_PROJECT_ID/IMAGE_NAME
docker push gcr.io/YOUR_PROJECT_ID/IMAGE_NAME

gcloud run deploy weekend-service \
    --image gcr.io/YOUR_PROJECT_ID/IMAGE_NAME
```

Instead of building locally with Docker, you could also let [Cloud Build](https://cloud.google.com/build) do it for you:

```bash
gcloud builds submit . --tag gcr.io/YOUR_PROJECT_ID/SERVICE_NAME
```

## With JIB

Instead of messing around with Dockerfiles, you can also let [JIB](https://github.com/GoogleContainerTools/jib) create the container for you, 
like I wrote in [another article]({{< ref "/posts/2020/08/04/running-micronaut-serverlessly-on-google-cloud-platform.md" >}}). 
You configure Gradle to use the JIB plugin:

```groovy
plugins {
    ...
id "com.google.cloud.tools.jib" version "2.8.0"
}
...
tasks {
    jib {
        from {
            image = "gcr.io/distroless/java17-debian11"
        }
        to {
            image = "gcr.io/YOUR_PROJECT_ID/SERVICE_NAME"
        }
    }
}
```

You specify the version of the plugin, but you also indicate that you want to use Java 17 by choosing a base image with that same version. 
Be sure to change the placeholders for your project ID and service name. 
Feel free to lookup the [documentation](https://github.com/GoogleContainerTools/jib/tree/master/jib-gradle-plugin) about the JIB Gradle plugin. 
You can then let Gradle build the container with ./gradlew jib, or with ./gradlew jibDockerBuild if you want to use your local Docker daemon.

## With Cloud Native Buildpacks

Now that we covered the other approaches, let's zoom in on using [Cloud Native Buildpacks](https://buildpacks.io/) instead, in particular, 
the [Google Cloud Native Buildpacks](https://github.com/GoogleCloudPlatform/buildpacks). 
With buildpacks, you don't have to bother with Dockerfiles or with building the container before deploying the service. 
You let Cloud Run use buildpacks to build, containerize, and deploy your application from sources.

Out of the box, the buildpack actually targets Java 8 or Java 11. 
But I'm interested in running the latest LTS version of Java, with Java 17, to take advantage of some preview features like records, sealed classes, switch expressions, etc.

In my Gradle build, I specify that I'm using Java 17, but also enable preview features:

```groovy
java {
    toolchain {
        languageVersion.set(JavaLanguageVersion.of(17))
    }
}
```

Like in Cédric Champeaus's [blog post](https://melix.github.io/blog/2020/06/java-feature-previews-gradle.html), to enable preview features, 
you should also tell Gradle you want to enable them for compilation, test, and execution tasks:

```groovy
tasks.withType(JavaCompile).configureEach {
 options.compilerArgs.add("--enable-preview")
}

tasks.withType(Test).configureEach {
    useJUnitPlatform()
    jvmArgs("--enable-preview")
}

tasks.withType(JavaExec).configureEach {
    jvmArgs("--enable-preview")
}
```


So far so good, but as I said, the default native buildpack isn't using Java 17, and I want to specify that I use preview features. 
So when I tried to deploy my Cloud Run app from sources with the buildpack, simply by running the gcloud deploy command, I would get an error.

```bash
gcloud beta run deploy SERVICE_NAME
```

To circumvent this problem, I had to add a configuration file, to instruct the buildpack to use Java 17. I created a project.toml file at the root of my project:

```toml
[[build.env]]
name = "GOOGLE_RUNTIME_VERSION"
value = "17"
[[build.env]]
name = "GOOGLE_ENTRYPOINT"
value = "java --enable-preview -jar /workspace/build/libs/app-0.1-all.jar"
```

I specify that the runtime version must use Java 17. But I also add the --enable-preview flag to enable the preview features at runtime.

## Adoptium Temuring OpenJDK 17

The icing on the cake is that the build is using [Adoptium](https://adoptium.net/)'s [Temurin](https://adoptium.net/temurin/releases/) build of OpenJDK 17, 
as we recently [announced](https://blog.adoptium.net/2022/10/adoptium-welcomes-google/)! 
If you look at the build logs in Cloud Build, you should see some output mentioning it, like:

```json
{
 "link": "https://github.com/adoptium/temurin17-binaries/releases/download/jdk-17.0.4.1%2B1/OpenJDK17U-jdk-sources_17.0.4.1_1.tar.gz",
 "name": "OpenJDK17U-jdk-sources_17.0.4.1_1.tar.gz",
 "size": 105784017
}
```

Way to go! Java 17 Micronaut app, deployed on Temurin on Cloud Run thanks to cloud native buildpacks! I win at buzzword bingo 🙂
# Choreography vs orchestration in microservices and best practices


We went from a single monolith to a set of microservices that are small, lightweight, and easy to implement. Microservices enable reusability, make it easier to change and scale apps on demand but they also introduce new problems. How do microservices interact with each other toward a common goal? How do you figure out what went wrong when a business process composed of several microservices fails? Should there be a central orchestrator controlling all interactions between services or should each service work independently, in a loosely coupled way, and only interact through shared events? In this talk, we’ll explore the Choreography vs Orchestration question and see demos of some of the tools that can help. And we'll explore some best practices and patterns to apply when adopting an orchestration approach.

{{< speakerdeck 328a826a55f447f7907db099c0aa03ab >}}
# Reuse old smartphones to monitor 3D prints with WebRTC WebSockets and serverless


Reuse old smartphones to monitor 3D prints, with WebRTC, WebSockets and Serverless
Monitoring my 3D prints in my basement means climbing lots of stairs back and forth! So here’s my story about how I reused an old smartphone to check the status of my prints. I built a small web app that uses WebRTC to exchange video streams between my broadcasting smartphone and viewers, with WebSockets for signaling, and a serverless platform for easily deploying and hosting my containerized app.

{{< speakerdeck 3e5dfb35f64c48d9ba4a211122711b7c >}}
# A Cloud Run service in Go calling a Workflows callback endpoint


It's all [Richard Seroter](https://seroter.com/)'s fault, I ended up dabbling with [Golang](https://go.dev/)! 
We were chatting about a use case using Google Cloud [Workflows](https://cloud.google.com/workflows) and a [Cloud Run](https://cloud.run/) service implemented in Go. 
So it was the occasion to play a bit with Go. Well, I still don't like error handling... But let's rewind the story a bit!

Workflows is a fully-managed service/API orchestrator on Google Cloud. You can create some advanced business workflows using YAML syntax. 
I've built numerous little projects using it, and [blogged](https://cloud.google.com/blog/topics/developers-practitioners/introducing-workflows-callbacks) about it. 
I particularly like its ability to pause a workflow execution, creating a [callback endpoint](https://cloud.google.com/workflows/docs/creating-callback-endpoints) 
that you can call from an external system to resume the execution of the workflow. 
With callbacks, you're able to implement human validation steps, for example in an expense report application 
where a manager validates or rejects an expense from someone in their team (this is what I implemented in this 
[article](https://cloud.google.com/blog/topics/developers-practitioners/smarter-applications-document-ai-workflows-and-cloud-functions)).

For my use case with Richard, we had a workflow that was creating such a callback endpoint. 
This endpoint is called from a Cloud Run service implemented in Go. 
Let's see how to implement the workflow:

```yaml
main:
    params: [input]
    steps:

    - create_callback:
        call: events.create_callback_endpoint
        args:
            http_callback_method: "POST"
        result: callback_details

    - log_callback_creation:
        call: sys.log
        args:
            text: ${"Callback created, awaiting calls on " + callback_details.url}

    - await_callback:
        call: events.await_callback
        args:
            callback: ${callback_details}
            timeout: 86400
        result: callback_request

    - log_callback_received:
        call: sys.log
        args:
            json: ${callback_request.http_request}

    - return_callback_request:
        return: ${callback_request.http_request}
```

The above workflow definition creates a callback endpoint. The URL of the callback endpoint is returned by that first step. 
Then the workflow is waiting for the callback endpoint to be called externally. 
The execution then resumes and logs some info about the incoming call and returns.

I deployed that workflow with a service account that has the Workflows Editor role, the Log Writer role (to log information), 
and the Service Account Token Creator role (to create OAuth2 tokens), 
as [explained](https://cloud.google.com/workflows/docs/creating-callback-endpoints#oauth-token) in the documentation.

Now let's look at the Go service. I did a go mod init to create a new project. 
I created a main.go source file with the following content:



```go
package main

import (
	metadata "cloud.google.com/go/compute/metadata"
	"encoding/json"
	"fmt"
	"log"
	"net/http"
	"os"
	"strings"
)
```

The metadata module is used to fetch an OAuth2 token from the [Cloud Run metadata server](https://cloud.google.com/run/docs/container-contract#metadata-server).

```go
// OAuth2 JSON struct
type OAuth2TokenInfo struct {
	// defining struct variables
	Token      string `json:"access_token"`
	TokenType  string `json:"token_type"`
	Expiration uint32 `json:"expires_in"`
}
```

The metadata information in `instance/service-accounts/default/token` returns a JSON document that we map with the above struct. 
We're interested in the access_token field, that we use further down to make the authenticated call to the Workflows callback endpoint.

```go
func main() {
	log.Print("Starting server...")
	http.HandleFunc("/", handler)

	// Determine port for HTTP service.	port := os.Getenv("PORT")	
    if port == "" {		
        port = "8080"		
        log.Printf("Defaulting to port %s", port)	
    }

	// Start HTTP server.	
    log.Printf("Listening on port %s", port)	
    if err := http.ListenAndServe(":"+port, nil); err != nil {		
        log.Fatal(err)	
    }
}
```

The `main()` function starts our Go service. Let's now see the `handler()` function in more detail:

```go
func handler(w http.ResponseWriter, r *http.Request) {
	callbackUrl := r.URL.Query().Get("callback_url")
	log.Printf("Callback URL: %s", callbackUrl)
```

We retrieve the `?callback_url` query parameter that will contain our callback endpoint URL.

```go
	// Fetch an OAuth2 access token from the metadata server
	oauthToken, errAuth := metadata.Get("instance/service-accounts/default/token")
	if errAuth != nil {
		log.Fatal(errAuth)
	}
```

Above, we make a call to the metadata server thanks to the metadata Go module. 
And then we unmarshall the returned JSON document in our previously defined struct, with the following code:

```go
	data := OAuth2TokenInfo{}
	errJson := json.Unmarshal([]byte(oauthToken), &data)
	if errJson != nil {
		fmt.Println(errJson.Error())
	}
	log.Printf("OAuth2 token: %s", data.Token)
```

Now it's time to prepare the call to our workflow callback endpoint, with a POST request:

```go
	workflowReq, errWorkflowReq := http.NewRequest("POST", callbackUrl, strings.NewReader("{}"))
	if errWorkflowReq != nil {
		fmt.Println(errWorkflowReq.Error())
	}
```

We add the OAuth2 token as a bearer authorization via headers:

```go
	workflowReq.Header.Add("authorization", "Bearer "+data.Token)
	workflowReq.Header.Add("accept", "application/json")
	workflowReq.Header.Add("content-type", "application/json")

    client := &http.Client{}	
    workflowResp, workflowErr := client.Do(workflowReq)	
    if workflowErr != nil {
        fmt.Printf("Error making callback request: %s\n", workflowErr)	
    }
    log.Printf("Status code: %d", workflowResp.StatusCode)
	fmt.Fprintf(w, "Workflow callback called. Status code: %d", workflowResp.StatusCode)}

```

We simply return the status code at the end of our Go service.

To deploy the Go service, I simply used the source deployment approach, by running gcloud run deploy, 
and answering some questions (service name, region deployment, etc.) 
After a couple of minutes, the service is up and running.

I create a new execution of the workflow from the Google Cloud console. 
Once it's started, it logs the callback endpoint URL. 
I copy its value, then I'm calling my Cloud Run service with the `?callback_url=` query string pointing at that URL. 
And voilà, the service resumes the execution of the workflow, and the workflow finishes.
# Monitoring Website Changes with Workflows Cloud Functions and Sendgrid


Every year in France, around mid-September, there's a special weekend where everyone can visit some famous places, usually closed the rest of the year. That's "[Journée du Patrimoine](https://journeesdupatrimoine.culture.gouv.fr/)". For example, you can visit places like the [Elysée Palace](https://www.elysee.fr/) or the [Matignon Palace](https://www.gouvernement.fr/le-patrimoine-de-l-hotel-de-matignon), if you want to see where the French president, or the French prime minister work. However, for some of those places, it's tricky to register online to book a slot, as there's always a high demand for them. Furthermore, you have to be there at the right time to register, and often, you don't even know when that day or time is! So I thought I could monitor the website of the Elysée Palace to see when the registration would open, by tracking changes on the Elysée website.

To monitor web page or website changes, there are a ton of online services available. There are often some limitations to the number of free requests, or to the frequency of the change checks. Being a developer on Google Cloud, I decided to write a simple solution that would take advantage of various Google Cloud services, namely:

-   [Workflows](https://cloud.google.com/workflows): to define the various steps of my site change workflow,
-   [Cloud Scheduler](https://cloud.google.com/scheduler): to call execute my workflow on a regular basis,
-   [Cloud Functions](https://cloud.google.com/functions): to compute a hash of the webpage, to see if the page changed,
-   [Cloud Storage](https://cloud.google.com/storage): to store the hashes,
-   [SendGrid](https://sendgrid.com/) (not a Google Cloud product): to send me an email when changes have appeared,
-   [Secret Manager](https://cloud.google.com/secret-manager): to store my SendGrid API key securely.

Let's have a look first at a function that computes the hash of a webpage. As there's no hash function in the Workflows standard library, I decided to use a function to do that job. I used the Node.js runtime, with the crypto module, which contains a sha1 implementation:

```javascript
const crypto = require('crypto');

exports.checksum = (req, res) => {
  const webpageBody = req.body.webpage;

  const shasum = crypto.createHash('sha1');
  shasum.update(webpageBody);

  const sha1 = shasum.digest('hex');

  res.status(200).send({sha1: sha1});
};
```

The function receives the web page content from the workflow. Then I create the sha1 hash with that content, and return it in hexadecimal form, in a small JSON payload.

I created a Google Cloud Storage bucket to contain my web page hashes:

![](/img/patrimoine/patrimoine-gcs.png)

Since I'm using SendGrid to notify me by email on changes, I store the API key securely in Secret Manager:

![](/img/patrimoine/patrimoine-secret.png)

Now let's zoom on our workflow, piece by piece.\
First, I define some variables, like the name of my bucket, the name of my hashes text file, and I retrieve my SendGrid API key (see this previous [article about using Secret Manager with Workflows]({{< ref "/posts/2022/02/04/using-the-secret-manager-connector-for-workflows-to-call-an-authenticated-service.md" >}})):

```yaml
main:
    params: [input]
    steps:
    - assignment:
        assign:
            - bucket: hash_results
            - file_name: hash.txt
    - get_email_api_key:
        call: googleapis.secretmanager.v1.projects.secrets.versions.accessString
        args:
            secret_id: SENDGRID_API_KEY
        result: EMAIL_API_KEY
```

Then I read the content of the previous hash in GCS (you can also check this article on how to [read and write JSON data to a file in a bucket from a workflow]({{< ref "/posts/2022/01/21/reading-in-and-writing-a-json-file-to-a-storage-bucket-from-a-workflow.md" >}})):

```yaml
    - read_hash_from_gcs:
        call: http.get
        args:
            url: ${"https://storage.googleapis.com/download/storage/v1/b/" + bucket + "/o/" + file_name}
            auth:
                type: OAuth2
            query:
                alt: media
        result: hash_from_gcs
```

It's time to make a simple HTTP GET call to the website. Currently, the URL is hard-coded, but we could parameterize the workflow to get that URL from the workflow execution input parameters instead.

```yaml
    - retrieve_web_page:
        call: http.get
        args:
           url: https://evenements.elysee.fr/
        result: web_page
```

Once I retrieved the content of the URL (the result of that request is stored in the web_page variable), I can compute my hash, by calling my cloud function:

```yaml
    - compute_hash:
        call: http.post
        args:
            url: https://europe-west1-patrimoine-check.cloudfunctions.net/checksum
            body:
                webpage: ${web_page.body}
        result: hash_result
```

That's where we introduce some branching in the workflow. If the web page hasn't changed we finish early, but if it has changed, then we're going to store the new hash in GCS:

```yaml
    - assign_hashes:
        assign:
            - old_hash: ${hash_from_gcs.body.sha1}
            - new_hash: ${hash_result.body.sha1}
            - hash_msg: ${"Old hash = " + old_hash + " / New hash = " + new_hash}
    - conditionalSwitch:
        switch:
        - condition: ${new_hash != old_hash}
          next: write_hash_to_gcs
        next: returnOutput
    - write_hash_to_gcs:
        call: http.post
        args:
            url: ${"https://storage.googleapis.com/upload/storage/v1/b/" + bucket + "/o"}
            auth:
                type: OAuth2
            query:
                name: ${file_name}
            body:
                sha1: ${hash_result.body.sha1}
```

I log the fact the website has changed, and I'm calling the SendGrid API (like in this article on using SendGrid for sending emails from Workflows):

```yaml
    - site_changed_log:
        call: sys.log
        args:
            text: Website has changed
    - notify_by_email:
        call: http.post
        args:
            url: https://api.sendgrid.com/v3/mail/send
            headers:
                Content-Type: "application/json"
                Authorization: ${"Bearer " + EMAIL_API_KEY}
            body:
                personalizations:
                    - to:
                        - email: me@gmail.com
                from:
                    email: you@gmail.com
                subject: "Elysée, page mise à jour"
                content:
                    - type: text/plain
                      value: "La page de l'Élysée a été mise à jour"
    - log_hashes:
        call: sys.log
        args:
            text: ${hash_msg}
    - returnOutput:
            return: ${hash_msg}
```

The workflows need to be invoked at a regular interval of time. Workflows can be configured to be invoked on a schedule via Cloud Scheduler (again, check this article on scheduling workflow executions). I configured my workflow to be triggered every minute, with the * * * * * cron pattern.\
![](/img/patrimoine/patrimoine-schedule.png)

And voila! I have my little workflow being invoked every minute to check if a web page has changed, and send me an email if so!

To be honest with you, the workflow worked perfectly... but the true story is that I wasn't monitoring the right URL, I should have monitored the front page instead. Furthermore, the page I was monitoring included some dynamic JavaScript code, but the HTML fetched wasn't really changing. I missed the registration window, and all the slots filled super rapidly before I even had the time to register my family for a visit! Shame on me, better check my URL next time, or create webpage screenshots with a headless Chrome running in Cloud Run or in Cloud Functions! Or, of course, use online services that have solved those problems with their years of experience! Hopefully, next year, I won't miss the registration! But it was fun to glue together all those useful services from Google Cloud, to solve a concrete problem.
# Some beans and gems, some snakes and elephants, with Java 17, Ruby 3, Python 3.10, and PHP 8.1 in App Engine and Cloud Functions


Time to spill the beans and show the gems, to our friendly snakes and elephants: we've got some great news for Java, Ruby, Python and PHP serverless developers today. Google App Engine and Cloud Functions are adding new modern runtimes, allowing you to update to the major version release trains of those programming languages.

In short, here's what's new:

-   Access to App Engine legacy bundled services for Java 11/17, Python 3 and Go 1.12+ runtimes, is **Generally Available**

-   The Java 17, Ruby 3.0, Python 3.10, and PHP 8.1 runtimes come into preview in App Engine and Cloud Functions

Let's have a closer look. First of all, the access to App Engine legacy bundled services for second generation runtimes for [Java](https://cloud.google.com/appengine/docs/standard/java-gen2/services/access), [Python](https://cloud.google.com/appengine/docs/standard/python3/services/access) and [Go](https://cloud.google.com/appengine/docs/standard/go/services/access) is now Generally Available. In the past, for example for the Java platform, only Java 8 (a first generation runtime) could access the [built-in APIs](https://cloud.google.com/appengine/docs/standard/java-gen2/reference/services/bundled) like Memcache, Images, Mail, or Task Queues. Now, if you use the Java 11 runtime (a second generation runtime), you can access those services as well as all the [Google Cloud APIs](https://cloud.google.com/java/docs/reference). For example, you can now store transient cached data in Memcache, or send an email to users of your application in a second generation runtime. Same thing for Python and Go developers, you can take advantage of the bundled services as well. If you're still using an old runtime version, this will further ease the transition to newer versions. Be sure to check it out and upgrade.

Next, let's continue with a fresh bean and a shiny gem, mixed in with some friendly animals, with the **preview of the Java 17, Ruby 3.0, Python 3.10 and PHP 8.1 runtimes for both App Engine and Cloud Functions**. What about having a look at what's new in those language versions?

## Java

Between the two Long-Term-Support versions of Java 11 and 17, a lot of new features have landed. Java developers can now write text blocks for strings spanning several lines, without having to concatenate multiple strings manually. The switch construct has evolved to become an expression, which lets you break away from the `break` keyword, and paves the way for more advanced pattern matching capabilities. Speaking of which, the `instanceof` keyword is indeed offering some pattern matching evolution, to avoid obvious but useless casts. Records allow you to create more streamlined immutable data classes, rather than writing your own Java beans for that purpose with proper `hashCode()`, `equals()` or `toString()` methods. For more control over your class hierarchy, sealed class gives you more control over the extension of your classes.

## Ruby

With Ruby 3.0, the big highlights were on performance, static type checking, and concurrency. The goal to make Ruby 3.0, three times faster on some benchmarks than Ruby 2.0 was reached, making your code run more swiftly. Also, Ruby programs can be annotated with some typing information, which allow type checkers to take advantage of those types to provide static type checking, to improve the quality of your code. For concurrency and parallelism, a new actor-inspired concurrency primitive called Ractor helps taming multiple cores in parallel, for your demanding workloads. And a fiber scheduler is introduced for intercepting blocking operations. And beyond those headlines, many improvements to various Ruby APIs have also landed.

## Python

In Python 3.10, the parser gives better and clearer error messages for syntax errors (with more accurate error location), also for indentation, attribute, and name errors, which greatly help developers to find the problems in their code. Structural pattern matching lands with a new `match` and `case` statement construct. Further PEP improvements are tackling more robust type hints for static type checkers. Parenthesized context managers have been added to make the code prettier when spanning a long collection of context managers across several lines. 

## PHP

With version 8.1, PHP gets a pretty major update. First, let's start with a new `enum` syntax construct instead of creating constants in classes, and you get validation out of the box. Classes now have the ability to define final class constants. The new `readonly` properties can't be changed after initialization, which is great for value objects and DTOs. A first class callable syntax is introduced, allowing you to get a reference to any function, with a short syntax. Developers will also find further improvements to initializers, that make it possible to even have nested attributes, using objects as default parameter values, static variables, and global constants. One last nice addition we can mention is the introduction of fibers to implement lightweight cooperative concurrency.

## Your turn

Gems, beans, elephants, snakes: there's something great in those new language versions for every developer. Thus, with these new runtimes in Preview, Java, Ruby, Python and PHP developers can update or develop new App Engine apps and Cloud Functions using the latest and greatest versions of their favorite languages. Be sure to check out the documentation for App Engine ([Java](https://cloud.google.com/appengine/docs/standard/java-gen2/runtime), [Ruby](https://cloud.google.com/appengine/docs/standard/ruby/runtime), [Python](https://cloud.google.com/appengine/docs/standard/python3/runtime), [PHP](https://cloud.google.com/appengine/docs/standard/php7/runtime)) and Cloud Functions ([Java](https://cloud.google.com/functions/docs/concepts/java-runtime), [Ruby](https://cloud.google.com/functions/docs/concepts/ruby-runtime), [Python](https://cloud.google.com/functions/docs/concepts/python-runtime), [PHP](https://cloud.google.com/functions/docs/concepts/php-runtime)). We're looking forward to hearing from you about how you'll take advantage of those new language runtimes.

[](https://cloud.google.com/blog/products/serverless/introducing-the-next-generation-of-cloud-functions)
# Schedule a Workflow Execution


There are [different ways to launch the execution](https://cloud.google.com/workflows/docs/executing-workflow) of a workflow. In previous articles, we mentioned that you can [use the gcloud command-line](https://cloud.google.com/workflows/docs/quickstart-gcloud) tool to create an execution, you can also use the various [client libraries](https://cloud.google.com/workflows/docs/quickstart-client-libraries) to invoke Workflows, or use the [REST API](https://cloud.google.com/workflows/docs/reference/executions/rest). A workflow itself can also invoke other workflows!

But today, I'd like to tell you how to schedule the execution of a workflow. For that purpose, we'll take advantage of [Cloud Scheduler](https://cloud.google.com/scheduler). The [documentation](https://cloud.google.com/workflows/docs/schedule-workflow) is actually covering this topic in detail, so be sure to grab all the info there. However, I'll go quickly through the steps, and tell you about a nice new feature in the cloud console to ease the scheduling of workflows!

First, you need to have both Workflows and Cloud Scheduler enabled:

```bash
gcloud services enable cloudscheduler.googleapis.com workflows.googleapis.com
```

Cloud Scheduler will need a service account with `workflows.invoker` role, to be allowed to call Workflows:

```bash
gcloud iam service-accounts create workflows_caller_sa
gcloud projects add-iam-policy-binding MY_PROJECT_ID \
  --member serviceAccount:workflows_caller_sa@MY_PROJECT_ID.iam.gserviceaccount.com \\
  --role roles/workflows.invoker
```

Now it's time to create the cron job:

```bash
gcloud scheduler jobs create http every_5_minute_schedule \
    --schedule="*/5 * * * *" \
    --uri="https://workflowexecutions.googleapis.com/v1/projects/MY_PROJECT_ID/locations/REGION_NAME/workflows/WORKFLOW_NAME/executions" \
    --message-body="{\"argument\": \"DOUBLE_ESCAPED_JSON_STRING\"}" \
    --time-zone="America/New_York" \
    --oauth-service-account-email="workflows_caller_sa@MY_PROJECT_ID.iam.gserviceaccount.com"
```

Here, you can see that Scheduler will run every 5 minutes (using the cron notation), and that it's going to call the Workflows REST API to create a new execution. You can also pass an argument for the workflow input.

The cool new feature I was eager to mention today was the direct integration of the scheduling as part of the Workflows creation flow, in the cloud console.

Now, when you create a new workflow, you can select a trigger:

![](/img/schedule-workflow/scheduler-trigger-1-600.jpg)

Click on the `ADD NEW TRIGGER` button, and select `Scheduler`. A side panel on the right will show up, and you will be able to specify the schedule to create, directly integrated, instead of having to head over to the Cloud Scheduler product section:

![](/img/schedule-workflow/scheduler-trigger-2-600.png)

And there, you can specify the various details of the schedule! It's nice to see both products nicely integrated, to ease the flow of creating a scheduled workflow.

# Using the Secret Manager connector for Workflows to call an authenticated service


Workflows allows you to call APIs, whether from or hosted on Google Cloud, or any external API in the wild. 
A few days ago, for example, we saw an example on 
[how to use the SendGrid API to send emails from a workflow]({{< ref "/posts/2022/02/01/sending-an-email-with-sendgrid-from-workflows.md" >}}). 
However, in that article, I had the API key hard-coded into my workflow, which is a bad practice. 
Instead, we can store secrets in [Secret Manager](https://cloud.google.com/secret-manager). 
Workflows has a specific [connector for Secret Manager](https://cloud.google.com/workflows/docs/reference/googleapis/secretmanager/Overview), 
and a useful method to access secrets.

In this article, we'll learn two things:
* How to access secrets stored in Secret Manager with the Workflows connector
* How to call an API that requires basic authentication

Let's access the secrets I need to do my basic auth call to the API I need to call:

```yaml
- get_secret_user:
    call:  googleapis.secretmanager.v1.projects.secrets.versions.accessString
    args:
      secret_id:  basicAuthUser
    result:  secret_user
- get_secret_password:
    call:  googleapis.secretmanager.v1.projects.secrets.versions.accessString
    args:
      secret_id:  basicAuthPassword
    result:  secret_password
```

The user login and password are now stored in variables that I can reuse in my workflow. 
I will create the Base64 encoded user:password string required to pass in the authorization header:

```yaml
- assign_user_password:
    assign:
    - encodedUserPassword:  ${base64.encode(text.encode(secret_user  +  ":"  +  secret_password))}
```

Equipped with my encoded user:password string, I can now call my API (here a cloud function) 
by added an authorization header with basic authentication (and return the output of the function):

```yaml
- call_function:
    call:  http.get
    args:
        url:  https://europe-west1-workflows-days.cloudfunctions.net/basicAuthFn
        headers:
            Authorization:  ${"Basic  " + encodedUserPassword}
    result: fn_output
- return_result:
    return: ${fn_output.body}
```

Workflows has built-in 
[OAuth2 and OIDC support for authenticating to Google hosted APIs, functions and Cloud Run services](https://cloud.google.com/workflows/docs/authentication#making_authenticated_requests), 
but it's also useful to know how to invoke other authenticated services, like those requiring basic auth, or other bearer tokens.
# Upload and use JSON data in your workflow from GCS


Following up the [article]({{< ref "/posts/2022/01/21/reading-in-and-writing-a-json-file-to-a-storage-bucket-from-a-workflow.md" >}}) 
on writing and reading JSON files in cloud storage buckets (GCS), we saw that we could access the data of the JSON file, and use it in our workflow. 
Let's have a look at a concrete use of this.

Today, we'll take advantage of this mechanism to avoid hard-coding the URLs of the APIs we call from our workflow. 
That way, it makes the workflow more portable across environments.

Let's regroup the logic for reading and loading the JSON data in a reusable subworkflow:

```yaml
read_env_from_gcs:
    params:  [bucket,  object]
    steps:
    - read_from_gcs:
        call:  http.get
        args:
            url:  ${"https://storage.googleapis.com/download/storage/v1/b/"  +  bucket  +  "/o/"  +  object}
            auth:
                type:  OAuth2
            query:
                alt:  media
        result:  env_file_json_content
    - return_content:
        return:  ${env_file_json_content.body}
```

You call this subworkflow with two parameters: the bucket name, and the object or file name that you want to load.

Now let's use it from the main workflow. We need a first step to call the subworkflow to load a specific file from a specific bucket. 
The subworkflow below will return the content of the JSON data in the env_details variable.

```yaml
​​main:
    params:  [input]
    steps:
    - load_env_details:
        call:  read_env_from_gcs
        args:
            bucket:  workflow_environment_info
            object:  env-info.json
        result:  env_details
```

Imagine the JSON file contains a JSON object with a `SERVICE_URL` key, pointing at the URL of a service, 
then you can call the service with the following expression: `${env_details.SERVICE_URL}` as shown below.

```yaml
    - call_service:
        call:  http.get
        args:
            url:  ${env_details.SERVICE_URL}
        result:  service_result
    - return_result:
        return:  ${service_result.body}
```

This is great for avoiding hardcoding certain values in your workflow definitions. 
However, for true environment-specific deployments, this is not yet ideal, as you would have to point to a different file in the bucket, or use a different bucket. 
And that information is currently hardcoded in the definition when you make the call to the subworkflow. 
But if you follow some naming conventions for the project names and bucket names, that map to environments, this can work! 
(ie. `PROD_bucket` vs `DEV_bucket`, or `PROD-env-info.json` vs `DEV-env-info.json`)

Let's wait for the support of environment variables in Workflows!
# Sending an email with SendGrid from Workflows


Following up the [article]({{< ref "/posts/2022/01/21/reading-in-and-writing-a-json-file-to-a-storage-bucket-from-a-workflow.md" >}}) 
on writing and reading JSON files in cloud storage buckets, we saw that we could access the data of the JSON file, 
and use it in our workflow. Let's have a look at a concrete use of this.

Today, we'll take advantage of this mechanism to avoid hard-coding the URLs of the APIs we call from our workflow. 
That way, it makes the workflow more portable across environments.

Let's regroup the logic for reading and loading the JSON data in a reusable subworkflow:

```yaml
read_env_from_gcs:
    params:  [bucket,  object]
    steps:
    - read_from_gcs:
        call:  http.get
        args:
            url:  ${"https://storage.googleapis.com/download/storage/v1/b/"  +  bucket  +  "/o/"  +  object}
            auth:
                type:  OAuth2
            query:
                alt:  media
        result:  env_file_json_content
    - return_content:
        return:  ${env_file_json_content.body}
```

You call this subworkflow with two parameters: the bucket name, and the object or file name that you want to load.

Now let's use it from the main workflow. We need a first step to call the subworkflow to load a specific file from a specific bucket. 
The subworkflow below will return the content of the JSON data in the `env_details` variable.

```yaml
​​main:
    params:  [input]
    steps:
    - load_env_details:
        call:  read_env_from_gcs
        args:
            bucket:  workflow_environment_info
            object:  env-info.json
        result:  env_details
```

Imagine the JSON file contains a JSON object with a `SERVICE_URL` key, pointing at the URL of a service, 
then you can call the service with the following expression: `${env_details.SERVICE_URL}` as shown below.

```yaml
    - call_service:
        call:  http.get
        args:
            url:  ${env_details.SERVICE_URL}
        result:  service_result
    - return_result:
        return:  ${service_result.body}
```

This is great for avoiding hardcoding certain values in your workflow definitions. 
However, for true environment-specific deployments, this is not yet ideal, 
as you would have to point to a different file in the bucket, or use a different bucket. 
And that information is currently hardcoded in the definition when you make the call to the subworkflow. 
But if you follow some naming conventions for the project names and bucket names, that map to environments, 
this can work! (ie. `PROD_bucket` vs `DEV_bucket`, or `PROD-env-info.json` vs `DEV-env-info.json`)

Let's wait for the support of environment variables in Workflows!
For notification purposes, especially in an asynchronous way, email is a great solution. 
I wanted to add an email notification step in [Google Cloud Workflows](https://cloud.google.com/workflows). 
Since GCP doesn't have an email service, I looked at the various email services available in the cloud: SendGrid, Mailgun, Mailjet, 
and even ran a quick Twitter [poll](https://twitter.com/glaforge/status/1488444661211533312) to see what folks in the wild are using. 
I experimented with SendGrid, and the [sign up](https://signup.sendgrid.com/) process was pretty straightforward, 
as I was able to [get started](https://docs.sendgrid.com/for-developers/sending-email/api-getting-started) quickly, 
by creating an API key, and sending my first email with cURL command.

Now comes the part where I needed to call that API from my workflow definition. 
And that's actually pretty straightforward as well. 
Let's see that in action:

```yaml
- retrieve_api_key:
    assign:
        - SENDGRID_API_KEY:  "MY_API_KEY"
- send_email:
    call:  http.post
    args:
        url:  https://api.sendgrid.com/v3/mail/send
        headers:
            Content-Type:  "application/json"
            Authorization:  ${"Bearer  " + SENDGRID_API_KEY}
        body:
            personalizations:
                - to:
                    - email: to@example.com
            from:
                email: from@example.com
            subject: Sending an email from Workflows
            content:
                - type: text/plain
                  value: Here's the body of my email
    result: email_result
- return_result:
    return: ${email_result.body}
```

In the `retrieve_api_key` step, I simply hard-coded the SendGrid API key. 
However, you can of course store that secret in Secret Manager, 
and then fetch the secret key thanks to the Workflows Secret Manager connector (that's probably worth a dedicated article!)

Then, in the `send_email` step, I prepare my HTTP POST request to the SendGrid API endpoint. 
I specify the content type, and of course, the authorization using the SendGrid API key. 
Next, I prepare the body of that request, describing my email, 
with a `from` field with a registered email user that I defined in SendGrid, a `to` field corresponding to the recipient, 
an email `subject` and `body` (just plain text, here). 
And that's pretty much it! 
I just translated the JSON body sent in the [cURL example](https://app.sendgrid.com/guide/integrate/langs/curl) from SendGrid's documentation, 
into YAML (using a handy JSON to YAML conversion [utility](https://www.json2yaml.com/))
# Smarter Applications With Document Ai Workflows and Cloud Functions


At enterprises across industries, documents are at the center of core business processes. Documents store a treasure trove of valuable information whether it's a company's invoices, HR documents, tax forms and much more. However, the unstructured nature of documents make them difficult to work with as a data source. We call this ["dark data"](https://www.gartner.com/en/information-technology/glossary/dark-data) or unstructured data that businesses collect, process and store but do not utilize for purposes such as analytics, monetization, etc. These documents in pdf or image formats, often trigger complex processes that have historically relied on fragmented technology and manual steps. With compute solutions on Google Cloud and [Document AI](https://cloud.google.com/document-ai), you can create seamless integrations and easy to use applications for your users. Document AI is a platform and a family of solutions that help businesses to transform documents into structured data backed by machine learning. In this blog post we'll walk you through how to use Serverless technology to process documents with [Cloud Functions](https://cloud.google.com/functions), and with workflows of business processes orchestrating microservices, API calls, and functions, thanks to [Workflows](https://cloud.google.com/workflows).

At Cloud Next 2021, we presented how to build easy [AI-powered applications with Google Cloud](https://cloud.withgoogle.com/next/catalog?session=DEV202#application-development). We introduced a sample application for handling incoming expense reports, analyzing expense receipts with [Procurement Document A](https://cloud.google.com/solutions/procurement-doc-ai)I, a DocAI solution for automating procurement data capture from forms including invoices, utility statements and more. Then organizing the logic of a report approval process with Workflows, and used Cloud Functions as glue to invoke the workflow, and do analysis of the parsed document.

![/img/smart-expense/smart-expenses-screens.max-1700x1700.png](/img/smart-expense/smart-expenses-screens.max-1700x1700.png)

We also open sourced the code on this [Github repository](https://github.com/GoogleCloudPlatform/smart-expenses), if you're interested in learning more about this application.

![/img/smart-expense/architecture-diagram.max-1500x1500.png](/img/smart-expense/architecture-diagram.max-1500x1500.png)

In the above diagram, there are two user journeys: the employee submitting an expense report where multiple receipts are processed at once, and the manager validating or rejecting the expense report. 

First, the employee goes to the website, powered by [Vue.js](https://vuejs.org/) for the frontend progressive JavaScript framework and [Shoelace](https://shoelace.style/) for the library of web components. The website is hosted via [Firebase Hosting](https://firebase.google.com/docs/hosting). The frontend invokes an [HTTP function](https://cloud.google.com/functions/docs/writing/http) that triggers the execution of our business [workflow](https://github.com/GoogleCloudPlatform/smart-expenses/blob/main/workflow.yaml), defined using the Workflows YAML syntax. 

Workflows is able to handle long-running operations without any additional code required, in our case we are asynchronously processing a set receipt files. Here, the Document AI [connector](https://cloud.google.com/blog/topics/developers-practitioners/better-service-orchestration-workflows) directly calls the batch processing endpoint for service. This API returns a long-running operation: if you poll the API, the operation state will be "RUNNING" until it has reached a "SUCCEEDED" or "FAILED" state. You would have to wait for its completion. However, Workflows' [connectors](https://cloud.google.com/workflows/docs/connectors) handle such long-running operations, without you having to poll the API multiple times till the state changes. Here's how we call the batch processing operation of the [Document AI connector](https://cloud.google.com/workflows/docs/reference/googleapis/documentai/Overview):

```yaml
- invoke_document_ai:
    call: googleapis.documentai.v1.projects.locations.processors.batchProcess
    args:
        name: ${"projects/" + project + "/locations/eu/processors/" + processorId}
        location: "eu"
    body:
        inputDocuments:
            gcsPrefix:
                gcsUriPrefix: ${bucket_input + report_id}
        documentOutputConfig:
            gcsOutputConfig:
                gcsUri: ${bucket_output + report_id}
        skipHumanReview: true
    result: document_ai_response
```

Machine learning uses state of the art Vision and Natural Language Processing models to intelligently extract schematized data from documents with Document AI. As a developer, you don't have to figure out how to fine tune or reframe the receipt pictures, or how to find the relevant field and information in the receipt. It's Document AI's job to help you here: it will return a JSON document whose fields are: `line_item`, `currency`, `supplier_name`, `total_amount`, etc. Document AI is capable of understanding standardized papers and forms, including invoices, lending documents, pay slips, driver licenses, and more.

A cloud function retrieves all the relevant fields of the receipts, and makes its own tallies, before submitting the expense report for approval to the manager. Another useful feature of Workflows is put to good use: Callbacks, that we [introduced](https://cloud.google.com/blog/topics/developers-practitioners/introducing-workflows-callbacks) last year. In the workflow definition we create a callback endpoint, and the workflow execution will wait for the callback to be called to continue its flow, thanks to those two instructions:

```yaml
- create_callback:
    call: events.create_callback_endpoint
    args:
        http_callback_method: "POST"
    result: callback_details
...

- await_callback:
    try:
        call: events.await_callback
        args:
            callback: ${callback_details}
            timeout: 3600
        result: callback_request
    except:
        as: e
        steps:
            - update_status_to_error:
...
```


In this example application, we combined the intelligent capabilities of Document AI to transform complex image documents into usable structured data, with Cloud Functions for data transformation, process triggering, and callback handling logic, and Workflows enabled us to orchestrate the underlying business process and its service call logic.

## Going further 

If you're looking to make sense of your documents, turning dark data into structured information, be sure to check out what [Document AI](https://cloud.google.com/document-ai) offers. You can also get your hands on a [codelab](https://codelabs.developers.google.com/codelabs/docai-form-parser-v3-node#0) to get started quickly, in which you'll get a chance at processing handwritten forms. If you want to explore [Workflows](https://cloud.google.com/workflows), [quickstarts](https://cloud.google.com/workflows/docs/quickstarts) are available to guide you through your first steps, and likewise, another [codelab](https://codelabs.developers.google.com/codelabs/cloud-workflows-intro?hl=en#0) explores the basics of Workflows. As mentioned earlier, for a concrete example, the source code of our [smart expense application](https://github.com/GoogleCloudPlatform/smart-expenses) is available on Github. Don't hesitate to reach out to us at [@glaforge](https://twitter.com/glaforge) and [@asrivas_dev](https://twitter.com/asrivas_dev) to discuss smart scalable apps with us.

# Open sourcing the App Engine Standard Java Runtime


One year after Google App Engine was [released](http://googleappengine.blogspot.com/2008/04/introducing-google-app-engine-our-new.html) in 2008, Java became the [second language runtime](http://googleappengine.blogspot.com/2009/04/seriously-this-time-new-language-on-app.html) available on the platform. Java developers were able to deploy and scale their servlet-based web applications easily, without worrying about infrastructure management. Not only Java was able to run then, but alternative JVM languages, like [Apache Groovy](https://spring.io/blog/2009/04/08/write-your-google-app-engine-applications-in-groovy), and [Kotlin](https://kotlinlang.org/) are also part of the game. Fast forward to today, we're pleased to announce that the Java Runtime for App Engine is now available as open source, in the [GoogleCloudPlatform/appengine-java-standard](https://github.com/GoogleCloudPlatform/appengine-java-standard) repository on Github.

## What's available?

The `appengine-java-standard` repository contains the Java source code for the Java standard environment, the production runtime, the APIs, and the local SDK. 

Zooming on the various directories of the project, you'll find the [APIs](https://github.com/GoogleCloudPlatform/appengine-java-standard/tree/main/api/src/main/java/com/google/appengine/api) from the `com.google.appengine.api` package for using and accessing App Engine services like Datastore to store your data, Blobstore to save your binary blobs, Taskqueue to enqueue computing tasks, Memcache to cache expensive results you don't want to recompute, or Urlfetch to call external services. 

The great developer experience of Google App Engine comes in part from the fact you can run your application locally on your development machine, thanks to the local development environment. The aforementioned services all have a local [implementation](https://github.com/GoogleCloudPlatform/appengine-java-standard/tree/main/api_dev/src/main/java/com/google/appengine/api) enabling you to start your app on your machine, rather than having to deploy in the cloud each time you make a change.

To use the services in the cloud, however, you can use Google's built-in [remote APIs](https://cloud.google.com/appengine/docs/standard/java/tools/remoteapi) ([code](https://github.com/GoogleCloudPlatform/appengine-java-standard/tree/main/remoteapi/src/main/java/com/google/appengine/tools/remoteapi)) that let you transparently access App Engine services from any Java application. For example, you can use the Remote API to access a production Datastore from an app running on your local machine. You can also use Remote API to access the Datastore of one App Engine application from a different App Engine application.

In the [runtime folder](https://github.com/GoogleCloudPlatform/appengine-java-standard/tree/main/runtime/impl/src/main/java/com/google/apphosting), you'll be able to see how your App Engine app is started, with the underlying [Jetty](https://www.eclipse.org/jetty/) servlet container, and understand how the various components or services are configured on startup.

What's not open source today are the specific layers that tie App Engine to the underlying [Borg](https://research.google.com/pubs/pub43438.html?hl=es) cluster management system, internal to the Google infrastructure, as developers can't replicate the whole Google backend easily in their own environment.

## Why make it open source?

It's important for our customers to not be locked in a particular tool, environment, or vendor, and give them the liberty to run their workloads elsewhere, and understand how we actually run their code. That's why Google Cloud follows an [Open Cloud](https://cloud.google.com/open-cloud) approach, and participates actively in the open source ecosystem. Our open cloud approach enables you to develop software faster, innovate more easily, and scale more efficiently---while also reducing technology risk. Through the years, we've open sourced various technologies, like [Kubernetes](https://kubernetes.io/), based on our experience of running containers at scale, or the [gVisor](https://gvisor.dev/) sandbox, an application kernel for containers that provides efficient defense-in-depth anywhere, and which was pioneered by the App Engine environment, as gVisor was its sandbox environment.

By open sourcing the App Engine Java runtime, we're making the first step towards letting you run the whole App Engine environment wherever you want: on your local development environment, on-premise in your own data center, or potentially on our other computing platforms like [Cloud Run](https://cloud.google.com/run/). We're also making a key step towards easier transitions for future runtimes based on newer Long-Term Support versions of the Java programming language. 

Finally, being able to compile, test and release the Java runtime environment for Java 8, Java 11 and soon Java 17 from an open source platform is much easier than relying on the huge internal Google mono repository system which is intended to support only one single version of everything, including a single JDK toolchain. We are releasing the binary artifacts in the [Maven central repository](https://repo1.maven.org/maven2/com/google/appengine/), including Javadocs and sources to find the relevant code regarding exceptions raised during runtime execution.

## Going further

If you're not familiar with App Engine yet, be sure to check out our [online resources](https://cloud.google.com/appengine) about this powerful and scalable serverless application platform on our website. And get started with the tutorials on the [Java 8](https://cloud.google.com/appengine/docs/standard/java/runtime) or [Java 11 standard environment](https://cloud.google.com/appengine/docs/standard/java11/services/access). To learn more about this open source App Engine Java runtime, please visit our [repository](https://github.com/GoogleCloudPlatform/appengine-java-standard) on Github, to discover how the serverless secret sauce is made. And if you're feeling like helping and [contributing](https://github.com/GoogleCloudPlatform/appengine-java-standard/blob/main/CONTRIBUTING.md), we're looking forward to hearing from you, by filing new [tickets](https://github.com/GoogleCloudPlatform/appengine-java-standard/issues) or by preparing some [pull requests](https://github.com/GoogleCloudPlatform/appengine-java-standard/pulls).

[](https://cloud.google.com/blog/products/application-development/turn-it-up-to-eleven-java-11-runtime-comes-to-app-engine)
# Reading in and writing a JSON file to a storage bucket from a workflow


[Workflows](https://cloud.google.com/workflows) provides several [connectors](https://cloud.google.com/workflows/docs/reference/googleapis) 
for interacting with various Google Cloud APIs and services. 
In the past, I've used for example the [Document AI connector](https://cloud.google.com/workflows/docs/reference/googleapis/documentai/Overview) 
to parse documents like expense receipts, 
or the [Secret Manager connector](https://cloud.google.com/workflows/docs/reference/googleapis/secretmanager/Overview) 
to store and access secrets like passwords. 
Another useful connector I was interested in using today was the 
[Google Cloud Storage connector](https://cloud.google.com/workflows/docs/reference/googleapis/storage/Overview), 
to store and read files stored in storage buckets.

Those connectors are auto-generated from their API discovery descriptors, 
but there are some limitations currently that prevent, for example, to download the content of a file. 
So instead of using the connector, I looked at the JSON API for cloud storage to see what it offered 
([insert](https://cloud.google.com/workflows/docs/reference/googleapis/storage/v1/objects/insert) and 
[get](https://cloud.google.com/storage/docs/json_api/v1/objects/get) methods).

What I wanted to do was to store a JSON document, and to read a JSON document. 
I haven't tried with other media types yet, like pictures or other binary files. 
Anyhow, here's how to write a JSON file into a cloud storage bucket:

```yaml
main:
    params:  [input]
    steps:
    - assignment:
        assign:
            - bucket:  YOUR_BUCKET_NAME_HERE
    - write_to_gcs:
        call:  http.post
        args:
            url:  ${"https://storage.googleapis.com/upload/storage/v1/b/"  +  bucket  +  "/o"}
            auth:
                type:  OAuth2
            query:
                name:  THE_FILE_NAME_HERE
            body:
                name:  Guillaume
                age:  99
```

In the file, I'm storing a JSON document that contains a couple keys, defined in the body of that call. 
By default, here, a JSON media type is assumed, so the body defined at the bottom in YAML is actually written as JSON in the resulting file. 
Oh and of course, don't forget to change the names of the bucket and the object in the example above.

And now, here's how you can read the content of the file from the bucket:

```yaml
main:
    params:  [input]
    steps:
    - assignment:
        assign:
            - bucket:  YOUR_BUCKET_NAME_HERE
            - name:  THE_FILE_NAME_HERE
    - read_from_gcs:
        call:  http.get
        args:
            url:  ${"https://storage.googleapis.com/download/storage/v1/b/"  +  bucket  +  "/o/"  +  name}
            auth:
                type:  OAuth2
            query:
                alt:  media
        result:  data_json_content
    - return_content:
        return:  ${data_json_content.body}
```

This time we change the GCS URL from `upload` to `download`, 
and we use the `alt=media` query parameter to instruct the GCS JSON API that we want to retrieve the content of the file (not just its metadata). 
In the end, we return the body of that call, which contains the content.
# How to get the project ID in a Java Cloud Function


As I was working with my colleague [Sara Ford](https://cloud.google.com/developers/advocates/sara-ford) 
on testing the Cloud Functions runtimes for the upcoming "second generation" of the product, 
rebased on the [Cloud Run](https://cloud.run/) platform, I wrote a few simple functions for the Java runtime. 
In one of those Java functions, I wanted to use Google Cloud Storage, to download a file from a bucket. 
I took a look at the existing 
[sample](https://github.com/googleapis/google-cloud-java/blob/main/google-cloud-examples/src/main/java/com/google/cloud/examples/storage/objects/DownloadObject.java) 
to download an object:

```java
Storage storage = StorageOptions.newBuilder()
    .setProjectId(projectId)
    .build()
    .getService();

Blob blob = storage.get(BlobId.of(bucketName, objectName));
blob.downloadTo(Paths.get(destFilePath));
```

I know the name of the bucket, the name of the file, I'm going to store the file in the local file system. 
So I have all the information needed... except the project ID within which I deployed my Java cloud function. 
So how do I get the project ID, in Java, inside the Cloud Functions environment?

A previous iteration of Cloud Functions had various useful environment variables available, which included the project ID. 
So you could retrieve the ID with a `System.getenv()` call. 
However, for various compatibility reasons between the various runtimes, 
with the [Knative](https://knative.dev/docs/) open source project, that variable disappeared along the road.

However, I know that the project ID is also part of the internal 
[compute metadata](https://cloud.google.com/appengine/docs/standard/java/accessing-instance-metadata) 
that is accessible via a special URL:

<http://metadata.google.internal/computeMetadata/v1/project/project-id>

With that knowledge in mind, I thought I could simply make a quick HTTP request to get that information:

```java
private String getProjectId() {
  String projectId = null;
  HttpURLConnection conn = null;
  try {
      URL url = new URL("http://metadata.google.internal/computeMetadata/v1/project/project-id");
      conn = (HttpURLConnection)(url.openConnection());
      conn.setRequestProperty("Metadata-Flavor", "Google");
      projectId = new String(conn.getInputStream().readAllBytes(), StandardCharsets.UTF_8);
      conn.disconnect();
  } catch (Throwable t) {}
  return projectId;
}
```

For the call to work, it is mandatory to set the `Metadata-Flavor` header that you see above. 
I used Java's built-in `HttpURLConnection` for the job. 
There are other HTTP libraries that could've made the code simpler, but at first, 
I didn't want to bring another HTTP client, just for retrieving a simple project meta-information.

I'm one of the developers who designed the 
[Functions Framework for Java](https://github.com/GoogleCloudPlatform/functions-framework-java) 
that is used to craft cloud functions in Java, however, I've written quite a few functions using Node.js as well. 
And in the Node ecosystem, there's actually an NPM module whose responsibility is to retrieve such project metadata. 
With the [gcp-metadata](https://www.npmjs.com/package/gcp-metadata) module, you can require it and then fetch the project ID with:

```javascript
const gcpMetadata = require('gcp-metadata');
const projectId = await gcpMetadata.project('project-id');
```

I was surprised I couldn't easily find an equivalent library in Java. 
It took me a while to find it, but it actually exists too! 
That's the [com.google.cloud:google-cloud-core](https://googleapis.dev/java/google-cloud-core/latest/index.html) library! 
And it's trivial to use:

```java
import com.google.cloud.ServiceOptions;

String projectId = ServiceOptions.getDefaultProjectId();
```

An extra dependency in my pom.xml, one import and one static method call on `ServiceOptions`, 
and I can get the GCP project ID! So I'm now able to pass the project ID to my `StorageOptions` builder.
But for some reason, I recalled that at times, in some other projects I had written, 
I remembered not really needing that project ID information, as the libraries 
I was using were smart enough to infer such information from the environment. 
Let's look again at the `StorageOptions` from the beginning. 
What if I simply omit the `setProjectId()` method call? 
Lo and behold... indeed, it was actually not required, and the project ID was inferred, transparently. 
So I didn't really need to search for how to retrieve this project ID at all! 
And actually, you can further simplify the creation of the StorageOptions down to:

```java
Storage storage = StorageOptions
    .getDefaultInstance()
    .getService();
```

At least, now, I know how to retrieve the project ID in Java, 
in case the libraries or the environment are not providing such details on their own!


# Introducing Workflows callbacks


With [Workflows](http://cloud.google.com/workflows), developers can easily orchestrate various services together, on Google Cloud or third-party APIs. Workflows [connectors](https://cloud.google.com/blog/topics/developers-practitioners/introducing-new-connectors-workflows) handle long-running operations of Google Cloud services till completion. And Workflow executions can also wait for time to pass with the built-in [`sys.sleep function`](https://cloud.google.com/workflows/docs/reference/stdlib/sys/sleep), till some computation finishes, or some event takes place. 

But what if you need some user input or some approval in the middle of the workflow execution, like validating automatic text translation? Or an external system like a fulfillment center or an inventory system that is going to notify that products are back in stock? Instead of using a combination of "sleep" instructions and API polling, now you'll be able to use Workflows callbacks! 

With callbacks, the execution of a workflow can wait until it receives a call to a specific callback endpoint. Let's have a look at a concrete example.

## Case study: human validation of automated translation

Let's have a look at a concrete example! Machine learning based translations have reached an incredible level of quality, but sometimes, you want a human being to validate the translations produced. Thanks to Workflows callbacks, we can add a human, or an autonomous system, into the loop.

To illustrate this case study, the following diagram will show you a possible implementation of the whole process:

![/img/workflows-days/architecture-translation.max-1200x1200.png](/img/workflows-days/architecture-translation.max-1200x1200.png)

1.  First, the user visits a translation web page. They fill a textarea with the text they want to translate, and click on the translate button.
2.  Clicking on the button will call a Cloud Function that will launch an execution of the workflow. The text to translate is passed as a parameter of the function, and as a parameter of the workflow too.
3.  The text is saved in Cloud Firestore, and the Translation API is called with the input text, and will return the translation, which will be stored in Firestore as well. The translation appears on the web page in real-time thanks to the Firebase SDK.
4.  A step in the workflow creates a callback endpoint (also saved in Firestore), so that it can be called to validate or reject the automatic translation. When the callback endpoint is saved in Firestore, the web page displays validation and rejection buttons.
5.  The workflow now explicitly awaits the callback endpoint to be called. This pauses the workflow execution.
6.  The user decides to either validate or reject the translation. When one of the two buttons is clicked, a Cloud Function is called, with the approval status as parameter, which will in turn call the callback endpoint created by the workflow, also passing the approval status. The workflow resumes its execution, and saves the approval in Firestore. And this is the end of our workflow.

## Creating a callback and awaiting incoming calls

Two new built-in functions are introduced in the standard Workflows library:

-   [`events.create_callback_endpoint`](https://cloud.google.com/workflows/docs/reference/stdlib/events/create_callback_endpoint) --- to create and setup the callback endpoint

-   [`events.await_callback`](https://cloud.google.com/workflows/docs/reference/stdlib/events/await_callback) --- to wait for the callback endpoint to be called

With `events.create_callback_endpoint` you specify the HTTP method that should be used for invoking the callback endpoint, and you get a dictionary with the URL of that endpoint that you can pass to other systems. And with `events.await_callback`, you pass the callback endpoint to wait on, pass a timeout defining how long you want to wait, and when the endpoint is called, you get access to the body that was sent to the endpoint.

Let's have a look at the [YAML definition](https://github.com/GoogleCloudPlatform/workflows-demos/blob/master/callback-translation/translation-validation.yaml#L73) of our workflow, where we apply those two new functions. First, we're going to create the callback:

```yaml
- create_callback:
    call: events.create_callback_endpoint
    args:
        http_callback_method: "POST"
    result: callback_details
```

The callback endpoint is now ready to receive incoming requests via a `POST HTTP` method, and the details of that endpoint are stored in the `callback_details` dictionary (in particular, the url key will be associated with the URL of the endpoint).

Next, we pause the workflow, and await the callback with:

```yaml
- await_callback:
    call: events.await_callback
    args:
        callback: ${callback_details}
        timeout: 3600
    result: callback_request
```

The `callback_details` from earlier is passed as argument, as well as a timeout in seconds to wait for the callback to be made. When the call is received, all the details of the request are stored in the `callback_request` dictionary. You then have access to the full HTTP request, including its headers or its body. In case the timeout is reached, a `TimeoutError` is raised and can be caught by a `try /` `except` block.

## Going further and calling us back!

If you want to have a closer look at the above example, all the [code for this workflow](https://github.com/GoogleCloudPlatform/workflows-demos/blob/master/callback-translation/translation-validation.yaml) can be found in the [Workflows samples](https://github.com/GoogleCloudPlatform/workflows-demos/) Github repository. And you can follow the details of this [tutorial](https://cloud.google.com/workflows/docs/tutorial-callbacks-firestore) to replicate this workflow in your own project. As this is still a preview feature for now, please be sure to [request access to this feature](https://docs.google.com/forms/d/e/1FAIpQLSdgwrSV8Y4xZv_tvI6X2JEGX1-ty9yizv3_EAOVHWVKXvDLEA/viewform), if you want to try it on your own.

For more information on callbacks, be sure to read the [documentation](https://cloud.google.com/workflows/docs/creating-callback-endpoints). To dive deeper into the example above, please checkout the Github [repository](https://github.com/GoogleCloudPlatform/workflows-demos/tree/master/callback-translation) of this translation validation sample. Don't hesitate to let us know via Twitter to [@glaforge](http://twitter.com/glaforge) what you think of this feature, and how you intend on taking advantage of it in your own workflows!

[](https://cloud.google.com/blog/topics/developers-practitioners/introducing-new-connectors-workflows)
# Skyrocketing Micronaut microservices into Google Cloud


Instead of spending too much time on infrastructure, take advantage of readily available serverless solutions. Focus on your [Micronaut](https://micronaut.io/) code, and deploy it rapidly as a function, an application, or within a container, on Google Cloud Platform, 
with [Cloud Functions](https://cloud.google.com/functions), 
[App Engine](https://cloud.google.com/appengine), 
or [Cloud Run](https://cloud.google.com/run).

In this presentation, you’ll discover the options you have to deploy your Micronaut applications and services on Google Cloud. With [Micronaut Launch](https://micronaut.io/launch/), it’s easy to get started with a template project, and with a few tweaks, you can then push your code to production.

Thanks to its performance, its low memory consumption, and its lightning-fast startup time, Micronaut is particularly well-suited for services that run on serverless solutions.

{{< speakerdeck d10a8e3b48244eab95ea9bd1c81547b5 >}}
# Introducing New Connectors for Workflows


[Workflows](http://cloud.google.com/workflows) is a service to orchestrate not only Google Cloud services, such as Cloud Functions,  Cloud Run, or machine learning APIs, but also external services. As you might expect from an orchestrator, Workflows allows you to define the flow of your business logic, as steps, in a YAML or JSON definition language, and provides an execution API and UI to trigger workflow executions. You can read more about the benefits of Workflows in our [previous article](https://cloud.google.com/blog/topics/developers-practitioners/better-service-orchestration-workflows).

We are happy to announce new [connectors](https://cloud.google.com/workflows/docs/connectors) for Workflows, which simplify calling Google Cloud services and APIs. 

The first documented connectors offered in preview when Workflows was launched in General Availability were:

-   Cloud Tasks
-   Compute Engine
-   Firestore
-   Pub/Sub
-   Secret Manager

The newly unveiled connectors are:

-   BigQuery
-   Cloud Build
-   Cloud Functions
-   Cloud Scheduler
-   Google Kubernetes Engine
-   Cloud Natural Language API
-   Dataflow
-   Cloud SQL
-   Cloud Storage
-   Storage Transfer Service
-   Cloud Translation
-   Workflows & Workflow Executions

In addition to simplifying Google Cloud service calls (no need to manually tweak the URLs to call) from workflow steps, connectors also handle errors and [retries](https://cloud.google.com/workflows/docs/connectors), so you don't have to do it yourself. Furthermore, they take care of APIs with [long-running operations](https://cloud.google.com/workflows/docs/connectors#long-running_operations), polling the service for a result when it's ready, with a back-off approach, again so you don't have to handle this yourself.

Let's take a look at some concrete examples on how connectors help. 

## Creating a Compute Engine VM with a REST API call

Imagine you want to create a Compute Engine Virtual Machine (VM) in a specified project and zone. You can do this by crafting an HTTP POST request with the proper URL, body, and OAuth2 authentication using the Compute Engine API's [instances.insert](https://cloud.google.com/compute/docs/reference/rest/v1/instances/insert) method as shown in [create-vm.yaml](https://github.com/GoogleCloudPlatform/workflows-demos/blob/master/connector-compute/create-vm.yaml):

```yaml
main:
  params: [args]
  steps:
  - init:
      assign:
      - project: ${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}
      - zone: "europe-west1-b"
      - machineType: "e2-small"
      - instanceName: "${args.instanceName}"
  - insert_machine:
      call: http.post
      args:
        url: ${"https://compute.googleapis.com/compute/v1/projects/" + project + "/zones/" + zone + "/instances"}
        auth:
          type: OAuth2
        body:
          name: ${instanceName}
          machineType: ${"zones/" + zone + "/machineTypes/" + machineType}
          disks:
          - initializeParams:
              sourceImage: "projects/debian-cloud/global/images/debian-10-buster-v20201112"
            boot: true
            autoDelete: true
          networkInterfaces:
          - network: "global/networks/default"
```


This works but it is quite error prone to construct the right URL with the right parameters and authentication mechanism. You also need to poll the instance status to make sure it's running before concluding the workflow:

```yaml
- get_instance:
      call: http.get
      args:
        url: ${"https://compute.googleapis.com/compute/v1/projects/" + project + "/zones/" + zone + "/instances/" + instanceName}
        auth:
          type: OAuth2
      result: getInstanceResult
  - assert_running:
      switch:
        - condition: ${getInstanceResult.body.status == "RUNNING"}
          next: end
      next: sleep
  - sleep:
      call: sys.sleep # Polling through sleep
      args:
        seconds: 3
      next: get_instance
```

Note that even the HTTP GET call above could fail and it'd be better to wrap the call in a retry logic. 

## Creating a Compute Engine VM with the Workflows compute connector

In contrast, let's now create the same VM with the compute connector dedicated to Compute Engine as shows in [create-vm-connector.yaml](https://github.com/GoogleCloudPlatform/workflows-demos/blob/master/connector-compute/create-vm-connector.yaml):

```yaml
main:
  params: [args]
  steps:
  - init:
      assign:
      - project: ${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}
      - zone: "europe-west1-b"
      - machineType: "e2-small"
      - instanceName: "${args.instanceName}"
  - insert_machine:
      call: googleapis.compute.v1.instances.insert
      args:
        project: ${project}
        zone: ${zone}
        body:
          name: ${instanceName}
          machineType: ${"zones/" + zone + "/machineTypes/" + machineType}
          disks:
          - initializeParams:
              sourceImage: "projects/debian-cloud/global/images/debian-10-buster-v20201112"
            boot: true
            autoDelete: true
          networkInterfaces:
          - network: "global/networks/default"
```

The overall structure and syntax is pretty similar, but this time, we didn't have to craft the URL ourselves, nor did we have to specify the authentication method. Although it's invisible in this YAML declaration, error handling and retry logic are handled by Workflows directly, unlike the first example where you have to handle it yourself.

## Transparent waiting for long-running operations

Some operations from cloud services are not instantaneous and can take a while to execute. A synchronous call to such operations will return immediately with an object that indicates the status of that long-running operation. 

From a workflow execution, you might want to call a long-running operation and move to the next step only when that operation has finished. In the standard REST approach, you have to check at regular intervals if the operation has terminated or not. To save you from the tedious work of iterating and waiting, connectors take care of this for you! 

Let's illustrate this with another example with Compute Engine. Stopping a VM can take a while. A [request](https://cloud.google.com/compute/docs/reference/rest/v1/instances/stop) to the Compute Engine REST API to stop a VM returns an [object](https://cloud.google.com/compute/docs/reference/rest/v1/instances/stop#response-body) with a status field that indicates whether the operation has completed or not.

The Workflows compute connector and its [instances.stop](https://cloud.google.com/compute/docs/reference/rest/v1/instances/stop) operation will appropriately wait for the stop of the VM -- no need for you  to keep checking its status until the VM stops. It greatly simplifies your workflow definition as shown in [create-stop-vm-connector.yaml](https://github.com/GoogleCloudPlatform/workflows-demos/blob/master/connector-compute/create-stop-vm-connector.yaml).

```yaml
main:
  params: [args]
  steps:
  - init:
      assign:
      - project: ${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}
      - zone: "europe-west1-b"
      - machineType: "e2-small"
      - instanceName: "${args.instanceName}"
  ...
  - stop_machine:
      call: googleapis.compute.v1.instances.stop
      args:
        instance: ${instanceName}
        project: ${project}
        zone: ${zone}
        # Optional connector parameters
        connector_params:
            timeout: 100 # total time is 100s
            polling_policy:  # optional polling parameters for LRO polling.
                initial_delay: 1
                multiplier: 1.25
  - assert_terminated:
      call: assert_machine_status
      args:
        expected_status: "TERMINATED"
        project: ${project}
        zone: ${zone}
        instanceName: ${instanceName}

assert_machine_status:
  params: [expected_status, project, zone, instanceName]
  steps:
  - get_instance:
      call: googleapis.compute.v1.instances.get
      args:
        instance: ${instanceName}
        project: ${project}
        zone: ${zone}
      result: instance
  - compare:
      switch:
      - condition: ${instance.status == expected_status}
        next: end
  - fail:
      raise: ${"Expected VM status is " + expected_status + ". Got " + instance.status + " instead."}
```

Note that we still use the [instances.get](https://cloud.google.com/compute/docs/reference/rest/v1/instances/get) operation in a subworkflow to check that the VM is indeed TERMINATED but this is nice-to-have as [instances.stop](https://cloud.google.com/compute/docs/reference/rest/v1/instances/stop) already waits for the VM to stop before returning.

In connector, users can set a timeout field, which is the total wait time for this connector call. All of the retries and polling logic is hidden. Now, compare this to [stop-vm.yaml](https://github.com/GoogleCloudPlatform/workflows-demos/blob/master/connector-compute/stop-vm.yaml) where the workflow stops the VM without the connector. You can see that the YAML is longer and the logic is more complicated with HTTP retry policy for the stop call and also the polling logic to make sure the VM is actually stopped.

## Increased reliability through connector retries

Even the best services can have momentary outages due to traffic spikes or network issues. Google Cloud Pub/Sub has an SLA of [99.95](https://uptime.is/99.95), which means no more than 43s of downtime per day on average, or under 22 minutes per month. Of course, most products routinely outperform their SLAs by a healthy margin. What if you want strong assurances your workflow won't fail if products remain within their SLAs? Since Workflows connectors retry operations over a period of several minutes, even if there is an outage of several minutes, the operation will succeed and so will the workflow.

## Let's connect!

To learn more about [connectors](https://cloud.google.com/workflows/docs/connectors), have a look at some of our [workflows-samples](https://github.com/GoogleCloudPlatform/workflows-samples/tree/main/src/connectors) repo, which show you how to interact with Compute Engine, Cloud Pub/Sub, Cloud Firestore, and Cloud Tasks. You can find the samples described in this blog post in [workflows-demos/connector-compute](https://github.com/GoogleCloudPlatform/workflows-demos/tree/master/connector-compute).

This is the initial set of connectors; there are many more Google Cloud products for which we will be creating dedicated connectors. We'd love to hear your thoughts about which connectors we should prioritize and focus on next (fill this [form](https://forms.gle/HKYn83bhDKWFSDQr7) to tell us). Don't hesitate to let us know via Twitter to [@meteatamel](https://twitter.com/meteatamel) and [@glaforge](http://twitter.com/glaforge)!
# Serverless: panacea or not?


At [DevDay Belgium](https://www.devday.be/Sessions/Details/94?slug=the-serverless-panacea-or-not), a few months ago, I had the pleasure to give a keynote on the theme of "serverless". Let me share with you this talk today!

**The Serverless Panacea... Or Not?**

> The term "serverless" has become a trendy buzzword: if you don't have the checkbox ticked, you're not cool anymore. Really?
>
> Spoiler alert: There may be servers involved in serverless solutions. It's not just about function-as-a-service. And it's actually more complicated than it may seem!
>
> But first, let's come back to the basics: what is serverless exactly, where does it come from, what are its characteristics? Then, beyond the definition, we'll discuss the challenges, and the risks associated with serverless architectures. Eventually, going further, we'll think about where serverless is heading in the near future.

You can find the slides below:

{{< speakerdeck cb3b04200d7b4b94a0b22dfd9a401d0a >}}

And you can find the video below. Further down, I'll detail each slide of my keynote:

{{< youtube id="EkE3UfzVO8o" t="4294s" >}}

Today, I'd like to tell you about Serverless.
As a Developer Advocate, for Google Cloud, that's products and the topic I'm focusing on.
Serverless is a big buzzword of the day, but is it a real panacea or not?

Like Obelix, I fell into the magic serverless potion a long time ago...
I started playing with Google App Engine Java in 2009, even before it was officially announced by Google at the Google I/O conference.
Google team reached out to me, to work together in stealth mode, to ensure that alternative JVM languages would run fine on their upcoming Java flavor for App Engine (I'm the co-founder of the Groovy language)

I couldn't imagine then that I'd be starting to work for Google 7 years later. And that I would focus on those serverless solutions!
It was still called Platform-as-a-Service, as the term "serverless" wasn't invented yet (although they are pretty similar)
And I've been a big fan and big user of App Engine ever since.

After this brief personal story with Obelix and Google, let's actually start with a little bit of background and history.
This is my version of the story, so don't take it too seriously.

At the beginning, humans created the server. 
A machine on which you could run various programs and apps.
Well, we also created the internet, of course, otherwise we couldn't connect our web apps to our users.
If you have a few users, a single server may suffice.
But you know how it goes, with the spread of the web and internet, we now have billions of users, and millions of servers.
Things kinda got complicated, and we introduced lots of hard concepts around distributed microservices, replicated databases.
We even coined theorems, like the CAP theorem, for Consistency, Availability, Partitioning. But you can only pick 2.

Humans invented the cloud, in order to avoid dealing with the physical world.
But there are still databases, servers, or virtual machines to manage.
However, you don't have to get your hands dirty with the ethernet cables, changing the failing hard-drives, upgrading to the latest CPU and RAM.
Usually, it's the cloud provider that has folks that wake up in the middle of the night to upgrade those things.
You can sleep a little bit better at night, even if your boss may still call you at 3am because your app is misbehaving.

To focus on the code, and to avoid the complexity of managing servers, provisioning clusters, configuring networking, fine-tuning databases, even in the cloud... humans came up with the concept of serverless! 
Here is a picture of the latest Google datacenter for serverless! Look, no servers!
Well, I'm kidding, of course, there are always servers around!

Even if the word serverless wasn't there yet, it all started with Platform-as-a-Service, with App Engine and Heroku.
The promise was "give us your code or your app, and we'll run it for you".
The hardware management aspect was already there. Scaling was also handled by the platform.
The pricing as well was proportional to the usage of the resources.

You also have BaaS --- Backend as a Service
It's pretty similar to PaaS actually.
It comes with batteries-included. You focus on the frontend, and all the backend is provided for you.
Parse and Firebase are two good examples. Facebook kinda abandoned Parse into open-source land.
But Firebase is still around and integrates more and more with the various Google Cloud Platform services.
So you can have hosting of static assets, a datastore to save your information, some kind of runtime environment to run your business logic.
And tons of other services, for authentication, mobile crash analysis, performance testing, analytics, and more.

PaaS, then BaaS, and also FaaS: Functions-as-a-service.
With a FaaS solution, your unit of work, of deployment, becomes a small, granular function.
This concept was popularized by Amazon Lambda.
And often, even still today, people tend to confuse FaaS with Serverless.
But FaaS is really just one facet of the Serverless ecosystem. Like PaaS or BaaS.

Another interesting facet of serverless is the Container-as-a-Service approach, with containerized workloads.
Instead deploying apps or functions, you're deploying containers.
Put anything you want inside a container. 
That's the approach that Google took with its Cloud Run container service.
You don't have the complexity of Kubernetes, but you can run your container easily in the cloud, in a fully managed environment.

Right, so I described a bit the history that lead us to serverless and its various facets, and some of the serverless products that are available today, but let's take some time to give a proper definition of what serverless is.

For me, Serverless is the easiest way to get an idea to production in a minimal amount of time.
As a developer, you work on some code, and then you deploy it. That's it! Really!

The term serverless was coined around 2010 by someone called Ken Elkabany, who created the PiCloud computing platform.
Compared to Heroku and App Engine which came earlier, and focusing on implementing web stacks in their cloud datacenters, PiCloud was more generic and supported different kinds of workloads, not just serving web requests.
The catchy term came from the fact that they were actually selling a service, rather than selling or renting servers, machines, VMs, to their customers.

There are 2 ways to think about Serverless: there's the Operational model, and the Programming model.

Operational model:
-   Fully managed, 
-   Automatic scaling, 
-   Pay as you go

Programming model
-   Service based, 
-   Event driven, 
-   Stateless

There's no provisioning of clusters, servers, instances, VMs or anything.
It's all handled by the platform, for you. Just give your code, your app, your function.
It's a fully managed environment. Security patches are applied automatically. 
You remember specter and meltdown recently? They've been mitigated transparently and rapidly for customers by Google Cloud. No wake up call in the night.
Your apps will scale automatically, from 0 to 1 instance, from 1 to n instances, and from n down to 1, as well as back to zero.
Tracking the CPU load, memory usage, number of incoming requests, with some magic formula, serverless platforms are able to scale up and down your services.
Without you having to worry about it. The cloud provider is handling that for you.

In terms of pricing, it's a Pay-as-you-go cost model.
It goes hand in hand with automatic scaling.
If there's no traffic, you pay zero.
If there's twice more traffic than usual, you pay proportionately.
And if the load goes back to zero, the instances serving your app are decommissioned, and again you pay zero.

Now onto the programming model.
More and more, we're transitioning from building big monoliths into orchestrating smaller services, or microservices.
It has its challenges though, but with smaller services, your teams can develop them more independently, scale them differently, or event deploy them with different life cycles.

Since you have some more loosely coupled services, they tend to react to incoming events from your system or from the cloud (for example a notification of a new file in cloud storage, a new line in a reactive datastore like Cloud Firestore, a message in a message bus like Pub/Sub), 
Your services usually communicate asynchronously, to stay properly decoupled.
But the more asynchronous you are, the harder things are to operate and monitor, when business logic spans several services, you have to figure out what's the current status of that workflow across those services.

Another important aspect of the fact that services can scale up and down and back to zero is that there's no guarantee that you're going to hit the same server all the time. 
So you can't be certain that some data that would be cached is still there.
You have to program defensively to ensure that any fresh instance of your app is able to cope with any incoming request.
State is pretty much an enemy of scaling. So the more stateless you can be, the better it is.

-   Compute, 
-   Data Analytics
-   ML & AI
-   Database & Storage
-   Smart assistants & chat
-   DevOps
-   Messaging

We've been speaking about serverless compute, but serverless is not just about compute.
You could consider that anything that is fully managed, that offers a pay-as-you-go cost model, that is a service in the cloud, then it's also all serverless, since you don't have to worry about the infrastructure and the scaling.
There are great examples of this in Google Cloud, for example BigQuery which is a fully-managed, serverless data warehouse and analytics platform. You pay proportionally to the amount of data your queries are going through! Not for the storage, not for the running servers, etc. 
But let's get back to serverless compute.

Serverless sounds pretty cool, right?
But there are also challenges, compared to running a good old monolith on your on-premises server.
We've already given some hints of some of the challenges.
In particular, I'd like to spend some time to tell you about four key aspects:
- The lock-in factor
- The infamous cold starts
- Cost controls
- And the mess of spaghetti microservices

PaaS or BaaS often come with batteries-included.
They have built-in APIs or databases, which are super convenient for developers.
As a developer, you are much more productive, because you don't have to wire things up, configure third-party services. The choice is already made for you.
But I'm seeing those batteries more and more being externalized, as their own standalone products. 
Google Cloud has externalized things like its NoSQL database, its Pub/Sub message hub, its scheduler, its task handling capabilities. Before those services were actually part of the Platform-as-a-Service.

However great having built-in powerful batteries is, often these are proprietary and specific to that platform.
You end up being locked to the platform you're building upon.
It can be a choice, as long as you are aware of it.
It's a trade-off between portability and time-to-market.
You might still be tied to those products, but at least, you can still move the business logic around, if those services are externalized. 
And you can create a level of indirection to be able, some day, potentially, to move away from those service dependencies if needed.

A common issue you hear about in serverless-land is the infamous "Cold Start".
Since you can scale to zero, it means there's currently no server, instance, or clone, to serve an incoming request.
So what happens? The cloud provider has to reinitialize, re-instantiate, re-hydrate some kind of server, VM, or container.
Additionally, the underlying language runtime has to startup as well, initializing its internal data structures.
Not only that, but your app also needs to get started too.
So you'd better try to minimize the time your apps need to be ready to serve their first request. Since you have control over this part.

There are workarounds, like pinging your service at regular intervals to keep it warm, but it's a bit of a hack, or even an anti-pattern.
Depending on the pricing, that might mean you're paying for nothing potentially, for something that's sitting idle.
Some platforms provide some knobs that you can play with like "min instances" or "provisioned instances", usually at a lower price.
For instance, on Google Cloud Functions or Cloud Run, you can specify that you want a certain minimum number of instances that are already warm, and ready to serve, and that are cheaper.

I mention a minimum number of instances, but what about the notion of maximum number of instances?
It's actually an important idea. 
With a platform that auto-scales transparently, that can spin up as many instances to serve increased traffic, it also means that your costs are going to increase just as much! 
So in order to bound your budget to a known quantity, rather than burning your money with all your hot instances, you can cap the number of instances that will serve your content. The service may be a bit degraded when you reach that limit, as latency will likely increase, but at least, your budget doesn't go through the roof!
That's why Google Cloud Platform introduced that notion of capping the number of instances running your functions, apps or containers in its serverless product: to have more visibility and control around costs.

The last challenge I'd like to mention is spaghetti services.
It's so easy to write many functions and services on a serverless platform.
One service does one thing and does it well, right?
But after a while, you end up with a spaghetti of microservices. A big mess.
It becomes very complicated to see what invokes what. 
Hard for monitoring and observability to really figure out what happened, when one microservice starting somehow to misbehave completely ruin your clockwork architecture.
And you know: monoliths aren't that bad, actually.
Don't start right away with writing the smallest unit of work possible. 
Pay attention to how you split the big monolith into microservices.
Otherwise, you'll end up with that big plate of spaghetti. 
There are good articles on when and how to split monolith, but it's not a simple rule of thumb answer.

So what does the future hold for serverless?
I believe that the highlights will be about:
-   Openness
-   Containers
-   Glue
-   Edge
-   Machine Learning

Let's start with open, and openness. That's open like in open source!
We want to avoid lock-in. We want portability.
For instance, the platforms rely on open source software for sure, but the platforms themselves can be open source too.
If you look at Google's Cloud Run, it's actually based on the Knative open source Kubernetes platform.
So you're not locked in Google Cloud when you're using Cloud Run. You can move your workload, your app, on a Knative compatible platform from another cloud provider, or even on-premises, on your own infrastructure.
I worked on the Java Cloud Functions runtime, and it is also available as open source. So you can deploy your functions in Google Cloud, but you can also run your functions elsewhere too, in a hybrid cloud scenario, or even just locally on your machine for greater developer experience and a tighter development feedback loop.
Also, the way you build your services from sources, this can be made more open too. 
For instance, Heroku and Google Cloud partnered together on Cloud Native Buildpacks, it helps you transform your application source code into images that can run on any cloud.
Really, it's all about portability and avoiding lock-in, by making things as open as possible.

As I'm mentioning Cloud Native Buildpacks, and the fact it builds portable containers for your app's source code, notice that we're speaking of containers.
Why containers, you may ask. 
With things like platform or function as a service, you are pushing apps on the platform runtime. But you may be limited in terms of language runtime, or library, or binary that you can run there or bundle. If you're using an esoteric language, or need some special software installed, perhaps you won't be able to run your app there.
Instead, if you could put everything you need in a box, and if the cloud could just run that box for you, then you can do pretty much anything.
That's why we're using containers more and more. And that's also why Google Cloud released Cloud Run, to run your containers, but serverlessly, with any runtime, library or language that you want, without limitations.
So I'm seeing more containers in the future.

You remember my plate of spaghettis? 
To orchestrate your services, to observe and monitor them, to track that they are communicating properly, asynchronously, you'll need more tools to ensure that it all runs fine in the cloud. That's why I'm seeing more tools like Google Cloud Tasks, Cloud Scheduler, Cloud Workflows, and in the Azure and AWS worlds, you have things like Logic App or Step Functions.
You also have various messaging busses, like Google Cloud Pub/Sub, Amazon SQS, Azure Service Bus.
And in the Kubernetes world, we've seen service meshes emerge as a key architectural pattern.
A monolith is much simpler to develop & operate, but as you move to a microservice architecture, those glue services will be needed more and more.
So I see more glue in the future!

Recently, CloudFlare released a product called CloudFlare Workers.
It's using the V8 JavaScript engine, and its isolates concept to run your functions, in a sandboxed manner.
There are two very interesting aspects to me in this new product.
First of all, that's the idea of having your serverless functions run at the edge of the network. 
Not deep in a handful of big data centers. Instead, those functions are as close to the users as possible.
So the latency is really minimal.
Secondly, to further reduce latency, there's a great innovation that almost completely eliminates cold starts!
CloudFlare actually starts warming up your function as soon as the SSL handshake is requested when you invoke the function via HTTPS, although normally the whole handshake operation has to be done first, and the call routed to your function, before really starting.
So that's a really great optimization! And we'll probably see more stuff moving to the edge of the cloud infrastructure.

Lastly, looking even further in the future, I'm curious to see how machine learning will play a role in the serverless offering of cloud providers.
In particular, you still have to specify a VM or instance size, its memory or CPU. Some would say it's not very serverless, since servers are supposed to be abstracted away.
In Google Cloud, for example, we have what we call a "clone scheduler" that is responsible for creating a new instance of your function or app, depending on various factors, like CPU usage, memory usage, number of incoming queries, etc. 
There's some magical calculation that figures out how and when to spin up a new instance.

Google recently automated its datacenter thanks to Machine Learning, reducing its power consumption by 40%! (Power Usage Efficiency)
I can imagine a future where Machine Learning is used to further upsize or downsize the underlying machines running your serverless code, and provision the right amount of resources, to reduce latency, CPU usage, etc.
So let's see what the future holds for Serverless!
# Orchestrating the Pic-a-Daily serverless app with workflows


Over the past year, we ([Mete](https://twitter.com/meteatamel) and [Guillaume](https://twitter.com/glaforge)) have developed a picture sharing application, named Pic-a-Daily, to showcase Google Cloud serverless technologies such as Cloud Functions, App Engine, and Cloud Run. Into the mix, we've thrown a pinch of Pub/Sub for interservice communication, a zest of Firestore for storing picture metadata, and a touch of machine learning for a little bit of magic.

![/img/picadailly-workflows/1_Shqfx7L.max-1400x1400.png](https://storage.googleapis.com/gweb-cloudblog-publish/images/1_Shqfx7L.max-1400x1400.png)

We also created a [hands-on workshop](https://codelabs.developers.google.com/serverless-workshop/) to build the application, and [slides](https://speakerdeck.com/meteatamel/pic-a-daily-serverless-workshop) with explanations of the technologies used. The workshop consists of codelabs that you can complete at your own pace. All the code is open source and available in a [GitHub repository](https://github.com/GoogleCloudPlatform/serverless-photosharing-workshop). 

## Initial event-driven architecture

The Pic-a-Daily application evolved progressively. As new services were added over time, a loosely-coupled, event-driven architecture naturally emerged, as shown in this architecture diagram:

![/img/picadailly-workflows/2_XMbrwvr.max-1100x1100.png](https://storage.googleapis.com/gweb-cloudblog-publish/images/2_XMbrwvr.max-1100x1100.png)

To recap the event-driven flow:

1.  Users upload pictures on an App Engine web frontend. Those pictures are stored in a Google Cloud Storage bucket, which triggers file creation and deletion events, propagated through mechanisms such as Pub/Sub and Eventarc. 
2.  A Cloud Function (Image analysis) reacts to file creation events. It calls the Vision API to assign labels to the picture, identify the dominant colors, and check if it's a picture safe to show publicly. All this picture metadata is stored in Cloud Firestore. 
3.  A Cloud Run service (Thumbnail service) also responds to file creation events. It generates thumbnails of the high-resolution images and stores them in another bucket. 
4.  On a regular schedule triggered by Cloud Scheduler, another Cloud Run service (Collage services) creates a collage from thumbnails of the four most recent pictures. 
5.  Last but not least, a third Cloud Run service (Image garbage collector) responds to file deletion events received through [(recently generally available) Eventarc](https://cloud.google.com/blog/products/serverless/eventarc-is-ga). When a high-resolution image is deleted from the pictures bucket, this service deletes the thumbnail and the Firestore metadata of the image.

These services are loosely coupled and take care of their own logic, in a smooth choreography of events. They can be scaled independently. There's no single point of failure, since services can continue to operate even if others have failed. Event-based systems can be extended beyond the current domain at play by plugging in other events and services to respond to them.

However, monitoring such a system in its entirety usually becomes complicated, as there's no centralized place to see where we're at in the current business process that spans all the services. Speaking of business processes, it's harder to capture and make sense of the flow of events and the interplay between services. Since there's no global vision of the processes, how do we know if a particular process or transaction is successful or not? And when failures occur, how do we deal properly and explicitly with errors, retries, or timeouts?

As we kept adding more services, we started losing sight of the underlying "business flow". It became harder to isolate and debug problems when something failed in the system. That's why we decided to investigate an orchestrated approach.

## Orchestration with Workflows

[Workflows](https://cloud.google.com/workflows) recently became generally available. It offered us a great opportunity to re-architect our application and use an orchestration approach, instead of a completely event-driven one. In orchestration, instead of microservices responding to events, there is an external service, such as Workflows, calling microservices in a predefined order. 

After some restructuring, the following architecture emerged with Workflows:

![/img/picadailly-workflows/3_temY387.max-1000x1000.png](https://storage.googleapis.com/gweb-cloudblog-publish/images/3_temY387.max-1000x1000.png)

Let's recap the orchestrated approach:

-   App Engine is still the same web frontend that accepts pictures from our users and stores them in the Cloud Storage bucket. 
-   The file storage events trigger two functions, one for the creation of new pictures and one for the deletion of existing pictures. Both functions create a workflow execution. For file creation, the workflow directly makes the call to the Vision API (declaratively instead of via Cloud Function code) and stores picture metadata in Firestore via its REST API. 
-   In between, there's a function to transform the useful information of the Vision API into a document to be stored in Firestore. Our initial image analysis function has been simplified: The workflow makes the REST API calls and only the data transformation part remains. 
-   If the picture is safe to display, the workflow saves the information in Firestore, otherwise, that's the end of the workflow. 
-   This branch of the workflow ends with calls to Thumbnail and Collage Cloud Run services. This is similar to before, but with no Pub/Sub or Cloud Scheduler to set up. 
-   The other branch of the workflow is for the picture garbage collection. The service itself was completely removed, as it mainly contained API calls without any business logic. Instead, the workflow makes these calls. 

There is now a central [workflows.yaml](https://github.com/GoogleCloudPlatform/serverless-photosharing-workshop/blob/master/workflows/workflows.yaml) file capturing the business flow. You can also see a visualization of the flow in Cloud Console:

![/img/picadailly-workflows/4_zpsaVq7.max-1500x1500.png](https://storage.googleapis.com/gweb-cloudblog-publish/images/4_zpsaVq7.max-1500x1500.png)

The Workflows UI shows which executions failed, at which step, so we can see which one had an issue without having to dive through heaps of logs to correlate each service invocation. Workflows also ensures that each service call completes properly, and it can apply global error and retry policies.

With orchestration, the business flows are captured more centrally and explicitly, and can even be version controlled. Each step of a workflow can be monitored, and errors, retries, and timeouts can be laid out clearly in the workflow definition. When using Cloud Workflows in particular, services can be called directly via REST, instead of relying on events on Pub/Sub topics. Furthermore, all the services involved in those processes can remain independent, without knowledge of what other services are doing.

Of course, there are downsides as well. If you add an orchestrator into the picture, you have one more component to worry about, and it could become the single point of failure of your architecture (fortunately, Google Cloud products come with SLAs!). Last, we should mention that relying on REST endpoints might potentially increase coupling, with a heavier reliance on strong payload schemas vs lighter events formats.

## Lessons learned

Working with Workflows was refreshing in a number of ways and offered us some lessons that are worth sharing. 

### Better visibility

It is great to have a high-level overview of the underlying business logic, clearly laid out in the form of a [YAML declaration](https://github.com/GoogleCloudPlatform/serverless-photosharing-workshop/blob/master/workflows/workflows.yaml). Having visibility into each workflow execution was useful, as it enabled us to clearly understand what worked in each execution, without having to dive into the logs to correlate the various individual service executions.

### Simpler code

In the original event-driven architecture, we had to deal with three types of events:

1.  Cloud Functions' direct integration with Cloud Storage events
2.  HTTP wrapped Pub/Sub messages with Cloud Storage events for Cloud Run
3.  Eventarc's CloudEvents based Cloud Storage events for Cloud Run

As a result, the code had to cater to each flavor of events:

```javascript
// Cloud Functions provides the event directly
exports.vision_analysis = async (event, context) => {
 const filename = event.name;
 const filebucket = event.bucket;
 ...

// Cloud Run encodes the GCS event in Base64 in a Pub/Sub message
// and wraps the message in an HTTP request
app.post('/', async (req, res) => {
 const pubSubMessage = req.body;
 const eventType = pubSubMessage.message.attributes.eventType;
 const fileEvent = JSON.parse(
 Buffer.from(pubSubMessage.message.data, 'base64')
 .toString().trim());
 ...
​
// Eventarc encodes events with CloudEvents
// and Cloud Run wraps it in an HTTP request
app.post('/', async (req, res) => {
 const cloudEvent = HTTP.toEvent({
 headers: req.headers, body: req.body });
 const tokens = logEntryData.protoPayload.resourceName.split('/');
 const bucket = tokens[3];
 const objectName = tokens[5];
 ...
```

In the orchestrated version, there's only a simple REST call and HTTP POST body to parse:

```javascript
// Workflows calls services directly,
// No events to unwrap
app.post('/', async (req, res) => {
 // gs://picture-bucket/image.jpg
 const gcsImageUri = req.body.gcsImageUri;
 const tokens = gcsImageUri.substr(5).split('/');
 const fileEvent = { bucket: tokens[0], name: tokens[1] };
```

### Less code

Moving REST calls into the workflow definition as a declaration (with straightforward authentication) enabled us to eliminate quite a bit of code in our services; one service was trimmed down into a simple data transformation function, and another service completely disappeared! Two functions for triggering two paths in the workflow were needed though, but with a future integration with Eventarc, they may not be required anymore. 

### Less setup

In the original event-driven architecture, we had to create Pub/Sub topics, and set up Cloud Scheduler and Eventarc to wire-up services. With Workflows, all of this setup is gone. [Workflows.yaml](https://github.com/GoogleCloudPlatform/serverless-photosharing-workshop/blob/master/workflows/workflows.yaml) is the single source of setup needed for the business flow. 

### Error handling

Error handling was also simplified in a couple of ways. First, the whole flow stops when an error occurs, so we were no longer in the dark about exactly which services succeeded and which failed in our chain of calls. Second, we now have the option of applying global error and retry policies. 

### Learning curve

Now, everything is not always perfect! We had to learn a new service, with its quirks and limited documentation --- it's still early, of course, and the documentation will improve over time with feedback from our customers.

### Code vs. YAML 

As we were redesigning the architecture, an interesting question came up over and over: "Should we do this in code in a service or should we let Workflows make this call from the YAML definition?"

In Workflows, more of the logic lands in the workflow definition file in YAML, rather than code in a service. Code is usually easier to write, test, and debug than YAML, but it also requires more setup and maintenance than a step definition in Workflows.

If it's boilerplate code that simply makes a call to some API, that should be turned into YAML declarations. However, if the code also has extra logic, then it's probably better to leave it in code, as YAML is less testable. Although there is some level of error reporting in the Workflows UI, it's not a full-fledged IDE that helps you along the way. Even when working in your IDE on your development machine, you'll have limited help from the IDE, as it only checks for valid YAML syntax.

### Loss of flexibility

The last aspect we'd like to mention is perhaps a loss of flexibility. Working with a loosely-coupled set of microservices that communicate via events is fairly extensible, compared to a more rigid solution that mandates a strict definition of the business process descriptions.

### Choreography or orchestration?

Both approaches are totally valid, and each has its pros and cons. We mentioned this topic when [introducing Workflows](https://cloud.google.com/blog/topics/developers-practitioners/better-service-orchestration-workflows). When should you choose one approach over the other? Choreography can be a better fit if services are not closely related, or if they can exist in different bounded contexts. Whereas orchestration might be best if you can describe the business logic of your application as a clear flow chart, which can then directly be described in a workflow definition. 

## Next steps

To go further, we invite you to have a closer look at [Workflows](http://cloud.google.com/workflows), and its supported [features](https://cloud.google.com/workflows#all-features), by looking at the [documentation](https://cloud.google.com/workflows/docs/overview), particularly the [reference documentation](https://cloud.google.com/workflows/docs/reference/syntax) and the [examples](https://cloud.google.com/workflows/docs/sample-workflows?hl=en). We also have a series of short articles that cover Workflows, with various [tips and tricks](https://glaforge.appspot.com/category/Google%20Cloud%20Platform), as well as introductions to Workflows, with a [first look at Workflows](https://atamel.dev/posts/2020/09-08_first_look_at_workflows/) and some thoughts on [choreography vs orchestration](https://glaforge.appspot.com/article/orchestrating-microservices-with-cloud-workflows).

If you want to study a concrete use case, with an event-based architecture and an equivalent orchestrated approach, feel free to look into our [Serverless Workshop](https://g.co/codelabs/serverless-workshop). It offers codelabs spanning Cloud Functions, Cloud Run, App Engine, Eventarc, and Workflows. In particular, lab 6 is the one in which we converted the event-based model into an orchestration with Workflows. All the code is also available as [open source on GitHub](https://github.com/GoogleCloudPlatform/serverless-photosharing-workshop).\
We look forward to hearing from you about your workflow experiments and needs. Feel free to reach out to us on Twitter at [@glaforge](https://twitter.com/glaforge) and [@meteatamel](https://twitter.com/meteatamel).

[](https://cloud.google.com/blog/products/application-development/get-to-know-google-cloud-workflows)
# Day 15 with Workflows — Built-in Cloud Logging function


In the two previous episodes, we saw how to 
[create and call subworkflows]({{< ref "/posts/2021/02/03/day-14-with-workflows-subworkflows" >}}), 
and we applied this technique to making a reusable routine for logging with Cloud Logging. 
However, there's already a built-in function for that purpose! So let's have a look at this integration.

{{< youtube V2hQekDwdRM >}}

To call the built-in logging function, just create a new step, and make a call to the `sys.log` function:

```yaml
- logString:
    call:  sys.log
    args:
        text:  Hello  Cloud  Logging!
        severity:  INFO
```

This function takes a mandatory parameter: text. And an optional one: severity.

The text parameter accepts all types of supported values, so it's not only string, 
but all kinds of numbers, as well as arrays and dictionaries. 
Their string representation will be used as text.

The optional severity parameter is an enum that can take the values: 
`DEFAULT`, `DEBUG`, `INFO`, `NOTICE`, `WARNING`, `ERROR`, `CRITICAL`, `ALERT`, `EMERGENCY`, 
with `DEFAULT` being... the default value if you don't specify a severity!

Here's another example with a dictionary as parameter, which will be output as text in the logs, and a severity of `WARNING`:

```yaml
- createDict:
    assign:
        - person:
            name:  Guillaume
            kids:  2
- logDict:
    call:  sys.log
    args:
        text:  ${person}
        severity:  WARNING
```

Looking at the results in the cloud logging console, you will see both messages appear:

![](/img/workflows-days/w15-builtin-log.png)

Don't hesitate to have a look at [reference documentation](https://cloud.google.com/workflows/docs/reference/stdlib/sys/log) 
to find more about the available built-in functions.
# Day 14 with Workflows — Subworkflows


Workflows are made of sequences of steps and branches. 
Sometimes, some particular sequence of steps can be repeated, and it would be a good idea to avoid error-prone repetitions in your workflow definition 
(in particular if you change in one place, and forget to change in another place). 
You can modularize your definition by creating subworkflows, a bit like subroutines or functions in programming languages. 
For example, yesterday, we had a look at [how to log to Cloud Logging]({{< ref "/posts/2021/02/02/day-13-with-workflows-logging-with-cloud-logging" >}}): 
if you want to log in several places in your workflow, you can extract that routine in a subworkflow.

Let's see that in action in the video below, and you can read all the explanations afterwards:

{{< youtube tbiFaO_LOdg >}}

First things first, let's step back and look at the structure of workflow definitions. 
You write a series of steps, directly in the main YAML file.
You can move back and forth between steps thanks to 
[jumps]({{< ref "/posts/2020/12/04/day-4-with-workflows-jumping-with-switch-conditions" >}}), 
but it wouldn't be convenient to use jumps to emulate subroutines 
(remember the good old days of BASIC and its gotos?). 
Instead, Cloud Workflows allows you to separate steps under a `main`, and subroutines under their own subroutine name.

So far we had just a sequence of steps:

```yaml
- stepOne:
 ...
- stepTwo:
 ...
- stepThree:
 ...
```

Those steps are implicitly under a `main` routine. 
And here's how to show this main routine explicitly, by having that `main` block, and `steps` underneath:

```yaml
main:
    steps:
        - stepOne:
 ...
        - stepTwo:
 ...
        - stepThree:
 ...
```

To create a subworkflow, we follow the same structure, but with a different name than `main`, but you can also pass parameters like so:

```yaml
subWorkflow:
    params:  [param1,  param2,  param3:  "default value"]
    steps:
        - stepOne:
 ...
        - stepTwo:
 ...
        - stepThree:
 ...
```

Notice that you can pass several parameters, and that parameters can have default values when that parameter is not provided at the call site.

Then in your main flow, you can call that subworkflow with a `call` instruction. 
Let's take a look at a concrete example, that simply concatenates two strings:

```yaml
main:
    steps:
        - greet:
            call:  greet
            args:
                greeting:  "Hello"
                name:  "Guillaume"
            result:  concatenation
        - returning:
            return:  ${concatenation}

greet:
    params:  [greeting,  name:  "World"]
    steps:
        - append:
            return:  ${greeting  +  ", "  +  name  +  "!"}
```

In the `call` instruction, we pass the `greeting` and `name` arguments, and the result will contain the output of the subworkflow call. 
In the subworkflow, we defined our parameters, and we have a single step just return an expression which is the desired greeting message concatenation.

One last example, but perhaps more useful than concatenating strings! 
Let's turn yesterday's Cloud Logging integration into a reusable subworkflow. 
That way, you'll be able to call the log subworkflow as many times as needed in your main workflow definition, without repeating yourself:

```yaml
main:
  steps:
    - first_log_msg:
        call:  logMessage
        args:
          msg:  "First message"
    - second_log_msg:
        call:  logMessage
        args:
          msg:  "Second message"

logMessage:
  params:  [msg]
  steps:
    - log:
        call:  http.post
        args:
            url:  https://logging.googleapis.com/v2/entries:write
            auth:
                type:  OAuth2
            body:
                entries:
                    - logName:  ${"projects/"  +  sys.get_env("GOOGLE_CLOUD_PROJECT_ID")  +  "/logs/workflow_logger"}
                      resource:
                        type:  "audited_resource"
                        labels:  {}
                      textPayload:  ${msg}
```

And voila! We called our `logMessage` subworkflow twice in our main workflow, just passing the text message to log into Cloud Logging.
# Day 13 with Workflows — Logging with Cloud Logging


Time to come back to our series on Cloud Workflows. 
Sometimes, for debugging purposes or for auditing, it is useful to be able to log some information via Cloud Logging. 
As we saw last month, you can 
[call HTTP endpoints]({{< ref "/posts/2020/12/15/day-8-with-workflows-calling-an-HTTP-endpoint" >}}) from your workflow. 
We can actually use 
[Cloud Logging's REST API](https://cloud.google.com/logging/docs/reference/v2/rest/v2/entries/write) to log such messages! 
Let's see that in action.

```yaml
- log:
    call:  http.post
    args:
        url:  https://logging.googleapis.com/v2/entries:write
        auth:
            type:  OAuth2
        body:
            entries:
                - logName:  ${"projects/"  +  sys.get_env("GOOGLE_CLOUD_PROJECT_ID")  +  "/logs/workflow_logger"}
                  resource:
                    type:  "audited_resource"
                    labels:  {}
                  textPayload:  Hello  World  from  Cloud  Workflows!
```

We call the <https://logging.googleapis.com/v2/entries:write> API endpoint to write new logging entries. 
We authenticate via OAuth2---as long as the service account used for the workflow execution allows it to use the logging API. 
Then we pass a JSON structure as the body of the call, indicating the name of the logger to use, 
which resources it applies to, and also the textPayload containing our text message. You could also use a ${} expression to log more complex values.

Once this workflow definition is done and deployed, you can execute it, and you should see in the logs your message appear:

![](/img/workflows-days/w13-cloud-logging.png)

Voila! You can log messages to Cloud Logging!

Let's recap in this video:

{{< youtube XwzSgBB6Kq4 >}}

In the next episode, we'll take advantage of subworkflows, 
to create a reusable set of steps that you will be able to call several times throughout your workflow definition,
without repeating yourself, by turning this logging example into a subworkflow.
# Day 12 with Workflows — Loops and iterations


In previous episodes of this Cloud Workflows series, we've learned about 
[variable assignment]({{< ref "/posts/2020/12/03/day-3-with-workflows-variable-assignment-and-expressions" >}}), 
data structures like [arrays]({{< ref "/posts/2020/12/09/day-6-with-workflows-arrays-and-dictionaries" >}}), 
[jumps]({{< ref "/posts/2020/12/02/day-2-with-workflows-a-workflow-is-made-of-steps-and-jumps" >}}) and 
[switch conditions]({{< ref "/posts/2020/12/04/day-4-with-workflows-jumping-with-switch-conditions" >}}) to move between steps,
and [expressions]({{< ref "/posts/2020/12/03/day-3-with-workflows-variable-assignment-and-expressions" >}}) 
to do some computations, including potentially some built-in functions.

With all these previous learnings, we are now equipped with all the tools to let us create loops and iterations, 
like for example, iterating over the element of an array, perhaps to call an API several times but with different arguments. 
So let's see how to create such an iteration!

{{< youtube OXhV2cuKwo >}}

First of all, let's prepare some variable assignments:

```yaml
- define:
    assign:
        - array:  ['Google',  'Cloud',  'Workflows']
        - result:  ""
        - i:  0
```

-   The `array` variable will hold the values we'll be iterating over.
-   The `result` variable contains a string to which we'll append each values from the array.
-   And the `i` variable is an index, to know our position in the array.

Next, like in a for loop of programming languages, we need to prepare a condition for the loop to finish. We'll do that in a dedicated step:

```yaml
- checkCondition:
    switch:
        - condition:  ${i  <  len(array)}
          next:  iterate
    next:  returnResult
```

We define a `switch`, with a `condition` expression that compares the current index position with the length of the array, using the built-in `len()` function. 
If the condition is true, we'll go to an `iterate` step. If it's false, we'll go to the ending step (called `returnResult` here).

Let's tackle the iteration body itself. 
Here, it's quite simple, as we're just assigning new values to the variables: 
we append the i-th element of the array into the result variable, and we increment the index by one. 
Then we go back to the `checkCondition` step.

```yaml
- iterate:
    assign:
        - result:  ${result  +  array[i]  +  " "}
        - i:  ${i+1}
    next:  checkCondition
```

Note that if we were doing something more convoluted, for example calling an HTTP endpoint with the element of the array as argument, 
we would need two steps: one for the actual HTTP endpoint call, and one for incrementing the index value. 
However in the example above, we're only assigning variables, so we did the whole body of the iteration in this simple assignment step.

When going through the `checkCondition` step, if the condition is not met (ie. we've reached the end of the array), then we're redirected to the `returnResult` step:

```yaml
- returnResult:
    return:  ${result}
```

This final step simply returns the value of the `result` variable.
# Day 11 with Workflows — Sleeping in a workflow


Workflows are not necessarily instantaneous, and executions can span over a long period of time. 
Some steps may potentially launch asynchronous operations, which might take seconds or minutes to finish, but you are not notified when the process is over. 
So when you want for something to finish, for example before polling again to check the status of the async operation, you can introduce a sleep operation in your workflows.

{{< youtube uaW_Cv3RCxQ >}}

To introduce a [sleep operation](https://cloud.google.com/workflows/docs/reference/syntax), add a step in the workflow with a call to the built-in sleep operation:

```yaml
- someSleep:
    call:  sys.sleep
    args:
        seconds:  10
- returnOutput:
    return:  We  waited  for  10  seconds!
```

A `sys.sleep` operation takes a `seconds` argument, where you can specify the number of seconds to wait.

By combining conditional jumps and sleep operations, you can easily implement polling some resource or API at a regular interval, to double check that it completed.
# Day 10 with Workflows — Accessing built-in environment variables


[Google Cloud Workflows](https://cloud.google.com/workflows) offers a few built-in environment variables that are accessible from your workflow executions.

{{< youtube sJQWbo49pWg >}}

There are currently [5 environment variables](https://cloud.google.com/workflows/docs/reference/environment-variables) that are defined:

- `GOOGLE_CLOUD_PROJECT_NUMBER`: The workflow project's number.
- `GOOGLE_CLOUD_PROJECT_ID`: The workflow project's identifier.
- `GOOGLE_CLOUD_LOCATION`: The workflow's location.
- `GOOGLE_CLOUD_WORKFLOW_ID`: The workflow's identifier.
- `GOOGLE_CLOUD_WORKFLOW_REVISION_ID`: The workflow's revision identifier.

Let's see how to access them from our workflow definition:

```yaml
- envVars:
    assign:
      - projectID:  ${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}
      - projectNum:  ${sys.get_env("GOOGLE_CLOUD_PROJECT_NUMBER")}
      - projectLocation:  ${sys.get_env("GOOGLE_CLOUD_LOCATION")}
      - workflowID:  ${sys.get_env("GOOGLE_CLOUD_WORKFLOW_ID")}
      - workflowRev:  ${sys.get_env("GOOGLE_CLOUD_WORKFLOW_REVISION_ID")}
- output:
    return:  ${projectID  +  " "  +  projectNum  +  " "  +  projectLocation  +  " "  +  workflowID  +  " "  +  workflowRev}
```

We use the built-in `sys.get_env()` function to access those variables. 
We'll revisit the various existing built-in functions in later episodes.

Then when you execute this workflow, you'll get an output like this:

```
"workflows-days 783331365595 europe-west4 w10-builtin-env-vars 000001-3af"
```

There's one variable I'd like to see added to this list, that would be the current execution ID. 
That could potentially be useful for identifying a particular execution, when looking in the logs, to reason about potential failure, or for auditing purposes.
# Day 9 with Workflows — Deploying and executing Workflows from the command-line


So far, in this series on [Cloud Workflows](https://cloud.google.com/workflows), 
we've only used the Google Cloud Console UI to manage our workflow definitions, and their executions. 
But it's also possible to deploy new definitions and update existing ones from the command-line, 
using the [GCloud SDK](https://cloud.google.com/sdk/). Let's see how to do that!

{{< youtube rVTPRUuidPI >}}

If you don't already have an existing service account, you should create one following these 
[instructions](https://cloud.google.com/workflows/docs/creating-updating-workflow#gcloud). 
I'm going to use the workflow-sa service account I created for the purpose of this demonstration.

Our workflow definition is a simple "hello world" like the one we created for 
[day #1]({{< ref "/posts/2020/12/01/day-1-with-workflows-your-first-step-to-hello-world" >}}) 
of our exploration of Google Cloud Workflows:

```yaml
- hello:
    return:  Hello  from  gcloud!
```

To deploy this workflow definition, we'll launch the following gcloud command, 
specifying the name of our workflow, passing the local source definition, and the service account:

```bash
$ gcloud beta workflows deploy w09-new-workflow-from-cli \
    --source=w09-hello-from-gcloud.yaml \
    --service-account=workflow-sa@workflows-days.iam.gserviceaccount.com
```

You can also add labels with the `--labels` flag, and a description with the `--description` flag, just like in the Google Cloud Console UI.

If you want to update the workflow definition, this is also the same command to invoke, passing the new version of your definition file.

Time to create an execution of our workflow!

```bash
$ gcloud beta workflows run w09-new-workflow-from-cli
```

You will see an output similar to this:

```yaml
Waiting for execution [d4a3f4d4-db45-48dc-9c02-d25a05b0e0ed] to complete...done.
argument: 'null'
endTime: '2020-12-16T11:32:25.663937037Z'
name: projects/783331365595/locations/us-central1/workflows/w09-new-workflow-from-cli/executions/d4a3f4d4-db45-48dc-9c02-d25a05b0e0ed
result: '"Hello from gcloud!"'
startTime: '2020-12-16T11:32:25.526194298Z'
state: SUCCEEDED
workflowRevisionId: 000001-47f
```

Our workflow being very simple, it executed and completed right away, hence why you see the result string 
(our Hello from gcloud! message), as well as the state as SUCCEEDED. 
However, workflows often take longer to execute, consisting of many steps. 
If the workflow hasn't yet completed, you'll see its status as `ACTIVE` instead, or potentially `FAILED` if something went wrong.

When the workflow takes a long time to complete, you can check the status of the last execution from your shell session with:

```bash
$ gcloud beta workflows executions describe-last
```

If you want to know about the ongoing workflow executions:

```bash
$ gcloud beta workflows executions list your-workflow-name
```

It'll give you a list of operation IDs for those ongoing executions. You can then inspect a particular one with:

```bash
$ gcloud beta workflows executions describe the-operation-id
```

There are other operations on executions, to wait for an execution to finish, or even cancel an ongoing, unfinished execution.

You can learn more about workflow execution in the [documentation](https://cloud.google.com/workflows/docs/executing-workflow). 
And in some upcoming episodes, we'll also have a look at how to create workflow executions from client libraries, and from the Cloud Workflows REST API.
# Day 8 with Workflows — Calling an HTTP endpoint


Time to do something pretty handy: calling an HTTP endpoint, from your Google Cloud Workflows definitions. 
Whether calling GCP specific APIs such as the ML APIs, REST APIs of other products like Cloud Firestore, 
or when calling your own services, third-party, external APIs, this capability lets you plug your business processes to the external world!

Let's see calling HTTP endpoints in action in the following video, before diving into the details below:

{{< youtube jyIonG-u4eM >}}

By default, when creating a new workflow definition, a default snippet / example is provided for your inspiration. 
We'll take a look at it for this article. 
There are actually two HTTP endpoint calls, the latter depending on the former: 
the first step (`getCurrentTime`) is a cloud function returning the day of the week, 
whereas the second step (`readWikipedia`) searches Wikipedia for articles about that day of the week.

```yaml
- getCurrentTime:
    call:  http.get
    args:
        url:  https://us-central1-workflowsample.cloudfunctions.net/datetime
    result:  CurrentDateTime
```

The `getCurrentTime` step contains a call attribute of type `http.get`, to make HTTP GET requests to an API endpoint. 
You have the ability to do either `call: http.get` or `call: http.post`. 
For other methods, you'll have to do call: `http.request`, and add another key/value pair under `args`, with method: 
`GET`, `POST`, `PATCH` or `DELETE`. 
Under `args`, for now, we'll just put the URL of our HTTP endpoint. 
The last key will be the result, which gives the name of a new variable that will contain the response of our HTTP request.

Let's call Wikipedia with our day of the week search query:

```yaml
- readWikipedia:
    call:  http.get
    args:
        url:  https://en.wikipedia.org/w/api.php
        query:
            action:  opensearch
            search:  ${CurrentDateTime.body.dayOfTheWeek}
    result:  WikiResult
```

Same thing with `call`, and `args.url`, however, we have a query where you can define the query parameters for the Wikipedia API. 
Also note how we can pass data from the previous step function invocation: `CurrentDateTime.body.dayOfTheWeek`. 
We retrieve the body of the response of the previous call, and from there, we get the `dayOfTheWeek` key in the resulting JSON document. 
We then return `WikiResult`, which is the response of that new API endpoint call.

```yaml
- returnOutput:
    return:  ${WikiResult.body[1]}
```

Then, the last step is here to return the result of our search. We retrieve the body of the response. 
The response's body is an array, with a first term being the search query, 
and the second item is the following array of document names, which is what our workflow execution will return:

```json
[
 "Monday",
 "Monday Night Football",
 "Monday Night Wars",
 "Monday Night Countdown",
 "Monday Morning (newsletter)",
 "Monday Night Golf",
 "Monday Mornings",
 "Monday (The X-Files)",
 "Monday's Child",
 "Monday.com"
]
```

So our whole workflow was able to orchestrate two independent API endpoints, one after the other. 
Instead of having two APIs that are coupled via some messaging passing mechanism, 
or worse, via explicit calls to one or the other, Cloud Workflows is here to organize those two calls. 
It's the orchestration approach, instead of a choreography of services 
(see my previous article on [orchestration vs choreography]({{< ref "/posts/2020/11/18/orchestrating-microservices-with-cloud-workflows" >}}), 
and my colleague's article on [better service orchestration](https://cloud.google.com/blog/topics/developers-practitioners/better-service-orchestration-workflows) with Cloud Workflows).

To come back to the details of API endpoint calls, here's their structure:

```yaml
- STEP_NAME:
    call:  {http.get|http.post|http.request}
    args:
        url:  URL_VALUE
        [method:  REQUEST_METHOD]
        [headers:
            KEY:VALUE  ...]
        [body:
            KEY:VALUE  ...]
        [query:
            KEY:VALUE  ...]
        [auth:
            type:{OIDC|OAuth2}]
        [timeout:  VALUE_IN_SECONDS]
        [result:  RESPONSE_VALUE]
```

In addition to the URL, the method and query, note that you can pass headers and a body. There is also a built-in mechanism for authentication which works with GCP APIs: the authentication is done transparently. You can also specify a timeout in seconds, if you want to fail fast and not wait forever a response that never comes. But we'll come back to error handling in some of our upcoming articles.
# Day 7 with Workflows — Pass an input argument to your workflow


All the workflow definitions we've seen so far, in this series, were self-contained. 
They were not parameterized. But we often need our business processes to take arguments 
(the ID of an order, the details of the order, etc.), so that we can treat those input values and do something about them. 
That's where workflow input parameters become useful!

Let's start with a simple greeting message that we want to customize with a `firstname` and `lastname`. 
We'd like our workflow to look something like this:

```yaml
- output:
    return:  ${"Your  name  is  " + person.firstname + "  " + person.lastname}
```

In the example above, we have a `person` variable, on which we're requesting the fields `firstname` and `lastname`. 
This is actually a dictionary. But how do we let Cloud Workflows know about this variable? We need to define it somehow.

Workflow arguments are global to all the steps, so they need to be defined outside the scope of the steps themselves. 
Actually, workflows can be structured in sub-workflows: 
there's a main workflow, and possibly additional sub-workflows which are like routines or internal function definitions. 
We'll revisit the topic of sub-workflows in a later article. 
To declare our input parameter, we'll do it at the level of the main workflow, but in a more explicit fashion, with the following notation:

```yaml
main:
    params:  [person]
    steps:
        - output:
            return:  ${"Your  name  is  " + person.firstname + "  " + person.lastname}
```

We explicitly show the name of our main workflow. We use the `params` instruction. 
Note that our single argument, `person`, is surrounded by square brackets. 
The main workflow can only take a single dictionary parameter, however, as we'll see later, 
sub-workflows can take several input arguments, hence the square brackets notation to specify a list of arguments.

![](/img/workflows-days/w7-input-argument.png)

How do we pass this input argument? 
In the execution screen, in the input pane on the left, we create a JSON object, with a firstname and lastname keys. 
This JSON object is the dictionary in the person variable of our workflow definition.

In this video, you'll see input arguments in action:

{{< youtube 3dyKx2zBiXA >}}
# Day 6 with Workflows — Arrays and dictionaries


So far, in this series of articles on [Cloud Workflows](https://cloud.google.com/workflows), 
we have used simple data types, like strings, numbers and boolean values. 
However, it's possible to use more complex data structures, 
like [arrays](https://cloud.google.com/workflows/docs/reference/syntax?hl=en#arrays) and 
[dictionaries](https://cloud.google.com/workflows/docs/reference/syntax?hl=en#dictionaries). 
In this new episode, we're going to use those new structures.

Arrays can be defined inline (like `anArray`) or spanning over several lines (like `anotherArray`):

```yaml
- assignment:
    assign:
        - anArray:  ["a",  "b",  "c"]
        - anotherArray:
            -  one
            -  two
- output:
    return:  ${anArray[0] + anotherArray[1]}
```

The output step will return the string `"atwo"`.

For dictionaries, you can define them as follows:

```yaml
- assignment:
    assign:
        - person:
            firstname:  "Guillaume"
            lastname:  "Laforge"
            age:  43
            kids:  ["Marion",  "Erine"]
- output:
    return:  ${person.firstname  +  " and "  + person.kids[1]}
```

The output step will return the string `"Guillaume and Erine"`.

Notice that we nested an array within a dictionary. 
So you can easily create dictionaries containing arrays, containing other dictionaries, etc, 
just like any JSON or YAML structures.

In the example we were able to access the second kid of the person, mixing both the field (dot) 
and index (square brackets) notations to access fields of our dictionary, and elements of our array.

This video shows both arrays and dictionaries in action:

{{< youtube 9JrqlV5s11Q >}}

In the coming articles, we'll see that such data structures are handy for dealing with API endpoint calls.


# Day 5 with Workflows — Visualizing the structure of your workflow definition


So far, in our Cloud Workflows series, we have seen some of the YAML syntax for defining workflows. 
However, steps are defined after each other, as a series of step definitions, 
but in spite of the jump instructions, the conditionals, 
you don't really see visually what is going to be the next potential step in a workflow execution.

Fortunately, a new UI enhancement has landed in the Google Cloud Console: 
the ability to visualize a workflow definition with a graph, when you're editing the definition. 
Furthermore, the graph is updated in quasi real-time as you make updates to the definition.

![](/img/workflows-days/w05-graph.png)

Let's see this in action in the video below:

{{< youtube RQ11ATLxf3I >}}

Thanks to this visualization, it's easier to further understand how your workflow definition is structured, how executions operate. You can more easily track which steps follows a particular step.

Enjoy!


# Day 4 with Workflows — Jumping with switch conditions


In the previous articles about Google [Cloud Workflows](https://cloud.google.com/workflows), 
we talked about how to [assign variables, create expressions]({{< ref "/posts/2020/12/03/day-3-with-workflows-variable-assignment-and-expressions" >}}), 
and also how to [jump from a step to another]({{< ref "/posts/2020/12/02/day-2-with-workflows-a-workflow-is-made-of-steps-and-jumps" >}}). 
It's time to combine both aspects to understand how we can do conditional jumps, thanks to the `switch` instruction.

Let's start with a first step defining a variable, whose value we'll use in our switch condition:

```yaml
- assignement:
    assign:
        - number:  42
```

Then we're going to create our second step that will use a `switch` instruction, with an expression:

```yaml
- evaluate:
    switch:
        - condition:  ${number  > 100}
          next:  highValue
        - condition:  ${number  <  100}
          next:  lowValue
    next:  end
```

We define two conditions with two expressions, checking if the number is above or below 100, 
then we go to a different step (`highValue` or `lowValue` steps). 
If none of the conditions are met, we go to the end of the workflow 
(or we could return some value or raise some error).

We also need our two steps to go to:

```yaml
- highValue:
    return:  "It's high!"
- lowValue:
    return:  "It's rather low!"
```

And we're done! If the number is `42`, like in our case, 
the execution of the workflow will go through the lowValue step, 
and return the string saying that it's a low value.

{{< youtube thSKszcLWSg >}}

Thanks to [switch conditionals](https://cloud.google.com/workflows/docs/reference/syntax?hl=en#jumps), 
with expressions and jumps, we can have non-linear logic in our workflow definitions. 
In upcoming articles, we will also have a look at how to use more complex data structures 
like arrays and dictionaries, and how to define inputs and outputs.


# Day 3 with Workflows — Variable assignment and expressions


Now that we have multiple steps in our workflow definition, 
let's see how we can pass data around, from a step to another.

![](/img/workflows-days/w03-var-assign.png)

In a step, you can assign values to variables. 
Those values can be ints, doubles, strings, or booleans (and also null). 
Use the `assign` keyword as follows:

```yaml
- assignments:
    assign:
        - two:  2
        - pi:  3.14
        - message:  "Hello"
        - bool:  True
```

Those variables are available in the whole scope of the workflow, and can be accessed in other steps. 
So let's see how we can do something with those variables. 
Let's add a second step to our workflow definition:

```yaml
- twoPi:
    return:  ${"Twice  pi  is  " + string(two * pi)}
```

We are using the `${}` notation to create an expression. 
We're multiplying two numbers, we're converting them to a string, 
and we're concatenating two strings together, to get our final value.

Note that not all operations are allowed on all types, so you might need to do some conversions 
with built-in [conversion functions](https://cloud.google.com/workflows/docs/reference/syntax?hl=en#conversion_functions) like the `string()` function in our example. 
There are all sorts of arithmetic operators or boolean logic operators.

{{< youtube dygoGp_tcCk >}}

For more information, you can read about 
[variable assignments](https://cloud.google.com/workflows/docs/reference/syntax?hl=en#assign-step), 
[data types](https://cloud.google.com/workflows/docs/reference/syntax?hl=en#data_types), and 
[expressions](https://cloud.google.com/workflows/docs/reference/syntax?hl=en#expressions). 
Next time, we'll also have a look at more complex data types.


# Day 2 with Workflows — A workflow is made of steps and jumps


Let's continue our discovery of [Goole Cloud Workflows](https://cloud.google.com/workflows)!

Yesterday, we discovered the UI of Workflows. 
We [created our first workflow]({{< ref "/posts/2020/12/01/day-1-with-workflows-your-first-step-to-hello-world" >}}). 
We started with a single step, returning a greeting message:

```yaml
- sayHello:
    return: Hello from Cloud Workflows!
```

A workflow definition is made of steps. 
But not just one! You can create several steps. 
In YAML, the structure of your workflow will be something like:

```yaml
- stepOne:
    # do something
- stepTwo:
    # do something else
- sayHello:
    return: Hello from Cloud Workflows!
```

By default, steps are executed in the order they appear, from top to bottom. 
The execution will finish when either you return a value, or you reach the final step. 
If there's no return statement, a null value is returned as result of the workflow execution.

A small step for a workflow execution, but you can also do a jump between steps! 
For that, you'll use the next instruction:

```yaml
- stepOne:
    next: stepTwo
- stepThree:
    next: sayHello
- stepTwo:
    next: stepThree
- sayHello:
    return: Hello from Cloud Workflows!
```

Here, we jump between steps, back and forth, before going to the final step that will return a value, and thus finish the execution of our workflow.

{{< youtube BTzb1m5pDXI >}}

Of course, we can go beyond a linear series of steps, and in subsequent articles, 
we'll see how we can create conditional jumps and switches, for more complex logic, 
and how we can pass some data and values between steps.


# Day 1 with Workflows — Your first step to Hello World


With more and more interconnected services, making sense of their interactions becomes critical. 
With Google [Cloud Workflows](https://cloud.google.com/workflows), 
developers can orchestrate and automate such complex systems by creating serverless workflows.

In this series of articles, we will learn together how to use Goole Cloud Workflows, 
and get to know all its features, with short and easy to read tutorials. 
For our first day, we'll discover and use the Workflows UI in the 
[cloud console](https://console.cloud.google.com/). 
We will create a simple "hello world" workflow, consisting of a simple step. 
Going further, in the coming days, we'll learn more about advanced features. 
But first things first!

{{< youtube 75BekrpL-qo >}}

In the Google Cloud console UI, you can locate Workflows in the `Tools` section of the hamburger menu:

![](/img/workflows-days/wf01-01-menu.png)

You can pin this menu item, to have it stick at the top of the list.

The first time you are accessing this page, you'll be greeted with the following screen, 
which will ask you to enable the Workflows API. So just click on `ENABLE`:

![](/img/workflows-days/wf01-02-enable-api.png)

Once the API is enabled, you'll be in the Workflows home screen:

![](/img/workflows-days/wf01-03-workflows-home.png)

Click on the `CREATE` button to create your first workflow definition:

![](/img/workflows-days/wf01-04-empty-state.png)

Find a name for your workflow (it should start with a letter). 
You can provide an optional description. Currently, only "us-central1" 
is available for the beta of Workflows, but more regions will be available later on.

Notice that we have to select a service account that Workflows will use to call other Google Cloud APIs, however here, there's a warning telling us that the project requires a service account. 
As I've created a brand new project, I didn't have any service account created. 
If you had used, for example, Cloud Functions beforehand, a default service account would have been created. If you need to create a service account, 
you can create one in `IAM & Admin > Service Accounts`, then use this one.

My first workflow will be called `w01-first-workflow`:

![](/img/workflows-days/wf01-05-form-filled.png)

Move on to the next section with the `NEXT` button. 
That's where you will define your workflow:

![](/img/workflows-days/wf01-06-definition.png)

This first workflow consists in one single step, called `sayHello`, 
and whose sole purpose is to return a hello world message:

```yaml
- sayHello:
    return: Hello from Cloud Workflows!
```

As you can see, workflow definitions are written using the 
[YAML](https://yaml.org/) configuration language.

Click `DEPLOY` to deploy the workflow. You will then see the details of your new workflow. 
In the "executions" tab, you can see past executions.

![](/img/workflows-days/wf01-07-created.png)

In the `logs` section, you can see the logging messages associated with your workflow creation, deployment and executions:

![](/img/workflows-days/wf01-08-logs.png)

And in the `definitions` section, you can see the YAML description you just created:

![](/img/workflows-days/wf01-09-definition.png)

Now click on the `EXECUTE` button. You will see the input section 
(we'll learn about input arguments in an upcoming article), and the YAML definition. 
Click the other `EXECUTE` button:

![](/img/workflows-days/wf01-10-exec-screen.png)

You will see the result of your execution (`succeeded`, with other details about the execution), 
as well as both the input and the output, with our greeting message:

![](/img/workflows-days/wf01-11-executed.png)

And here you are! You created your first workflow definition, and launched the first execution of this workflow!

In the coming days, we will have a closer look at the structure of workflow definitions (its steps), 
how to define input arguments, but also how to create an execution of a workflow from the command-line.


# Orchestrating microservices with Google Cloud Workflows


The trend toward splitting a monolith into fine-grained loosely-coupled microservices has its merits. 
It allows us to scale parts of an application more easily. Teams become more effective on their focused perimeter. 
However, in a chain or graph of services interacting with each other via message buses or other eventing mechanisms, 
it becomes difficult to understand when things start to break. 
Your business processes spanning those services are in limbo. 
Here starts detective work to find out how to get back on track.

**Choreography**: like a bunch of dancers on the floor composing a ballet. 
Loosely-coupled microservices compose business processes without really being aware of each other, 
casually interacting by receiving and sending messages or events.

**Orchestration**: more like a conductor of an orchestra who directs musicians and their instruments to play each part. 
The approach of using a higher level solution that purposefully invokes and tracks each individual service, 
enables developers to know what the current state of a business process is.

Both approaches have their pros and cons. The loosely-coupled aspects of choreography certainly enables agility. 
But business processes are harder to follow. 
Although orchestration adds a single-point-of-failure with its orchestrator tying all the pieces together, 
it brings clarity in the spaghetti of myriads of microservices.

In addition to GCP's existing messaging ([Cloud Pub/Sub](https://cloud.google.com/pubsub/)) 
and eventing solutions ([Eventarc](https://cloud.google.com/blog/products/serverless/build-event-driven-applications-in-cloud-run)) 
for your service choreography, the newly launched product [Cloud Workflows](https://cloud.google.com/workflows) 
is tackling the orchestration approach.

Cloud Workflows is a scalable fully-managed serverless system that automates and coordinates services, 
takes care of error handling and retries on failure, and tells you if the overall process has finished.

In this short video, during the "demo derby" at Google Cloud Next OnAir, 
I had the chance to present a demo of Cloud Workflows, with some concrete examples:

{{< youtube id="_4fo_u5rY_8" t="7164s" >}}

In this video, I started with the proverbial Hello World, using the Yaml syntax for defining workflows:

```yaml
- hello:
    return: "Hello from Cloud Workflows!"
```

I defined a `hello` step, whose sole purpose is to return a string, as the result of its execution.

Next, I showed that workflow definitions can take arguments, and also return values thanks to more complex expressions:

```yaml
main:
    params: [args]
    steps:
        - returnGreeting:
            return: ${"Hello " + args.first + " " + args.last}
```

Cloud Workflows is able to invoke any HTTP-based service (and supports OAuth2 and OIDC), 
whether in Google Cloud or outside (on premises, or other servers). 
Here, I invoke 2 Cloud Functions:

```yaml
- getRandomNumber:
    call: http.get
    args:
        url: https://us-central1-myprj.cloudfunctions.net/randomNumber
    result: randomNumber
- getNthPoemVerse:
    call: http.get
    args:
        url: https://us-central1-myprj.cloudfunctions.net/theCatPoem
        query:
            nth: ${randomNumber.body.number}
    result: randomVerse
- returnOutput:
    return: ${randomVerse.body}
```

The `getRandomNumber` step calls a function that returns a random number with an HTTP GET, 
and stores the result of that invocation in the `randomNumber` variable.

The `getNthPoemVerse` calls another function that takes a query parameter, 
which is found in the `randomNumber` variable which holds the result of the previous function invocation.

The `returnOutput` step then returns the resulting value.

My fourth example shows variable assignment and conditional switches in action:

```yaml
- getRandomNumber:
    call: http.get
    args:
        url: https://us-central1-myprj.cloudfunctions.net/randomNumber
    result: randomNumber
- assign_vars:
    assign:
        - number: ${int(randomNumber.body.number)}
- conditionalSwitch:
    switch:
        - condition: ${number < 33}
          next: low
        - condition: ${number < 66}
          next: medium
    next: high
- low:
    return: ${"That's pretty small! " + string(number)}
- medium:
    return: ${"Hmm, okay, an average number. " + string(number)}
- high:
    return: ${"It's a big number! " + string(number)}
```

Reusing the random function from the previous example, notice how variables are assigned, 
and how to create a switch with multiple conditions, 
as well as showing how to redirect the execution of the workflow to different steps, depending on the outcome of the switch.

But there's really more to this! You can double check the [syntax reference](https://cloud.google.com/workflows/docs/reference/syntax), 
to see all the constructs you can use in your workflow definitions.

### Summary

Cloud Workflows:

-   Orchestrate Google Cloud and HTTP-based API services into serverless workflows
-   Automate complex processes
-   Fully managed service requires no infrastructure or capacity planning
-   Fast scalability supports scaling down to zero and pay-per-use pricing model

In terms of features:

-   Reliable workflow execution
-   Built-in error handling
-   Passing variable values between workflow steps
-   Built-in authentication for Google Cloud products
-   Low latency of execution
-   Support for external API calls
-   Built-in decisions and conditional step executions
-   Cloud Logging

If you want to get started with [Cloud Workflows](https://cloud.google.com/workflows), you can head over to this [hands-on codelabs](https://codelabs.developers.google.com/codelabs/cloud-workflows-intro#0) from my colleague [Mete Atamel](https://twitter.com/meteatamel). Learn more by watching this [longer video](https://www.youtube.com/watch?v=Uz8G8fTwwXs) by Product Manager Filip Knapik who dives into Cloud Workflows. In upcoming articles, we'll come back to Workflows into more details, diving into some more advanced features, or how to migrate a choreographed example, into an orchestrated one. So, stay tuned!
# The developer advocacy feedback loop


For one of the [closing keynotes](https://2020.devrel.net/speaker/guillaume-laforge/) of [DevRelCon Earth 2020](https://2020.devrel.net/), I spoke about what I call the Developer Advocacy Feedback Loop. People often think about developer relations and advocacy as just being about external outreach. However, there's more to it! Developer Advocates are here to represent users, developers, technical practitioners, to influence the roadmap and development of the services and products to suit their needs. That's the internal advocacy that loops back into improving the products.

Without further ado, let me share with you the slide deck here:

{{< speakerdeck c9aa5be6e7534443963a5b981ef0b713 >}}

Let me paraphrase what I presented in this talk.

For the past 4 years, I've been a Developer Advocate, for Google, focusing on Google Cloud, and especially our serverless solutions (like App Engine, Cloud Functions, Cloud Run). I fell in the magic potion of advocacy, inadvertently, a long time ago while working on an open source project. This project is the [Apache Groovy](http://groovy-lang.org/) programming language. I was leading the project, but at the same time, I was also evangelising it at events, through articles,, and was trying to incorporate the feedback I was getting in the field back into the project. I was doing advocacy without really realizing it, like [Mr Jourdain](https://literature.stackexchange.com/questions/11844/meaning-of-the-prose-of-monsieur-jourdain) in Molière's play who was speaking in prose without knowing it. But I really saw a loop, a feedback loop, in the process, in how you spread the word about technologies, but also how you can listen to the feedback and improve your product.

![](/img/developer-advocacy-feedback-loop/01+-+feedback+loop.png)

If you've studied Electronics, you might have seen such diagrams about the feedback loop. There's something in input, something in output, but there's a loop back, that brings some output back into the input channel. To make the parallel with advocacy... Advocacy is not just a one-way monologue, it's a conversation: you're here to tell a story to your kids for example, but you listen to feedback from the audience, on how to make your story even better. Not just how you tell the story (better intonation, pauses), but really improving the plot, the characters, the setting,≈‹ everything, perhaps making up a totally different story in the end!

![](/img/developer-advocacy-feedback-loop/03+-+devrel+multitude.png)

Let me start with a short disclaimer. If you ask this room to give a definition of developer relations, or developer advocacy, or evangelism (a term I avoid because of its connotations), you'll get as many answers as there are attendees. I don't claim I have THE ultimate definitions for these concepts and approaches. I don't claim those things are the same things, or are different. And anyway, there's not just one way to do it, there's a multitude of ways. They are many things we do the same way, but I'm sure there are many incredible things you do that I'm not even aware of but that I'd like to learn more about! But I'll tell you how I am doing developer advocacy, and where this feedback loop comes into play.

![](/img/developer-advocacy-feedback-loop/02+-+who+are+we.png)

So, who are we? DevRel is not always the same thing everywhere, in every company. And there's not just one way to do DevRel.

Are we salespeople? Not necessarily, I don't get any bucks when I indirectly help sign a new customer deal. My metrics are more about the number of developers reached, or views on my articles or videos, or Twitter impressions.

So are we marketing people? Well, I have some similar metrics for sure, I advertise the products or company I represent, but my goal is that my audience (the technical practitioners) be successful, even if they end up not using my technology. I want my audience to even advocate themselves for those products if possible (if the product is good and makes sense for them).

Are we engineers? In my case, yes I am, I'm even in the Engineering org chart, and to show more empathy towards our engineer users, it's easier if we're engineers ourselves. We speak the same language. We're part of the same community. We have the same tool belt. Also as an engineer, I can even sometimes contribute to the products I talk about. But it's not because you're not an engineer that you can't succeed, and be a good advocate! Empathy is really key in this role, more so probably than engineering chops.

Or are we PMs? In a previous life, in a small startup, I was actually wearing 2 hats: PM & DA. But it's tough to do two jobs like these at the same time. As a DA (without being a PM), with my contributions, my feedback from the field, from the community I advocate for, I do influence the roadmap of our products, for sure. But I'm only a part of the equation. However providing critical product feedback is super important in my job. That's the key aspect of the developer advocacy feedback loop!

Perhaps we're just international travelers? We're measured by the number of visa stamps on our passports? Ah well, maybe. Or maybe not, we try to be greener, but with COVID-19, things have changed recently! The pandemic refines our job, our duties, our ways to communicate. There's lots we can do in the comfort of our home office too.

Ultimately, we're all different, but we all have myriads of ways to contribute and reach our goal. Some of us may be focusing more on awesome videos tutorials, some on organizing hours-long hackathons, and others will be awesome beta-testers for our products, write cristal-clear code samples or SDKs, etc. There's not just one way to be a great Developer Advocate. You don't need to do it all. And we're a team. So we complement each other with our respective strengths. And we work with others too, like marketing, sales, consulting, tech writers, leadership.

![](/img/developer-advocacy-feedback-loop/04+-+our+goal.png)

What do we do, what's our goal? We are empowering our users to reach their goals. We want to make them successful. We're enabling customer success. We're driving mindshare in the field, in our communities. We are making our users happy!

![](/img/developer-advocacy-feedback-loop/05+-+our+tools.png)

How do we make our community, our users, our customers be successful? There are many tools for that. Some of the most well-known tools that we can use are outward facing: it's about external outreach (talks, articles, videos, etc.) But to make our communities more successful, we also need to get our products improved. That's where we create the feedback loop, with our internal influence, thanks to some tools I'll enumerate, we can help make the products better, by bringing our users' feedback up the chain to the PMs, Product Leads, etc. Let me show you.

![](/img/developer-advocacy-feedback-loop/06+-+the+advocacy+loop.png)

Let me introduce you to our personas of my story, of my feedback loop.

![](/img/developer-advocacy-feedback-loop/07+-+the+personnas.png)

At the top, you have the product leadership, the PM, CxOs, the SWEs. At the bottom, that's our users, our customers, our technical practitioners And in the middle, in between, there's you, the Developer Advocate.

![](/img/developer-advocacy-feedback-loop/08+-+company.png)

But in a way, there are two teams. Here, in the white cloud, at the top, that's your company.

![](https://glaforge.appspot.com/media/09+-+community.png)

But at the bottom, that's your community, with your users. You're not just part of the company, you're also part of the community. You are the advocate for your users, representing them to the product leadership, so that their voice is being heard!

![](/img/developer-advocacy-feedback-loop/10+-+external+outreach.png)

That's the external outreach. What some call evangelism, the outward part of the loop. You're the voice of the company. You spread the word on your cool technology. You're creating great demos, code samples, polished videos. You're writing helpful articles, useful tutorials, readable documentation. You're attending and presenting at events to talk about the products. You're helping users succeed by answering questions on social media, StackOverflow, or other forums.

![](/img/developer-advocacy-feedback-loop/11+-+internal+advocacy.png)

What makes it a feedback loop is this part. It's not just a by-product of the external outreach. It's an integral part of the advocacy work. There's the obvious stuff like filing bugs, or being a customer zero by testing the product before it launches. But things like writing trip reports, friction logs, customer empathy sessions may be new to you. If you can, make it a habit to produce such artifacts. And you can list, and track, and report about all those feedback elements that you bring upstream, and check how it's being enacted or not.

Often people think about us mostly for the outreach part, the arrow going downward toward our community. They can think we're just kind of marketing puppets. And I've seen conference organisers complaining they only got "evangelists" at their show, when they wanted "real engineers" instead, working on the products or projects. But frankly, they are not necessarily always the best at explaining their own projects! Folks often forget that we're here to make them successful, and report their feedback, their needs, to advocate for them, and to influence the decision makers to make better products that fill the needs of those users. Both parts are critical! And please pay attention to that feedback loop, to that arrow going back to the top of the slide, to the leadership.

So let's see some concrete examples of the things you can put in place to provide feedback, and show that DevRel is important and has a strong impact.

![](/img/developer-advocacy-feedback-loop/12+-+friction+logs.png)

To make developers happy, you need to remove as much friction as possible. You want the developer experience to be as smooth as possible. You might need to work with UX designers and PMs directly for that. But you can also report about your findings, where you saw friction by writing a friction log. Last week, my colleague Emma [spoke about this](https://www.youtube.com/watch?v=765wLWVcyS0) at DevRelCon Earth, and another great colleague, Aja, wrote about [friction logging](https://devrel.net/developer-experience/an-introduction-to-friction-logging) on DevRel.net a while ago. Great resources to check out!

![](/img/developer-advocacy-feedback-loop/13+-+example+friction+log.png)

I'm going to show you a real friction log. There's some metadata about the environment, date, user name, scenario title, etc. You're reporting about some concrete use case you were trying to implement (an app you were building, a new API you were trying to use, etc.) You document all the steps you followed, and tell what worked or not, how you expected things to work out. This document will be shared broadly via an alias which pings most PMs, tech leads, etc. So it's very visible.

![](/img/developer-advocacy-feedback-loop/14+-+friction+log+color+coding.png)

But the key thing here is the color coding aspect. You show where there's friction, where there's frustration, where you'd quit if you were a real user. But also, it's super important to highlight what worked well, what surprised you, what delighted you. It's not just about the negative things.

![](/img/developer-advocacy-feedback-loop/15+-+tagging+stakeholders.png)

And the last trick to make it effective: add comments, tagging key stakeholders (PMs, Tech Leads, etc), so they really acknowledge the problem. Create associated bug requests, and track them to check if progress is made.

![](/img/developer-advocacy-feedback-loop/16+-+friction+vlog.png)

My colleague [Zack](https://twitter.com/ZackAkil) even developed an application for creating friction vlogs. Video friction logs! With a video, you can show concretely your frustration (but perhaps don't swear too much). A video shows where you struggle, where you lose time. You can navigate to various sections in the video, and annotate those sections, with the green / orange / red color coding scheme. The tool also creates a classical written friction log document as well. I found that application pretty neat, to be honest, especially as it also shows where users struggle, where they lose time.

![](/img/developer-advocacy-feedback-loop/17+-+advocacy+reporting.png)

You can apply the same approach to other kinds of reporting activities. We often write reports for our trips, events, meetups, customer engagements. In particular, although we're not sales people, we're trying to show that we also have an impact on sales. Customers love having DevRel people come and show cool stuff! And we can collect and show the feedback coming from the field to the leadership. It's not just us sharing our own impressions and ideas, it's really coming from someone else's mouth, so it has more weight in the conversation. I'd like to highlight our internal advocacy reporting: we have someone on the team that collects all our bug reports (and included them in bug hotlists), all our friction logs, our trip reports, and who actively tracks how this feedback is taken into account, and it's a very effective way of showing that we do have impact to the leadership, beyond the usual metrics. And by the way, even those DevRel product feedback reports make use of the color coding we have in friction logs. So it's a very familiar thing for all our engineering team.

![](/img/developer-advocacy-feedback-loop/18+-+customer+empathy+sessions.png)

Another interesting thing we're running is what we call customer empathy sessions, a concept invented by my colleague [Kim](https://twitter.com/kmbannerman). Gather various PMs, SWEs, DevRel people, potentially customers but not mandatory, in the same room (or virtually nowadays) and craft some concrete scenarios of something you'd like them to build in small groups (but where you know there's gonna be lots of friction). With teams of 3 or more, each one has a role: a driver, a scribe, and a searcher. Have them do the task. Then compare copies at the end. It's a bit like creating new Critical User Journeys that have not been addressed, that exhibit a lot of friction. But this time the engineers, the PM, will really feel the very same frustration our customers can potentially feel when they can't accomplish their tasks. The various teams often work in silos, on a particular aspect, and avoid certain paths (when you know you shouldn't click somewhere, you won't do it, you'll use the other path you know works). But customer empathy sessions are here to show what our users have to go through in real scenarios, beyond a handful of critical journeys. In summary, feel the pain, and show empathy toward your customers! Really, I won't stress this enough, but empathy is key here, and a real driver for positive change.

![](/img/developer-advocacy-feedback-loop/19+-+hallway+track+office+hours.png)

We can do scalable advocacy, by creating things like videos that are broadcasted to many thousands of watchers. That have a long shelf time, which is less ephemeral than a conference talk. But sometimes, it's also good to do things that actually don't scale. Helping one single person can make a big difference: at a conference after my talk, I had a long conversation with an attendee that had a particular need. I onboarded them on our early access program for a new product, which seemed to be what they needed. They could provide key feedback to our PMs and engineers. And they helped us get that new product ready with a real use case. And the next year, the attendee was a key customer, that even came on stage to talk about the product. So I both won a new customer and a new advocate for that product. So the hallway track at events is very important. And that's the kind of feedback signals I'm missing in those times of pandemic.

Another approach is office hours: you set up some time slots in your calendar, and anyone can book time with you. That's a great way to get feedback, and see what problems users are facing. I haven't tried that myself, as I'm a bit shy, and afraid someone would ask questions on topics I don't know much about! But that's very effective, and I have several colleagues doing that, and who are learning along the way.

![](/img/developer-advocacy-feedback-loop/20+-+create+new+products.png)

Sometimes, your community, your users, will highlight a missing gap in your product portfolio. And it might give you some ideas of a product that would delight those persons, and they could become customers if you had that product. So that's actually how some of my colleagues went on creating totally new products, for example for gaming companies, or for secret management. On another occasion, as I had strong ideas on how a new product runtime should look like, I went on designing and prototyping an API that our users would use. Somehow, it's a bit like being the change you want to see in the world! And the API I designed, further improved with the engineering team, is now an API our customers are using today.

![](/img/developer-advocacy-feedback-loop/21+-+pudding.png)

Time to wrap up. Often, the proof is in the pudding. It's not just about our intuitions or own personal experience. You need to gather feedback, in particular concrete customer feedback, to prove that you're right. And when it's a customer with some money to spend, usually product leadership listens.

![](/img/developer-advocacy-feedback-loop/22+-+roses.png)

Sometimes, it's all roses and bloom! Our feedback, ideas, features are implemented! Woohoo! Success!

![](/img/developer-advocacy-feedback-loop/23+-+brick+wall.png)

There's the ideal world where we indeed influence products, but sometimes, we also hit a brick wall, a dead end, we're not at the helm, and our feedback is not taken into account. Our companies can be big, work in silos, and it's sometimes a struggle to find the right people who are able to listen to us, and are able to get change enacted. Be resilient, let it not affect you personally, but return to the charge if you really think it's important for your community!

![](/img/developer-advocacy-feedback-loop/06+-+the+advocacy+loop.png)

Remember: We're in it together! It's a team's effort. Let's make our users happy! And how to make them happy? By making great products, with great user and developer experience. By showing empathy toward our users, wear their shoes, listen to their feedback, and let that feedback be heard up above, to improve our products, by advocating for our users. That's where the feedback loop closes. Thanks for your attention.
# Running Micronaut serverlessly on Google Cloud Platform


Last week, I had the pleasure of presenting [Micronaut](https://micronaut.io/) in action on Google Cloud Platform, via a [webinar](https://objectcomputing.com/products/micronaut/resources/serverless-micronaut-on-google-cloud) organized by OCI. Particularly, I focused on the serverless compute options available: [Cloud Functions](https://cloud.google.com/functions), [App Engine](http://cloud.google.com/appengine), and [Cloud Run](https://cloud.google.com/run).

Here are the slides I presented. However, the real meat is in the demos which are not displayed on this deck! So let's have a closer look at them, until the video is published online.

{{< speakerdeck 9da7fe86bd4047508effb1ae34af5ed0 >}}

On Google Cloud Platform, you have three solutions when you want to deploy your code in a serverless fashion (ie. hassle-free infrastructure, automatic scaling, pays-as-you-go): 

-   For event-oriented logic that reacts to cloud events (a new file in cloud storage, a change in a database document, a Pub/Sub message) you can go with a function. 
-   For a web frontend, a REST API, a mobile API backend, also for serving static assets for single-page apps, App Engine is going to do wonders. 
-   But you can also decide to containerize your applications and run them as containers on Cloud Run, for all kinds of needs.

Both Cloud Functions and App Engine provide a Java 11 runtime (the latest LTS version of Java at the time of writing), but with Cloud Run, in a container, you can of course package whichever Java runtime environment that you want.

And the good news is that you can run Micronaut easily on all those three environments!

## Micronaut on Cloud Functions

### HTTP functions

Of those three solutions, Cloud Functions is the one that received a special treatment, as the Micronaut team worked on a [dedicated integration](https://micronaut-projects.github.io/micronaut-gcp/2.0.x/guide/#cloudFunction) with the [Functions Framework API](https://github.com/GoogleCloudPlatform/functions-framework-java) for Java. Micronaut supports both types of functions: HTTP and background functions.

For HTTP functions, you can use a plain Micronaut controller. Your usual controllers can be turned into an HTTP function.

```java
package com.example;

import io.micronaut.http.annotation.*;

@Controller("/hello")
public class HelloController {
    @Get(uri="/", produces="text/plain")
    public String index() {
        return "Micronaut on Cloud Functions";
    }
}
```

Micronaut Launch tool even allows you to create a dedicated scaffolded project with the right configuration (ie. the right Micronaut integration JAR, the Gradle configuration, including for running functions locally on your machine.) Pick the application type in the Launch configuration, and add the `google-cloud-function` module.

In build.gradle, Launch will add the Functions Frameworks' invoker dependency, which allows you to run your functions locally on your machine (it's also the framework that is used in the cloud to invoke your functions, ie. the same portable and open source code):

```groovy
invoker("com.google.cloud.functions.invoker:java-function-invoker:1.0.0-beta1")
```

It adds the Java API of the Functions Framework, as `compileOnly` as it's provided by the platform when running in the cloud:

```groovy
compileOnly("com.google.cloud.functions:functions-framework-api")
```

And Micronaut's own GCP Functions integration dependency:

```groovy
implementation("io.micronaut.gcp:micronaut-gcp-function-http")
```

And there's also a new task called `runFunction`, which allows you to run your function locally:

```bash
./gradlew runFunction
```

If you decide to use Maven, the same dependencies are applied to your project, but there's a dedicated Maven plugin that is provided to run functions locally.

```
./mvnw function:run
```

Then to deploy your HTTP function, you can learn more about the topic in the [documentation](https://cloud.google.com/functions/docs/deploying). If you deploy with the gcloud command-line SDK, you will deploy with a command similar to the following one (depending on the region, or size of the instance you want to use):

```bash
gcloud functions deploy hello \
    --region europe-west1 \
    --trigger-http --allow-unauthenticated \
    --runtime java11 --memory 512MB \
    --entry-point io.micronaut.gcp.function.http.HttpFunction
```

Note that Cloud Functions can build your functions from sources when you deploy, or it can deploy a pre-build shadowed JAR (as configured by Launch.)

### Background functions

For background functions, in Launch, select the Micronaut serverless function type. Launch will create a class implementing the BackgroundFunction interface from the Function Frameworks APIs. But it will extend the `GoogleFunctionInitializer` class from Micronaut's function integration, which takes care of all the usual wiring (like dependency injection). This function by default receives a Pub/Sub message, but there are other types of events that you can receive, like when a new file is uploaded in cloud storage, a new or changed document in the Firestore nosql document database, etc.

```java
package com.example;

import com.google.cloud.functions.*;
import io.micronaut.gcp.function.GoogleFunctionInitializer;
import javax.inject.*;
import java.util.*;

public class PubSubFunction extends GoogleFunctionInitializer
        implements BackgroundFunction {
    @Inject LoggingService loggingService;
    @Override
    public void accept(PubSubMessage pubsubMsg, Context context) {
        String textMessage = new String(Base64.getDecoder().decode(pubsubMsg.data));
        loggingService.logMessage(textMessage);
    }
}

class PubSubMessage {
    String data;
    Map attributes;
    String messageId;
    String publishTime;
}

@Singleton
class LoggingService {
    void logMessage(String txtMessage) {
        System.out.println(txtMessage);
    }
}
```

When deploying, you'll define a different trigger, for example here, it's a Pub/Sub message, so you'll use a `--trigger-topic TOPIC_NAME` flag to tell the platform you want to receive messages on that topic.

For deployment, the gcloud command would look as follows:

```bash
gcloud functions deploy pubsubFn \
    --region europe-west1 \
    --trigger-topic TOPIC_NAME \
    --runtime java11 --memory 512MB \
    --entry-point com.example.PubSubFunction
```

## Micronaut on App Engine

Micronaut deploys fine as well on App Engine. I [wrote about it]({{< ref "/posts/2019/07/04/getting-started-with-micronaut-on-google-app-engine-java-11" >}}) in the past already. If you're using Micronaut Launch, just select the Application type. App Engine allows you to deploy the standalone runnable JARs generated by the configured shadow JAR plugin. But if you want to easily stage your application deliverable, to run the application locally, to deploy, you can also use the Gradle App Engine plugin.

For that purpose, you should add the following build script section in `build.gradle`:

```groovy
buildscript {
    repositories {
        mavenCentral()
    }
    dependencies {
        classpath 'com.google.cloud.tools:appengine-gradle-plugin:2.3.0'
    }
}
```

And then apply the plugin with:

```groovy
apply plugin: 'com.google.cloud.tools.appengine'
```

Before packaging the application, there's one extra step you need to go through, which is to add the special App Engine configuration file: app.yaml. You only need to add one line, unless you want to further configure the instance types, specify some JVM flags, point at static assets, etc. But otherwise, you only need this line in `src/main/appengine/app.yaml`:

```yaml
runtime: java11
```

Then, stage your application deliverable with:

```bash
./gradlew appengineStage
```

Cd in the directory, and you can deploy with the plugin or with the gcloud SDK:

```bash
cd build/staged-app/
gcloud app deploy
```

During the demonstration, I showed a controller that was accessing some data from the [Cloud Firestore](https://cloud.google.com/firestore/) nosql database, listing some pet names:

```java
package com.example;

import java.util.*;
import com.google.api.core.*;
import com.google.cloud.firestore.*;
import com.google.cloud.firestore.*;
import io.micronaut.http.annotation.*;

@Controller("/")
public class WelcomeController {
    @Get(uri="/", produces="text/html")
    public String index() {
        return "Hello Google Cloud!";
    }

    @Get(uri="/pets", produces="application/json")
    public String pets() throws Exception {
        StringBuilder petNames = new StringBuilder().append("[");
        FirestoreOptions opts = FirestoreOptions.getDefaultInstance();
        Firestore db = opts.getService();
        ApiFuture query = db.collection("pets").get();
        QuerySnapshot querySnapshot = query.get();
        List documents = querySnapshot.getDocuments();
        for (QueryDocumentSnapshot document : documents) {
            petNames.append("\"")
                .append(document.getString("name"))
                .append("\", ");
        }
        return petNames.append("]").toString();
    }
}
```

## Micronaut on Cloud Run

### Building a Micronaut container image with Jib

In a previous article, I talked about how to try [Micronaut with Java 14 on Google Cloud]({{< ref "/posts/2020/03/24/start-the-fun-with-java-14-and-micronaut-inside-serverless-containers-on-cloud-run" >}}). I was explaining how to craft your own `Dockerfile`, instead of the one generated then by default by Micronaut Launch (now, it is using `openjdk:14-alpine`). But instead of fiddling with Docker, in my demos, I thought it was cleaner to use Jib. [Jib](https://github.com/GoogleContainerTools/jib) is a tool to create cleanly layered container images for your Java applications, without requiring a Docker daemon. There are plugins available for Gradle and Maven, I used the Gradle one by configuring my `build.gradle` with:

```groovy
plugins {
    ...
    id "com.google.cloud.tools.jib" version "2.4.0"
}
```

And by configuring the `jib` task with:

```groovy
jib {
    to {
        image = "gcr.io/serverless-micronaut/micronaut-news"
    }
    from {
        image = "openjdk:14-alpine"
    }
}
```

The from/image line defines the base image to use, and the `to`/`image` points at the location in Google Cloud Container Registry where the image will be built, and we can then point Cloud Run at this image for deployment:

```bash
gcloud config set run/region europe-west1
gcloud config set run/platform managed

./gradlew jib

gcloud run deploy news --image gcr.io/serverless-micronaut/micronaut-news --allow-unauthenticated
```

## Bonus points: Server-Sent Events

In the demo, I showed the usage of [Server-Sent Events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events). Neither Cloud Functions nor App Engine support any kind of streaming, as there's a global frontend server in the Google Cloud infrastructure that buffers requests and responses. But Cloud Run supports streaming (HTTP/2 streaming, gRPC streaming, server-sent events, and WebSocket streaming).

So that was a great excuse to play with Micronaut's SSE support. I went with a slightly modified example from the documentation, to emit a few string messages a second apart:

```java
package com.example;

import io.micronaut.http.MediaType;
import io.micronaut.http.annotation.*;
import io.micronaut.http.sse.Event;
import io.micronaut.scheduling.TaskExecutors;
import io.micronaut.scheduling.annotation.ExecuteOn;
import io.reactivex.Flowable;
import org.reactivestreams.Publisher;

@Controller("/news")
public class NewsController {
    @ExecuteOn(TaskExecutors.IO)
    @Get(produces = MediaType.TEXT_EVENT_STREAM)
    public Publisher> index() { 
        String[] ids = new String[] { "1", "2", "3", "4", "5" };
        return Flowable.generate(() -> 0, (i, emitter) -> { 
            if (i < ids.length) {
                emitter.onNext( 
                    Event.of("Event #" + i)
                );
                try { Thread.sleep(1000); } catch (Throwable t) {}
            } else {
                emitter.onComplete(); 
            }
            return ++i;
        });
    }
}
```

Then I accessed the /news controller and was happy to see that the response was not buffered and that the events were showing up every second.

Apart from getting on board of this alpha feature of Cloud Run (via the form mentioned to get my GCP project whitelisted), I didn't have to do anything special to my Micronaut setup from the previous section. No further configuration required, it just worked out of the box.

## Summary

The great benefit to using Micronaut on Google Cloud Platform's serverless solutions is that thanks to Micronaut's ahead-of-time compilation techniques, it starts and runs super fast, and consumes much less memory than other Java frameworks. Further down the road, you can also take advantage of GraalVM for even faster startup and lower memory usage. Although my examples were in Java, you can also use Kotlin or Groovy if you prefer.
# Video: Getting started with Java on Google Cloud Functions


For the 24 hours of talks by Google Cloud DevRel, I recorded my talk about the new Java 11 runtime for Google Cloud Functions. 
I wrote about this runtime in this [article](http://glaforge.appspot.com/article/deploying-serverless-functions-in-groovy-on-the-new-java-11-runtime-for-google-cloud-functions) 
showing for example how to run [Apache Groovy](https://groovy-lang.org/) functions, and I also wrote about it on the 
[GCP blog](https://cloud.google.com/blog/products/application-development/introducing-java-11-on-google-cloud-functions) 
and [Google Developers blog](https://developers.googleblog.com/2020/05/java-11-for-cloud-functions.html) as well.

In this video, I'm giving a quick explanations on the serverless approach, the various serverless options provided by Google Cloud, 
and then I dive into the various shapes Java functions can take (HTTP and background functions), 
the interfaces you have to implement when authoring a function. 
And I also do various demonstrations, deploying Java functions, Groovy functions, or Micronaut functions!

{{< youtube d7eYFI-jbcc >}}
# Introducing Java 11 on Google Cloud Functions


The Java programming language recently turned 25 years old, and it's still one of the top-used languages powering today's enterprise application customers. On Google Cloud, you can already run serverless Java microservices in App Engine and Cloud Run. Today we're bringing Java 11 to Google Cloud Functions, an event-driven serverless compute platform that lets you run locally or in the cloud without having to provision servers. That means you can now write Cloud Functions using your favorite JVM languages ([Java](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/functions/helloworld/helloworld), [Kotlin](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/functions/helloworld/kotlin-helloworld), [Groovy](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/functions/helloworld/groovy-helloworld), [Scala](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/functions/helloworld/scala-helloworld), etc) with our [Functions Framework for Java](https://github.com/GoogleCloudPlatform/functions-framework-java), and also with [Spring Cloud Functions](https://cloud.spring.io/spring-cloud-static/spring-cloud-function/3.0.6.RELEASE/reference/html/gcp.html) and [Micronaut](https://micronaut-projects.github.io/micronaut-gcp/2.0.x/guide/#simpleFunctions)!

With Cloud Functions for Java 11, now in beta, you can use Java to build business-critical applications and integration layers, and deploy the function in a fully managed environment, complete with access to resources in a private VPC network. Java functions will scale automatically based on your load. You can write [HTTP functions](https://cloud.google.com/functions/docs/writing/http) to respond to HTTP events, and [background functions](https://cloud.google.com/functions/docs/writing/background) to process events sourced from various cloud and GCP services, such as Pub/Sub, Cloud Storage, Firestore, and more.

![/img/j11gcf/Cloud_Functions__Product_Strategy-01.jpg](/img/j11gcf/Cloud_Functions__Product_Strategy-01.jpg)

Functions are a great fit for serverless application backends for integrating with third-party services and APIs, or for mobile or IoT backends. You can also use functions for real-time data processing systems, like processing files as they are uploaded to Cloud Storage, or to handle real-time streams of events from Pub/Sub. Last but not least, functions can serve intelligent applications like virtual assistants and chat bots, or video, image and sentiment analysis.

## Cloud Functions for Java 11 example

{{< youtube UsYRKkibLPI >}}

You can develop functions using the [Functions Framework for Java](https://github.com/GoogleCloudPlatform/functions-framework-java/), an open source functions-as-a-service framework for writing portable Java functions. You can develop and run your functions locally, deploy them to Cloud Functions, or to another Java environment.

An HTTP function simply implements the [`HttpFunction`](https://javadoc.io/static/com.google.cloud.functions/functions-framework-api/1.0.1/com/google/cloud/functions/HttpFunction.html) interface:

```java
public class HelloWorld implements HttpFunction {
    @Override
    public void service(HttpRequest request, HttpResponse response)
        throws IOException {
        var writer = response.getWriter();
        writer.write("Hello world!");
    }
}
```

Add the Functions Framework API dependency to the Maven pom.xml:


```xml
<dependency>
    <groupId>com.google.cloud.functions</groupId>
    <artifactId>functions-framework-api</artifactId>
    <version>1.0.1</version>
    <scope>provided</scope>
</dependency>
```

Then add the the [Function Maven plugin](https://github.com/GoogleCloudPlatform/functions-framework-java#running-a-function-with-the-maven-plugin) so you can run the function locally:

```xml
<plugin>
 <groupId>com.google.cloud.functions</groupId>
 <artifactId>function-maven-plugin</artifactId>
 <version>0.9.2</version>
 <configuration>
 <functionTarget>function.HelloWorld</functionTarget>
 </configuration>
</plugin>
```

Run the function locally:

```bash
mvn function:run
```

You can also use your IDE to launch this Maven target in Debugger mode to debug the function locally.

![/img/j11gcf/2_Cloud_Functions_for_Java_11.max-900x900.png](/img/j11gcf/2_Cloud_Functions_for_Java_11.max-900x900.png)

To deploy the function, you can use the gcloud command line:

```bash
gcloud beta functions deploy helloworld-function \
 --entry-point function.HelloWorld --runtime java11 --trigger-http
```

Alternatively, you can also deploy with the Function Maven plugin:

```bash
mvn function:deploy -Dfunction.deploy.name=helloworld-function
```


You can find the [full example on GitHub](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/functions/helloworld/helloworld). In addition to running this function in the fully managed Cloud Functions environment, you can also [bring the Functions Framework runtime](https://github.com/GoogleCloudPlatform/functions-framework-java#running-the-functions-framework-directly) with you to other environments, such as Cloud Run, Google Kubernetes Engine, or a virtual machine. In addition, Java 8 users can now take advantage of Java 11 features. The majority of the use cases of the Java 8 programming model are supported in Java 11.

## Third-party framework support

In addition to our Functions Framework for Java, both the [Micronaut ](https://micronaut-projects.github.io/micronaut-gcp/2.0.x/guide/#simpleFunctions)framework and the [Spring Cloud Function](https://spring.io/projects/spring-cloud-function) project now have out-of-the-box support for Google Cloud Functions. You can create both an HTTP function and background function using the respective framework's programming model, including capabilities like dependency injection.

### Micronaut

The Micronaut team implemented dedicated support for the Cloud Functions Java 11 runtime. Instead of implementing Functions Framework's HttpFunction interface directly, you can use Micronaut's programming model, such that a Helloworld HTTP Function can simply be a [Micronaut controller](https://docs.micronaut.io/2.0.0.M2/guide/index.html#creatingServer):

```java
@Controller("/hello")
public class HelloController {
    @Get("/{name}")
    String greet(String name) {
        return "Hello " + name;
    }
}
```

You can find a [full example of Micronaut with Cloud Functions](https://github.com/micronaut-projects/micronaut-gcp/tree/master/examples/hello-world-cloud-function) and its [documentation](https://micronaut-projects.github.io/micronaut-gcp/snapshot/guide/#httpFunctions) on GitHub.

### Spring Cloud Functions

The Google Cloud Java Frameworks team worked with the Spring team to bring [Spring Cloud GCP](https://spring.io/projects/spring-cloud-gcp) project to help Spring Boot users easily leverage Google Cloud services. More recently, the team worked with the Spring Cloud Function team to bring you [Spring Cloud Function GCP Adapter](https://cloud.spring.io/spring-cloud-static/spring-cloud-function/3.0.7.RELEASE/reference/html/gcp.html). A function can just be a vanilla Java function, so you can run a Spring Cloud Function application on Cloud Functions without having to modify your code to run on Google Cloud.

```java
@Bean
public Function<String, String> uppercase() {
    return value -> value.toUpperCase();
}
```

You can find a full example of a [Spring Cloud Function with Cloud Functions](https://github.com/spring-cloud/spring-cloud-function/tree/master/spring-cloud-function-samples/function-sample-gcp-http) on GitHub.

## JVM Languages

In addition to using the [latest Java 11 language features](https://advancedweb.hu/new-language-features-since-java-8-to-14/) with Cloud Functions, you can also use your favorite JVM languages, such as Kotlin, Groovy, and Scala, and more. For example, here's a function written with Kotlin:

```kotlin
class HelloWorld : HttpFunction {
    fun helloWorld(req: HttpRequest, res: HttpResponse) {
        with(res.writer) {
            write("Hello Kotlin World!")
        }
    }
}
```

Here's the same function with Groovy:

```groovy
class HelloWorld implements HttpFunction {
    void service(HttpRequest req, HttpResponse res) {
        res.writer.write("Hello Groovy World!")
    }
}
```

You can take a [deeper dive into a Groovy example](http://glaforge.appspot.com/article/deploying-serverless-functions-in-groovy-on-the-new-java-11-runtime-for-google-cloud-functions), and otherwise, find all the examples on GitHub ([Kotlin](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/functions/helloworld/kotlin-helloworld), [Groovy](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/functions/helloworld/groovy-helloworld), [Scala](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/functions/helloworld/scala-helloworld)).

## Try Cloud Functions for Java 11 today

Cloud Functions for Java 11 is now in beta, so you can try it today with your favorite JVM language and frameworks. Read the [Quick Start guide](https://cloud.google.com/functions/docs/quickstart-java), learn how to [write your first functions](https://cloud.google.com/functions/docs/first-java), and try it out with a Google Cloud Platform [free trial](https://cloud.google.com/free). If you want to dive a little bit deeper into the technical aspects, you can also read this [article on Google Developers blog](https://developers.googleblog.com/2020/05/java-11-for-cloud-functions.html). If you're interested in the [open-source Functions Framework](https://github.com/GoogleCloudPlatform/functions-framework-java) for Java, please don't hesitate to have a look at the project and potentially even contribute to it. We're looking forward to seeing all the Java the functions you write! 

* * * * *

*Special thanks to Googlers Éamonn McManus, Magda Zakrzewska‎, Sławek Walkowski, Ludovic Champenois, Katie McCormick, Grant Timmerman, Ace Nassri, Averi Kitsch, Les Vogel, Kurtis Van Gent, Ronald Laeremans, Mike Eltsufin, Dmitry Solomakha, Daniel Zou, Jason Polites, Stewart Reichling, Michael Skura, Karol Farbiś, and Vinod Ramachandran. We also want to thank [Micronaut](https://micronaut.io/) and [Spring Cloud Function](https://spring.io/projects/spring-cloud-function) teams for working on the Cloud Functions support!*

# Sip a Cup of Java 11 for Your Cloud Functions


With the [beta of the new Java 11 runtime](https://cloud.google.com/blog/products/application-development/introducing-java-11-on-google-cloud-functions) for Google [Cloud Functions](https://cloud.google.com/functions), Java developers can now write their functions using the Java programming language (a language often used in enterprises) in addition to Node.js, Go, or Python. Cloud Functions allow you to run bits of code locally or in the cloud, without provisioning or managing servers: Deploy your code, and let the platform handle scaling up and down for you. Just focus on your code: handle incoming HTTP requests or respond to some cloud events, like messages coming from Cloud Pub/Sub or new files uploaded in Cloud Storage buckets.

In this article, let's focus on what functions look like, how you can write portable functions, how to run and debug them locally or deploy them in the cloud or on-premises, thanks to the [Functions Framework](https://github.com/GoogleCloudPlatform/functions-framework-java), an open source library that runs your functions. But you will also learn about third-party frameworks that you might be familiar with, that also let you create functions using common programming paradigms.

## The shape of your functions

There are two types of functions: [HTTP functions](https://cloud.google.com/functions/docs/writing/http), and [background functions](https://cloud.google.com/functions/docs/writing/background). HTTP functions respond to incoming HTTP requests, whereas background functions react to cloud-related events.

The Java Functions Framework provides an [API](https://javadoc.io/doc/com.google.cloud.functions/functions-framework-api/latest/index.html) that you can use to author your functions, as well as an invoker which can be called to run your functions locally on your machine, or anywhere with a Java 11 environment.

To get started with this API, you will need to add a dependency in your build files. If you use Maven, add the following dependency tag in `pom.xml`:

```xml
<dependency>
    <groupId>com.google.cloud.functions</groupId>
    <artifactId>functions-framework-api</artifactId>
    <version>1.0.1</version>
    <scope>provided</scope>
</dependency>
```

If you are using Gradle, add this dependency declaration in `build.gradle`:

```groovy
compileOnly("com.google.cloud.functions:functions-framework-api")
```

### Responding to HTTP requests

A Java function that receives an incoming HTTP request implements the `[HttpFunction](https://javadoc.io/doc/com.google.cloud.functions/functions-framework-api/latest/com/google/cloud/functions/HttpFunction.html)` interface:

```java
import com.google.cloud.functions.*;
import java.io.*;

public class Example implements HttpFunction {
    @Override
    public void service(HttpRequest request, HttpResponse response)
            throws IOException {
        var writer = response.getWriter();
        writer.write("Hello developers!");
    }
}
```

The `service()` method provides an `[HttpRequest](https://javadoc.io/doc/com.google.cloud.functions/functions-framework-api/latest/com/google/cloud/functions/HttpRequest.html)` and an `[HttpResponse](https://javadoc.io/doc/com.google.cloud.functions/functions-framework-api/latest/com/google/cloud/functions/HttpResponse.html)` object. From the request, you can get information about the HTTP headers, the payload body, or the request parameters. It's also possible to handle multipart requests. With the response, you can set a status code or headers, define a body payload and a content-type.

Responding to cloud events
--------------------------

Background functions respond to events coming from the cloud, like new [Pub/Sub](https://cloud.google.com/pubsub) messages, [Cloud Storage](https://cloud.google.com/storage) file updates, or new or updated data in [Cloud Firestore](https://cloud.google.com/firestore). There are actually two ways to implement such functions, either by dealing with the JSON payloads representing those events, or by taking advantage of object marshalling thanks to the [Gson](https://github.com/google/gson) library, which takes care of the parsing transparently for the developer.

With a [RawBackgroundFunction](https://javadoc.io/doc/com.google.cloud.functions/functions-framework-api/latest/com/google/cloud/functions/RawBackgroundFunction.html), the responsibility is on you to handle the incoming cloud event JSON-encoded payload. You receive a JSON string, so you are free to parse it however you like, with your JSON parser of your choice:

```java
import com.google.cloud.functions.Context;
import com.google.cloud.functions.RawBackgroundFunction;

public class RawFunction implements RawBackgroundFunction {
    @Override
    public void accept(String json, Context context) {
        ...
    }
}
```

But you also have the option to write a [BackgroundFunction](https://javadoc.io/doc/com.google.cloud.functions/functions-framework-api/latest/com/google/cloud/functions/BackgroundFunction.html) which uses Gson for unmarshalling a JSON representation into a Java class (a POJO, Plain-Old-Java-Object) representing that payload. To that end, you have to provide the POJO as a generic argument:

```java
import com.google.cloud.functions.Context;
import com.google.cloud.functions.BackgroundFunction;

public class PubSubFunction implements BackgroundFunction<PubSubMsg> {
    @Override
    public void accept(PubSubMsg msg, Context context) {
        System.out.println("Received message ID: " + msg.messageId);
    }
}

public class PubSubMsg {
    String data;
    Map<String, String> attributes;
    String messageId;
    String publishTime;
}
```

The [Context](https://javadoc.io/doc/com.google.cloud.functions/functions-framework-api/latest/com/google/cloud/functions/Context.html) parameter contains various metadata fields like timestamps, the type of events, and other attributes.

Which type of background function should you use? It depends on the control you need to have on the incoming payload, or if the Gson unmarshalling doesn't fully fit your needs. But having the unmarshalling covered by the framework definitely streamlines the writing of your function.

## Running your function locally

Coding is always great, but seeing your code actually running is even more rewarding. The Functions Framework comes with the API we used above, but also with an invoker tool that you can use to run functions locally. For improving developer productivity, having a direct and local feedback loop on your own computer makes it much more comfortable than deploying in the cloud for each change you make to your code.

### With Maven

If you're building your functions with Maven, you can install the Function Maven plugin in your `pom.xml`:

```xml
<plugin>
    <groupId>com.google.cloud.functions</groupId>
    <artifactId>function-maven-plugin</artifactId>
    <version>0.9.2</version>
    <configuration>
        <functionTarget>com.example.Example</functionTarget>
    </configuration>
</plugin>
```

On the command-line, you can then run:

```bash
$ mvn function:run
```

You can pass extra parameters like `--target` to define a different function to run (in case your project contains several functions), `--port` to specify the port to listen to, or `--classpath` to explicitly set the classpath needed by the function to run. These are the parameters of the underlying `[Invoker](https://github.com/GoogleCloudPlatform/functions-framework-java/blob/master/invoker/core/src/main/java/com/google/cloud/functions/invoker/runner/Invoker.java)` class. However, to set these parameters via the Maven plugin, you'll have to pass properties with `-Drun.functionTarget=com.example.Example` and `-Drun.port`.

### With Gradle

With Gradle, there is no dedicated plugin, but it's easy to configure `build.gradle` to let you run functions.

First, define a dedicated configuration for the invoker:

```groovy
configurations {
    invoker
}
```

In the dependencies, add the Invoker library:

```groovy
dependencies {
    invoker 'com.google.cloud.functions.invoker:java-function-invoker:1.0.0-beta1'
}
```

And then, create a new task to run the Invoker:

```groovy
tasks.register("runFunction", JavaExec) {
    main = 'com.google.cloud.functions.invoker.runner.Invoker'
    classpath(configurations.invoker)
    inputs.files(configurations.runtimeClasspath,
                 sourceSets.main.output)
    args('--target',
         project.findProperty('runFunction.target') ?:
         'com.example.Example',
         '--port',
         project.findProperty('runFunction.port') ?: 8080
    )
    doFirst {
        args('--classpath', files(configurations.runtimeClasspath,
                                  sourceSets.main.output).asPath)
    }
}
```

By default, the above launches the function `com.example.Example` on port 8080, but you can override those on the command-line, when running gradle or the gradle wrapper:

```bash
$ gradle runFunction -PrunFunction.target=com.example.HelloWorld\
                     -PrunFunction.port=8080
```

### Running elsewhere, making your functions portable

What's interesting about the [Functions Framework](https://github.com/GoogleCloudPlatform/functions-framework-java) is that you are not tied to the Cloud Functions platform for deploying your functions. As long as, in your target environment, you can run your functions with the Invoker class, you can run your functions on [Cloud Run](https://cloud.google.com/run), on [Google Kubernetes Engine](https://cloud.google.com/kubernetes-engine), on [Knative](https://cloud.google.com/knative/) environments, on other clouds when you can run Java, or more generally on any servers on-premises. It makes your functions highly portable between environments. But let's have a closer look at deployment now.

## Deploying your functions

You can [deploy](https://github.com/GoogleCloudPlatform/functions-framework-java/blob/master/invoker/function-maven-plugin/src/main/java/com/google/cloud/functions/plugin/DeployFunction.java) functions with the Maven plugin as well, with various parameters to tweak for defining regions, memory size, etc. But here, we'll focus on using the [cloud SDK](https://cloud.google.com/sdk), with its `gcloud` command-line, to deploy our functions.

For example, to deploy an HTTP function, you would type:

```bash
$ gcloud functions deploy exampleFn\
    --region europe-west1\
    --trigger-http\
    --allow-unauthenticated\
    --runtime java11\
    --entry-point com.example.Example\
    --memory 512MB
```

For a background function that would be notified of new messages on a Pub/Sub topic, you would launch:

```bash
$ gcloud functions deploy exampleFn\
    --region europe-west1\
    --trigger-topic msg-topic\
    --runtime java11\
    --entry-point com.example.PubSubFunction\
    --memory 512MB
```

Note that deployments come in two flavors as well, although the above commands are the same: functions are deployed from source with a `pom.xml` and built in Google Cloud, but when using a build tool other than Maven, you can also use the same command to deploy a pre-compiled JAR that contains your function implementation. Of course, you'll have to create that JAR first.

## What about other languages and frameworks?

So far, we looked at Java and the plain [Functions Framework](https://github.com/GoogleCloudPlatform/functions-framework-java), but you can definitely use alternative JVM languages such as [Apache Groovy](http://groovy-lang.org/), [Kotlin](https://kotlinlang.org/), or [Scala](https://www.scala-lang.org/), and third-party frameworks that integrate with Cloud Functions like [Micronaut](https://micronaut.io/) and [Spring Boot](https://spring.io/projects/spring-boot)!

### Pretty Groovy functions

Without covering all those combinations, let's have a look at two examples. What would an HTTP function look like in Groovy?

The first step will be to add Apache Groovy as a dependency in your `pom.xml`:

```xml
<dependency>
    <groupId>org.codehaus.groovy</groupId>
    <artifactId>groovy-all</artifactId>
    <version>3.0.4</version>
    <type>pom</type>
</dependency>
```

You will also need the GMaven compiler plugin to compile the Groovy code:

```xml
<plugin>
    <groupId>org.codehaus.gmavenplus</groupId>
    <artifactId>gmavenplus-plugin</artifactId>
    <version>1.9.0</version>
    <executions>
        <execution>
            <goals>
                <goal>addSources</goal>
                <goal>addTestSources</goal>
                <goal>compile</goal>
                <goal>compileTests</goal>
            </goals>
        </execution>
    </executions>
</plugin>
```

When writing the function code, just use Groovy instead of Java:

```groovy
import com.google.cloud.functions.*

class HelloWorldFunction implements HttpFunction {
    void service(HttpRequest request, HttpResponse response) {
        response.writer.write "Hello Groovy World!"
    }
}
```

The same explanations regarding running your function locally or deploying it still applies: the Java platform is pretty open to alternative languages too! And the Cloud Functions builder will happily build your Groovy code in the cloud, since Maven lets you compile this code thanks to the Groovy library.

### Micronaut functions

Third-party frameworks also offer a dedicated Cloud Functions integration. Let's have a look at Micronaut.

[Micronaut](https://micronaut.io/) is a *"modern, JVM-based, full-stack framework for building modular, easily testable microservice and serverless applications"*, as explained on its website. It supports the notion of serverless functions, web apps and microservices, and has a dedicated integration for Google Cloud Functions.

In addition to being a very efficient framework with super fast startup times (which is important, to avoid long cold starts on serverless services), what's interesting about using Micronaut is that you can use Micronaut's own programming model, including Dependency Injection, annotation-driven bean declaration, etc.

For HTTP functions, you can use the framework's own `@Controller` / `@Get` annotations, instead of the Functions Framework's own interfaces. So for example, a Micronaut HTTP function would look like:

```java
import io.micronaut.http.annotation.*;

@Controller("/hello")
public class HelloController {

    @Get(uri="/", produces="text/plain")
    public String index() {
        return "Example Response";
    }
}
```

This is the standard way in Micronaut to define a Web microservice, but it transparently builds upon the Functions Framework to run this service as a Cloud Function. Furthermore, this programming model offered by Micronaut is portable across other environments, since Micronaut runs in many different contexts.

Last but not least, if you are using the [Micronaut Launch](https://micronaut.io/launch/) project (hosted on [Cloud Run](https://cloud.google.com/run)) which allows you to scaffold new projects easily (from the command-line or from a nice UI), you can opt for adding the `google-cloud-function` support module, and even choose your favorite language, build tool, or testing framework:

[![Micronaut Launch](https://3.bp.blogspot.com/-dgW0l2rewn0/Xs1EprFntNI/AAAAAAAAI3Q/XlDOiwKN_98CGp8qGSRJkTv_ETjqynbjgCLcBGAsYHQ/s1600/micronautlaunch.png)](https://3.bp.blogspot.com/-dgW0l2rewn0/Xs1EprFntNI/AAAAAAAAI3Q/XlDOiwKN_98CGp8qGSRJkTv_ETjqynbjgCLcBGAsYHQ/s1600/micronautlaunch.png)

Be sure to check out the documentation for the [Micronaut Cloud Functions support](https://micronaut-projects.github.io/micronaut-gcp/2.0.0.M3/guide/index.html#cloudFunction), and [Spring Cloud Function support](https://cloud.spring.io/spring-cloud-static/spring-cloud-function/3.0.6.RELEASE/reference/html/gcp.html).

## What's next?

Now it's your turn to try Cloud Functions for Java 11 today, with your favorite JVM language or third-party frameworks. Read the [getting started guide](https://cloud.google.com/functions/docs/quickstart-java), and try this for free with Google Cloud Platform [free trial](https://cloud.google.com/free). Explore Cloud Functions' [features and use cases](https://cloud.google.com/functions), take a look at the [quickstarts](https://cloud.google.com/functions/docs/quickstarts), perhaps even contribute to the [open source Functions Framework](https://github.com/GoogleCloudPlatform/functions-framework-java). And we're looking forward to seeing what functions you're going to build on this platform!
# Deploying serverless functions in Groovy on the new Java 11 runtime for Google Cloud Functions


Java celebrates its 25th anniversary!  
Earlier this year, the Apache Groovy team released the big 
[3.0 version](https://groovy-lang.org/releasenotes/groovy-3.0.html) of the programming language. 
[GMavenPlus](https://github.com/groovy/GMavenPlus/releases/tag/1.9.0) was published in version 1.9 
(the Maven plugin for compiling Groovy code) which works with Java 14.
And today, Google Cloud opens up the beta of the 
[Java 11 runtime for Cloud Functions](https://cloud.google.com/blog/products/application-development/introducing-java-11-on-google-cloud-functions). 
What about combining them all?

I've been working for a bit on the Java 11 runtime for Google Cloud Functions 
(that's the Function-as-a-Service platform of Google Cloud, pay-as-you-go, hassle-free / transparent scaling), 
and in this article, I'd like to highlight that you can also write and deploy functions with alternative JVM languages 
like [Apache Groovy](http://groovy-lang.org/).

So today, you're going to:

-   Write a simple Groovy 3.0 function,
-   Compile it with Maven 3.6 and the GMavenPlus 1.9 plugin, 
-   Deploy and run the function on the Cloud Functions Java 11 runtime!

Note: If you want to try this at (work from?) home, you will need an account on Google Cloud, 
you can easily create a [free account](https://cloud.google.com/free) 
and benefit from $300 of cloud credits to get started (including also free quotas for many products). 
You will also need to create a billing account, but for the purpose of this tutorial, 
you should be within the free quota (so your credit card shouldn't be billed). 
Then, head over to the [console.cloud.google.com](https://console.cloud.google.com/) cloud console to create a new project. 
And then navigate to the Cloud Functions section to enable the service for your project.

Let's get started! So what do we need? A pom.xml file, and a Groovy class!

Let's start with the `pom.xml` file, and what you should add to your build file. 
First of all, since I'm using Groovy as my function implementation language, I'm going to use GMavenPlus for compilation. 
So in the build/plugins section, I configure the plugin as follows:

```xml
      <plugin>
        <groupId>org.codehaus.gmavenplus</groupId>
        <artifactId>gmavenplus-plugin</artifactId>
        <version>1.9.0</version>
        <executions>
          <execution>
            <id>groovy-compile</id>
            <phase>process-resources</phase>
            <goals>
              <goal>addSources</goal>
              <goal>compile</goal>
            </goals>
          </execution>
        </executions>
        <dependencies>
          <dependency>
            <groupId>org.codehaus.groovy</groupId>
            <artifactId>groovy-all</artifactId>
            <version>3.0.4</version>
            <scope>runtime</scope>
            <type>pom</type>
          </dependency>
        </dependencies>
      </plugin>

```

That way, when I do an `mvn compile`, my Groovy sources are compiled as part of the compilation lifecycle of Maven.

But I'm adding a second plugin, the Functions Framework plugin! 
That's a Maven plugin to run functions locally on your machine, 
before deploying into the cloud, so that you can have a local developer experience that's easy and fast. 
The [Functions Framework](https://github.com/GoogleCloudPlatform/functions-framework-java) is actually an open source project on Github. 
It's a lightweight API to write your functions with, and it's also a function runner / invoker. 
What's interesting is that it also means that you are not locked in the Cloud Functions platform, 
but you can run your function locally or anywhere else where you can run a JAR file on a JVM! Great portability!

So let's configure the Functions Framework Maven plugin:

```xml
      <plugin>
        <groupId>com.google.cloud.functions</groupId>
        <artifactId>function-maven-plugin</artifactId>
        <version>0.9.2</version>
        <configuration>
          <functionTarget>mypackage.HelloWorldFunction</functionTarget>
        </configuration>
      </plugin>
```

I specify a configuration flag to point at the function I want to run. 
But we'll come back in a moment on how to run this function locally. We need to write it first!

We need two more things in our `pom.xml`, a dependency on Groovy, but also on the Functions Framework Java API.

```xml
    <dependency>
      <groupId>com.google.cloud.functions</groupId>
      <artifactId>functions-framework-api</artifactId>
      <version>1.0.1</version>
      <scope>provided</scope>
    </dependency>

    <dependency>
      <groupId>org.codehaus.groovy</groupId>
      <artifactId>groovy-all</artifactId>
      <version>3.0.4</version>
      <type>pom</type>
    </dependency>
```

So you're all set for the build, let's now create our function in `src/main/groovy/mypackage/HelloWorldFunction.groovy`.

There are two flavors of functions: [HTTP functions](https://cloud.google.com/functions/docs/writing/http) and 
[background functions](https://cloud.google.com/functions/docs/writing/background). 
The latter react to cloud events like a new file stored in Cloud Storage, a new data update in the Firestore database, etc. 
Whereas the former directly exposes a URL that can be invoked via an HTTP call. 
That's the one I want to create to write a symbolic `"Hello Groovy World"` message in your browser window.

```groovy
package mypackage

import com.google.cloud.functions.*

class HelloWorldFunction implements HttpFunction {
    void service(HttpRequest request, HttpResponse response) {
        response.writer.write "Hello Groovy World!"
    }
}
```

Yes, that's all there is to it! 
You implement a Functions Framework interface, and its `service()` method. 
You have a `request` / `response` mode (a `request` and a `response` parameters are passed to your method). 
You can access the writer to write back to the browser or client that invoked the function.

Now it's time to run the function locally to see if it's working. Just type the following command in your terminal:

```bash
mvn function:run
```

After a moment, and some build logs further, you should see something like:

```
INFO: Serving function...
INFO: Function: mypackage.HelloWorldFunction
INFO: URL: http://localhost:8080/
```

With your browser (or curl), you can browse this local URL, and you will see the hello world message appearing. Yay!

With the Maven plugin, you can also deploy, but you can use the [gcloud](https://cloud.google.com/sdk) 
command-line tool to deploy the function:

```bash
gcloud functions deploy helloFunction\
    --region europe-west1\
    --trigger-http --allow-unauthenticated\
    --runtime java11\
    --entry-point mypackage.HelloWorldFunction\
    --memory 512MB
```

After a little moment, the function is deployed, and you'll notice you'll have a URL created for your function looking something like this:

```
https://europe-west1-myprojectname.cloudfunctions.net/helloFunction
```

The very same function now runs in the cloud! 
A pretty Groovy function! This function is portable: 
you can invoke it with the Functions Framework invoker, anywhere you can run a JVM.

Going further, I encourage you to have a look at the [Functions Framework documentation on 
Github](https://github.com/GoogleCloudPlatform/functions-framework-java) to learn more about it. 
Here you deployed the function source and the pom.xml file, as the function will be built directly in the cloud. 
But it's also possible to compile and create a JAR locally and deploy that instead. 
That's interesting for example if you want to use another build tool, like Gradle. And this will be the purpose of another upcoming article!
# Video: the Pic-a-Daily serverless workshop


With my partner in crime, [Mete Atamel](https://twitter.com/meteatamel/status/1262316915642576896), 
we ran two editions of our "Pic-a-Daily" serverless workshop. It's an online, hands-on, workshop, 
where developers get their hands on the the [serverless products](https://cloud.google.com/serverless) 
provided by [Google Cloud Platform](https://cloud.google.com/):

-   [Cloud Functions](https://cloud.google.com/functions) --- to develop and run functions, small units of logic glue, to react to events of your cloud projects and services
-   [App Engine](https://cloud.google.com/appengine) --- to deploy web apps, for web frontends, or API backends
-   [Cloud Run](https://cloud.google.com/run) --- to deploy and scale containerised services

[![](/img/pic-a-daily-workshop/picadaily.png)](https://codelabs.developers.google.com/serverless-workshop/)

The theme of the workshop is to build a simple photosharing application (hence the play on words, with a picture a day) with those serverless products, but along the way, developers also get to use other services like:

-   [Pub/Sub](https://cloud.google.com/pubsub/) --- as a messaging fabric to let events flow between your services
-   [Firestore](https://cloud.google.com/firestore) --- for storing picture metadata in the scalable document database
-   [Cloud Storage](https://cloud.google.com/storage) --- to store the image blobs
-   [Cloud Scheduler](https://cloud.google.com/scheduler) --- to run a services on a schedule (ie. cron as a service)
-   [Cloud Vision API](https://cloud.google.com/vision/) --- a machine learning API to make sense of what's in your pictures

[![](/img/pic-a-daily-workshop/diagram.png)](https://codelabs.developers.google.com/serverless-workshop/)

The workshop is freely accessible on our codelabs platform: ["Pic-a-Daily" serverless workshop](https://codelabs.developers.google.com/serverless-workshop/). So you can follow this hands-on workshop on your own, at your own pace. There are 4 codelabs:

-   The [first one](https://codelabs.developers.google.com/codelabs/cloud-picadaily-lab1/index.html?index=..%2F..serverless-workshop#13) lets you build a function that responds to events as new pictures are uploaded into Cloud Storage, invoking the Vision API to understand what is in the picture, and storing some picture metadata information in Firestore.
-   The [second lab](https://codelabs.developers.google.com/codelabs/cloud-picadaily-lab2/index.html?index=..%2F..serverless-workshop#0) will use a Cloud Run service which reacts to new files stored in Cloud Storage too, but will create thumbnails of the pictures.

-   A [third lab](https://codelabs.developers.google.com/codelabs/cloud-picadaily-lab3/index.html?index=..%2F..serverless-workshop#0) is also taking advantage of Cloud Run to run on a schedule, thanks to Cloud Scheduler. It creates a collage of the most recent pictures.

-   Last but not least, the [fourth lab](https://codelabs.developers.google.com/codelabs/cloud-picadaily-lab4/index.html?index=..%2F..serverless-workshop#0) will let you build a web frontend and backend API on Google App Engine.

[![](/img/pic-a-daily-workshop/codelabs.png)](https://codelabs.developers.google.com/serverless-workshop/)

We have a dedicated [Github repository](https://github.com/GoogleCloudPlatform/serverless-photosharing-workshop) where you can check-out the code of the various functions, apps and containers, and you can have a look at the [slide deck](https://speakerdeck.com/meteatamel/pic-a-daily-serverless-workshop) introducing the workshop and the technologies used.

And now, the videos of the first edition are also available on YouTube!

The first part covers Cloud Functions and Cloud Run with the first two labs:

{{< youtube wEENQouNsGk >}}

The second part covers Cloud Run and App Engine:

{{< youtube Y9E1fQcPXP0 >}}
# Machine learning applied music generation with Magenta


I missed this talk from Alexandre Dubreuil, when attending Devoxx Belgium 2019, but I had the chance to watch while doing my elliptical bike run, confined at home. It's about applying Machine Learning to music generation, thanks to the [Magenta project](https://magenta.tensorflow.org/), which is based on [Tensorflow](https://www.tensorflow.org/).

{{< youtube O4uBa0KMeNY >}}

I like playing music (a bit of piano & guitar) once in a while, so as a geek, I've also always been interested in computer generated music. And it's hard to generate music that actually sounds pleasant to the ear! Alexandre explains that it's hard to encode the rules a computer could follow to play music, but that machine learning is pretty interesting, as it's able to learn complex functions, thus understanding what does sound good.

He, then, covers the various types of music representations, like MIDI scores which are quite light in terms of data, and audio waves which on the high end of data as there are thousands of data points representing the position on the wave along the time axis. While MIDI represents a note of music, audio waves really represent the sound physically as a wave (of data points).

Note that in the following part of the article, I'm not an ML / AI expert, so I'm just trying to explain what I actually understood :-)

For MIDI, Recurrent Neural Networks (RNN) make sense, as they work on sequences for the input and output, and also have the ability to remember past information. And that's great as you find recurring patterns in music (series of chords, main song lines, etc.)

RNN tend to forget progressively those past events, so those networks often use Long-Short-Term-Memory to keep some of their memory fresh.

Variational Auto-Encoders are a pair of networks that diminish the dimensions of outputs compared to the quantity in input, but to then re-expand back to the same size of output. So VAEs try to actually generate back something that's close to what was initially given in input, but it events to reproduce similar patterns.

For audio waves, Magenta comes with a Convolutional Neural Network (CNN) called WaveNet, that's used for example for voice generation on devices like Google Home. There are WaveNet Auto-Encoders that also generate audio waves, because it can learn to generate the actual sound of instruments, or create totally new instruments, or mixes of sounds. Alexandre shows some cool demos of weird instruments made of cat sounds and musical instruments.

Magenta comes with various RNNs for drums, melody, polyphony, performance. With auto-encoders for WaveNet and MIDI too. There's also a Generative Adversarial Network (GAN) for audio waves. GANs are often used for generating things like pictures, for example.

The demos in this presentation are quite cool, with creating new instruments (cat + musical instrument), or for generating sequences of notes (drum score, melody score)

Alexandre ends the presentation with pointers to things like data sets of music, as neural networks further need to learn about style, performance, and networks need plenty of time to learn from existing music and instrument sounds, so as to create something nice to hear! He shows briefly some other cool demos using [TensorFlow.js](https://www.tensorflow.org/js), so that it works in the browser and that you can more easily experiment with music generation.

Also, Alexandre wrote the book "[Hands-On Music Generation with Magenta](https://www.packtpub.com/eu/data/hands-on-music-generation-with-magenta)", so if you want to dive deeper, there's much to read and experiment with!


# HTML semantic tags


We all know about HTML 5, right? Well, I knew about some of the new semantic tags, 
like `header` / `nav` / `main` / `article` / `aside` / `footer`, 
but I'm still falling down to using tons of divs and spans instead. So as I want to refresh that blog at some point, 
it was time I revise those semantic tags. Let's take the little time we have during confinement to learn something!

There are likely plenty of videos of the topic, but this one was in my top results, so I watched:

{{< youtube kGW8Al_cga4 >}}

[HTML & CSS Crash Course Tutorial #6 - HTML 5 Semantics](https://www.youtube.com/watch?v=kGW8Al_cga4&list=WL&index=3&t=0s). 
It's part of a series of videos on the topic of HTML & CSS by the [Net Ninja](https://www.youtube.com/channel/UCW5YeuERMmlnqo4oq8vwUpg). 
This particular episode was covering the topic of the semantic tags:

So you have a main tag that wraps the meaty content of your page (ie. not stuff like `header` / `footer` / `navigation`). 
Inside, you would put articles, that wrap each piece of content (a blog post, a news article, etc). 
Sections tend to be for grouping some other information, like a list of resources, some contact info. 
Asides can be related content like similar articles, or something somewhat related to your current article 
(perhaps a short bio of a character you're mentioning in your article?) 
In the header section, you'd put the title of your site, the navigation. 
The footer will contain your contact info.

Here's a basic structure of how those tags are organised:

![](/img/misc-learning/HTML+5+semantic+tag+structure.png)

After an explanation of those tags, the author does a live demo, building up a web page with all those tags. 
So it was a good refresher for me to remember how to use those tags, rather than nesting `div` after `div`!
# Modern web game development


Next in my series of videos while doing sports at home, I watched this video from my colleague [Tom Greenaway](https://twitter.com/tcmg)! 
It's about modern web game development, and was recorded last year at Google I/O.

{{< youtube aVTYxHL45SA >}}

There are big gaming platforms, like Sony's PlayStation, Microsoft's XBox, Nintendo Switch, 
as well as plenty of mobile games on Android and iOS. 
But the Web itself, within your browser, is also a great platform for developing and publishing games! 
There's all that's needed for good games!

Tom explains that you need a functioning game (runs well on device, looks good, sounds good). 
And today, most of the game engines you can use for developing games actually provide an HTML5 target. 
You need users, and you need to have a good monetisation strategy. 
The web already provides all the right APIs for nice graphics, sound mixing, etc, and its a very open platform for spreading virally.

It was pretty interesting to hear about one of the key advantages of the web: it's URLs! 
You can be pretty creative with URLs. A game can create a URL for a given game session, 
for a particular state in a game, for inviting others to join.

In addition to game engines with a web target, Tom mentions also that it's possible to port games from C/C++ for example, 
to JavaScript in the browser, with a tool like [Emscripten](https://emscripten.org/). 
Even things like OpenGL 3D rendering can be translated into WebGL. 
But he also advises to look at WebAssembly, as it's really become the new approach to native performance in the browser. 
He mentioned [construct](https://www.construct.net/fr), it's basically the Box2D game engine, but optimised for WebAssembly.

For 3D graphics, for the web, the future lies in [WebGPU](https://gpuweb.github.io/gpuweb/), 
which is a more modern take on WebGL and OpenGL. For audio, 
there's the [Web Audio](https://www.w3.org/TR/webaudio/) APIs 
and worklets which allows you to even create effects in JavaScript or WebAssembly. 
But there are other useful APIs for game development, 
like the [Gamepad](https://www.w3.org/TR/gamepad/) API, the [Gyroscope](https://www.w3.org/TR/gyroscope/) API, etc.

For getting users, ensure that your game is fun of course, but also make it fast, in particular load fast, 
to avoid using users even before you actually got them to load the game! 
But you also need to think about this user acquisition loop: make the game load and start fast to enter the action right away, 
so you're really pulled in in the game, and that's then a good reason for users to share this new cool games with others. 
Of course, being featured on game sites & libraries helps, it gives a big boost, 
but it's not necessarily what will make you earn the most in the long run. 
Tom also shares various examples of games that were successful and worked well.
# Decoding a QR code by hand


Doing sport at home on a treadmill or an elliptical bike is pretty boring, when you're confined, 
so to make things more interesting, I'm watching some videos to learn something new while exercising. 
This time, I found this old video about how to decode QR codes... by hand! 
Have you ever thought how these were encoded?

{{< youtube KA8hDldvfv0 >}}

This video comes from the [Robomatics](https://www.youtube.com/channel/UCnqifAqGaat6blFe8wlllOw) YouTube channel. 
You recognise easily QR codes thanks to the 3 big squares with the inner white line. 
I knew about the purple dotted lines that was fixed in those patterns. 
What I didn't know however was that there's a mask that is applied to the data, to avoid QR codes to potentially look all white or black. 
It was interesting to see also how the bytes were encoded: how they follow a path through out the matrix.

However, what this video doesn't cover, for example, is how error correction is working. 
You might have some holes or a bad picture of a QR code, but still being able to decode it with some level of loss of data. 
So I'll have to learn how that part works some day!
# Defence against the Docker arts by Joe Kutner


Confined at home, because of the corona-virus pandemic, I'm also doing sport at home. I have a small treadmill for light walks (mostly during conf calls!) and also an elliptical bike. I'd much rather run outside though, but I have to use what I have, even if I hate that stationary elliptical bike in my basement. It's so boring! So to avoid feeling like wasting my time, I decided to watch videos during my sessions! Not necessarily series on Netflix. No! But interesting technical videos. So today, I'd like to share with you a series of posts on those interesting videos I'm watching while exercising.

Today, thanks to the wonderful [Joe Kutner](https://twitter.com/codefinger), from [Heroku](https://www.heroku.com/), I learned about the Defence Against the Docker Arts! It was recorded at Devoxx Belgium 2019.

{{< youtube ofH9_sE2qy0 >}}

Joe starts with clearly differentiating Docker and Dockerfiles. Docker is an ecosystem, while Dockerfiles describe docker container images. An important distinction. The first part of the video, shows best practices on how to writer proper Dockerfiles, and references an article on the Docker blog [post](https://www.docker.com/blog/intro-guide-to-dockerfile-best-practices/) from last year on that topic: 

-   use official base images, rather than reinventing the wheel, as they are usually more up-to-date and secure
-   remember that images are built in layers, so to speed up your builds, ensure that the base layers are the ones that change less, and keep your source file changes in the last layer as they change the most
-   join several RUN commands into one by binding them together with ampersands
-   be explicit about the version of base images you use
-   try to chose minimal flavors of base images, as they can be pretty big
-   build from source in a consistent environment, so that developers are on the same page, with the same version of their environment (build tool, runtime versions)
-   fetch dependencies in a separate step, so dependencies are cached in their own layer
-   use multi-staged build to remove build dependencies not needed at runtime

That's a lot of things to know! Joe then moves on to talk about higher-level approaches, starting with the [BuildKit](https://github.com/moby/buildkit) Go library. It's more for platform developers than developers, but it gives you lots of advanced controls on how to build docker images.

Joe introduces [Jib](https://github.com/GoogleContainerTools/jib) which is a build plugin (both for Maven and Gradle) that let developers focus on writing and building their apps, but letting that plugin create properly layered docker images for you, using minimal base images. You can even build without a local Docker daemon.

After BuildKit and Jib, Joe talks about the new Cloud Native [BuildPacks](https://buildpacks.io/), a tool that builds OCI images from source, cleverly. There are buildpacks for plenty of platforms and runtimes, not just Java. Those new cloud native buildpacks build upon years of experience from Heroku and CloudFoundry, on the first version of the buildpack concept. Joe says that buildpacks are reusable, fast, modular and safe, and goes on to show the power of this approach that allowed Heroku, for instance, to safely and rapidly upgrade Heartbleed affected images by replacing the underlying OS with a patched / upgraded version, thanks to image rebasing.
# Start the fun with Java 14 and Micronaut inside serverless containers on Cloud Run


Hot on the heels of the [announcement](https://mail.openjdk.java.net/pipermail/jdk-dev/2020-March/004089.html) of the general availability of JDK 14, I couldn't resist taking it for a spin. Without messing up my environment --- I'll confess I'm running 11 on my machine, but I'm still not even using everything that came past Java 8! --- I decided to test this new edition within the comfy setting of a Docker container.

## Minimal OpenJDK 14 image running JShell

Super easy to get started (assuming you have Docker installed on your machine), create a Dockerfile with the following content:

```dockerfile
FROM openjdk:14
CMD ["jshell"]
```

Only two lines: one to declare an [OpenJDK base image](https://hub.docker.com/_/openjdk) with the 14 tag, and one to launch the [JShell](https://docs.oracle.com/en/java/javase/14/jshell/introduction-jshell.html) REPL (introduced in Java 9).

Build and tag the image with:

```bash
$ docker build -t 14fun .
```

I called it 14fun, because you could almost pronounce it "one for the fun"! And then you can run this container image interactively with:

```bash
$ docker run -it 14fun
```

Then you will land directly in JShell, and can try a hello world of sorts:

```
Mar 20, 2020 9:17:28 AM java.util.prefs.FileSystemPreferences$1 run
INFO: Created user preferences directory.
| Welcome to JShell -- Version 14
| For an introduction type: /help intro
jshell> System.out.println("Stay at home!")
Stay at home!
```

You can enter /exit to quit the REPL.

And you certainly noticed that we're indeed on version 14, congrats!

## New and preview features

If you read the [announcement](https://mail.openjdk.java.net/pipermail/jdk-dev/2020-March/004089.html), you will have remarked that some of the new features are not necessarily generally available, but are still only in preview mode. 

Here's what's new:

-   [improved switch expressions](https://openjdk.java.net/jeps/361) (standard),
-   [pattern matching on instanceof](https://openjdk.java.net/jeps/305) (preview), 
-   [records](https://openjdk.java.net/jeps/359) (preview), and 
-   [text blocks](https://openjdk.java.net/jeps/368) (second preview).

If you want to play with those upcoming features, you have to let the Java tooling know that you want to enable them. You can do that with the --enable-preview flag. So let's update our Dockerfile accordingly:

```dockerfile
FROM openjdk:14
CMD ["jshell", "--enable-preview"]
```

Rebuild and rerun the docker commands.

### Text blocks

What about trying the [text blocks](https://openjdk.java.net/jeps/368)? With text blocks, don't bother with appending strings with + operations, not forgetting the \n at the end of each line. It's now sweeter to write long strings spanning several lines, for example:

```
$ docker run -it 14fun 
Mar 20, 2020 1:12:28 PM java.util.prefs.FileSystemPreferences$1 run
INFO: Created user preferences directory.
| Welcome to JShell -- Version 14
| For an introduction type: /help intro
jshell> var s = """
   ...> Hello everyone!
   ...> How are you doing?
   ...> """
s ==> "Hello everyone!\nHow are you doing?\n"
```

### Records

Java is often criticized for its verbosity --- think for instance how writing good POJOs can be tiresome, with proper equals() / hashCode() / toString() methods, constructors, getters and setters. Fortunately, IDEs help a lot here, but sometimes you really want some simple data holder classes without all the boilerplate. That's where [records](https://openjdk.java.net/jeps/359) come into the picture. 

Note however that these are not immutable (for example, like in Apache Groovy with its [@Immutable](http://docs.groovy-lang.org/latest/html/gapi/groovy/transform/Immutable.html) transformation), if the fields in the record are mutable objects.

Let's imagine a 3D point Record, what would it look like?

```
jshell> record Point3D(double x, double y, double z) { }
| created record Point3D

jshell> var p1 = new Point3D(0, 1, 2)
p1 ==> Point3D[x=0.0, y=1.0, z=2.0]

jshell> var p2 = new Point3D(0, 1, 2)
p2 ==> Point3D[x=0.0, y=1.0, z=2.0]

jshell> p1.equals(p2)
$5 ==> true
```

Notice the toString() representation, and that equals() is implemented comparing the values of each field.

### Improved switch expressions

Switch statements are... indeed statements, not expressions. It means they didn't so far return any value, or couldn't be passed as parameter values to methods. 

Times they are [a-changin](https://en.wikipedia.org/wiki/The_Times_They_Are_a-Changin%27_(Bob_Dylan_album))! Switch borrows the arrow syntax from lambdas to get a... break from break! And they can be used as values too!

```
jshell> var day = "Saturday"
day ==> "Saturday"

jshell> var isWeekend = switch (day) {
   ...> case "Monday", "Tuesday", "Wednesday", 
   ...> "Thursday", "Friday" -> false;
   ...> case "Saturday", "Sunday" -> true;
   ...> default -> false;
   ...> }
isWeekend ==> true
```

### Pattern matching on instanceof

Working with Apache Groovy for years, whether with its static type checking or dynamic nature, I'm quite used to skipping the redundant cast inside if (someObj instanceof SomeObject) {} blocks, thanks to [smart type inference](http://docs.groovy-lang.org/latest/html/documentation/core-semantics.html#_instanceof_inference) and flow typing. Java 14 takes a slightly different approach to this problem by with its [pattern matching on instanceof](https://openjdk.java.net/jeps/305), introducing a new local variable of the right type, rather than assuming the variable itself is of the right type. Well, it's better explained with an example:

```
jshell> String name = " Guillaume "
name ==> " Guillaume "

jshell> if (name instanceof String nameString) {
   ...> System.out.println(nameString.trim());
   ...> } else {
   ...> System.out.println("Not a string!");
   ...> }
Guillaume
```

JDK 14 in a serverless container, with Cloud Run
------------------------------------------------

Together we discovered the cool new syntax enhancements and constructs, and how we can play with them inside a Docker container image. But what about deploying some Java 14 powered containerized app in the cloud, in a serverless fashion? (ie. transparent scaling from 0 to 1, 1 to n, and back, paying only for what you use). For that purpose, you can easily deploy and scale containers in the cloud thanks to [Cloud Run](https://cloud.run/).

With the launch of Java / JDK 14, also came the first [2.0 milestone of the lovely and powerful Micronaut framework](https://objectcomputing.com/news/2020/03/20/micronaut-20-milestone-1-released)! Micronaut is probably the best framework for serverless microservices on the market, thanks to its awesome performance, lightness, in particular regarding super fast startup times. So it's the right occasion to have fun with [Micronaut](https://micronaut.io/) again. So let's build a Java 14 application, with Micronaut, running on Cloud Run.

### Create a Micronaut app

To get started, have a look at the [installation guide](https://docs.micronaut.io/latest/guide/index.html#buildCLI) for Micronaut. In a nutshell, it's using the [Sdkman](https://sdkman.io/) tool to manage versions of various SDKs. You can install Sdkman easily:

```bash
$ curl -s "https://get.sdkman.io" | bash
```

Once installed, you can also install the Micronaut command-line:

```bash
$ sdk install micronaut 2.0.0.M1
```

Next, we'll create an empty app named "app" with:

```bash
$ mn create-app app
```

The project will be created in the app/ subdirectory, cd into it, to also create a controller, and call it hello:

```bash
$ mn create-controller hello
```

You'll need to implement the controller, and tweak the app/build.gradle file to enable Java 14's preview features.

Update this section at the bottom of the build file to add the --enable-preview flag:

```groovy
tasks.withType(JavaCompile) {
    options.encoding = "UTF-8"
    options.compilerArgs.add('-parameters')
    options.compilerArgs.add('--enable-preview')
}
```

Now, open the src/main/java/app/HelloController.java class:

```java
package app;

import io.micronaut.http.MediaType;
import io.micronaut.http.annotation.Controller;
import io.micronaut.http.annotation.Get;
import io.micronaut.http.annotation.Produces;

@Controller("/")
public class HelloController {

    @Produces(MediaType.TEXT_HTML)
    @Get("/{day}")
    public String index(String day) {
        var isWeekend = switch(day.toLowerCase()) {
            case "saturday", "sunday" -> true;
            case "monday", "tuesday", "wednesday",
                 "thursday", "friday" -> false;
            default -> false;
        };

        return String.format(
            """

                        It's %s, it is %s the weekend!

           """,
           day, (isWeekend ? "" : "not"));
    }
}
```

Notice how you take advantage of the improved switch expression and the text block!

### Create a Docker image

Micronaut's project template comes with a default Dockerfile, but update it to look like this:

```dockerfile
FROM openjdk:14
WORKDIR /app
COPY ./ ./
RUN ./gradlew shadowJar
EXPOSE 8080
CMD ["java", "--enable-preview", "-jar", "build/libs/app-0.1-all.jar"]
```

Then build this container image (with your name of choice) with:

```bash
docker build -t IMAGE_NAME .
```

And check that it runs fine with this docker run command:

```bash
docker run -p 8080:8080 -it IMAGE_NAME
```

Then head over to <http://127.0.0.1/Monday> or <http://127.0.0.1/Sunday> to see if it works fine.

So you now have a working Micronaut 2.0 application, running on JDK 14, using some of the new and preview features of Java 14! Congrats!

### Scaling your container image in the cloud

Time to deploy your Java 14-powered Micronaut web application into the cloud, on Cloud Run. Why [Cloud Run](https://cloud.google.com/run/)? Because with Cloud Run, you can easily push a container in production in matters of seconds. It abstracts away all the infrastructure, so you don't have to worry about it. Google Cloud Platform handles it for you, so you can focus on your code instead. You pay proportionally to your usage: it's serveless, so if nobody pings your app, you won't pay anything as no container will be running. But as traffic ramps up, one or more containers will be lined up to serve your requests.

If you haven't already, you can get started on Google Cloud Platform with its [free trial](https://cloud.google.com/free) (and free quota). For this tutorial however, you need to create a billing account. Once you have an account ready, create a new GCP project in the Google Cloud [console](https://console.cloud.google.com/). Head over to the Cloud Run section, from the hamburger menu, and click on the "Enable API" button.

Last thing before heading to the command-line, install the [gcloud SDK](https://cloud.google.com/sdk/docs/quickstarts) command-line to work from your terminal. Once gcloud is installed, you can login with:

```bash
gcloud auth login
```

Set the project name to the one you created in the console:

```bash
gcloud config set project YOUR_PROJECT_ID
```

You'll be using the fully-managed version of Cloud Run:

```bash
gcloud config set run/platform managed
```

Define a default region, for me, that's gonna be europe-west1

```bash
gcloud config set run/region REGION
```

It's possible to also build container images in [Cloud Build](https://cloud.google.com/cloud-build) (see some [instructions](https://cloud.google.com/run/docs/quickstarts/build-and-deploy) that show this), but here you are using Docker locally to build your images. So let's configure the Docker integration and Container Registry access with the following commands:

```bash
gcloud auth configure-docker
gcloud components install docker-credential-gcr
```

Tag your image with the following naming convention:

```bash
docker build . --tag gcr.io/YOUR_PROJECT_ID/IMAGE_NAME
```

Let's push our image to Container Registry (and change the image and project names accordingly):

```bash
docker push gcr.io/YOUR_PROJECT_ID/IMAGE_NAME
gcloud run deploy weekend-service\
 --image gcr.io/YOUR_PROJECT_ID/IMAGE_NAME
 --allow-unauthenticated
```

You should see output similar to this, showing the URL where you can access your app:

```
Deploying container to Cloud Run service [weekend-service] in project [YOUR_PROJECT_ID] region [europe-west1]
✓ Deploying new service... Done.
 ✓ Creating Revision...
 ✓ Routing traffic...
 ✓ Setting IAM Policy...
Done.
Service [weekend-service] revision [weekend-service-00001-xig] has been deployed and is serving 100 percent of traffic at https://weekend-service-brxby8yoda-ew.a.run.app
```

Navigate to that URL, append the name of the day, and check whether it's weekend time!

## And voilà! 

Less than a minute later, your Java 14 + Micronaut container app has been deployed to Cloud Run. Automatically, you got a secured HTTPS endpoint for your app (you can also provide your own domain name), without bothering with the infrastructure and scaling aspects.
# Serverless tip #7 — Create mini APIs with Cloud Functions and Express routing


Requirements:

-   an existing Google Cloud Platform account and project
-   Cloud Functions should be enabled for that project

Compared to the previous tip when using Exress' request path attribute, we can take advantage of Express routing.

So to support the following paths:

```
https://us-central1-myproject.cloudfunctions.net/api/customers
https://us-central1-myproject.cloudfunctions.net/api/customers/32
https://us-central1-myproject.cloudfunctions.net/api/customers/32/address
```

We can have our functions require Express by adding Express in `package.json`:

```json
{
  "name": "mini-api-router",
  "version": "0.0.1",
  "dependencies": {
    "express": "^4.17.1"
  }
}
```

Then we can require that dependency in our new functions script:

```javascript
// we use express explicitly
const express = require('express');
const app = express();

// some customer data retrieved from Firestore or elsewhere
const customers = {
  "32": { name: 'Alice', address: '21 Jump Street' },
  "33": { name: 'Bob', address: '1 Main Street' }
};

// this time we can define the path easily
app.get('/', (req, res) => 
        res.send('Hello World!'));
app.get('/customers', (req, res) => 
        res.status(200).json(customers).end());
// we can also specify path variables like :id 
// that we can retrieve via the request params object
app.get('/customers/:id', (req, res) => 
        res.status(200).json(customers[req.params.id]).end());
app.get('/customers/:id/address', (req, res) => 
        res.status(200).json({address: customers[req.params.id].address}).end());

// we need to export the app object for Cloud Functions to expose it
exports.api = app;
```

More information:

-   [Express framework](https://expressjs.com/)
-   Express [routing](http://expressjs.com/en/guide/routing.html#routing)
# Serverless tip #6 — Create a mini web API with Cloud Functions


Requirements:

-   an existing Google Cloud Platform account and project
-   Cloud Functions should be enabled for that project

We often use individual HTTP [Cloud Functions](https://cloud.google.com/functions/) as a single endpoint, and we pass data to the functions with either query parameters, or via a POST body payload. Although it's a good practice to keep the scope of a function small, however, you can easily write mini Web APIs for a given function, with different paths for different needs, like with usual Web frameworks.

So instead of having just a single endpoint with:

```
https://us-central1-myproject.cloudfunctions.net/myfunction
```

You can have sub-paths below the name of your function:

```
https://us-central1-myproject.cloudfunctions.net/myapi/customers
https://us-central1-myproject.cloudfunctions.net/myapi/customers/32
https://us-central1-myproject.cloudfunctions.net/myapi/customers/32/address
```

Let's have a look at the Node functions runtime, and how you can implement this approach. The key trick here is to use the request path: req.path, which will give you the `/customers/32` part of the fully qualified URL.

```javascript
// some customer data retrieved from Firestore or elsewhere
const customers = {
  "32": { name: 'Alice', address: '21 Jump Street' },
  "33": { name: 'Bob', address: '1 Main Street' }
};
exports.myapi = (req, res) => {
  if (req.path.startsWith('/customers')) {
    const pathElements = req.path.split('/') // split along the slashes
      .filter(e => e)                        // remove the empty strings in the array
      .splice(1);                            // remove the first "customers" element
    // path: /customers
    if (pathElements.length == 0) { 
      // return all customers
      res.status(200).json(customers).end();
    }
    // path: /customers/32
    else if (pathElements.length == 1) {
      res.status(200).json(customers[pathElements[0]]).end();
    }
    // path: /customers/33/address
    else if (pathElements.length == 2 && pathElements[1] == "address") {
      res.status(200).json({address: customers[pathElements[0]].address}).end();
    }
  }
  res.status(404).send('Unknown path').end();
};
```

In the Node.JS runtime, Cloud Functions uses the Express framework under the hood. We have access to the request object, which has lots of useful attributes, including the path.

In this simplistic example, we are using this path attribute directly, but it's also possible to use more advanced routing capabilities, as we shall see in a forthcoming tip.

More information

-   [Express framework](https://expressjs.com/)
-   Node's request [path](https://expressjs.com/en/api.html#req.path)
# Serverless tip #5 — How to invoke a secured Cloud Run service locally


Requirements:

-   an existing Google Cloud Platform account with a project
-   you have enabled the Cloud Run service and already deployed a container image
-   your local environment's gcloud is already configured to point at your GCP project

By default, when you deploy a [Cloud Run](https://cloud.run/) service, it is secured by default, unless you use the --allow-unauthenticated flag when using the gcloud command-line (or the appropriate checkbox on the Google Cloud Console).

But once deployed, if you want to call it locally from your development machine, for testing purpose, you'll have to be authenticated.

If you look at the Cloud Console, alongside the URL of the service, you can hover the little icon next to the URL, and you'll see the a pop-up showing how you can invoke that service with a curl command:

![](/img/serverless-tips/st5-cr-call-authenticated-service.png)

```bash
curl -H \
    "Authorization: Bearer $(gcloud auth print-identity-token)" \
    https://authenticated-x2rq3lgmra-uc.a.run.app
```

Note how a bearer token generated by the gcloud command is passed as header to the curl request.

More information

-   [https://cloud.run](https://cloud.run/), the serverless container platform
-   [Authentication overview documentation](https://cloud.google.com/run/docs/authenticating/overview)
-   [Unauthenticated invocations](https://cloud.google.com/run/docs/authenticating/public) of your services
-   [gcloud auth print-identity-token](https://cloud.google.com/sdk/gcloud/reference/auth/print-identity-token)
# 8 production-ready features you'll find in Cloud Run fully managed


Since we [launched Cloud Run](https://cloud.google.com/blog/products/serverless/announcing-cloud-run-the-newest-member-of-our-serverless-compute-stack) at Google Cloud Next in April, developers have discovered that "serverless" and "containers" run well together. With [Cloud Run](https://cloud.google.com/run/), not only do you benefit from fully managed infrastructure, up and down auto-scaling, and pay-as-you-go pricing, but you're also able to package your workload however you like, inside a stateless container listening for incoming requests, with any language, runtime, or library of your choice. And you get all this without compromising portability, thanks to its [Knative](https://knative.dev/) open-source underpinnings. 

Many Google Cloud customers already use Cloud Run in production, for example, to deploy public websites or APIs, or as a way to perform fast and lightweight data transformations or background operations. 

*"Cloud Run promises to dramatically reduce the operational complexity of deploying containerized software. The ability to put an automatically scaling service in production with one command is very attractive."* - Jamie Talbot, Principal Engineer at Mailchimp.

[Cloud Run recently became generally available](https://cloud.google.com/blog/products/serverless/knative-based-cloud-run-services-are-ga), as both a fully managed platform or on [Anthos](https://cloud.google.com/anthos/), and offers a bunch of new features. What are those new capabilities? Today, let's take a look at what's new in the fully managed Cloud Run platform.

## 1. Service level agreement

With general availability, Cloud Run now comes with a [Service Level Agreement](https://cloud.google.com/run/sla) (SLA). In addition, it now offers [data location commitments](https://cloud.google.com/terms/service-terms) that allow you to store customer data in a specific region/multi-region. 

## 2. Available in 9 GCP regions

In addition to South Carolina, Iowa, Tokyo, and Belgium, in the coming weeks, you'll also be able to deploy containers to Cloud Run in North Virginia, Oregon, Netherlands, Finland, and Taiwan, for a total of nine [cloud regions](https://cloud.google.com/about/locations).

![/img/8cr/Cloud_run_regions.max-2000x2000.png](/img/8cr/Cloud_run_regions.max-2000x2000.png)

## 3. Max instances

Auto-scaling can be magic, but there are times when you want to limit the maximum number of instances of your Cloud Run services, for example, to limit costs. Or imagine a backend service like a database is limited to a certain number of connections---you might want to limit the number of instances that can connect to that service. With the [max instance](https://cloud.google.com/run/docs/configuring/max-instances) feature, you can now set such a limit.

Use the Cloud Console or Cloud SDK to set this limit:

```bash
gcloud run services update SERVICE-NAME --max-instances 42
```

## 4. More secure: HTTPS only
All fully managed Cloud Run services receive a stable and secure URL. Cloud Run now only accepts secure HTTPS connection and redirects any HTTP connection to the HTTPS endpoint. 

But having an HTTPS endpoint does not mean that your service is publicly accessible---you are in control and can opt into [allowing public access](https://cloud.google.com/run/docs/authenticating/public) to your service. Alternatively, you can [require authentication](https://cloud.google.com/run/docs/authenticating/overview) by leveraging the "Cloud Run Invoker" IAM role.

## 5. Unary gRPC protocol support

Cloud Run now lets you deploy and run [unary gRPC](https://grpc.io/docs/guides/concepts/) services (i.e., non-streaming gRPC), allowing your microservices to leverage this RPC framework. 

To learn more, read Peter Malinas' tutorial on [Serverless gRPC with Cloud Run](https://medium.com/@petomalina/%EF%B8%8Fserverless-grpc-with-cloud-run-bab3622a47da) using Go, as well as Ahmet Alp Balkan's article on [gRPC authentication on Cloud Run](https://ahmet.im/blog/grpc-auth-cloud-run/).

## 6. New metrics to track your instances

Out of the box, Cloud Run integrates with [Stackdriver Monitoring](https://cloud.google.com/monitoring/). From within the Google Cloud Console, the Cloud Run page now includes a new "Metrics" tab that shows charts of key performance indicators for your Cloud Run service: requests per second, request latency, used instance time, CPU and memory.

A new built-in Stackdriver metric called [`container/billable_instance_time`](https://cloud.google.com/monitoring/api/metrics_gcp#gcp-run) gives you insights into the number of container instances for a service, with the billable time aggregated from all container instances.

![/img/8cr/billable_container_instance_time.max-1200x1200.jpg](/img/8cr/billable_container_instance_time.max-1200x1200.jpg)

## 7. Labels
Like the bibs that identify the runners in a race, GCP [labels](https://cloud.google.com/run/docs/configuring/labels) can help you easily identify a set of services, break down costs, or distinguish different environments.

You can set labels from the Cloud Run service list page in Cloud Console, or update labels with this command and flag:

```bash
gcloud run services update SERVICE-NAME --update-labels KEY=VALUE
```

## 8. Terraform support

Finally, if you practice [Infrastructure as Code](https://cloud.google.com/solutions/infrastructure-as-code/), you'll be glad to know that [Terraform now  supports Cloud Run](https://www.terraform.io/docs/providers/google/r/cloud_run_service.html), allowing you to provision Cloud Run services from a Terraform configuration. 

```hcl
resource "google_cloud_run_service" "default" {
    name     = "hello"
    location = "us-central1"
    template {
        spec {
            containers {
                image = "gcr.io/cloudrun/hello"
            }
        }
    }
}
```

## Ready, set, go!

The baton is now in your hands. To start deploying your container images to Cloud Run, head over to our quickstart guides on [building and deploying your images](https://cloud.google.com/run/docs/quickstarts/build-and-deploy). With the [always free tier](https://cloud.google.com/free/) and the $300 credit for new GCP accounts, you're ready to take Cloud Run for a spin. To learn more, there's the [documentation](https://cloud.google.com/run/docs/) of course, as well as the [numerous samples](https://github.com/GoogleCloudPlatform/cloud-run-samples) with different language runtimes (don't miss the "Run on Google Cloud" [button](https://github.com/GoogleCloudPlatform/cloud-run-button) to automatically deploy your code). In addition, be sure to check out the community-contributed resources on the [Awesome Cloud Run](https://github.com/steren/awesome-cloudrun) github project. We're looking forward to seeing what you build and deploy!
# Serverless tip #4 — Discover the full URL of your deployed Cloud Run services with gcloud format flag


Requirements:

-   an existing Google Cloud Platform account
-   you have enabled the Cloud Run service and deployed already a container image

One of the nice things with Cloud Run is that when you deploy your services, you get a URL like https://myservice-8oafjf26aq-ew.a.run.app/, with a certificate, on the run.app domain name, etc.

You see the name of the service: myservice, the region shortcut where it was deployed: ew (Europe West), and then .a.run.app. However, you can't guess ahead of time what the final URL will be, as there is a randomly generated part in the URL (here: `8oafjf26aq`). Let's see how we can discover this whole URL.

From my terminal, I can request the list of deployed services (here, on the fully managed Cloud Run):

```bash
gcloud run services list \
       --platform managed
```

It's going to show me something like the following output:

```
   SERVICE      REGION        URL                                        LAST DEPLOYED BY     LAST DEPLOYED AT
✔  myservice    europe-west1  https://myservice-8oafjf26aq-ew.a.run.app  myself@foobar.com    2019-11-20T15:26:39.442Z
```

When describing the specific service (I had to specify the region as well, but you can set it by default if needed to avoid repeating yourself):

```bash
gcloud run services describe myservice \
       --platform managed \
       --region europe-west1
```

You'll see:

```
✔ Service hello in region europe-west1
https://myservice-8oafjf26aq-ew.a.run.app
Traffic:
  100%               LATEST (currently myservice-00002-dox)
Last updated on 2019-11-20T15:26:39.442Z by myself@foobar.com:
  Revision myservice-00002-dox
  Image:             gcr.io/my-sample-project/my-container-image:latest
```

So instead of parsing that ourselves somehow, there's a built-in way to get just the info we want, with the useful `--format` flag:

```bash
gcloud run services describe myservice \
    --format='value(status.url)' \
    --platform managed --region europe-west1 
```

This time, in output, you'll get just the URL, which you can then export or reuse with other commands.

```bash
https://myservice-8oafjf26aq-ew.a.run.app
```

The `glcoud` command provides three useful mechanisms to filter, format, or project the output and values returned. Here, we took advantage of format.

More information:

-   [https://cloud.run](https://cloud.run/), the serverless container platform
-   [Filtering and formatting fun with gcloud, GCP's command line interface](https://cloud.google.com/blog/products/gcp/filtering-and-formatting-fun-with)
-   [gcloud filters](https://cloud.google.com/sdk/gcloud/reference/topic/filters)
-   [gcloud formats](https://cloud.google.com/sdk/gcloud/reference/topic/formats)
-   [gcloud projections](https://cloud.google.com/sdk/gcloud/reference/topic/projections)
# Serverless tip #3 — Use the Cloud Run button on your Git repository to deploy your project in a click


Requirements:

-   an existing Google Cloud Platform account
-   a Git or Github repository containing your project
-   your project can have a Dockerfile (but not mandatory)

With [Cloud Run](https://cloud.run/), you can easily deploy a container image and let it scale up and down as needed, in a serverless fashion:

-   No need to focus on infrastructure (provisioning servers, clusters, upgrading OS, etc.)
-   Your application can scale transparently from 0 to 1, and from 1 to n (no need for a pager when your app is featured on Hackernews)
-   You pay as you go, proportionally to the usage

If your project is hosted on Github, for example, how can you help users get started with your project? You usually explain all the steps needed to build a container image, or where to fetch a pre-made image from a hub, and then steps to actually deploy that image on the platform. But thanks to the Cloud Run button, you can add a button image on your README.md page for instance, and then users can click on it and get started with building and deploying to a GCP project automagically.

![](https://deploy.cloud.run/button.svg)

If the Git repository contains a Dockerfile, it will be built using the docker build command. Otherwise, the CNCF Buildpacks (with the pack build command) will be used to build the repository.

The Cloud Run button github project gives extra information on the parameterization of the deploy URL of the button, for example if you want to specify a particular branch or directory.

More information

-   [https://cloud.run](https://cloud.run/), the serverless container platform
-   Cloud Run button [github project](https://github.com/GoogleCloudPlatform/cloud-run-button)
-   Cloud Run button [announcement](https://cloud.google.com/blog/products/serverless/introducing-cloud-run-button-click-to-deploy-your-git-repos-to-google-cloud)
-   [CNFC Buildpacks](https://buildpacks.io/)
# Serverless tip #2 — Deploy an executable JVM application with gcloud without app.yaml or build tool plugin


Requirements:

-   an existing Google Cloud Platform account and project
-   a Java or alternative language web application
-   a build that creates a standalone executable JAR file

Usually App Engine applications in Java are deployed with the gcloud command-line interface, or via a Maven or Gradle build plugin. 
Either way, an `app.yaml` file to describe your application is required to let the cloud SDK know that the project at hand is an App Engine project.

With the Java 11 runtime, however, it's possible to deploy a standalone executable JAR without `app.yaml`. 
The `gcloud app deploy` command now takes also a path to a standalone JAR file:

```bash
gcloud app deploy path/to/app.jar
```

App Engine will automatically assume that you are deploying to the Java 11 runtime, using an F1 instance (256MB of RAM and 600MHz of CPU). 
So this deployment would be equivalent to having a simple app.yaml file as follows:

```yaml
runtime: java11
instance_class: F1

```

More information:

-   [gcloud app deploy](https://cloud.google.com/sdk/gcloud/reference/app/deploy) command details
-   [app.yaml](https://cloud.google.com/appengine/docs/standard/java11/config/appref)
-   [Announcement and example with Maven and Spring](https://cloud.google.com/blog/products/application-development/app-engine-java-11-is-ga-deploy-a-jar-scale-it-all-fully-managed)
# Serverless tip #1 — Deploy a standalone JVM web app with Gradle and the App Engine plugin


Requirements:

-   an existing Google Cloud Platform account and project
-   a Java or alternative language web application
-   a Gradle build that creates a standalone executable JAR file

In youd `build.gradle` file, add the App Engine gradle plugin to your `buildscript` dependencies:

```groovy
buildscript {
    repositories {
        jcenter()
        mavenCentral()
    }
    dependencies {
        classpath 'com.google.cloud.tools:appengine-gradle-plugin:2.+'
    }
}
```

Apply the plugin, to make use of it:

```groovy
apply plugin: "com.google.cloud.tools.appengine-appyaml"
```

Then you can configure the `appengine` task to point at the standalone executable JAR:

```groovy
appengine {
    stage.artifact = 
            "${buildDir}/libs/${project.name}-${project.version}.jar"
    deploy {
        projectId = "YOUR-PROJECT-ID"
        version = "1"
    }
}
```

You can customize the path of the artifact, specify the project ID outside, or define an App Engine version that's dependent on your project version, a git commit, etc.

Note that the App Engine gradle plugin expects to find the `app.yaml` configuration file in `src/main/appengine`.

You can then deploy your application with:

```bash
$ ./gradlew appengineDeploy
```

More information:

-   [app.yaml](https://cloud.google.com/appengine/docs/standard/java11/config/appref)
-   [App Engine gradle plugin](https://github.com/GoogleCloudPlatform/app-gradle-plugin)
# Implementing Webhooks, not as trivial as it may seem


You've certainly interacted with **webhooks** at some point: with a Github commit webhook, for Slack or Dialogflow chatbots, for being notified of Stripe payments, or when you receive an SMS via Twilio. The concept is fairly well known, but there are some roadblocks along the way, whether you implement a webhook handler (the URL being called) or a webhook backend (the service notifying URLs). It's not necessarily as trivial as it may first seem. As I've been interested in Web APIs for a long time, I decided to look into this topic a bit more, by working on a new talk.

## Videos

I've had the chance of giving this talk at GeeCON Prague:

{{< youtube hRz38zGPSAU >}}

As well as (in French) at BDX.IO:

{{< youtube DRf7-dmhNHA >}}

You can also watch the slide deck here:

{{< speakerdeck b89328ff810c4955a8c2427d05f18bed >}}

## Summary

Initially, I was focusing on the backend webhook implementation aspects, but both the sending and receiving ends of webhooks have their own challenges.

Let me name the ones I encountered.

On the handler / client / receiving side, your webhook handlers should:

-   Reply with a 200 HTTP status code, to let the service provider know that you successfully received the event notification.
-   Reply fast, so that the service provider doesn't have to keep as many open connections to the handlers, to let it scale more gracefully to more customers. So a good approach is to acknowledge the reception of the event, but treat that event asynchronously afterwards.
-   Ack reception and defer event handling, as mentioned above when replying fast, it's important to "ack" quickly the reception, and then you're free to do long event handling afterwards, potentially with some worker queue, with workers that can treat those events at their own pace. You can then scale your workers pool when you need to deal with more notifications.
-   Calls should be idempotent. Sometimes, for various reasons, it's possible you get event notifications twice for the same event.
-   Use IP whitelisting, when possible, to ensure that only some IP addresses can ping your handler. Since you're opening an URL to the public, better be sure that it's only the service provider that calls you. But it's not always possible to define such a whitelist, as IP addresses are not necessarily fixed for the service provider.
-   Check request signature, this time not to avoid a DDoS, but more to ensure the integrity of the event payload that you receive. More on signatures in the server part below.
-   Take advantage of serverless solutions, as sometimes, you don't get a frequent or regular flow of event notifications, why have a server running all the time? Instead, you can take advantage of serverless solutions, like [App Engine](https://cloud.google.com/appengine/) or [Cloud Run](https://cloud.google.com/run/), as you're only billed for the time used.

On the service provider / server / notifier side, your webhook backend should:

-   Send small data payloads, instead of the whole resource that triggered the event. For instance, your service might notified handlers that there's a new video available. But you don't want to send tons of gigabytes of videos to each and every handler subscribed to that event. So just send a reference to that resource, and keep the event payload small.
-   Timeout if client is too slow, as you can't wait forever for a faulty handler to reply. Cut the connection if the client handler doesn't reply under a set time interval, and treat this as if the message hasn't been successfully delivered. Which means you'll have to retry sending that event later on.
-   Retry sending events with exponential backoff, to not overload a handler which is struggling to keep pace, in order to avoid DDoS-ing it with your retries. Instead, use exponential backoff to try to redeliver, for example, after 1s, 2s, 4s, 8s, 16s, etc. 
-   Keep track of non-responding handlers, after too many failed delivery attempts, mark those handlers as non-responding, and perhaps somehow notify the creator of the handler that it's not responding correctly.
-   Deliver messages from a work queue, as you have potentially tons of subscribers interested in your events, you don't want your event loop to be taking longer and longer to operate as the number of handlers grow, and instead, offload the work to some worker queue that you can scale independently from the work of keeping pace with ongoing events flow.
-   Batch events when too frequent, when there are too many event notifications to send. It might be more costly to send each and every event as they come, in real-time. If there are too many events, you can group them in one batch, so as to deliver them at an increased interval of time to your handlers.
-   Use a dead letter queue, for auditing purpose in particular. For non-responding handlers, or in case of handlers sometimes miss some events, you can push those never-received events in a dead letter queue, so that later on handler developers can check it to see if they actually missed something at some point in the flow.
-   Use HTTPS for secured connections, well, everyone should use HTTPS all the time these days anyone, but it's better for avoiding man-in-the-middle attacks, to avoid events replay, etc.
-   Sign requests with a secret, when handlers and service providers share a common secret, the provider can signe the request it sends to handlers, so that handlers can check the message is really coming from the service provider. For example, the Github API is using an HMAC signature, with a SHA-1 digest.
-   Use proper authentication/authorization mechanisms. This one is a bit vague, but the usual authentication/authorization best practices still apply to webhooks!

Going further, I'd like to expand this presentation with more hands-on concrete demos, that put all those best practices into action, and perhaps create some animations to show what happens when handlers are flooded with notifications, when handlers don't respond rapidly enough, etc, as that would probably help visualise more concretely each of those problems or practices. Let's see how I can continue iterating and improving this presentation and topic!

Resources

Last but not least, there are some great resources available on the topic, that I've added at the end of my slide deck. Be sure to check them out as well:

-   [Crafting a great webhooks experience](https://speakerdeck.com/apistrat/crafting-a-great-webhooks-experience-by-john-sheehan) (John Sheehan)
-   [WebHooks: the definitive guide](https://requestbin.com/blog/working-with-webhooks/)
-   [WebHooks: The API Strikes Back](https://www.infoq.com/presentations/webhooks-api/) (InfoQ)
-   [Webhooks vs APIs](https://hackernoon.com/webhook-vs-api-whats-the-difference-8d41e6661652)
-   [What is a Webhooks push-style API & how does it work](https://www.programmableweb.com/news/what-webhooks-push-styled-api-and-how-does-it-work/analysis/The2017/03/28) (ProgrammableWeb)
-   [Webhooks do's & dont's: what we learned after integration 100+ APIs](https://restful.io/webhooks-dos-and-dont-s-what-we-learned-after-integrating-100-apis-d567405a3671)
-   [How & why Pusher adopted Webhooks](https://www.programmableweb.com/news/what-are-webhooks-and-how-do-they-enable-real-time-web/2012/01/30)
-   [Webhooks vs WebSub: Which Is Better For Real-Time Event Streaming?](https://nordicapis.com/webhooks-vs-websub-which-one-is-better-to-stream-your-events-in-real-time/)
-   [Webhooks, the devil is in the details](https://techblog.commercetools.com/webhooks-the-devil-in-the-details-ca7f7982c24f)
-   [How to design a webhook for my API](https://phalt.github.io/webhooks-in-apis/)
-   [Serverless webhooks to revolutionize the SaaS](https://tomasz.janczuk.org/2018/03/serverless-webhooks-to-revolutionize-the-saas.html)
# App Engine 2nd generation runtimes and serverless containers with Cloud Run at Cloud Next Tokyo


Last week, I was in Tokyo for the first time, to speak at the Google Cloud Next conference. During the DevDay, I spoke about Google App Engine and its 2nd generation runtimes, and I also presented Cloud Run on how to deploy and run containers in a serverless fashion. It's been awesome to visit Japan for the first time and get a chance to meet developers there. Here are the slides I presented:

## App Engine 2nd generation runtimes

{{< speakerdeck 675bbf764343407d92eb4c2d9618de5c >}}

## Serverless containers with Cloud Run

{{< speakerdeck 59137c528fc04162a7806605fd936b4e >}}

# Getting started with Micronaut on Google App Engine Java 11


A [new Java runtime was announced for Google App Engine](https://cloud.google.com/blog/products/application-development/turn-it-up-to-eleven-java-11-runtime-comes-to-app-engine) standard: with Java 11. It's currently in beta, but anybody can already try it out. Another interesting announcement was the fact that the instances running your apps now get [double the memory](https://cloud.google.com/blog/products/application-development/app-engine-second-generation-runtimes-now-get-double-the-memory-plus-go-112-and-php-73-now-generally-available)! So with this double dose of great news, I decided to craft a little tutorial to show how to deploy a Micronaut application on App Engine Java 11. And because Apache Groovy is, well, groovy, I'll go ahead and use Groovy for my programming language, but of course, the same steps apply to Java workloads as well.

## Getting started on Google Cloud Platform

In this article, I assume you've created an account on Google Cloud Platform already (follow the "getting started" blue buttons to create an account otherwise and benefit from the [free tier and free quota](https://cloud.google.com/free/)), and that you've downloaded and installed the [gcloud](https://cloud.google.com/sdk/gcloud/) command-line SDK. You'll be able to follow the first few steps in the [quickstart guide](https://cloud.google.com/appengine/docs/standard/java11/quickstart), to create your GCP project and make it ready for using App Engine, in particular those commands:

```bash
$ gcloud projects create mn113-gae-java11 --set-as-default
```

You'll have to change the project ID from `"mn113-gae-java11"` to your own name of choice.

```bash
$ gcloud app create --project=mn113-gae-java11
```

It'll ask for a cloud region to use, I've decided to go with europe-west for this one.

The above steps can as well be done from the cloud console UI as well, at [https://console.cloud.google.com](https://console.cloud.google.com/).

Although your application will run for free within the free quota, we need to enable billing for our app, as it's going to use Cloud Build to build our app, and the latter requires billing to be enabled.

To enable billing and the Cloud Build API, please follow the first step of the [quickstart guide](https://cloud.google.com/appengine/docs/standard/java11/quickstart) mentioned above.

## Building our Micronaut application

Time to fire the Micronaut goodness! On my machine, I'm using SDKman to install my SDKs, so I've installed Java 11 and Micronaut 1.1.3 as explained in [Micronaut's getting started guide](https://docs.micronaut.io/latest/guide/index.html#buildCLI).

Our first step will be to create our basic Micronaut application, thanks to the following command, with the mn command-line SDK:

```bash
$ mn create-app mn113-gae-java11 --lang=groovy
```

The structure of your Micronaut project is created, with a Gradle-based build, an Application main class, an `application.yml` file to configure your application.

As this application isn't yet doing anything useful, we're create a `"Hello World"` controller with:

```bash
$ mn create-controller hello
```

We'll modify this newly created HelloController.groovy controller as follows:

```groovy
package mn113.gae.java11

import io.micronaut.http.annotation.*
@Controller("/hello")
class HelloController {
    @Get("/")
    String index() {
        return "Hello Micronaut!"
    }
}
```

 |

On the `/hello` path, we'll simply return a plain text response showing our greeting message.

To run your application locally, to check everything is working fine, you'll simply run:

```bash
$ ./gradlew run
```

And you can check that `localhost:8080/hello` returns the `Hello Micronaut` message. So far so good.

## Configure our Micronaut application for App Engine

In order to deploy the App Engine, we'll use the App Engine Gradle plugin. So we need to amend our `build.gradle` a little.

Let's define where Gradle will find the plugin:

```groovy
buildscript {
    repositories {
        jcenter()
        mavenCentral()
    }
    dependencies {
        classpath 'com.google.cloud.tools:appengine-gradle-plugin:2.+'
    }
}
```

We'll make use of the plugin:

```groovy
apply plugin: "com.google.cloud.tools.appengine-appyaml"
```

Let's configure the App Engine section:

```groovy
appengine {
    stage.artifact =
            "${buildDir}/libs/${project.name}-${project.version}.jar"
    deploy {
        projectId = "mn113-gae-java11"
        version = "1"
    }
}
```

Note that App Engine's version string is not supporting dots or underscores (only alphanumeric characters), hence why I replaced the `version` property. Furthermore a reported [issue](https://github.com/GoogleCloudPlatform/app-gradle-plugin/issues/353) prevents me from reusing the Gradle project's own project property in the `projectId` property.

## Configure the App Engine deployment

App Engine has its own deployment configuration file, where you will define the App Engine runtime (in our case Java 11), and you can also decide what kind of instance will be used to run your code. Last but not least, you can customize the entry point which defines how your application should be started.

In `src/main/appengine` we'll add a file named app.yaml:

```yaml
runtime: java11
instance_class: F4
entrypoint: 'java -agentpath:/opt/cdbg/cdbg_java_agent.so=--log_dir=/var/log -jar mn113-gae-java11-0.1.jar'
```

## Deploying to App Engine

Now you're ready to deploy your Micronaut application on App Engine's Java 11 runtime!

```bash
$ ./gradlew appengineDeploy
```

After a minute or so, and if billing and the Cloud Build API are enabled as said in the introduction, your Micronaut app should be deployed! You can then browse <https://mn113-gae-java11.appspot.com/hello> and get your Hello Micronaut greeting.

## What's next

In upcoming articles, I'll cover some other aspects, like how to configure and optimize static asset serving, or perhaps how to integrate with databases or other services of Google Cloud Platform. So stay tuned!
# Update on the recent serverless developments on GCP at DataXDay 2019


At [DataXDay 2019](https://dataxday.fr/), last week, I had the chance to present an updated version of my introductory talk on the [serverless compute options](https://cloud.google.com/serverless/) on Google Cloud Platform. There's always something new to cover!

For instance, if I put my Java Champion hat on, I'd like to mention that there are new runtimes for App Engine standard, like the beta for Java 11, and there's twice the amount of memory as before. On Cloud Functions, we have an alpha for Java as well (currently Java 8, but it'll be soon moved to Java 11 instead, as customers are more interested in the latest LTS version)

In this talk, I also covered [Cloud Run](http://cloud.run/), and Cloud Run on GKE (Google Kubernetes Engine), as well as telling a few words about the [Knative](https://knative.dev/) open source building blocks for Kubernetes, which allows to create serverless portable containers.

Here's the slide deck I presented at the conference:

{{< speakerdeck 620a008ef3694e93b3a43d15583ff980 >}}

# Turn it up to eleven: Java 11 runtime comes to App Engine


Yesterday, we [announced](https://cloud.google.com/blog/products/application-development/app-engine-second-generation-runtimes-now-get-double-the-memory-plus-go-112-and-php-73-now-generally-available) new second-generation runtimes for Go 1.12 and PHP 7.3. In addition, App Engine standard instances now run with double the memory. Today, we're happy to announce the availability of the new Java 11 second-generation runtime for App Engine standard in beta. Now, you can take advantage of the latest [Long-Term-Support version](https://www.oracle.com/technetwork/java/java-se-support-roadmap.html) of the Java programming language to develop and deploy your applications on our fully-managed serverless application platform.

Based on technology from the [gVisor container sandbox](https://github.com/google/gvisor), second-generation runtimes let you write portable web apps and microservices that take advantage of App Engine's unique auto-scaling, built-in security and pay-per-use billing model---without some of App Engine's earlier runtime restrictions. Second generation-runtimes also let you build applications more idiomatically. You're free to use whichever framework or library you need for your project---there are no limitations in terms of what classes you can use, for instance. You can even use native dependencies if needed. Beyond Java, you can also use alternative JVM (Java Virtual Machine) languages like [Apache Groovy](http://groovy-lang.org/), [Kotlin](https://kotlinlang.org/) or [Scala](https://www.scala-lang.org/) if you wish.

In addition to more developer freedom, you also get all the benefits of a serverless approach. App Engine can transparently scale your app up to n and back down to 0, so your application can handle the load when it's featured on primetime TV or goes viral on social networks. Likewise, it scales to zero if no traffic comes. Your bill will also be proportional to your usage, so if nobody uses your app, you won't pay a dime (there is also a free tier available).

App Engine second-generation runtimes also mean you don't need to worry about security tasks like applying OS security patches and updates. Your code runs securely in a [gVisor](https://gvisor.dev/)-based sandbox, and we update the underlying layers for you. No need to provision or manage servers yourself---just focus on your code and your ideas!

## What's new?

When you migrate to Java 11, you gain access to all the goodies of the most recent Java versions: you can now use advanced type inference with the new var keyword, create lists or maps easily and concisely with the new immutable collections, and simplify calling remote hosts thanks to the graduated HttpClient support. Last but not least, you can also use the JPMS module system introduced in Java 9.

You'll also find some changes in the Java 11 runtime. For example, the Java 11 runtime does not provide a Servlet-based runtime anymore. Instead, you need to bundle a server with your application in the form of an executable JAR. This means that you are free to choose whichever library or framework you want, be it based on the Servlet API or other networking stacks like the Netty library. In other words, feel free to use [Spring Boot](https://spring.io/projects/spring-boot), [Vert.x](https://vertx.io/), [SparkJava](http://sparkjava.com/), [Ktor](https://ktor.io/), [Helidon](https://helidon.io/#/) or [Micronaut](https://micronaut.io/) if you wish!

Last but not least, second-generation runtimes don't come with the built-in APIs like Datastore or memcache from the App Engine SDK. Instead, you can use the standalone services with their Google Cloud client libraries, or use other similar services of your choice. Be sure to look into our [migration guide](https://cloud.google.com/appengine/docs/standard/java11/java-differences) for more help on these moves.

## Getting started

To deploy to App Engine Java 11, all you need is an app.yaml file where you specify `runtime: java11`, signifying that your application should use Java 11. That's enough to tell App Engine to use the Java 11 runtime, regardless of whether you're using an executable JAR, or a WAR file with a provided servlet-container. However, the new runtime also gives you more control on how your application starts: by specifying an extra `entrypoint` parameter in `app.yaml`, you can then customize the java command flags, like the -X memory settings.

With Java 11, the `java` command now includes the ability to run single independent `*.java` files without compiling them with `javac`! For this short getting started section, we are going to use it to run the simplest hello world example with the JDK's built-in HTTP server:

```java
import com.sun.net.httpserver.HttpServer;
import java.io.*;
import java.net.InetSocketAddress;

public class Main {
    public static void main(String[] args) throws IOException {
        var server = HttpServer.create(new InetSocketAddress(8080), 0);
        server.createContext("/", t -> {
            var response = "Hello World from Java 11.".getBytes();
            t.sendResponseHeaders(200, response.length);
            try (var os = t.getResponseBody()) {
                os.write(response);
            }
        });
        server.start();
    }
}
```

Notice how our Main class uses the var keyword introduced in Java 10, and how we re-used the keyword again in the `try-`with-resources block, as `Java 11` makes possible.

Now it's time to prepare our `app.yaml` file. First, specify the `java11` runtime. In addition, `entrypoint` define the actual `java` command with which to we'll be running to launch the server. The `java` command points at our single Java source file:

```yaml
runtime: java11

entrypoint: java Main.java
```

Finally, don't forget to deploy your application with the `gcloud app deploy app.yaml` command. Of course, you can also take advantage of dedicated Maven and Gradle plugins for your deployments.

## Try Java 11 on App Engine standard today

You can write your App Engine applications with Java 11 today, thanks to the newly released runtime in beta. Please read the documentation to get started and learn more about it, have a look at the [many samples](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/appengine-java11) that are available, and check out the [migration guide](https://cloud.google.com/appengine/docs/standard/java11/java-differences) on moving from Java 8 to 11. And don't forget you can take advantage of the [App Engine free tier](https://cloud.google.com/free/docs/always-free-usage-limits) while you experiment with our platform.

*From the App Engine Java 11 team Ludovic Champenois, Eamonn McManus, Ray Tsang, Alexis Moussine-Pouchkine, Averi Kitsch, Lawrence Latif, Angela Funk.*
# A serverless Java developer's journey


Last week at the Google [Cloud Next](https://cloud.withgoogle.com/next/sf/) conference, I had the chance to speak about the Java developer's journey through the "serverless" offering of [Google Cloud Platform](https://cloud.google.com/), with my colleague Vinod Ramachandran (Product Manager on some of our serverless products):

Serverless Java in 2019 is going to be ubiquitous in your favorite cloud. Well, it's actually been 10 years since you could take advantage of Java on Google App Engine. But now you can run your apps on the brand-new Java 11 runtime. Not only servlet-based apps but also executable JARs. And what about authoring functions? Until now, you could only use Node or Python, but today, Java is the third runtime available for Google Cloud Functions. We will review the various ways you can develop your Java functions. Last but not least, thanks to serverless containers, containerized Java workloads run serverlessly, without you caring for infrastructure, scaling, or paying for idle machines. Through various demos, we will look at the many ways Java developers will be able to write, build, test, and deploy code in Java on the rich serverless offering of Google Cloud Platform.

Until fairly recently, our compute serverless products consisted only of [Google App Engine](https://cloud.google.com/appengine/) for deploying apps and services, and [Cloud Functions](https://cloud.google.com/functions/) for deploying functions. Furthermore, for the Java developer, the situation wasn't that great as Cloud Functions wasn't offering any Java support (only Node, Python and Go runtimes), and only App Engine provided a Java 8 runtime.

Fortunately, some very important announcements were made at Cloud Next:

-   First of all, in addition to the Java 8 runtime, we have launched an alpha for a brand [new App Engine Java 11 runtime](https://docs.google.com/forms/d/e/1FAIpQLSf5uE5eknJjFEmcVBI6sMitBU0QQ1LX_J7VrA_OTQabo6EEEw/viewform).
-   We introduced a [Java 8 flavor for Cloud Functions](https://docs.google.com/forms/d/e/1FAIpQLScC98jGi7CfG0n3UYlj7Xad8XScvZC8-BBOg7Pk3uSZx_2cdQ/viewform).

-   Last but not least, we launched a new product, [Cloud Run](https://cloud.google.com/run/), which allows you to run containers serverlessly, and thus any Java workload that can be containerized.

So you can develop Java functions, Java apps and Java-powered containers in a serverless fashion:

-   Scaling on demand as needed to serve incoming requests as well as down to zero when no traffic comes.
-   Paying proportionally to the usage.
-   And all of that, without having to worry with server or cluster provisioning and management.

Without further ado, let me share with you the video and the slides of this presentation:

Video recording:

{{< youtube WnhAYX1Phxw >}}

Now it's your turn! If you want to try out functions, apps, and containers in Java, here are a few pointers to get you started:

-   [Sign-up form](https://docs.google.com/forms/d/e/1FAIpQLSf5uE5eknJjFEmcVBI6sMitBU0QQ1LX_J7VrA_OTQabo6EEEw/viewform) for App Engine Java 11
-   [Sign-up form](https://docs.google.com/forms/d/e/1FAIpQLScC98jGi7CfG0n3UYlj7Xad8XScvZC8-BBOg7Pk3uSZx_2cdQ/viewform) for Cloud Functions Java 8
-   Cloud Run [documentation](https://cloud.google.com/run/)

# On curiosity and sharing with the world


At the end of December, I was contacted by someone I didn't know, who asked me some interesting questions, and that led me to quite a bit of introspection.

As a Java Champion and with your career history. I wanted to ask you what you consider are the most important skills for a Java programmer to have in their toolbox, especially a Senior Java programmer? Or maybe even a better question is what skills you developed that helped you become the Java Developer/Groovy Language Developer that you are today.

In a nutshell, as I answered this person, for me it all boiled down to lots of curiosity, and the desire to share my findings with the world. It's not really about knowing specific methodologies, technologies or languages, or which soft or hard skills to master. It's about the core attitudes from which all the rest will derive from. But first, a bit of background about me.

## A bit of history

Alright, so if I was contacted (and actually a few others as well) with those questions, it's because I'm considered to be a visible and public person. Because I'm known for my work in the Java community and more precisely in the Apache Groovy ecosystem. I've been in the field for quite a number of years, along with my contributions in Open Source, and that makes me a senior developer. But how did I get there?

You've learned a lot during your studies, but often, not much of what you learned is immediately applicable in your daily duties and tasks. So there's even more to learn to become a productive developer. I started working as a junior Java developer in 2001. I was lucky to have had a great mentor that helped me design and write better code. I also spent quite some time reading Java and development related news websites or blogs. I wanted to know what were the latest trends (new language features, frameworks), the best tools for the job, how developers were developing on their projects. So clearly, I was pretty curious to look beyond just what I was doing at work, but to see if I could become a better programmer by learning from others. There's so much great content on the web, so much information that is shared, from best practices to bug fixes explanations, that you can learn a lot. That's also more or less when I started blogging. I saw so many useful blog posts that helped me, that I thought it would be a good thing to share back things I learned that could be helpful to others as well.

In 2003, at work, I needed a way to extend an app I was working on, and clearly, some kind of scripting solution was what would allow the end-users of our app to further customize and tailor the application to their needs. So I spent some time reviewing existing Java scripting solutions, but none were really ideal. Fortunately, that's when Groovy was born. It was embryonic, and not really ready for prime time though. But it was what I needed.

I started playing with Groovy, but quickly I encountered tons of problems and bugs. Since the code was Open Source, I started looking at its codebase, outside of work. I quickly understood where some of the bugs were coming from, and found ways to fix them. Since the community was pretty open, I participated in the mailing-lists to tell about those bugs, to help other users. It was nice to feel being part of a nice, friendly and helpful community.

I used the bug tracker to file bugs and feature requests, and when I could I even submitted some patches to fix these. My patches were accepted, and in a handful of months, I was asked to become an official committer on the project (which I gladly accepted). By working with the other committers, I learned a lot about Java, the JVM, or how open source projects worked. That was super interesting. Since the code was public, I really wanted all my contributions to be top-notch, perfectly well tested and commented. Somehow I had the impression that the scrutiny of my peers mandated that I had to produce even better code than at work! So I perfected my craft. A lot.

Since I had already started sharing my findings on my blog (and later on on social networks), I became part of the so-called "blogosphere", and started interacting with other bloggers. I wrote about Java and Groovy, of course, but the discussions with other open source developers, allowed me to also meet them in the real world. We even started a meetup of open source developers that shared what they were working on. That's how I did my first public presentation, to show Groovy to my peers, in 2004 or so, at our local gatherings. I came to know people working for big companies like Sun or Oracle, as well as smaller actors, from freelancers, to entrepreneurs. A handful of those companies started using Groovy, and that's how one day, someone asked if I'd be ready to talk with them at a big conference. That was for JavaOne! My first big conference and presentation was in the US in front of 600 persons. Woh... That's how I started sharing more widely with the world, and also started travelling to spread the word.

I spent a lot of time on Groovy and its ecosystem, and I later got the chance to both work on those technologies for a living (after doing quite a bit of consulting), as well as even creating my own company to focus on the project. At the same time, I was still continuing presenting about Groovy, and still improving the language thanks to the feedback I was getting from the many developers I was meeting all around the world. I was doing developer advocacy at the same time as product management and development. Three hats in one. And by doing developer advocacy, that's also what landed me my current job of developer advocate at Google.

## The ever changing nature of our field

From the narrated history above, there's a theme that emerges: curiosity. But what lead me to being curious? Tons of people are doing 9-to-5 jobs, and that's totally fine. However, as we spend so much time in our lives at work, for me, it had to be interesting and motivating. To be interesting, work has to be somehow entertaining --- beside spending quality time with great coworkers. If it's not interesting, you get bored very easily, and you don't want to wake up every morning to go to the office. So how not to be bored? By making your job more interesting. How to make it more interesting? Well, if you're passionate about what you're doing, it's much easier to go through the day and do fun and interesting things, event for a project that could appear as not being very fancy.

Programming was first a hobby, for me, as a child and teenager. It never really occurred to me it could become my job. Initially, I just wanted to be... an "engineer". Perhaps in aerospace, or something like this. Who hasn't dreamt of becoming an astronaut? It's only late in my studies that I thought I could actually become a developer. So my hobby, my passion, became my job. But there's a big difference between working on stuff you want, versus being asked to work on stuff for the company which hired you. In order to not be bored, be sure to push for improving the project in interesting ways both for you and the end-users. If possible, perhaps try to introduce and learn new technologies that can make the product better, and at the same time make you learn something new. Be passionate about improving both your projects and your skills.

Notice also that in our field, we actually don't really have a choice but to learn. When I was a student, my current job didn't even exist. When I started working, the languages or tools I'm using today weren't available then yet. So in IT, in programming, etc, there's always a new language, a new tool, a new practice, new patterns, etc, that come to light. It's a field where we have to be in a constant learning state, in order to stay relevant. If you're not learning, your skills will rot, you'll be less employable, you'll diminish your chances of having a fantastic job. So you have to be curious and learn all the time. To not be bored, but also to get better at your craft.

With all those new tools, languages, frameworks, technologies, you have to keep up with what's going on. You have to be ready to learn something new.

## Sharing is caring

We talked a lot about being curious, about learning all along, but I also mentioned about sharing. As the saying goes, sharing is caring, but it's also about creating opportunities for you.

Sharing what I learned or worked on was helpful for others too (who encountered similar problems, for example), but it's also how I came to meet wonderful people along the way. Even mentors and role models. If I hadn't blogged or tweeted, I wouldn't have been able to start making presentations at meetups and conferences. And many of the friends I have today are friends I met along the way, at meetups, conferences, working on open source projects together, and so on.

Without sharing my code, I wouldn't have had the opportunity to meet my future employers and colleagues, as well as the co-founders of my own startup. Sharing is great to be visible, of course, but it's a wonderful way to meet new people from whom you'll learn a lot.

Open source is sharing too. Working on open source projects, nurturing communities and ecosystems around those, further allowed me to meet great people around the world. And it's what lead me to get the jobs at companies I was interested in. It created great professional opportunities.

## Summary

Let's try to wrap up a bit. It's really not about learning a particular tool or technology. It's all about being curious and passionate about your craft, and to share what you've learned with the world.

### Be curious!

It'll make your daily job more interesting. You will learn lots of great new technologies. You'll become a better developer by learning from your peers. You'll improve your craft and expertise. It'll increase your employability. You'll even likely become an expert in your field!

### Share with the world!

Write, blog, tweet, present about the things you've learned at meetups or conferences. You'll learn a lot from others along the way. Write and share code, and/or contribute to open source projects. You'll meet awesome peers and mentors. And will create all sorts of interesting job opportunities.

### Be curious and share with the world!

# Tip: Making a Google Cloud Storage bucket or file public


[Google Cloud Storage](https://cloud.google.com/storage/) is the ideal product to store your object files (binary files, pictures, audio/video assets, and more).

Until recently, there was an option in the Google cloud console with a checkbox to quickly make a file or bucket public. However, and I would add "unfortunately", users tended to inadvertently clicking the checkbox, thus making potentail confidential assets public. So this risky, but easy, option, has been removed to avoid any unwanted data leak.

However, of course, it's still possible to [make buckets or files stored in Cloud Storage public](https://cloud.google.com/storage/docs/access-control/making-data-public). But you can't do it without paying attention! As I never quite remember how to do that (in spite of the linked documentation easily found with a quick Google search), I decided to highlight with a few screenshots how to achieve that!

I assume you already have or created a GCP project, and you also have a bucket full of assets that you want to make public, because you need to share them on the Web, for your mobile application, etc.

To illustrate this tip, let's have a look at the GCP cloud console:

![](/img/public-bucket/gcs-01-file-browser-small.png)

## Making a file public

First, we'll have a look at making a single file public.

You'll have to click the vertical triple dot icon on the right of the screen, and click on `Edit permissions`:

![](/img/public-bucket/gcs-02-permissions-drop-down-small.png)

Once you've clicked on this option, you'll be given the choice to add new permissions to members or groups of members:

![](/img/public-bucket/gcs-03-permissions-dialog-small.png)

In our case, we want to allow all the users to have read access on that particular file. So I'm giving the `Group` of `allUsers` the `Reader` access level. Then, once saved, in the file browser, you should see the following icon warning you the file is now public:

![](/img/public-bucket/gcs-04-public-warning-small.png)

## Making a bucket public

Instead of doing this for each individual file, you can also do the same at the bucket level, to give read access to the bucket and all its files in one go.

From the object browser, click on the `Permissions` tab. You will have to add the `allUsers` members the `Storage Object Viewer` role:

![](/img/public-bucket/gcs-05-bucket-permissions-small.png)

Click on the `Add members button`, type `allUsers`, select the `Storage > Storage Object Viewer` option, as follows, and click `add`:

![](/img/public-bucket/gcs-06-add-role-to-bucket-users-small.png)

Now if you head back to the file browser, you'll see all the files have the little warning icon telling you the resource is publicly accessible.

## For command-line gurus

I showed the visual approach from the cloud console... but there's a one-liner you can use, thanks to the [gsutil](https://cloud.google.com/storage/docs/gsutil) command.

For an individual file:

```bash
gsutil acl ch -u AllUsers:R gs://[BUCKET_NAME]/[OBJECT_NAME]
```

For a whole bucket:

```bash
gsutil iam ch allUsers:objectViewer gs://[BUCKET_NAME]
```

(Where you replace `[BUCKET_NAME]` with your project name, and `[OBJECT_NAME]` with the file name)

## More...

There's also a REST API that you can use to handle your buckets and file, as well as different client libraries in different languages that you can use as well.
# Mais c'est quoi un Developer Advocate ?


J'ai eu le plaisir d'encadrer des stagiaires de 3ème récemment chez Google. Nous accueillons des enfants, neveux, nièces, cousins d'employés de Google (donc non :-P, je ne prends pas de stagiaire, pas la peine de demander !!!) pour leur faire découvrir les différents métiers que nous exerçons dans l'entreprise. Et il y en a beaucoup !

L'un de mes stagiaires m'a interviewé lorsque je décrivais mon travail de "Developer Advocate", au sein de Google Cloud. J'ai trouvé cette interview intéressante, et je me suis dit que ça valait le coup de la partager avec vous, en Français (si, si, j'écris en Français parfois sur ce blog.)

L'exercice de cet entretien est intéressant parce qu'il me permet d'essayer d'expliquer de manière simple ce que je fais... et ce n'est pas évidant, vu la technicité de cet univers, des produits sur lesquels on travaille (qui ne sont pas à la portée du grand public). Donc voici quelques unes des questions auxquelles j'ai eu à répondre. J'espère que vous trouverez cela intéressant.

## Quel est ton métier ?

Je suis **Developer Advocate** pour la branche **Google Cloud** de Google.

C'est un titre en anglais qui n'a pas vraiment d'équivalent en Français.

[Google Cloud](https://cloud.google.com/), c'est la partie de Google qui propose des produits comme par exemple Gmail pour la messagerie électronique, Google Docs pour le traitement de texte ou de tableurs, mais qui offre également aux développeurs et ingénieurs des serveurs sur lesquels les développeurs peuvent héberger leurs applications, des bases de données pour stocker leurs données, ou bien encore des services autour de l'intelligence artificielle pour reconnaître ce qu'il y a comme objets dans des images.

## Quelles sont les principales activités dans ce métier ?

Le rôle d'un Developer Advocate est d'être une sorte de représentant des développeurs (nos utilisateurs et clients qui créent des applications). Nous collectons les retours de ces développeurs pour voir comment améliorer les produits de Google, en écoutant leurs besoins, leurs demandes, les problèmes qu'ils rencontrent.

Par ailleurs, une autre grande partie de ce rôle (la partie la plus visible de l'extérieur), c'est de présenter et promouvoir les produits de Google (Google Cloud dans mon cas). Il s'agit alors d'écrire des articles, de coder des exemples de programmes utilisant nos technologies, enregistrer des vidéos, préparer des présentations que nous donnons lors de conférences locales ou internationales, puis aussi tirer partie des réseaux sociaux pour faire passer notre message.

Enfin, nous sommes également les utilisateurs "zéro" de nos futurs nouveaux produits. Nous sommes donc les premiers à tester ces produits, pour voir ce qui fonctionne ou pas, s'ils sont faciles à utiliser, s'ils ont des bugs, si l'on peut trouver des façons de les améliorer ou de les enrichir avant de les sortir publiquement.

## Travailles-tu plutôt seul ou en équipe ? Pourquoi ?

Je travaille dans une équipe internationale, répartie dans différents pays, avec des bureaux à San Francisco, Seattle, New York, Londres, Paris ou Tokyo. Parfois je travaille effectivement en équipe, à plusieurs sur un même sujet, mais beaucoup de mes activités sont aussi solitaires, comme lorsque l'on prépare une démonstration et une présentation pour une conférence.

## Dois-tu prendre des initiatives ? Pourquoi ?

Le poste de Developer Advocate est un travail qui demande beaucoup d'autonomie, et donc qui nécessite de prendre soi même beaucoup d'initiatives. C'est à moi de décider sur quel sujet travailler, quel article écrire, à quelle conférence je souhaite assister.

Parfois, les Developer Advocates ont des demandes venant des chefs de produits qui souhaiteraient que nous représentions leur produit, mais c'est généralement par soi même que l'on décide sur quoi travailler.

## As-tu des responsabilités ? Si oui lesquelles ? Pourquoi ?

Je n'encadre personne, donc je n'ai en tout cas pas de responsabilité managériales. Par contre, je me focalise sur une certaine gamme de produits, et c'est de ma responsabilité de représenter et d'améliorer ces produits là.

## As-tu des contacts avec des personnes autres que tes collègues de travail ? Pourquoi ?

Comme une partie de mon travail consiste à aller présenter les produits de Google Cloud à des conférences, des "meetups", des groupes d'utilisateurs, je rencontre effectivement beaucoup de monde lors de ces événements. Egalement au travers des réseaux sociaux, j'interagis souvent avec des développeurs aux quatre coins du monde. Et j'ai également la chance de pouvoir rencontrer nos clients, pour discuter de leurs problèmes, de leurs besoins, mais aussi de leurs réussites.

## Les activités sont-elles variées ou répétitives ?

Les activités sont effectivement variées, aussi bien de la programmation (pour préparer des démonstrations des produits), de la communication (pour des présentations), de l'écriture (pour les articles, la documentation que nous rédigeons), mais aussi le voyage au travers le monde permets de découvrir de nouveaux horizons et de nouvelles cultures.

## Dois-tu organiser ton travail ou plutôt exécuter des consignes ?

Comme je le disais plus haut, c'est un travail qui demande beaucoup d'autonomie, donc c'est à moi d'organiser mon travail, d'autant plus que j'ai déjà un certain niveau d'ancienneté. Il arrive parfois qu'on me demande certaines choses effectivement, mais le plus souvent c'est à moi de m'organiser.

## Est-ce que le travail est fatigant (nerveusement et physiquement) ? Pourquoi ?

Parfois oui. Il y a beaucoup à faire : Google Cloud possède de nombreux produits, qui sont développés rapidement, il y a donc énormément de choses à couvrir et étudier. Ce qui est également fatigant, c'est le fait de voyager au travers le monde avec les décalages horaires, les tracas associés au voyage de manière générale.

Outre le voyage et la quantité de travail, il faut travailler régulièrement avec la maison mère qui est sur la côte Ouest des Etats-Unis, avec 9 heures de décalage horaire, ce qui veut dire qu'il faut pouvoir faire des conférences téléphoniques avec mes collègues outre-Atlantique après 18 ou 19 heures, voire parfois même à 21 ou 22 heures ! Autre exemple, lorsque l'on donne des présentations à des "meetups", c'est souvent le soir après le travail, donc on peut rentrer parfois très tard chez soi.

## Est-ce que cette profession permet d'obtenir une promotion ? Laquelle ?

Dans ce rôle, il y a différents grades, différents niveaux. Quand on commence dans ce métier, on entrera à un certain niveau, et au fil des années, on pourra progresser et monter de niveau en niveau. L'entreprise n'attends pas la même chose de ses employés en fonction de leur niveau d'ancienneté. Nous avons une sorte d'échelle qui décrit ce qui est attendu de chacun à chaque niveau de sa progression hiérarchique.

## Quels sont les diplômes requis ?

Il faut généralement un Bac+5 (type mastère, école d'ingénieur) en informatique et avoir déjà une certaine expérience professionnelle dans le domaine de l'informatique pour bien comprendre la problématique de nos utilisateurs et clients.

## Quel est le contenu des études ?

Dans mon cas (un DESS en informatique), ce sont des études qui permettent aux étudiants d'apprendre comment fonctionnent les ordinateurs, d'apprendre des langages de programmation, comment écrire des algorithmes, comment fonctionne les réseaux informatiques ou les bases de données, etc.

## Est-ce qu'il y a d'autres formations possibles (formation continue, cours du soir, autres) pour cette profession ?

Bien qu'un diplôme Bac+5 en informatique soit le plus commun, du moment qu'on a une bonne expérience professionnelle dans le domaine, il est aussi possible de bifurquer vers cette profession. Mais il n'y a à proprement parlé pas de formation spécifique pour le rôle de Developer Advocate à ma connaissance.

On demande souvent aux jeunes "qu'est-ce que tu voudras faire plus tard ?" 

Dans mon cas, je voulais être "ingénieur", et j'aimais bien l'informatique, mais ce qui est amusant c'est qu'à l'époque où j'ai fait mes études, le métier de "Developer Advocate" n'existait pas vraiment. Donc qui peut dire quels métiers existeront quand vous serez sur le marché du travail ? Il faut savoir s'adapter, car de nouveaux métiers voient le jour régulièrement, et il n'y aura pas forcément de formation spécialisée pour y parvenir, ou de parcours type.

## Quelle sont les qualités requises ?

Outre le fait d'être un bon ingénieur en informatique (savoir programmer, etc.), il faut aussi avoir de très bonnes capacités communicationnelles, un esprit de synthèse et de vulgarisation, car nous devons aider nos utilisateurs et clients à comprendre comment se servir de nos produits.

Par ailleurs, la majeure partie de mon travail s'effectue en anglais, qui est la langue de la maison mère, mais la langue internationale en informatique et lorsque l'on voyage. Donc il faut absolument être bon en Anglais pour ce travail.
# Machine learning APIs with Apache Groovy


At [GR8Conf Europe](https://gr8conf.eu/) last year, I [talked](https://2018.gr8conf.eu/talks/610) 
about how to take advantage of the [Google Cloud machine learning APIs](https://cloud.google.com/products/ai/building-blocks/) 
using [Apache Groovy](http://groovy-lang.org/).

With Groovy, you can call the Vision API that recognises what's in your pictures, or reads text.

You can invoke the Natural Language API to understand the structure of your text.

With the Speech-To-Text API, you can get transcriptions of what's been said in an audio stream, or with Text-To-Spech, 
you can also generate human-like voices from your own text.

With those ready-made APIs, no need to be an expert data scientist! Just call an SDK or a REST API, and you're ready to go.

Here's the video of the presentation:

{{< youtube WKK1iUoB6CE >}}

And here are the slides that I showed:

{{< speakerdeck c2927b99b7b64b9c83a90fe81704a9f2 >}}

In a [previous article](http://glaforge.appspot.com/article/vision-recognition-with-a-groovy-twist), 
I also presented one of the sample that I used with the Vision API.

The [Call for Paper](https://www.gr8conf.eu/cfp) for the new edition of GR8Conf Europe is still open, 
so don't miss the opportunity to tell the world about all the cool things you've been doing with Apache Groovy!




# Interview InfoQ en Français sur les microservices sur Google Cloud Platform


Une fois n'est pas coutume, je vais parler de Google Cloud Platform en français ! 
Lors de la conférence Voxxed Days Microservices, que j'ai 
[couverte récemment]({{< ref "/talks/2019/01/03/new-serverless-solutions-on-google-cloud-for-functions-apps-and-containers" >}}), 
j'ai eu l'occasion de répondre à une interview pour InfoQ France.

[Interview sur les microservices sur Google Cloud Platform](https://www.infoq.com/fr/interviews/voxxeddays-microservices-2018-guillaume-laforge)

Voici la liste des questions auxquelles j'ai répondues, et je vous laisserai écouter les réponses sur 
[InfoQ France](https://www.infoq.com/fr/interviews/voxxeddays-microservices-2018-guillaume-laforge) !

-   Pour ceux qui ne te connaissent pas, peux-tu nous dire qui tu es ?
-   Elles sont où les équipes produits ?
-   Et les utilisateurs, en France, il y en a beaucoup ?
-   Pour les néophytes, les microservices, qu'est-ce que c'est ?
-   C'est quoi le "nouveau" par rapport aux architectures dites distribuées, soa, webservices ?
-   On va parler de la platforme cloud de google, où ça en est ?
-   C'est quoi serverless, le retour du mainframe ?
-   Quelles nouveautés ?
-   Et Google vis à vis de java ?
-   C'est quoi les langages que vous poussez le plus ?
-   Le futur des microservices ?
# New Serverless Solutions on Google Cloud for Functions Apps and Containers


At [Voxxed Days Microservices](https://voxxeddays.com/microservices/), in Paris, 
I talked about the latest development in serverless solutions on [Google Cloud Platform](https://cloud.google.com/products/), 
to deploy [functions](https://cloud.google.com/functions/), [apps](https://cloud.google.com/appengine/) 
and even [containers](https://cloud.google.com/blog/products/gcp/bringing-the-best-of-serverless-to-you).

I answered an [interview](https://voxxeddays.com/microservices/2018/09/16/guillaume-laforge-on-serverless-solutions-on-google-cloud/) 
on the theme of microservices, and how this maps to the Google cloud products.

And the video of my presentation was published on YouTube:

{{< youtube Ke89_rFx7tI >}}

Here's the abstract of the session:

> Plenty of novelties in the Serverless offering of Google Cloud Platform, whether you're developing functions, apps or containers.
>
> Let's get started with the new modern runtimes for the venerable Google App Engine, 
> sandboxed thanks to the open source gVisor container sandboxing technology. 
> Cloud Functions is now GA with Node.js, but also offers new languages like Python to let you implement your functions.
> If you need more flexibility, you will also be able to run serverless containers: just dockerize your project and off you go!
> 
> But the crux of the show has to be the new open source project, Knative, a collaboration of Google with key vendors like Pivotal, 
> IBM, Red Hat or SAP, which offers a set of portable building blocks on top of Kubernetes to build serverless platforms. 
> Additionally, you will be able to try out Knative on Google Kubernetes Engine thanks to a dedicated add-on.
> 
> In this session, we'll review all the new serverless-related features of Google Cloud Platform with concrete demos, 
> so you can get started easily and rapidly.
# Deploy a Micronaut application containerized with JIB to Google Kubernetes Engine


A few weeks ago, I had the chance to be at [Devoxx Belgium](https://devoxx.be/) once again, to meet developers and learn about new things from awesome speakers. Google Cloud Platform had its own booth on the exhibition floor, and the team was running codelabs: 10 laptops were at the disposal of attendees to go through various hands-on tutorials on several GCP products. I took a chance at crafting my own codelab: deploying a Micronaut application, containerized with Jib, to Google Kubernetes Engine.

For the impatient, follow this link: [g.co/codelabs/micronaut](https://g.co/codelabs/micronaut)

Note: If you haven't got a GCP account already, know that there's a [free trial with $300 of cloud credits](https://console.cloud.google.com/freetrial) to get started.

More information on the tools used:

-   [Micronaut](http://micronaut.io/) is a modern, JVM-based, full-stack framework for building modular, easily testable microservice and serverless applications. Micronaut aims to deliver great startup time, fast throughput, with a minimal memory footprint. Developers can develop with Micronaut in Java, Groovy or Kotlin.

-   Jib is an open source tool that lets you build Docker and OCI images for your Java applications. It is available as plugins for Maven and Gradle, and as a Java library.

-   [Kubernetes](https://kubernetes.io/) is an open source project which can run in many different environments, from laptops to high-availability multi-node clusters, from public clouds to on-premise deployments, from virtual machines to bare metal.

-   [Google Kubernetes Engine](https://cloud.google.com/kubernetes-engine/) is Google Cloud Platform's hosted Kubernetes platform.

In this codelab, you deploy a simple Groovy-based Micronaut microservice to Kubernetes running on Kubernetes Engine.

The goal of this codelab is for you to run your microservice as a replicated service running on Kubernetes. You take code that you have developed on your machine, turn it into a Docker container image built with Jib, and then run and scale that image on Kubernetes Engine.
# An Intro to Google Cloud Platform


In a matter of a few years, Google Cloud Platform has evolved from a very small set of products or APIs to a wealth of close to a hundred of products, services and APIs that developers can take advantage of.

This week, at the event [Le Meilleur Dev de France](https://www.meilleurdevdefrance.com/), I gave an introduction to the whole platform, focusing on three key axis: compute, storage and machine learning. After an introduction on famous users of GCP, like Snapchat, Spotify or PokemonGo, I also gave a few examples of big French companies as well as French startups who have decided to go to the cloud with Google.

Later on, over the course of three sections, as I was covering the multiple solutions in each areas (compute / storage / ML), I also tried to give concrete hints as to when to use what, depending on your application needs. Indeed, as many solutions are at your disposal, comes the paradox of choice, as with more options, choice becomes more complicated.

Here are the slides I presented:

{{< speakerdeck 5bc87feeb5914782a2476411c01d353a >}}
# Nice Series on Spring Cloud Integration for Google Cloud Platform


My friend and former colleague [Josh Long](https://twitter.com/starbuxman) wrote a nice series of articles showing the Spring Cloud integration for Google Cloud Platform. The series contains 8 articles, covering:

-   [the setup & authentication](https://spring.io/blog/2018/08/20/bootiful-gcp-getting-started-with-spring-cloud-for-google-cloud-platform-1-8), 
-   how to [access relational databases](https://spring.io/blog/2018/08/23/bootiful-gcp-relational-data-access-with-spring-cloud-gcp-2-8), 
-   how to [connect to Spanner](https://spring.io/blog/2018/08/27/bootiful-gcp-globally-consistent-data-access-with-spanner-3-8), 
-   how to [send/receive messages with Pub/Sub](https://spring.io/blog/2018/08/30/bootiful-gcp-integration-with-google-cloud-pub-sub-4-8), 
-   how to [use the runtime configuration](https://spring.io/blog/2018/09/03/bootiful-gcp-runtime-configuration-with-spring-cloud-gcp-runtime-config-5-8), 
-   how to look into [Stackdriver tracing](https://spring.io/blog/2018/09/06/bootiful-gcp-supporting-observability-with-spring-cloud-gcp-stackdriver-trace-6-8), 
-   how to [access other services like the machine learning APIs](https://spring.io/blog/2018/09/10/bootiful-gcp-use-spring-cloud-gcp-to-connect-to-other-gcp-services-7-8), 
-   and last but not least, how to [go to production](https://spring.io/blog/2018/09/13/bootiful-gcp-to-production-8-8).

So if you're using Spring and Spring Boot, this is the way to go for getting started on using Google Cloud Platform. For further reference, you can go read the [documentation](https://cloud.spring.io/spring-cloud-gcp/) that covers this integration.
# Building and deploying microservices with App Engine and Cloud Functions


A coupe weeks ago, I had the chance to talk at [Cloud Next](https://cloud.withgoogle.com/next18/sf/) 2018, in San Francisco, with my colleague and friend [Alexis](https://twitter.com/alexismp). We talked about building and deploying microservices with Google App Engine and Cloud Functions. I've been a big fan of App Engine since 2009 when Google released the Java flavor, and have been enjoying doing a bit of Node / JavaScript on Cloud Functions since it came in beta. So I was very happy to be able to talk about those two serverless solutions.

Without further ado, let's start by sharing the video (and slides) of the talk!

{{< youtube oALEthV9z_U >}}

Now that I've shared the video, let me tell you a bit more about this session and the demo we built.

![](/img/microservices-with-ae-cf/gae-gcf-01.png)

First, a few words about the buzzword du jour: serverless. What I particularly like about this approach (which I also liked in the good old times of another old buzzword: PaaS) is how it lets me focus on the idea I want to implement, instead of being bothered from the get go with server or cluster provisioning, OS choice, monitoring/logging/alerting, etc. I can directly start coding something, and quickly deploy my app or function in the cloud and see how well it's working (compared to my dreamed up idea). Additionally, besides the ops-less aspect, I also don't have to think about scaling, as it scales pretty much auto-magically for me. Last but not least, I don't have to pay upfront big costs for renting machines or vms, as it's really pay as you go, and not paying for an idle server (after all, my idea might be just a quick idea not geared towards prime-time success!)

![](/img/microservices-with-ae-cf/gae-gcf-02.png)

Google Cloud Platform offers various solutions which follow those characteristics, not only for compute with App Engine and Cloud Functions, but also for data storage (like Datastore which I'm using in my demo as my database), or the machine learning APIs (like the Vision API that I also integrated in my app). Database-as-a-Service, Platform-as-a-Service, Function-as-a-Service, Software-as-a-Service often fall into that category for me, if you don't pay for infrastructure, when it takes care of scaling, and if it's price proportionally to your usage.

## Cloud Functions

Cloud Functions (or GCF for short) is a great fit for event driven problems: a new picture is stored on Google Cloud Storage? A function is triggered. I get a message on Pub/Sub? Another function is invoked. It's also possible to invoke a function directly via an HTTP call, without requiring any kind of gateway to expose it.

At Next, the general availability of Cloud Functions was announced, with an SLA of 99.5%, additional regions (2 in the US, 1 in Europe, 1 in APAC), and also new runtimes with Node.js 8 and Python 3.7. Further improvements are the ability to get a function hooked to a VPN in order to connect your functions with your VMs, new scaling controls to limit the number of instances serving your function, a direction connection to Cloud SQL to take advantage of GCP's great network instead of going through the wider public Internet, and the availability of environment variables to customize your deployments for example to tackle different environments like dev vs staging vs prod.

## App Engine

As I said, I've always been a big fan of App Engine, long before I actually joined Google. This blog you're reading has been running on App Engine Java for many years! GAE (for short) is really a great fit for hosting web frontends or backend APIs, which are generally more long-lived that functions.

With Java 8 in GA last year, Node.js 8 in beta, new runtimes are also coming up: Python 3.7 and PHP 7.2. With the recently released new [instance scheduler](https://cloudplatform.googleblog.com/2018/05/Increase-performance-while-reducing-costs-with-the-new-App-Engine-scheduler.html), you have more control on your scaling which allows you to scale faster and have lower costs too. Deployments of new versions should also be faster with better caching and diff'ing between versions.

During the hallway session, I had a nice conversation with an attendee who was pretty happy with the fact he'd be able to have Python 3.7 for both Cloud Functions and App Engine, which will allow them to have a chance to share some code between projects.

The new runtimes are running on the [gVisor sandbox container runtime](https://cloudplatform.googleblog.com/2018/05/Open-sourcing-gVisor-a-sandboxed-container-runtime.html) technology, a lightweight solution to isolate containers securely to run your payloads. A big advantage of gVisor is that App Engine runtimes are not limited anymore with things like the class whitelist which prevented usage of some particular classes.

![](/img/microservices-with-ae-cf/gae-gcf-03.png)

Back to the topic of microservices, App Engine has this concept of services. In your GCP project, your GAE application can run several services at the same time, potentially with different runtimes (for example a Java service and a Go service), and those services can be deployed with different versions.

![](/img/microservices-with-ae-cf/gae-gcf-04.png)

Last thing I'll mention here for App Engine, that's the traffic splitting capability. You can easily split traffic (on the command-line or in the web UI) between different versions of a particular service. So for example if you want to do some A/B testing to see if users prefer the new feature or layout of your app, you can say that only 5% of incoming requests will be showing it, whereas the 95% of your users will continue to see the old version. This is also useful for canary deployments or blue / green deployments.

![](/img/microservices-with-ae-cf/gae-gcf-05.png)

For my demo, I developed a simple picture sharing app. My web frontend is a Vue.js + App Engine Java backend using the SparkJava light framework. When a user takes a picture, it's uploaded to Google Cloud Storage, which triggers a Cloud Function which will store picture metadata in Datastore, and calls the Vision API to get the labels of things found in the picture, as well as check if the picture can be safely published (no racy, adult, spoof, violent content in it), and gives the dominant color in the image. Another function is triggered on at regular intervals to compute the most frequent tags (stored in Datastore), so a snapshot of them can be displayed in the dedicate page of the app.

![](/img/microservices-with-ae-cf/gae-gcf-06.png)

## Scaling down...

Getting to scale down towards our talk conclusion, we also shared a few words about the upcoming serverless containers for Cloud Functions, which we unveiled at the conference and on the GCP [blog post](https://cloudplatform.googleblog.com/2018/07/bringing-the-best-of-serverless-to-you.html). For serverless compute, you can deploy functions and apps, but we're seeing units of compute in the form of containers as well, and sometimes your project might need specific native libraries or particular compute abilities (like GPUs), or you simply want more control over your business logic's environments. So it makes sense to let you serve containers as well, in addition to functions and apps. If you're interested in trying out serverless containers, feel free to request access to the EAP program via [g.co/serverlesscontainers](http://g.co/serverlesscontainers).
# In the top 20 Java influencers for 2018


![](/img/misc/JAX_London_2018_Infografik_Influencer_Teaser_600x3700_47308_v1.jpg)

Just before heading to [Google Cloud Next](https://cloud.withgoogle.com/next18/sf/), I was notified I was listed 4th in JAX London's Top 20 Java influencers of 2018 on social media! It's an honor to be listed among famous figures like Josh Bloch, Brian Goetze, Martin Thompson, Arun Gupta, Jessica Kerr, Mario Fusco, Josh Long, Venkat Subramanian, Charles Nutter and many others. You can see the full list of the top influencers [here](https://jaxlondon.com/blog/java-core-languages/top-20-java-influencers-of-2018/).

I'll definitely continue to advocate for Java (and Apache Groovy) developers around the world, and share whatever I learn along the way through articles or conference talks. I'm looking forward to meeting you, my fellow Java/Groovy developer friends, at an event near you.

{{< x user="jaxlondon" id="1021684076779065344" >}}
# The Big Green Button Automating Continuous Delivery With Chatbots


Last month in sunny Napa valley, my awesome colleague [Seth Vargo](https://www.sethvargo.com/) and I had the chance to speak at [SwampUp](https://swampup.jfrog.com/), the devops focused conference organized by [JFrog](https://jfrog.com/). Our talk & demo were focused on the topic of "ChatOps". But what is ChatOps? Here's what our abstract said:

> Heard of ChatOps? It's a movement in the DevOps community to take advantage of Chatbots. 
>
> Chatbots centralize the conversation and history of your daily operations including build status, issue management, deployment, and monitoring, so that you access all the information and actions needed at the whim of a chat message in your team communication solution.
>
> After a quick introduction about the principles and pros&cons of ChatOps, Guillaume Laforge & Seth Vargo will walk you through Dialogflow to design your conversational interface to your CI/CD infrastructure. With the help of demos on the Google Cloud Platform, we'll see together how chatbots can make you more productive in your DevOps activities.

The video has been published last week:

{{< youtube gIE1gQGTc >}}
# Chatbots: switching the second gear


My buddy [Wassim](https://twitter.com/manekinekko) and I were back on stage together to talk about chatbots, 
with [Actions on Google](https://developers.google.com/actions/) and [Dialogflow](https://twitter.com/manekinekko), 
at [DevFest Lille](https://devfest.gdglille.org/) and [Best of Web Paris](http://bestofweb.paris/). 
I'd like to share with you the slides of the presentation (the video has been recorded and will be available at a later time.)

You might be interested in those two codelabs to get started on this journey:

-   [Build Actions for the Google Assistant - level 1](https://codelabs.developers.google.com/codelabs/actions-1/index.html?index=..%2F..%2Findex#0)
-   [Build Actions for the Google Assistant - level 2](https://codelabs.developers.google.com/codelabs/actions-2/index.html?index=..%2F..%2Findex#0)

Here's the presentation given at DevFest Lille:

{{< speakerdeck 2466bf9bc1544289ba163b1fc4f2589a >}}

And at Best of Web Paris:

{{< speakerdeck afa17255e9ea4db8a4138102cefeeec3 >}}
# Putting a Groovy Twist on Cloud Vision


Powerful machine learning APIs are at your fingertips if you're developing with [Google Cloud Platform](https://cloud.google.com/), as client libraries are available for various programming languages. Today, we're investigating the Cloud Vision API and its Java SDK, using the [Apache Groovy](http://groovy-lang.org/) programming language---a multi-faceted language for the Java platform that aims to improve developer productivity thanks to a concise, familiar and easy to learn syntax.

At [GR8Conf Europe](https://gr8conf.eu/), in Denmark, the conference dedicated to the [Apache Groovy](http://groovy-lang.org/) ecosystem, I spoke about the machine learning APIs provided by [Google Cloud Platform](https://cloud.google.com/): Vision, Natural Language, Translate, and Speech (both recognition and synthesis). Since it's a groovy conference, we presented samples and demos using a pretty [Groovy](http://groovy-lang.org/) language. I wanted to share the underlying examples with a wider audience, so here's the first of a series of blog posts covering the demos I presented. I'll start with the Google Cloud Vision API, and I will cover the other APIs in future posts.

Google Cloud Vision API lets you:

-   Get labels of objects and places from your pictures
-   Detect faces, with precise location of facial features
-   Determine if the picture is a particular landmark
-   Check for inappropriate content
-   Obtain some image attributes information
-   Find out if the picture is already available elsewhere on the internet
-   Detect brand logos
-   Extract text that appears in your images (OCR)

You can try out those features online directly at the Cloud Vision API [product page](https://cloud.google.com/vision/).

Here's the output of a visibly egocentric example that I tried on the product page:

![/img/groovy-vision/groovy-vision-13lw1.max-800x800.png](/img/groovy-vision/groovy-vision-13lw1.max-800x800.png)

In this first installment, I focus on two aspects: labels and OCR. But before diving in, I want to illustrate some of the use cases that all of the Vision API features enable, when you want to enhance your apps by integrating the Vision API.

## Label detection

What's in the picture? That's what label detection is all about. So for example, if you're showing a picture from your vacation of your family and your dog on the beach, you might get labels like *People, Beach, Photograph, Vacation, Fun, Sea, Sky, Sand, Tourism, Summer, Shore, Ocean, Leisure, Coast, Girl, Happiness, Travel, Recreation, Friendship, and Family*. Those labels are also accompanied by a percentage confidence score.

Example use cases:

-   If you run a photography website, you might want to let your users search for particular pictures on specific topics. Rather than having someone manually label each and every picture uploaded, you can store labels generated by the API as keywords for your search engine.
-   If you're building the next friend-finder app for animals, perhaps you want to check that the picture indeed contains a dog. Again, labels will help to tell you if that's the case without manually checking each submitted image.
-   If you need to find pictures that match a certain theme, you can use the labels to help with automatic categorization.

## Face detection

The Cloud Vision API can spot faces in your pictures with great precision: it gives you detailed information about the location of the face (with a bounding box), plus the position of each eye, eyebrow, and ear, as well as the nose, lips, mouth, and chin. It also tells you how the face is tilted, and even at what angle!\
You can also learn about the sentiment of the person's expression: joy, sorrow, anger, or surprise, for example. In addition, you're told if the face is exposed, blurred, or is sporting  headwear.

Example use cases:

-   You are building a light-hearted app in which users add a mustache or silly hat to uploaded pictures, you now know how to initially position and size the added objects.
-   If you want to know (or estimate) the number of attendees in a meeting or presentation at a conference, you can use the API to provide a count of the number of faces in the picture.

## Landmark detection

For pictures of famous landmarks, like say, the Eiffel Tower, Buckingham Palace, the Statue of Liberty, or the Golden Gate bridge, the API will tell you which landmark it recognized, and will even give you the GPS location coordinates.

Example use cases:

-   If you want users of your app or site to upload only pictures of a particular location, you could use those coordinates (provided in latitude and longitude) to automatically check that the place photographed is within the right geo-fenced bounding box.
-   If you want to automatically show pictures on a map in your app, you could take advantage of the GPS coordinates, or automatically enrich tourism websites with pictures from the visitors of specific locales.

## Inappropriate content detection

Vision API gives you a confidence percentage about different types of potentially inappropriate content in images, including adult content, depictions of violence, medical content (such as surgical procedures or MRIs), and spoofed pictures (with user-added text and marks).

Example use case:

-   If you want to avoid the unwelcome surprise of inappropriate user-generated content showing up in your site or app, you can use this capability to filter images automatically.

## Image attributes and web annotations

Pictures all have dominant colors, and you can use the Vision API get a sense of which colors are represented in your image and in which proportion. The Cloud Vision API gives you a palette of colors corresponding to your picture.

In addition to color information, it also suggests possible crop hints, so you can crop the picture to different aspect ratios.

You also get information about whether your picture can be found elsewhere on the net, with a list of URLs with matched images as well as full and partial matches.

Beyond the label detection, the API identifies "entities", returning to you IDs of those entities from the Google [Knowledge Graph](https://www.google.com/intl/bn/insidesearch/features/search/knowledge.html).

Example use cases:

-   If you want to make your app or website responsive, before loading the full images you may want to show colored placeholders for them. You can get that information with the palette information from the API.
-   If you'd like to automatically crop pictures while keeping their essential aspects, you can use the crop hints.
-   If you allow photographers to upload their pictures on your website and you want to check that no one is stealing pictures and posting them without proper attribution, you can use the API to check if each picture can be found elsewhere on the web.
-   For the picture of me in the introduction of this post, Vision API recognized entities like "[Guillaume Laforge](http://glaforge.appspot.com/)" (me!), [Groovy](http://groovy-lang.org/) (the programming language I've been working on since 2003), [JavaOne](https://en.wikipedia.org/wiki/JavaOne) (a conference I've often spoken at), "[Groovy in Action](https://www.manning.com/books/groovy-in-action-second-edition)" (the book I've co-authored), "[Java Champions](https://community.oracle.com/community/java/java-champions)" (I've recently been nominated!), and "Software Developer" (yes, I do code!). Thanks to those entities, you are able to automatically recognize famous people---more than just me!

## Brand or logo detection

In addition to text recognition (discussed immediately below), the Vision API tells you if it recognized any logos or brands.

Example use case:

-   If you want your company's brand or products to be displayed on supermarket shelves, you might have people take pictures of those shelves and confirm automatically that your logo is being displayed.

## OCR or text recognition

With OCR text detection, you can find text that is displayed in your pictures. Not only does the API gives you the raw text and automatically detects the locale, but you also get all the bounding boxes for the recognized words, as well as a kind of document format, showing the hierarchy of the various blocks of text that appear.

Example use case:

-   When you want to automatically scan expense receipts, enter text rapidly from pictures, or tackle any of the usual use cases for OCR, you can use the API to find and extract any text identified within.

## Time to get Groovy!

Now that I've provided lots of use cases for where and when you may want to use Vision API, it's time to look at some code, right? So as I said, in this post I'll highlight just two features: label detection and text detection.

Using the [Apache Groovy](http://groovy-lang.org/) programming language, I will illustrate two approaches: the first one uses a REST client library like [`groovy-wslite`](https://github.com/jwagenleitner/groovy-wslite), and the second one uses the [Java client library](https://cloud.google.com/vision/docs/libraries) provided for the API.

## Prerequisites

In order to use Vision API, you'll need to have an account on Google Cloud Platform (GCP). You can benefit from the $300 [free trial](https://cloud.google.com/free/) credits, as well as free quotas. For instance, for Vision API, without even consuming your credits, you can make 1000 calls for free every month. You can also take a look at the API's [pricing](https://cloud.google.com/vision/pricing) details, once you exceed the quota or your credits.

Briefly, if you're not already using GCP or still don't have an account, please [register and create one](https://cloud.google.com/getting-started/).

Once you've set up your GCP account, create a cloud project and [enable access to Vision API](https://cloud.google.com/vision/docs/before-you-begin) for the project. That's it---now you're ready to follow the steps detailed below.

Note that after you have enabled the API, you still need to authenticate your client to use the service. There are different possibilities here. In the OCR example, I call the REST API and use an API key passed as a query parameter. In the label detection sample, I use a service account with application default credentials. You can learn more about those approaches in the [authentication](https://cloud.google.com/vision/docs/auth) documentation.

Okay, let's get started!

## OCR using the Vision REST endpoint

During the spring and summer allergy season, many people are interested in which pollens are likely to trigger their allergies. In France (where I live), we have a website that shows a map of the country, and when you hover over your region, it shows you a picture of the active allergens and their levels. However, this is really just a picture with the names of said allergens. So I decided to extract a list of allergens from this image using the Vision API's OCR method:

![/img/groovy-vision/groovy-vision-2yg2j.max-600x600.png](/img/groovy-vision/groovy-vision-2yg2j.max-600x600.png)

In Apache Groovy, when calling REST APIs, I often use the [`groovy-wslite`](https://github.com/jwagenleitner/groovy-wslite) library. But there are other similar great libraries like [`HTTPBuilder-NG`](https://http-builder-ng.github.io/http-builder-ng/), which offer similar capabilities via a nice syntax too.

To start, let's [grab](http://docs.groovy-lang.org/latest/html/documentation/grape.html) the REST client library and instantiate it:

```groovy
@Grab('com.github.groovy-wslite:groovy-wslite:1.1.2')import wslite.rest.*

def client = new RESTClient('https://vision.googleapis.com/v1/')
```

Here's the URL of the picture with the text I'm interested in:

```groovy
def imgUrl = "http://internationalragweedsociety.org/vigilance/d%2094.gif"
def API_KEY = 'REPLACE_ME_WITH_REAL_API_KEY'
```

Be sure to change this dummy text for the API key with a proper API key that you can generate from the "APIs & services > Credentials" section in the cloud console, as explained [here](https://support.google.com/cloud/answer/6158862?hl=en).

Next, I'm going to send a post request to the /images:annotate path with the API key as a query parameter. My request is in JSON, and I'm using [Groovy's nice list and maps syntax](http://docs.groovy-lang.org/latest/html/documentation/working-with-collections.html) to represent that [JSON](http://groovy-lang.org/json.html) request, providing the image URL and the feature I want to use (i.e. text detection):

```groovy
def response = client.post(path: '/images:annotate', query: [key: API_KEY]) {
    type ContentType.JSON
    json "requests": [
        [
            "image": [
                "source": [
                    "imageUri": imgUrl
                ]
            ],
            "features": [
                [
                    "type": "TEXT_DETECTION"
                ]
            ]
        ]
    ]
}
```

This corresponds to the following JSON payload:

```javascript
{ "requests": [{
    "image": {
        "source": { "imageUri": imgUrl }
    },
    "features": [
        { "type": "TEXT_DETECTION" }
    ]}
]}
```


Thanks to Apache Groovy's flexible nature, it's then easy to go through the returned JSON payload to get the list and `println` all the text annotations and their descriptions (which correspond to the recognized text):

```groovy
response.json.responses[0].textAnnotations.description.each { println it }
```

In spite of the low quality of the image and some odd font kerning, the API was able to find allergens like "châtaignier" (with the correct circumflex accent) and "urticacées" (acute accent). On the allergen "cupressacées," the diacritical mark was missed though, and a space is intertwined, but the font seems to be adding extra space between some letters.

## Label detection with the Java client library

For my second sample, I was inspired by my visit to Copenhagen for [GR8Conf Europe](https://gr8conf.eu/). I decided to see what labels the API would return for a typical picture of the lovely colorful facades of the [Nyhavn](https://en.wikipedia.org/wiki/Nyhavn) harbor.

![/img/groovy-vision/groovy-vision-39426.max-800x800.jpeg](/img/groovy-vision/groovy-vision-39426.max-800x800.jpeg)

Let's [grab](http://docs.groovy-lang.org/latest/html/documentation/grape.html) the Java client library for the vision API:

```groovy
@Grab('com.google.cloud:google-cloud-vision:1.24.1')
import com.google.cloud.vision.v1.*
import com.google.protobuf.*
```

Here's the URL of the picture:

```groovy
def imgUrl =
   "https://upload.wikimedia.org/wikipedia/commons/3/39/Nyhavn_MichaD.jpg"
   .toURL()
```

Now, let's instantiate the ImageAnnotatorClient class. It's a Closeable object, so we can use Groovy's `withCloseable{}` method:
`ImageAnnotatorClient.create().withCloseable { vision ->`
We need the bytes of the picture, which we obtain via the `.bytes` shortcut, and we create a ByteString object from the [protobuf](https://developers.google.com/protocol-buffers/) library used by the Vision API:

```groovy
def imgBytes = ByteString.copyFrom(imgUrl.bytes)
```

To create the request with the AnnotateImageRequest builder, we can employ the Groovy [`tap{}`](http://docs.groovy-lang.org/latest/html/groovy-jdk/java/lang/Object.html#tap(groovy.lang.Closure)) method to simplify usage of the builder design pattern:

```groovy
def request = AnnotateImageRequest.newBuilder().tap {
    addFeatures Feature.newBuilder()
                       .setType(Feature.Type.LABEL_DETECTION)
                       .build()
    setImage Image.newBuilder()
                  .setContent(imgBytes)
                  .build()
}.build()
```

In that request, we ask for the label detection feature and pass the image bytes. Next, we call the API with our request and then iterate over the resulting label annotations and their confidence score:

```groovy
vision.batchAnnotateImages([request]).responsesList.each { res ->
    if (res.hasError()) println "Error: ${res.error.message}"
    res.labelAnnotationsList.each { annotation ->
        println "${annotation.description.padLeft(20)} (${annotation.score})"
    }
}
```

The labels found (and their confidence) are as follows:

```
                waterway (0.97506875)
    water transportation (0.9240114)
                    town (0.9142202)
                   canal (0.8753313)
                    city (0.86910504)
                   water (0.82833123)
                  harbor (0.82821053)
                 channel (0.73568773)
                     sky (0.73083687)
                building (0.6117833)
```

That looks pretty accurate to me!

## Conclusion

There are tons of situations where you can benefit from [Google Cloud Vision](https://cloud.google.com/vision/)'s simple and effective image analysis and your use of the API becomes even groovier when using the [Apache Groovy](http://groovy-lang.org/) language! Be sure to try out the API directly from the website with the built-in demo, and get started with our [Cloud Vision codelabs](https://codelabs.developers.google.com/codelabs/cloud-vision-intro/index.html?index=..%2F..%2Findex#0).

If you want to go further, I also encourage you to also have a look at the alpha version of [Cloud AutoML Vision](https://cloud.google.com/automl/): you can extend the Vision API by training it on your own picture dataset. By doing so, you can let Cloud Vision recognize particular objects or elements in your photos with finer-grained labels that are specific to your needs.

Upcoming installments in this series will cover natural language understanding (NLU), text translation, speech recognition, and voice synthesis. So stay tuned!
# Automating Chrome Headless mode on App Engine with Node.JS 8


On the [Google Cloud](http://cloud.google.com/) front today, the big news is the release of the [new Node.JS 8 runtime for Google App Engine Standard](https://cloudplatform.googleblog.com/2018/06/Now-you-can-deploy-your-Node-js-app-to-App-Engine-standard-environment.html). It's been a while since a completely new runtime was added to the list of supported platforms (Python, Java, PHP, Go). You could already run anything in custom containers on App Engine Flex, including your own containerized Node app, but now you can have all the nice developer experience on the Standard environment, with fast deployment times, and 0 to 1 to n instance automatic scaling (you can see the difference between those two environments [here](https://cloud.google.com/appengine/docs/nodejs/)).

To play with this new runtime, I decided to follow the steps in this guide about [using Chrome headless with Puppeteer](https://cloud.google.com/appengine/docs/standard/nodejs/using-headless-chrome-with-puppeteer).

As my readers know, I'm not really a Node person, and usually dabble more with [Apache Groovy](http://groovy-lang.org/) and Java, but this runtime was interesting to me as there's a nice integration with native packages. Let me explain.

The App Engine Node runtime [includes tons of native package out of the box](https://cloud.google.com/appengine/docs/standard/nodejs/reference/system-packages), without requiring you to install anything (except the Node modules that take advantage of those packages, of course.) For instance, if you need to do any audio / video manipulation, there's an ffmpeg package. If you want to deal with Git repositories, there's a git package. Need to manipulate images, there's ImageMagick, etc. And there are usually nice Node wrapper modules around those native components.

Among those system pre-installed packages, there's all the necessary ones to run [Headless Chrome](https://developers.google.com/web/updates/2017/04/headless-chrome), ie. running the Chrome browser but without displaying its window basically.

Furthermore, there's the [Puppeteer](https://developers.google.com/web/tools/puppeteer/) Node module, which is a library to control Chrome. With those two, you can completely automate the usage of Chrome on the server-side.

What can you do with that? Well, you can:

-   look at / introspect / manipulate the DOM,
-   pre-render content for your single page apps,
-   take screenshots of web pages,
-   watch a particular page and compute diffs between different versions, etc.

## Let's get started!

Without blindly recopying all the steps explained in the tutorial for [running Chrome headless](https://cloud.google.com/appengine/docs/standard/nodejs/using-headless-chrome-with-puppeteer), I'll simply highlight some of key points. The goal is to let puppeteer take screenshots of webpages.

In your package.json, you need the reference the puppeteer module, and potentially express for handling your web requests:

```json
  "dependencies": {
    "express": "^4.16.3",
    "puppeteer": "^1.2.0"
  },
```

Taking advantage of Node 8's async capabilities, in your `app.js` file, you can instantiate puppeteer:

```javascript
const browser = await puppeteer.launch({
  args: ['--no-sandbox', '--disable-setuid-sandbox']
});
```

Then navigate to the desired page:

```javascript
  const page = await browser.newPage();
  await page.goto(url);
```

Take a screenshot and render it back to the browser:

```javascript
  const imageBuffer = await page.screenshot();
  res.set('Content-Type', 'image/png');
  res.send(imageBuffer);
```

To deploy to the Node runtime, you also need the app.yaml deployment descriptor:

```yaml
runtime: nodejs8
instance_class: F4_1G
```

We specify that we want to use the new node runtime, but also that we want a slightly bigger instance to run our Node app, as Chrome is pretty hungry with RAM!

Then deploy your app with the [gcloud CLI](https://cloud.google.com/sdk/gcloud/).

Be sure to check the [whole code on Github](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/tree/master/appengine/headless-chrome) for all the details.

One quick remark: although it's not mentioned in the tutorial, when you'll first try to deploy the application, it'll tell you that you need to enable the Container Builder API. The error message will be something like `Container Builder has not been used in project xyz before or it is disabled. Enable it by visiting...` You just need to follow the indicated URL to enable Container Builder. Container Builder is responsible for containerizing your application to be run on App Engine.

Then I was able to navigate to my app, pass it a URL, and get back the screenshot of the web page at that URL. It's pretty handy if you want to integrate thumbnails of websites you reference in your blog posts, for example, or if you want to see if there are differences between different versions of a web page (for integration testing purposes).

## Conclusion

The Java ecosystem has a wealth of libraries for various tasks, but often, there are native libraries which are more fully-featured, and Node generally provides nice wrappers for them. Chrome headless with Puppeteer is one example, but ImageMagick for image manipulation is another great one, where I could not find a good equivalent library in the Java ecosystem. So as they say, use the best tool for the job! In the age of microservices, feel free to use another tech stack that best fit the task at hand. And it's really exciting to see this [new Node 8 runtime for App Engine](https://cloudplatform.googleblog.com/2018/06/Now-you-can-deploy-your-Node-js-app-to-App-Engine-standard-environment.html) now being available so that you can take advantage of it in your projects.
# Vision recognition with a Groovy twist


Last week at [GR8Conf Europe](https://gr8conf.eu/), I spoke about the machine learning APIs provided by 
[Google Cloud Platform](https://cloud.google.com/): Vision, Natural Language, Speech recognition and synthesis, etc. 
Since it's GR8Conf, that means showing samples and demos using a pretty [Groovy](http://groovy-lang.org/) language, 
and I promised to share my code afterwards. So here's a series of blog posts covering the demos I've presented. 
We'll start with the Vision API.

The Vision API allows you to:

-   Get labels of what appears in your pictures,
-   Detect faces, with precise location of face features,
-   Tell you if the picture is a particular landmark,
-   Check for inappropriate content,
-   Give you some image attributes information,
-   Find if the picture is already available on the net,
-   Detects brand logos,
-   Or extract text that appears in your images (OCR).

You can try out those features online directly from the Cloud Vision API product page:

<https://cloud.google.com/vision/>

Here's a selfish example output:

![](/img/vision-groovy/ml-apis-01-try-out+small.png)

In this first installment, I'll focus on two aspects: labels and OCR. But before diving, I wanted to illustrate some of the **use cases** that those features enable, when you want to boost your apps by integrating the Vision API.

## Label detection

What's in the picture? That's what label detection is all about. So for example, if you're showing a picture from your vacations with your family and dog on the beach, you might be getting labels like *"People, Beach, Photograph, Vacation, Fun, Sea, Sky, Sand, Tourism, Summer, Shore, Ocean, Leisure, Coast, Girl, Happiness, Travel, Recreation, Friendship, Family"*. Those labels are also accompanied by percentage confidence.

### Example use cases:

-   If your website is a photography website, you might want your users to be able to search for particular pictures on specific topics. Rather than having someone manually label each and every picture uploaded, you can store those labels as keywords for your search engine.
-   You're building the next Instagram for animals, perhaps you want to check that the picture indeed contains a dog in it. Again labels will help to tell you if that's the case or not.
-   Those labels can help with automatic categorization as well, so you can more easily find pictures along certain themes.

## Face detection

Vision API can spot faces in your pictures with great precision, as it gives you detailed information about the location of the face (with a bounding box), as well as the position of each eye, eyebrows, nose, lips / mouth, ear, or chin. It also tells you how your face is tilted, even with which angle!

You can also learn about the sentiment of the person: joy, sorrow, anger, surprise. In addition, you're told if the face is exposed, blurred, or has some headwear.

### Example use cases:

-   Snapchat-style, you want to add a mustache or silly hat to pictures uploaded by your users.
-   Another handy aspect is that you can also count the number of faces in a picture. For example, if you want to count the number of attendees in a meeting or presentation at a conference, you'd have a good estimate of people with the number of faces recognized.

## Landmark detection

If the picture is of a famous landmark, like say, the Eiffel Tower, Buckingham Palace, the Statue of Liberty, the Golden Gate, the API will tell you which landmark it recognized, and will even give you the GPS coordinates of the place.

### Example use cases:

-   Users of your app or site should only upload pictures of a particular location, you could use those coordinates to automatically check that the place photographed is within the right geo-fenced bounding box.
-   You want to automatically show pictures on a map on your app, you could take advantage of the GPS coordinates, or automatically enrich a tourism websites with pictures from the visitors of that place.

## Inappropriate content detection

Vision API will give you a percentage confidence about whether the picture contains adult content, is a spoofed picture (with user added text and marks), bears some medical character, displays violence or racy materials.

### Example use case:

-   The main use case here is indeed to be able to filter images automatically, to avoid any bad surprise of user-generated content showing up in your site or app when it shouldn't.

## Image attributes and web annotations

Pictures all have dominant colors, and you can get a sense of which colors are indeed representing the best your image, 
in which proportion. Vision API gives you a palette of colors corresponding to your picture.

In addition to color information, it also suggests possible crop hints, so you could crop the picture to different aspect ratios.

You get information about whether this picture can be seen elsewhere on the net, 
with a list of URL with matched images, full matches, or partial matches.

Beyond the label detection, the API identifies "entities", returning to you IDs of those entities 
from the Google [Knowledge Graph](https://www.google.com/intl/bn/insidesearch/features/search/knowledge.html).

### Example use cases:

-   To make your app or website responsive, before loading the full images, you'd like to show colored placeholders for the picture. You can get that information with the palette information returned.
-   You'd like to automatically crop pictures to keep the essential aspects of it.
-   Photographers upload their pictures on your website, but you want to ensure that no one steals those pictures and put them on the net without proper attribution. You can find out whether this picture can be seen elsewhere on the web.
-   For the picture of me above, Vision API recognized entities like "Guillaume Laforge" (me!), Groovy (the programming language I've been working on since 2003), JavaOne (a conference I've often spoken at), "Groovy in Action" (the book I've co-authored), "Java Champions" (I've recently been nominated!), or "Software Developer" (yes, I still code a bit)

## Brand / logo detection

In addition to text recognition, that we'll mention right below, Vision API tells you if it recognized some logos or brands.

### Example use case:

-   If you're a brand, have some particular products, and you want your brand or products to be displayed on supermarket shelves, you might have people take pictures of those shelves and confirm automatically if your logo is displayed or not.

### OCR / text recognition

You can find the text that is displayed on your pictures. Not only does it gives you the raw text, but you also get all the bounding boxes for the recognized words, as well as offers a kind of document format, showing the various blocks of texts that appear.

### Example use case:

-   You want to automatically scan expense receipts, enter text rapidly from pictures, etc. The usual use cases for OCR!

## Time to get Groovy!

People often wonder where and when they can use the Vision API, I think I've given enough use cases for now, with detailed explanations. But it's time to show some code, right? So as I said, I'll highlight just two features: label detection and text detection.

Using the Apache Groovy programming language, I wanted to illustrate two approaches: the first one using the a REST client like [groovy-wslite](https://github.com/jwagenleitner/groovy-wslite), and the second one just using the [Java SDK](https://cloud.google.com/vision/docs/libraries) provided for the API.

### Preliminary

In order to use the Vision API, you'll need to have created an account on Google Cloud Platform (GCP for short). 
You can benefit from the $300 of credits of the [free trial](https://cloud.google.com/free/), as well as free quotas. 
For instance, for the Vision API, without even using your credits, you can make 1000 calls for free every month. 
You can also have a look at the [pricing](https://cloud.google.com/vision/pricing) of the API, once you go above the quota or your credits.

Briefly, if you're not already using GCP or have an account on it, please register and create your account on GCP, 
then create a cloud project. Once the project is created, 
[enable access to Vision API](https://cloud.google.com/vision/docs/before-you-begin), 
and you're ready to follow the steps detailed hereafter.

Although we've enabled the API, we still need somehow to be authenticated to use that service. 
There are different possibilities here. 
In the first sample with the OCR example, I'm calling the REST API and will be using an API key passed as query parameter, 
whereas for my label detection sample, I'm using a service account with applicaction default credentials. 
You can learn more about those approaches in the documentation on [authentication](https://cloud.google.com/vision/docs/auth).

Okay, let's get started!

### OCR calling the Vision REST endpoint

With spring and summer, allergetic people might be interested in which pollens are going to cause their allergies to bother them. Where I live, in France, there's a website showing a map of the country, and you can hover the region where you are, and see a picture of the allergens and their levels. However, this is really just a picture with the names of said allergens. So I decided to get their list with the Vision API.

![](/img/vision-groovy/ml-apis-03-allergens-labels+small.png)

In Apache Groovy, when calling REST APIs, I often use the [groovy-wslite](https://github.com/jwagenleitner/groovy-wslite) library. But there are other similar great libraries like [HTTPBuilder-NG](https://http-builder-ng.github.io/http-builder-ng/), which offer similar capabilities with nice syntax too.

Let's [grab](http://docs.groovy-lang.org/latest/html/documentation/grape.html) the REST client library and instantiate it:

```groovy
@Grab('com.github.groovy-wslite:groovy-wslite:1.1.2')
import wslite.rest.*

def client = new RESTClient('https://vision.googleapis.com/v1/')
```

Here's the URL of the picture whose text I'm interested in:

```groovy
def imgUrl = "http://internationalragweedsociety.org/vigilance/d%2094.gif"
def API_KEY = 'REPLACE_ME_WITH_REAL_API_KEY'
```

Then I'm going to send a post request to the `/images:annotate` path with the API key as query parameter. 
My request is in JSON, and I'm using Groovy's nice list & maps syntax to represent that JSON request, 
providing the image URL and the feature I'm interested in (ie. text detection):

```groovy
def response = client.post(path: '/images:annotate', query: [key: API_KEY]) {
    type ContentType.JSON
    json "requests": [
        [
            "image": [
                "source": [
                    "imageUri": imgUrl
                ]
            ],
            "features": [
                [
                    "type": "TEXT_DETECTION"
                ]
            ]
        ]
    ]
}
```

This corresponds to the following JSON payload:

```json
{
    "requests": [
        {
            "image": {
                "source": {
                    "imageUri": imgUrl
                }
            },
            "features": [
                {
                    "type": "TEXT_DETECTION"
                }
            ]
        }
    ]
}
```

Thanks to Groovy's flexible nature, it's then easy to go through the returned JSON payload to get the list and println all the text annotations and their description (which corresponds to the recognized text):

```groovy
println response.json.responses[0].textAnnotations.description
```

### Label detection with the Java client library

For my second sample, as I visited Copenhagen for [GR8Conf Europe](https://gr8conf.eu/), 
I decided to see what labels the API would return for a typical picture of the lovely colorful facades of the 
[Nyhavn](https://en.wikipedia.org/wiki/Nyhavn) harbor.

![](/img/vision-groovy/ml-apis-02-nyhavn+small.png)

Let's [grab](http://docs.groovy-lang.org/latest/html/documentation/grape.html) the Java client library for the vision API:

```groovy
@Grab('com.google.cloud:google-cloud-vision:1.24.1')
import com.google.cloud.vision.v1.*
import com.google.protobuf.*
```

Here's the URL of the picture:

```groovy
def imgUrl = "https://upload.wikimedia.org/wikipedia/commons/3/39/Nyhavn_MichaD.jpg" .toURL()
```

Let's instantiate the ImageAnnotatorClient class. It's a closeable object, so we can use Groovy's withCloseable{} method:

```
ImageAnnotatorClient.create().withCloseable { vision ->
```

We need the bytes of the picture, that we obtain with the `.bytes` shortcut, and we create a `ByteString` object from the [protobuf](https://developers.google.com/protocol-buffers/) library used by the Vision API:

```groovy
def imgBytes = ByteString.copyFrom(imgUrl.bytes)
```

Now it's time to create our request, with the @AnnotateImageRequest` builder, 
using Groovy's [tap{}](http://docs.groovy-lang.org/latest/html/groovy-jdk/java/lang/Object.html#tap(groovy.lang.Closure)) 
method to make the use of the builder pattern easier:

```groovy
def request = AnnotateImageRequest.newBuilder().tap {
    addFeatures Feature.newBuilder().setType(Feature.Type.LABEL_DETECTION).build()
    setImage    Image.newBuilder().setContent(imgBytes).build()
}.build()
```

In that request, we ask for the label detection feature, and pass the image bytes. 
Then it's time to call the API with our request, and iterate over the resulting label annotations and their confidence score:

```groovy
vision.batchAnnotateImages([request])
      .responsesList.each { res ->
    if (res.hasError())
        println "Error: ${res.error.message}"

    res.labelAnnotationsList.each { annotation ->
        println "${annotation.description.padLeft(20)} (${annotation.score})"
    }
  }
}
```

The labels found (and their confidence) are the following:

```
            waterway (0.97506875)
water transportation (0.9240114)
                town (0.9142202)
               canal (0.8753313)
                city (0.86910504)
               water (0.82833123)
              harbor (0.82821053)
             channel (0.73568773)
                 sky (0.73083687)
            building (0.6117833)
```

Pretty good job!

## Conclusion

First of all, there are tons of situations where you can benefit from image recognition thanks to [Google Cloud Vision](https://cloud.google.com/vision/). Secondly, it can get even groovier when using the [Apache Groovy](http://groovy-lang.org/) language!

In the upcoming installment, we'll speak about natural language understanding, text translation, speech recognition and voice synthesis. So stay tuned!
# Machine learning APIs and AI panel discussion at QCon



Last March, I had the chance to attend and speak at [QCon London](https://qconlondon.com/london2018/schedule/london2018/tabular.html). I spoke at the event for its first edition, many moons prior, so it was fun coming back and seeing how the conference evolved. 

This year, [Eric Horesnyi](https://twitter.com/erichoresnyi) of [Streamdata](https://streamdata.io/) 
was leading the Artificial Intelligence track, and invited me to speak about Machine Learning.

First, I gave an overview of the Machine Learning offering, from the off-the-shelf ready-made APIs like 
[Vision](https://cloud.google.com/vision/), [Speech](https://cloud.google.com/speech-to-text/), 
[Natural Language](https://cloud.google.com/natural-language/), [Video Intelligence](https://cloud.google.com/video-intelligence/). 
I also mentioned [AutoML](https://cloud.google.com/automl/), 
to further train existing models like the Vision model in order to recognize your own specific details in pictures. 
For chatbots, I also covered [Dialogflow](https://dialogflow.com/). 
And I said a few words about Tensorflow and [Cloud Machine Learning Engine](https://cloud.google.com/ml-engine/) 
for training & running your [Tensorflow](https://www.tensorflow.org/) models in the cloud. 
You can watch the video by clicking on the picture below:

[![](/img/qcon-2018/qcon-ml-talk.png)](https://www.infoq.com/presentations/google-ml-services)

Eric hosted a panel discussion with all the speakers in the AI track, where we discussed many interesting topics, 
to demystify AI and answer questions from the audience. Click on the picture below to watch the panel discussion:

[![](/img/qcon-2018/qcon-ai-panel.png)](https://www.infoq.com/presentations/ai-panel)
# Getting started with Groovy technologies on Google Cloud Platform


Back to [GR8Conf Europe](https://gr8conf.eu/) in Denmark, for the yearly [Groovy](http://www.groovy-lang.org/) community reunion! I had the chance to present two talks.

The first one on Google's [Machine Learning APIs](https://cloud.google.com/products/machine-learning/), with samples in Groovy using vision recognition, speech recognition & generation, natural language analysis. I'll come back on ML in Groovy in forthcoming articles.

And the second talk was an overview of Google Cloud Platform, focusing on the compute and storage options, with demos using Groovy frameworks ([Ratpack](https://ratpack.io/), [Gaelyk](http://gaelyk.appspot.com/), and the newly released [Micronaut](http://micronaut.io/)) and how to deploy apps on Compute Engine, Kubernetes Engine, App Engine. I'll also come back in further articles on those demos, but in the meantime, I wanted to share my slide deck with you all! Without further ado, here's what I presented:

{{< speakerdeck a9b1167d2ffb418082553a879f51c869 >}}

> Time to release your marvelous project or website, powered with GR8 tech, into the wild? 
> Let's see together what Google Cloud Platform has to provide for the Apache Groovy ecosystem developer. 
> If you have a Grails or Ratpack app, what are the best compute options for deploying it? 
> What other services are useful to your app: databases with Cloud SQL, messaging 
> with Cloud Pub/Sub, monitoring, and more, are at your disposal. 
> We'll explore together what options you have to deploy and scale your next great idea in the Google cloud.
# Ten years of App Engine with a Groovy twist


The venerable Google [App Engine](https://cloud.google.com/appengine/) platform celebrated its [10th anniversary](https://cloudplatform.googleblog.com/2018/04/reflecting-on-our-ten-year-App-Engine-journey.html)!

Back in 2008, it started with Python, as its first runtime, but I got way more interested in App Engine when the Java runtime would launch the following year. It's a bit of a special story for me, as I've always been a fan of App Engine, since the beginning.

Over the years, I've built several apps running on App Engine. For instance, this blog you're reading now is running on App Engine, as well as my personal picture / video sharing app, some Github post-commit webhook for the [Apache Groovy](http://www.groovy-lang.org/) project, or the [Groovy Web Console](http://groovyconsole.appspot.com/) to share / edit / run Groovy scripts in the cloud.

App Engine is my go-to platform for deploying and running my ideas in the cloud!

I like to focus on the idea I want to implement, rather than thinking upfront about infrastructure, provisioning, ops, etc. App Engine was the pioneer in PaaS (Platform-as-a-Service) and the new trendy [Serverless](https://cloud.google.com/serverless/) approach.

Although I've ranted back in the day about the pricing changes ([once]({{< ref "/posts/2011/09/01/google-app-engine-s-new-pricing-model" >}}) and [twice]({{< ref "/posts/2011/11/25/coming-back-to-the-new-google-app-engine-pricing-policy" >}})), it lead me to optimize my own apps and code. But ultimately, most of my apps run within the [free tier](https://cloud.google.com/free/) of App Engine. The "pay-as-you-go" approach is appealing: for my apps, it's been pretty much free for my use, except on those few occasions where I had big peaks of traffic and users, and then, i only had to spend a few dollars to cope with the load, but I didn't even have to think about dealing with infrastructure, as App Engine was transparently scaling my apps itself, without any intervention on my part.

![](/img/misc/google-app-engine-groovy.png)

But let's step back a little and let me tell you more about my story with App Engine. In 2009, thanks to my friend Dick Wall, I was contacted by Google, signed an NDA, and worked with the engineering team who was responsible for the upcoming Java runtime. As the engineering team was working on its launch, they wanted to ensure that alternative languages like [Apache Groovy](http://www.groovy-lang.org/) would run well on the platform. So we worked hand in hand, patching Groovy to be more compliant with App Engine's sandboxing mechanism (which is now lifted, as past limitations are now gone in the newer runtimes.)

Thanks to this work on the Groovy and App Engine integration, I got the chance to present at Google I/O 2009 about running Groovy and Grails on App Engine!

{{< youtube NEnniZTdOYk >}}

And as I worked on the integration, I quickly found nice handy shortcuts thanks to the flexible nature of Groovy, and I arranged those shortcuts into a reusable library: the [Gaelyk](http://gaelyk.appspot.com/) framework.

Max Ross, Toby Reyelts, Don Scwhartz, Dick Wall, Patrick Chanezon, Christian Schalk, and later on, Ludovic Champenois, Éamonn McManus, Roberto Chinnici, and many others, I'd like to say thank you, congratulations, and happy anniversary for this lovely platform!

It's an honor for me today to [work for Google Cloud Platform]({{< ref "/posts/2016/06/02/joining-google-as-a-developer-advocate-for-the-google-cloud-platform" >}}) (almost 2 years already!), and to use the awesome serverless products available, and I'm looking forward to covering the [serverless](https://cloud.google.com/serverless/) area even more!
# What can we learn from millions of (groovy) source files in Github


What can you learn from millions of (Groovy) source files stored on Github?
In this presentation, I analized source files in the Github archives stored on BigQuery,
and in particular Groovy source file, but also Gradle build files, or Grails controllers and services.

{{< speakerdeck c9876f9890d84d378b5b18c9b57ad7aa >}}

What kind of questions can we answer

-   How many Groovy files are there on Github?
-   What are the most popular Groovy file names?
-   How many lines of Groovy source code are there?
-   What's the distribution of size of source files?
-   What are the most frequent imported packages?
-   What are the most popular Groovy APIs used?
-   What are the most used AST transformations?
-   Do people use import aliases much?
-   Did developers adopt traits?

For [Gradle](https://gradle.org/), here are the questions that I answered:

-   How many Gradle build files are there?
-   How many Maven build files are there?
-   Which versions of Gradle are being used?
-   How many of those Gradle files are settings files?
-   What are the most frequent build file names?
-   What are the most frequent Gradle plugins?
-   What are the most frequent "compile" and "test" dependencies?

And for [Grails](https://grails.org/), here's what I covered:

-   What are the most used SQL database used?
-   What are the most frequent controller names?
-   What are the repositories with the biggest number of controllers?
-   What is the distribution of number of controllers?

You can see a version of this talk in French in the following YouTube video, recorded at the BreizhCamp conference:

{{< youtube wk2CRBRrki8 >}}

And in English at Devoxx US:

{{< youtube Aw4sgZ8kIeg >}}

# Keynote: IT holy wars


A few months ago, I had some fun doing the keynote of Voxxed Days Singapore and JUG Summer Camp, and I realized I didn't get a chance to share my deck. Furthermore, the videos of both events are actually available online: one in English, one in French!

I spoke about the so-called IT Holy Wars, you know, like Vi vs Emacs, Tabs & Spaces, or other funny things of that kind. How developers circle from client-side to server-side, how we are polarized across strong positions on certain frameworks or practices, on clean vs ugly code, on tooling (build, front, back), dark / light background themes for your IDE, how do you format dates, and more.

I had lots of fun preparing and delivering this talk, both in English and French.

Let's start with English deck & video:

{{< speakerdeck d3cac7c15adb45e8bf10233754b04de9 >}}

{{< youtube 4MDTBBEEyho >}}

And now "en français dans le texte" : 

{{< speakerdeck f15e5f8b54544fd29408ca72dfd29885 >}}
# Build apps for voice, chat, web and mobile


**ServerlessConf Paris** is in full swing this week, and I had the chance yesterday to participate in a workshop with my colleague Frank, to cover building apps for voice, chat, web and mobile, using Google's serverless [solutions. In particular, for voice & chat, I spoke about Dialogflow and Google Assistant / Actions](https://developers.google.com/actions/) on Google, using [Cloud Functions](https://cloud.google.com/functions/) for my business logic, while in the afternoon we covered [Firebase](https://firebase.google.com/) un more depth.

If you want to have a quick look at the deck, here are the slides that I presented:

{{< speakerdeck 14c2dc2fe2d44413be0b4697469e4311 >}}
# I'm a Java Champion!


The Java Champions recently nominated me to become a Java Champion!

{{< x user="java_champions" id="933194279412891648" >}}

There's also a [post](https://blogs.oracle.com/java/new-java-champions-in-2017) on the Java Champions' blog, and [InfoQ](https://www.infoq.com/news/2018/01/JavaChampions2017) also echoed the new nominees recently.

I'm super happy and proud of this nomination, and I'm looking forward to continuing being involved in the Java ecosystem, present at Java-friendly conferences, contribute to Open Source projects using Java and Apache Groovy, and write articles here and there using my favorite languages.
# Pre-trained machine learning APIs


Last month, for the first time, I visited Riga (Latvia), for the [DevTernity conference](https://devternity.com/). I really enjoyed my time there, and wish to come back with other topics next time. The organizers took very well care of the speakers, and the presentations were very interesting.

I had the pleasure to talk about the [pre-trained machine learning APIs](https://cloud.google.com/products/machine-learning/) provided by Google Cloud Platform, and say a few words as well about [TensorFlow](https://www.tensorflow.org/) and [Cloud ML Engine](https://cloud.google.com/ml-engine/).

The talk was recorded, and I wanted to share with you the video and the slides of the presentation.

{{< youtube _5SmyANkq3o >}}

And here is the deck:



{{< speakerdeck c2927b99b7b64b9c83a90fe81704a9f2 >}}
# The 2018 countdown: a tip a day about Google Cloud Platform


A few weeks ago, I've started a new blog dedicated to [Google Cloud Platform](https://cloud.google.com/), to share tips'n tricks I come across while exploring the platform, getting to know new products, or gathered through experience with a particular service I've been using:

<https://googlecloud.tips/>

[![](/img/gcp-tips/gcp-tips-frontpage.jpg)](https://googlecloud.tips/)

With the holidays season, I went with a "2018 countdown" approach (like an "advent calendar" without the religious connotation), where I publish a tip every day of the month of December.

As of today, December 18th, we already have 18 tips available!

Those tips span about a dozen technologies! (as you can also explore the tips via "tags", which represent a technology / service / API / product each)

![](/img/gcp-tips/gcptips-tags.png)

Initially, I thought it would be a challenge to author tips every day (without even thinking of the fact you have to publish tips during weekends, holidays or vacations), but there are actually plenty of tricks to share. Furthermore, I opened the blog to contributions: anyone who wants to contribute a tip or two is welcome, and should just share with me a quick gist describing the tip. I've already received a bunch of contributions, from 8 distinct authors. Thanks a lot to Alexandre, Bastien, Fabien, Graham, Jim, Mark, Victor, or Wassim!

Although it all started as a tip a day for the 2018 countdown, it won't stop there. Perhaps the frequency will be a bit lower (once a week? more?), but I definitely intend on continuing sharing tips on a regular basis next year and beyond!

If you want to help, please spread the word! Tell your friends and colleagues about the site: <https://googlecloud.tips/>.

Also please follow the [@gcptips](https://twitter.com/GcpTips) Twitter account where new tips'n tricks are announced.

And if you've got some time, don't hesitate to share your own tips! All help is welcome :-)
# Gradle vs Maven and Gradle in Kotlin or Groovy


Once in a while, when talking about Gradle with developers, at conferences or within the Groovy community (but with the wider Java community as well), I hear questions about Gradle. In particular Gradle vs Maven, or whether developers adopt the Kotlin DSL for Gradle builds.

In the past, I blogged several times about using BigQuery and the Github dataset to analyze open source projects hosted on Github, by running some SQL queries against that dataset. You might want to have a look at this past article on some [Gradle analysis with BigQuery]({{< ref "/posts/2016/12/03/analyzing-half-a-million-gradle-build-files" >}}). Considering those questions popped up recently, I decided to do a quick run through those questions with some simple queries.

## Gradle vs Maven?

First, let's look at Maven builds. We can run the following query:

```sql
SELECT count(*) 
FROM [bigquery-public-data:github_repos.files] 
WHERE path LIKE '%pom.xml'
```

There are 1,125,150 pom files.

![](/img/bq-groovy/gradle-builds-vs-maven-builds.png)

Then, for Gradle, I ran this query (even if projects could have different build file names):

```sql
SELECT count(*) 
FROM [bigquery-public-data:github_repos.files] 
WHERE path LIKE '%build.gradle'
```

There are 414,329 build.gradle files.

![](/img/bq-groovy/gradle-builds-in-groovy.png)

So that's 1 Gradle build file for 2.7 Maven build file.

## Gradle builds in Kotlin or in Groovy?

Now for Kotlin, the convention seems to be about naming your build files with build.gradle.kts. So let's run the following query:

```sql
SELECT count(*) 
FROM [bigquery-public-data:github_repos.files] 
WHERE path LIKE '%build.gradle.kts'
```

There are only 207 Gradle builds files written in Kotlin.

![](/img/bq-groovy/gradle-builds-in-kotlin.png)

Basically, Groovy-based Gradle builds are 2000 times more popular than Kotlin-based builds.

## A grain of salt

Now, all that said, remember that developers can name their build files differently, that it's only a snapshot of the projects available on Github, and furthermore, just open source projects (at least projects that explicitly have a LICENSE file). Note for example as well that there are Gradle based projects that also have a pom.xml file available, although they're not using Maven for their build.

Also, perhaps it'd be more interesting to run the queries by counting repositories, rather than build files: Perhaps Gradle users tend to split their build files in smaller build files, in a less monolithic way than with Gradle? Practices and habits may vary greatly.

For the Gradle vs Maven question, at Devoxx Belgium, I ran the following (more complex) query where I look at repositories containing Gradle or Maven build files:

```sql
#standardSQL
select file, count(file) FROM (
  (SELECT 'gradle' as file, count(repo_name)
  FROM `bigquery-public-data.github_repos.files`
  WHERE path LIKE '%build.gradle'
  GROUP BY repo_name)

  UNION ALL

  (SELECT "maven" as file, count(repo_name)
  FROM `bigquery-public-data.github_repos.files`
  WHERE path LIKE '%pom.xml'
  GROUP BY repo_name)
)
group by file
```

Gradle and Maven are already much closer to each other by looking at repository counts than just by pure number of build files, perhaps indeed showing a trend with Gradle users to modularize their builds more.

We get 118,386 repositories using Gradle versus 143,290 repositories using Maven. So Gradle is almost at the same level as Maven from that repository perspective, Still catching up with Maven!

## Famous last words

Don't necessarily draw too big conclusions out of those figures, there are many ways to make stats, and those figures are only a small fraction of all the projects in existence in the world... but at least, they certainly exhibit a certain trend, which is still interesting to know and think about!
# The JDK built-in web server with Apache Groovy


In my timeline, I saw a tweet from Joe Walnes about the built-in HTTP server available in the JDK since Java 6. It's super convenient, starts super fast, easy to use, but I often forget about it. I'd probably not use it for serving planet-wide load, but it's very useful when you need to create a quick service, a little mock for testing some web or micro-service.

Here's a little hello world for the fun.

I'm taking advantage of Apache Groovy's closure-to-functional-interface coercion support, as well as the `with{}` method to reuse the `HttpServer` instance for two method calls on the same instance (I could've used it for the `http` variable as well, actually).

```groovy
import com.sun.net.httpserver.HttpServer

HttpServer.create(new InetSocketAddress(8080), 0).with {
    createContext("/hello") { http ->
        http.responseHeaders.add("Content-type", "text/plain")
        http.sendResponseHeaders(200, 0)
        http.responseBody.withWriter { out ->
            out << "Hello ${http.remoteAddress.hostName}!"
        }
    }
    start()
}
```
# More voice control for Actions on Google


Today, there were some interesting [announcements for Actions on Google](https://developers.googleblog.com/2017/11/help-users-find-interact-re-engage-with.html), for building your conversational interfaces for the [Google Assistant](https://assistant.google.com/). Among the great news, one item particularly caught my attention: the improved SSML support:

> **Better SSML**:
> We recently rolled out an update to the web simulator
> which includes a new SSML audio design experience.
> We now give you more options for creating natural,
> quality dialog using newly supported SSML tags, including \<prosody>,
> \<emphasis>, \<audio> and others. The new tag \<par> is coming soon
> and lets you add mood and richness, so you can play background music
> and ambient sounds while a user is having a conversation with your app.
> To help you get started, we've added over 1,000 sounds to the sound library.
> Listen to a brief SSML audio experiment that shows off some of the new features here.

SSML stands for [Speech Synthesis Markup Language](https://www.w3.org/TR/speech-synthesis/). It's a W3C standard whose goal is to provide better support for a more natural sounding speech generation.

So far, [Actions on Google](https://developers.google.com/actions/) had limited SSML support, but today, there's a bit more you can do with SSML to enhance your apps' voice!

At the Devoxx Belgium conference last week, in a couple of talks showing Dialogflow, 

Actions on Google, and Cloud Functions, I showed some quick examples of SSML.

For example, I [made an attendee do some squats on stage](https://youtu.be/7NjRqMYH11s?t=40m41s)! (but the camera didn't catch that unfortunately.) I created a loop over a tick-tock sound to mimick a countdown. I repeated x times the tick-tock sound. With x audio elements. But we can do better now, by using the repeatCount attribute instead!

```xml
<audio src="gs://my-bucket-sounds/tick-tock-1s.wav" repeatCount="10" />
```

It's much better than repeating my audio tag 10 times!

If you want to make your interactions even more lively, you could already use the Actions on Google [sound library](https://developers.google.com/actions/tools/sound-library/), or use a free sound library like [Freesound](https://www.freesound.org/).

But there's a promising upcoming tag that's gonna be supported soon: \<par/>

If you will, par is a bit like a multi-track audio mixer. You'll be able to play different sounds in parallel, or make the voice speak in parallel. So you could very well have a background sound or music, with your app speaking at the same time.

Speaking of voice, the human voice goes up and down in pitch. With the prosody element, you can define the rate, pitch, and volume attributes. For instance, I make my voice sing some notes with semitones (but to be honest, it doesn't quite sound yet like a real singer!)

```xml
<speak>
  <prosody rate="slow" pitch="-7st">C</prosody>
  <prosody rate="slow" pitch="-5st">D</prosody>
  <prosody rate="slow" pitch="-3st">E</prosody>
  <prosody rate="slow" pitch="-2st">F</prosody>
  <prosody rate="slow" pitch="0st">G</prosody>
  <prosody rate="slow" pitch="+2st">A</prosody>
  <prosody rate="slow" pitch="+4st">B</prosody>
  <prosody rate="slow" pitch="+6st">C</prosody>
</speak>
```

You can also play with different levels of emphasis:

```xml
<speak>
  This is 
  <emphasis level="strong">really</emphasis>
  cool!
</speak>
```

Learn more about all the [support SSML tags in the Actions on Google documentation](https://developers.google.com/actions/reference/ssml)! It's gonna be even more fun to create lively voice interactions with all those improvements!
# JavaOne — How languages influence each other: Reflections on 14 years of Apache Groovy


Last week, I was in San Francisco for my tenth JavaOne! I had two sessions: one on the past / present / future of Java Platform-as-a-Service offerings, and one on programming language influences, and particularly how was Apache Groovy influenced, and how it also inspired other languages.

Here's the abstract:

> Languages have been influencing one another since the dawn of computer programming. There are families of languages: from Algol descendants with begin/end code blocks to those with curly braces such as C. Languages are not invented in a vacuum but are inspired by their predecessors. This session's speaker, who has been working on Apache Groovy for the past 14 years, reflects on the influences that have driven the design of programming languages. In particular, Groovy's base syntax was directly derived from Java's but quickly developed its own flavor, adding closures, type inference, and operators from Ruby. Groovy also inspired other languages: C#, Swift, and JavaScript adopted Groovy's null-safe navigation operator and the famous Elvis operator.

And you can have a look at the slides below:

{{< speakerdeck 2159d9f06d0b4b388a849823f43e82fc >}}

[Apache Groovy](http://www.groovy-lang.org/) is a multi-faceted language for the Java platform, allowing developers to code in a Java-friendly syntax, with great integration with the Java ecosystem, and powerful scripting and Domain-Specific Language capabilities, while at the same time being able to offer you type safety and static compilation.

In this presentation, I revisited some of the influences from other languages, from the C-family and its Java older brother, going through its Python-inspired strings, its Smalltalk and Ruby heritage for named parameters and closures, its type system à-la-Java. But I'm also showing some of the innovations Groovy came up with that were later borrowed by others (Swift, C#, Kotlin, Ceylon, PHP, Ruby, Coffeescript...). Things like Groovy's trailing closure, Groovy builders, null-safe navigation, the Elvis operator, ranges, the spaceship operator, and more.

Ultimately, inspiration is really a two-way street, as languages don't come from nowhere and inherit from their older brothers and sisters. No language is perfect, but each one of them somehow help the next ones to get better, by borrowing here and there some nice features that make developers more productive and write more readable and maintainable code.

# Building your own chatbots with API.ai and Cloud Functions


A few weeks ago, my buddy [Wassim](https://twitter.com/manekinekko) and I had the chance to present again on the topic of chatbots, with API.AI and Cloud Functions, at the [DevFest Toulouse](https://devfesttoulouse.fr/) conference.

Here's the latest update to our slide deck:

{{< speakerdeck 1b47c1e6bb7c4f81b5e0237cbfbda1ca >}}

There's also a video (in French) of the same content from Devoxx France, where I was showing how to build a conference chatbot:

{{< youtube vNoiTnnlGC0 >}}

Chatbots, per se, are not really new, in the sense that we've been developing bots for things like IRC for a long time, but back in the day, it was simply some regular expression labor of love, rather than the natural language that we use today. The progress in machine learning, in both speech recognition (for when you use devices like Google Home) and natural language understanding (NLU), is what led us to being able to speak and chat naturally to those chatbots we encounter now.

In this presentation, we're covering the key concepts that underpin the NLU aspects:

-   **Intents** --- the various kind of sentences or actions that are recognized (ex: "I-want-to-eat-something")
-   **Entities** --- the concepts and values that we manipulate or that are parameterizing intents (ex: the kind of food associated with the "I-want-to-eat-something" intent)
-   **Context** --- a conversation is not just a request-reply exchange, but the discussion between you and the chatbot can span longer back'n forth exchanges, and the chatbot needs to remember what was previously said to be useful and avoid any frustration for the user

We're also clarifying some of the terminology used when working with the Google Assistant and its Actions on Google developer platform:

-   **Google Assistant** --- a conversation between you and Google to help GTD
-   **Google Home** --- voice activated speaker powered by the Google Assistant
-   **Google Assistant SDK** --- kit to embed the Google Assistant in your devices
-   **Agent / chatbot / action** --- an actual app serving a particular purpose
-   **Actions on Google** --- developer platform to build apps for the Assistant
-   **Apps for the Google Assistant** --- 3rd party apps integrated to the Assistant
-   **Actions SDK** --- a software SDK for creating apps
-   **API.AI** (now called **DialogFlow**) --- a platform for creating conversational interfaces

It's important that your chatbot has a consistent persona, that corresponds to the core values or attributes of your brand, the spirit of your bot. A bot for children will likely be more friendly and use easy to understand vocabulary, vs a more formal tone for, say, a bank chatbot).

There are some great resources available for seeing if your chatbot and its conversation is ready for prime time:

-   [g.co/dev/ActionsChecklist](http://g.co/dev/ActionsChecklist) --- a checklist with various aspects to double check
-   [g.co/dev/ActionsDesign](http://g.co/dev/ActionsDesign) --- several useful guides explaining how proper human conversation work

Our tool of choice for our demo is [API.AI](https://api.ai/), for implementing the voice interactions. It's clearly one of the best platforms on the market that makes it simple to create intents, entities, handle contexts, deal with many predefined entity types, that also provides various pre-built conversations that you can peruse.

For the business logic, we went with [Google Cloud Functions](https://cloud.google.com/functions/) which allows us to define our logic using JavaScript and Node.JS. We also took advantage of the local [Cloud Functions emulator](https://cloud.google.com/functions/docs/emulator), to run our logic on our local machine, and [ngrok](https://ngrok.com/) for creating a tunnel between that local machine and API.AI. In API.AI, in the fulfillment webhook, you'll put the temporary URL given by ngrok, that then points at your local machine, via ngrok's tunnel. That way, you can see changes immediately, thanks to the live reloading supported by the emulator, making it easy to evolve your code.

Cloud Functions is Google's function-as-a-service offering, which is a serverless service, taylored for event-oriented systems as well as for direct HTTP invocation, and you pay only as you go, as requests are made or events are sent to your function. It's a cost effective solution, that scale automatically with your load.

To finish, we're also saying a few words about how to submit your bot to the Actions on Google development platform, to extend the Google Assistant with your own ideas.
# Cloud Shell and its Orion-based text editor to develop in the cloud


After deploying in the cloud, there's a new trend towards programming in the cloud. Although I'm not sure we're quite there yet, there are a couple of handy tools I've been enjoying when working on the [Google Cloud Platform](https://cloud.google.com/).

I had been using the built-in [Cloud Shell](https://cloud.google.com/shell/) console, on the Google Cloud console, to have a terminal already pre-configured for my Google Cloud project. It allows you to easily have access to your whole environment, run commands, etc, just like you would from your own computer. The fact that all the command-line tools you can imagine (gradle, maven, gcloud sdk, etc) are already there is helpful, as well as the fact that you are already configured for using other cloud services.

To launch the shell, look no further than the top right hand corner, and click on the little [>_] button. It will launch the terminal in the bottom part of your cloud console.

![](/img/cloud-shell/cloud-shell-launch.png) 

You will see the console popping up below, and you'll be ready to access your project's environment:

![](/img/cloud-shell/cloud-shell-terminal.png)

But look at this little pen icon above? If you click it, you'll get your terminal in full screen in another window, but more interestingly, it will launch a proper file editor! It's an editor based on [Eclipse Orion's web editor](https://orionhub.org/). You have your usual file browsing pane, to navigate to and select which files you want to edit, and you also have things like syntax highlighting to better understand the code at hand.

![](/img/cloud-shell/cloud-shell-editor.png)

The more friendly those built-in web editors will become, the sooner we'll really be able to develop in the cloud. I believe I will still continue to work on my local computer a long, but there are already times when I prefer running some operations directly in the cloud: for example, tasks that are really network hungry, they benefit directly from the wonderful network that cloud shell has access to, which is much snappier than the connection I have at home on my DSL router. For example, running some Docker build command, or fetching tons of dependencies for Node or Maven/Gradle, and it's really much nicer and faster within Cloud Shell. So having the added capability of also editing some files in my project make things pretty snappy.

There was a recent article on the Google Cloud blog outlining the [beta launch of the Cloud Shell's code editor](https://cloudplatform.googleblog.com/2017/07/Cloud-Shells-code-editor-now-in-beta.html), which is why I wanted to play with this new built-in editor.
# Apache Groovy and Google App Engine at JavaOne


I'll be back at [JavaOne](https://www.oracle.com/javaone/index.html) in San Francisco in October to speak about [Apache Groovy](http://www.groovy-lang.org/) and [Google App Engine](https://cloud.google.com/appengine/).

## Apache Groovy

I've been involved with the Apache Groovy project for 14 years now, it's a long time, and it's interesting to see how the language has evolved over time, how it was influenced by other languages, but also how it influenced those other languages itself! Let's see which operators or syntax constructs evolved and moved from one to the other.

## Google App Engine

These days, the hype is around containers, containers everywhere! We tend to relegate Platform-as-a-Service solutions to the side, but it's still one of the most convenient way to deploy and scale an application today. After all, Snapchat and others are able to take advantage of a PaaS like App Engine, so why couldn't you too? (and you don't need to scale to their level anyway, but you'd still get the convenience of easy development and deployment)

Anyhow, I've invited my friends from Heroku and Oracle to join me for a panel discussion on the theme of Java PaaS-es. We'll see how Java PaaS-es are relevant today, more than ever.

## The abstracts

So if you want to lear more about those [two talks](https://events.rainfocus.com/catalog/oracle/oow17/catalogjavaone17?search=%22Guillaume%20Laforge%22&showEnrolled=false), here are their abstracts.

### [CON5034] How Languages Influence Each Other: Reflections on 14 Years of Apache Groovy

> Languages have been influencing one another since the dawn of computer programming. There are families of languages: from Algol descendants with begin/end code blocks to those with curly braces such as C. Languages are not invented in a vacuum but are inspired by their predecessors. This session's speaker, who has been working on Apache Groovy for the past 14 years, reflects on the influences that have driven the design of programming languages. In particular, Groovy's base syntax was directly derived from Java's but quickly developed its own flavor, adding closures, type inference, and operators from Ruby. Groovy also inspired other languages: C#, Swift, and JavaScript adopted Groovy's null-safe navigation operator and the famous Elvis operator.

### [CON5945] Java PaaS -- Then, Now and Next

> Java developers want to deploy their apps easily. Fortunately, there are great solutions for them in the form of Platform-as-a-Service for Java. In this discussion panel, we will share the views of Oracle, Heroku and Google engineers about their respective Java PaaS-es, how this space has evolved over the past few years, and what makes a great developer experience for users today. We'll discuss the future of PaaS in light of new technologies like microservices, containerization, and serverless architectures. Finally, we'll open up the space for an interactive discussion with the audience.

(with Joe Kutner from Heroku, Shaun Smith from Oracle, Ludovic Champenois from Google, and Frank Greco from NY JavaSIG as moderator)
# Scale an OpenAPI based web API with Cloud Endpoints


InfoQ recently released a [video](https://www.infoq.com/presentations/web-api-scale-google-cloud) from the [APIDays](http://paris.apidays.io/) conference that took place in Paris last year. I talked about scaling an [Open API](https://www.openapis.org/) based web API using [Cloud Endpoints](https://cloud.google.com/endpoints/), on the Google Cloud platform.

I spoke about the topic a few times, as web APIs is a topic I enjoy, at Nordic APIs, at APIDays, or Devoxx. But it's great to see the video online. So let me share the slide deck along with the [video](https://www.infoq.com/presentations/web-api-scale-google-cloud):

{{< speakerdeck 490a2aa1c3c142d0ac2c40ea60af2cf5 >}}

In a nutshell, the API contract is the source of truth. Whether you're the one implementing the API backend, or you're the consumer calling the API, there's this central contract that each party can rely on, to be certain how the API should be looking like, what kind of endpoint to expect, what payloads will be exchanged, or which status codes are used.

With a central contract, team communication and collaboration is facilitated: I've seen customers where a central architecture team would define a contract, that was implemented by a third-party (an outsourcing consulting company), and the API was consumed by different teams, both internally and externally. The central contract was here to facilitate the work between those teams, to ensure the contract would be fulfilled.

In addition, having such a computer-friendly contract is really useful for tooling. Out of the contract, you can generate various useful artifacts, such as:

-   **static & live mocks** --- that consumers can use when the API is not finalized, 
-   **test stubs** --- for facilitating integration tests, 
-   **server skeletons** --- to get started implementing the business logic of the API with a ready-made project template,
-   **client SDKs** --- offering kits consumers can use, using various languages, to call your API more easily,
-   **sandbox & live playground** --- a visual environment for testing and calling the API, for developers to discover how the API actually works,
-   **an API portal with provisioning** --- a website offering the API reference documentation and allowing developers to get credentials to get access to the API,
-   **static documentation** --- perhaps with just the API reference documentation, or a bundle of useful associated user guide, etc.

However, be careful with artifact generation. As soon as you start making some customizations to what's been generated by tools, you might run the risk of overwriting those changes the next time you re-generate those artifacts! So beware, how customization can be done and be integrated with those generated artifacts.

In my presentation and demo, I decided to use Cloud Endpoints to manage my API, and to host the business logic of my API implementation on the Google Cloud Platform. GCP (for short) provides various "compute" solutions for your projects:

-   [Google App Engine](https://cloud.google.com/appengine/) (Platform-as-a-Service): you deploy your code, and all the scaling is done transparently for you by the platform,
-   [Google Container Engine](https://cloud.google.com/container-engine/) (Container-as-a-Service): it's a Kubernetes-based container orchestrator where you deploy your apps in the form of containers,
-   [Google Compute Engine](https://cloud.google.com/compute/) (Infrastructure-as-a-Service): this time, it's full VMs, with even more control on the environment, that you deploy and scale.

In my case, I went with a containerized [Ratpack](https://ratpack.io/) implementation for my API, implemented using the [Apache Groovy](http://www.groovy-lang.org/) programming language (what else? :-). So I deployed my application on Container Engine.

I described my web API via an Open API descriptor, and managed it via Cloud Endpoints. Cloud Endpoints is actually the underlying infrastructure used by Google themselves, to host all the APIs developers can use today (think Google Maps API, etc.) This architecture already serves literally hundreds of billions of requests everyday... so you can assume it's certainly quite scalable in itself. You can manage APIs described with Open API, regardless of how they were implemented (totally agnostic from the underlying implementation), and it can manage both HTTP-based JSON web APIs, as well as [gRPC](https://grpc.io/) based ones.

There are three interesting key aspects to know about Cloud Endpoints, regardless of whether you're using the platform for public / private / mobile / micro-services APIs:

-   Cloud Endpoints takes care of security, to control access to the API, to authenticate consumers (taking advantage of API keys, Firebase auth, Auth0, JSON Web Tokens)
-   Cloud Endpoints offers logging and monitoring capabilities of key API related metrics
-   Cloud Endpoints is super snappy and scales nicely as already mentioned (we'll come back to this in a minute)

Cloud Endpoints actually offers an [open source "sidecar" container proxy](https://github.com/cloudendpoints/esp/). Your containerized application will go hand in hand with the [Extensible Service Proxy](https://cloud.google.com/endpoints/docs/running-esp-localdev), and will actually be wrapped by that proxy. All the calls will actually go through that proxy before hitting your own application. Interestingly, there's not one single proxy, but each instance of you app will have its own proxy, thus diminishing the latency between the call to the proxy and the actual code execution in your app (there's no network hop between the two, to a somewhat distant central proxy, as the two containers are together). For the record, this proxy is based on [Nginx](https://www.nginx.com/). And that proxy container can also be run elsewhere, even on your own infrastructure.

In summary, Cloud Endpoints takes care of securing, monitoring and scaling your Web API. Developing, deploying, and managing your API on Google Cloud Platform gives you the choice: in terms of protocol with JSON / HTTP based APIs or gRPC, in terms of implementation technology as you can chose any language or framework you wish that are supported by the various compute options of the platform allow you to go from PaaS, to CaaS, or IaaS. Last but not least, this solution is open: based on open standards like Open API and gRPC, or by implementing its proxy on top of Nginx.
# Scale Jenkins with Kubernetes on Google Container Engine


Last week, I had the pleasure to speak at the [Jenkins Community Day](https://jcd-paris.jfrog.com/) conference, in Paris, organized by my friends from [JFrog](https://www.jfrog.com/), provider of awesome tools for software management and distribution. I covered how to scale [Jenkins](https://jenkins.io/) with [Kubernetes](https://kubernetes.io/) on [Google Container Engine](https://cloud.google.com/container-engine/).

For the impatient, here are the slides of the presentation I've given:

{{< speakerdeck 47af08ec8f0b40e48335ff0390270b28 >}}

But let's step back a little. In this article, I'd like to share with you why you would want to run Jenkins in the cloud, as well as give you some pointers to interesting resources on the topic.

## Why running Jenkins in the cloud?

So why running Jenkins in the cloud? First of all, imagine your small team, working on a single project. You have your own little server, running under a desk somewhere, happily building your application on each commit, a few times a day. So far so good, your build machine running Jenkins isn't too busy, and stays idle most of the day.

Let's do some bottom of the napkin calculations. Let's say you have a team of 3 developers, committing roughly 4 times a day, on one single project, and the build takes roughly 10 minutes to go.

3 developers * 4 commits / day / developer * 10 minutes build time * 1 project = 1 hour 20 minutes

So far so good, your server indeed stays idle most of the day. Usually, at most, your developers will wait just 10 minutes to see the result of their work.

But your team is growing to 10 persons, the team is still as productive, but the project becoming bigger, the build time goes up to 15 minutes:

10 developers * 4 commits / day / developer * 15 minutes build time * 1 project = 10 hours

You're already at 10 hours build time, so your server is busy the whole day, and at times, you might have several build going on at the same time, using several CPU cores in parallel. And instead of building in 15 minutes, sometimes, the build might take longer, or your build might be queued. So in theory, it might be 15 minutes, but in practice, it could be half an hour because of the length of the queue or the longer time to build parallel projects.

Now, the company is successful, and has two projects instead of one (think a backend and a mobile app). Your teams grow further up to 20 developers per project. The developers are a little less productive because of the size of the codebase and project, so they only commit 3 times a day. The build takes more time too, at 20 minutes (in ideal time). Let's do some math again:

20 developers * 3 commits / day / developer * 20 minutes build time * 2 projects = 40 hours

Woh, that's already 40 hours of total build time, if all the builds are run serially. Fortunately, our server is multi-core, but still, there are certainly already many builds that are enqueued, and many of them, perhaps up to 2-3 or perhaps even 4 could be run in parallel. But as we said, the build queue increases further, the real effective time of build is certainly longer than 30 minutes. Perhaps at times, developers won't see the result of their developments before at least an hour, if not more.

One last calculation? With team sizes of 30 developers, decreased productivity of 2 commits, 25 build time, and 3 projects? And you'll get 75 hours total build time. You may start creating a little build farm, with a master and several build agents. But you also increase the burden of server management. Also, if you move towards a full Continuous Delivery or Continuous Deployment approach, you may further increase your build times to go up to deployment, make more but smaller commits, etc. You could think of running builds less often, or even on a nightly basis, to cope with the demand, but then, your company is less agile, and the time-to-market for fixes of new features might increase, and your developers may also become more frustrated because they are developing in the blind, not knowing before the next day if their work was successful or not.

With my calculations, you might think that it makes more sense for big companies, with tons of projects and developers. This is quite true, but when you're a startup, you also want to avoid taking care of local server management, provisioning, etc. You want to be agile, and use only compute resources you need for the time you need them. So even if you're a small startup, a small team, it might still make sense to take advantage of the cloud. You pay only for the actual time taken by your builds as the build agent containers are automatically provisioned and decommissioned. The builds can scale up via Kubernetes, as you need more (or less) CPU time for building everything.

And this is why I was happy to dive into scaling Jenkins in the cloud. For that purpose, I decided to go with building with containers, with [Kubernetes](https://kubernetes.io/), as my app was also containerized as well. [Google Cloud](https://cloud.google.com/) offers [Container Engine](https://cloud.google.com/container-engine/), which is basically just Kubernetes in the cloud.

## Useful pointers

I based my presentation and demo on some great solutions that are published on the Google Cloud documentation portal. Let me give you some pointers:

* [Overview of Jenkins on Container Engine](https://cloud.google.com/solutions/jenkins-on-container-engine)
* [Setting up Jenkins on Container Engine](https://cloud.google.com/solutions/jenkins-on-container-engine-tutorial)
* [Configuring Jenkins for Container Engine](https://cloud.google.com/solutions/configuring-jenkins-container-engine)
* [Continuous Deployment to Container Engine using Jenkins](https://cloud.google.com/solutions/continuous-delivery-jenkins-container-engine)
* [Lab: Build a Continuous Deployment Pipeline with Jenkins and Kubernetes](https://github.com/GoogleCloudPlatform/continuous-deployment-on-kubernetes)

The latter one is the tutorial I actually followed for the demo that I presented during the conference. It's a simple Go application, with a frontend and backend. It's continuously build, on each commit (well, every minute to check if there's a new commit), and deployed automatically in different environments: dev, canary, production. The sources of the project are stored in [Cloud Source Repository](https://cloud.google.com/source-repositories/) (it can be mirrored from Github, for example). The containers are stored in [Cloud Container Registry](https://cloud.google.com/container-registry/). And both the Jenkins master and agents, as well as the application are running inside Kubernetes clusters in [Container Engine](https://cloud.google.com/container-engine/).

## Summary and perspective

Don't bother with managing servers! Quickly, you'll run out of CPU cycles, and you'll have happier developers with builds that are super snappy!

And for the record, at Google, dev teams are also running Jenkins! There was a presentation ([video](https://www.youtube.com/watch?v=7ERV9C20GSE) and [slides](https://www.cloudbees.com/sites/default/files/2016-jenkins-world-jenkins_inside_google.pdf) available) given last year by David Hoover at Jenkins World talking about how developers inside Google are running hundreds of build agents to build projects on various platforms.
# A year as a Google Cloud Developer Advocate


Time flies! Last week was my first "Googleversary": It's already been a year since I joined Google Cloud as a Developer Advocate. What a ride it's been so far!

I announced my [move to Google]({{< ref "/posts/2016/06/02/joining-google-as-a-developer-advocate-for-the-google-cloud-platform" >}}) in June last year. And since then got the chance to:

-   talk at more than 20 conferences or meetups
-   give 3 keynotes
-   write 36 articles
-   meet with a dozen customers or so
-   addressed literally thousands of developers

For some conferences, like Devoxx Belgium, I even spoke 5 times! Or for my [trip to Singapore]({{< ref "/posts/2017/05/16/flying-east-to-singapore" >}}), I had 6 talks or workshops lined up!

There's a great level of freedom in this job, and you can decide where to put the cursor in terms of travel, or where to put the puck regarding the topics and products to cover. This is really wonderful!

I had the chance to cover things like Google [App Engine](https://cloud.google.com/appengine/) (you know I've been a big fan of it since 2009!), [Kubernetes](https://kubernetes.io/) / [Container Engine](https://cloud.google.com/container-engine/), or [Cloud Functions](https://cloud.google.com/functions/), on the compute side of the story, with a bit of [Cloud Endpoints](https://cloud.google.com/endpoints/) for the Web API aspect. And on the Big Data / ML side, I talked about the various [Machine Learning APIs](https://cloud.google.com/products/machine-learning/) (Vision, Speech recognition, Natural Language processing, Video intelligence), or played with [BigQuery](https://cloud.google.com/bigquery/) for analyzing the Github dataset. And lately, my big hit at conferences and meetups, it's been the hot topic of chatbots + serverless, with [API.AI](https://api.ai/) and Cloud Functions for building conversational interfaces.

But there are just so many hours in a day, and there's so much more I want to work on and play with! As I often tell friends and developers that I meet here and there: working as a developer advocate for Google Cloud, it's a bit like being a kid entering a toy store where you'd be told: "hey, here are all the toys we have, feel free to play with everything you want!" But it's not only the toys... you also get the chance to play with other kids (err, sorry, fellow DAs) on all those things, to imagine the next epic game together!

I'm looking forward to telling you more about Google Cloud! Let's meet and chat at the next conference or meetup!
# Trying out Apache Groovy's new Antlr4 parser with Java 8 support


[Apache Groovy](http://www.groovy-lang.org/) is coming up with a new parser, that supports the Java 8 syntax elements, as well as some new notation and operators of its own (like !in, !instanceof or ?[] for safe navigation with collections, or with ?= for Elvis assignment). I blogged recently about the fact that you can [try this new flavor online on this forked Groovy Web Console]({{< ref "/posts/2017/03/24/testing-java-8-snippets-on-the-new-app-engine-java-8-runtime" >}}) version, without the need of installing everything. But today I'll tell you how to build it for yourself in order to run it on your machine.

It's still to be decided which is going to be the version number of the release containing the new "parrot" parser, but you can already play with this syntax today. As I'm the kind of guy living on the edge of Groovy, I always use Groovy from the firehose, using the master branch with the latest and greatest changes. But I always forget about the right parameters or environment variable to use to build Groovy with the new parser, and to activate it... although it's clearly [explained in the documentation](https://github.com/apache/groovy/tree/master/subprojects/parser-antlr4#how-to-enable-the-new-parser). So as a note to self, to know where to look at, I decided to write it down in this post!

Build Apache Groovy from the master branch with the Antlr4 parser:

```bash
./gradlew -PuseAntlr4=true installGroovy
```

It's going to build an installation of Groovy that you can point [SDKman](http://sdkman.io/) at:

```bash
$ sdk install groovy target/install/ dev
$ sdk use groovy dev
```

That way, you can use this "dev" version of Groovy in your shell. However, you still need to enable the Antlr4 parser, and you can do so with the following exported environment variable:

```bash
$ export JAVA_OPTS=-Dgroovy.antlr4=true
```

Then, when running groovyConsole or groovysh, you'll be able to try the new syntax.

To learn more about the new parser, you can have a look at my presentation with some of the novelties provided by the "parrot" parser here:

{{< speakerdeck cdbf0cee31fd4eeca3c4add6ad86b3b0 >}}

And you can read Sergio's translation of Daniel's article on the new features [here](http://sergiodelamo.es/preview-of-groovy-3/).
# Flying East to Singapore


In two weeks, I'll be flying east, much further east than I've ever been! I'll visit Singapore! And I'll have a pretty busy week with several events: conference, meetup, user groups, brown bag lunch... and I'll talk about Groovy, Machine Learning, and chatbots!

First of all, on Wednesday 31st, I'll participate to the [Singapore Java User Group](https://www.meetup.com/fr-FR/singajug/events/240026369/?eventId=240026369), where I'll give an update on [Apache Groovy](http://groovy-lang.org/) (the latest improvements, new features, the roadmap).

![](/img/sin/sin-jug-groovy.png)

Thursday 1st, I'll visit [Crédit Agricole CIB](https://www.ca-cib.com/our-global-presence/asia-pacific/singapore), for a brown-bag lunch about Machine Learning. They did a fun survey to decide which topics I should cover! And funnily, this is in this office that is maintained and developed a banking project on which I worked more than ten years before!

![](/img/sin/sin-ca.png)

Then, it's Voxxed Days Singapore time! I'll talk again about the Machine Learning APIs offered by Google Cloud, as well as a few words about TensorFlow and Cloud Machine Learning Engine.

![](/img/sin/sin-voxxed.png)

Then, on Saturday 3rd, two events, one organized by the GDG Singapore, which will be a [workshop on building chatbots](http://peatix.com/event/263477/view), using API.AI and Cloud Functions, and covering the Google Home and Assistant too.

![](/img/sin/sin-gdg-chatbot.png)

And the last event will be held in Google's offices, on the theme of [data science](https://events.withgoogle.com/going-beyond-data-science/), where I'll will also give a presentation on chatbots, the Google Assistant with Google Home, with API.AI for the conversational interface, and Cloud Functions for the business logic.

![](/img/sin/sin-data-science.png)

It's gonna be a pretty busy week, and I'm looking forward to meeting tons of developers in Singapore, as well as reconnect with some of my friends & former colleagues living in the area!
# Machine Learning and Scaling Web Apis



The [JAX conference](https://jax.de/), in Mainz, Germany, is coming to an end. I was there with my colleagues [Mete](https://twitter.com/meteatamel) and [Robert](https://twitter.com/hostirosti), and had the chance to cover two topics: Machine Learning and Scaling Web APIs. It's a pleasure to come back to this conference where the audience is always very focused, eager to learn, and is engaging in great and interesting conversations.

## Machine Intelligence at Google Scale

My [first presentation](https://jax.de/session/machine-intelligence-at-google-scale-visionspeech-api-tensorflow-and-cloud-machine-learning/) was about Machine Learning, and in particular with the Google Cloud APIs, including [Vision](https://cloud.google.com/vision/), [Speech](https://cloud.google.com/speech/), [Natural Language](https://cloud.google.com/natural-language/), [Translate](https://cloud.google.com/translate/), and [Video Intelligence](https://cloud.google.com/video-intelligence/). Although I'm not an expert in [TensorFlow](https://www.tensorflow.org/) and the [Cloud Machine Learning Engine](https://cloud.google.com/ml-engine/), I got a chance to say a few words about these. I guess I'll have to play with both at some point to be able to tell even more!

> The biggest challenge of Deep Learning technology is the scalability. As long as using single GPU server, you have to wait for hours or days to get the result of your work. This doesn't scale for production service, so you need a Distributed Training on the cloud eventually. Google has been building infrastructure for training the large scale neural network on the cloud for years, and now started to share the technology with external developers. In this session, we will introduce new pre-trained ML services such as Cloud Vision API and Speech API that works without any training. Also, we will look how TensorFlow and Cloud Machine Learning will accelerate custom model training for 10x -- 40x with Google's distributed training infrastructure.

{{< speakerdeck b3fe3f4eb13547fc8e81785c54aceafd >}}

## Scale a Swagger-based Web API with Google Cloud Endpoints

My [second session](https://jax.de/session/scale-a-swagger-based-web-api/) was about scaling web APIs, defined using the [Open API specification](https://www.openapis.org/), thanks to [Kubernetes](https://kubernetes.io/) and [Google Container Engine](https://cloud.google.com/container-engine/), for the scaling part of the story, and managing those APIs thanks to [Google Cloud Endpoints](https://cloud.google.com/endpoints/).

> Web APIs are more often specified with API definition languages like Swagger (now named OpenAPI Spec), as it can help you generate nice interactive documentation, server skeletons, and client SDKs, mocks, and more, making it simpler to get started both producing and consuming an API. In this session, Guillaume will demonstrate how to define a Web API with Swagger/OpenAPI Spec, and scale it using Cloud Endpoints, on the Google Cloud Platform.

{{< speakerdeck 490a2aa1c3c142d0ac2c40ea60af2cf5 >}}

# A chatbot for the Devoxx conference agenda with API.ai and Cloud Functions


That's Devoxx France this week, and I've had the pleasure of delivering today another [talk on the theme of chatbots, using Cloud Functions for the business logic, API.AI for the bot cleverness](https://cfp.devoxx.fr/2017/talk/NSJ-9765/Un_bot_pour_gerer_l'agenda_de_ta_conference), with a bonus of a demo through Google Home and the Google Assistant platform.

I'll post the YouTube video recording once it's online, but in the meantime, I wanted to share my slides here:

{{< speakerdeck 5bbe77c6ff1e4f0da337c7328c75936a >}}

And the video in French:

{{< youtube vNoiTnnlGC0 >}}
# Testing Java 8 Snippets on the new App Engine Java 8 runtime


A new Java 8 runtime for [Google App Engine standard](https://cloud.google.com/appengine/docs/standard/) is coming soon, and is currently in alpha testing. You can [request to join](https://docs.google.com/a/google.com/forms/d/1MDzykTWp77YzRgFs5R6ONOuKWYnKEhfy5VhSJYbDvmo/viewform?edit_requested=true) the alpha program, if you want to try it out for yourself. But I wanted to let anyone play with it, easily, to see how well the Java 8 APIs work, but also to try some Java 8 syntax too. So here's a [web console](https://cafe-huitre.appspot.com/) where you can do just that!

[![](/img/j8snip/groovy-web-console-java8.png)](https://cafe-huitre.appspot.com/)

But to be precise, it's actually my good old [Groovy Web Console](http://groovyconsole.appspot.com/), where people can write, execute and save [Apache Groovy](http://www.groovy-lang.org/) snippets. It is a special version, in fact, as it's built on Java 8, uses the invoke dynamic flavor, and... drum roll... it's using the upcoming "Parrot" parser which adds the Java 8 syntax constructs to the Groovy grammar. So not only can you try Java snippets, but it's a great opportunity to try the future Groovy parser that's gonna be released in Apache Groovy 2.5 or 3.0 (still to be decided).

A meetup about Java 8 on Google App Engine standard

Also, for those who live in Paris and the area, we have the chance of having [Ludovic Champenois](https://twitter.com/ludoch), an engineer working on App Engine, that will be in France, and will be speaking at this [GDG Cloud meetup hosted by Xebia](https://www.meetup.com/fr-FR/GDG-Cloud-Paris/events/238519360/?rv=ea1&_af=event&_af_eid=238519360&https=on), which takes places on Tuesday, April 4th, just on the even of Devoxx France!

So if you want to learn more about Java 8 on App Engine, please [sign up](https://www.meetup.com/fr-FR/GDG-Cloud-Paris/events/238519360/?rv=ea1&_af=event&_af_eid=238519360&https=on)!

I will also be presenting about [Google Home](https://madeby.google.com/home/), the [Google Assistant](https://assistant.google.com/), [API.AI](https://api.ai/), and Google [Cloud Functions](https://cloud.google.com/functions/) to host the logic of your very own bots and agents. It's based on the [presentation I gave at Cloud Next]({{< ref "/talks/2017/03/13/extending-the-google-assistant-with-actions-on-google" >}}) 2017 in San Francisco. If you want to learn more about

[![](/img/j8snip/gae-home-cf-xebia.png)](https://www.meetup.com/fr-FR/GDG-Cloud-Paris/events/238519360/?rv=ea1&_af=event&_af_eid=238519360&https=on)
# Happy Pi Day! Google Home helps you learn the digits of Pi


You know what? It's Pi Day today! Well, if you follow the American date standard, it's 3.14 today, a nice approximation of Pi. Last year, in a past life, I had [played with Pi](http://restlet.com/company/blog/2016/03/14/win-a-raspberry-pi-3-to-celebrate-pi-day-with-a-pi-api/) already, but this year, my awesome colleagues ([Ray](https://twitter.com/saturnism), [Sandeep](https://twitter.com/SandeepDinesh), [Francesc](https://twitter.com/francesc), [Ian](https://twitter.com/IanMLewis)) have been working on some very cool demos around Pi, with the "Pi delivery", at <https://pi.delivery/>

![](/img/pi-day/pi-delivery-music.png)

You can transform the Pi digits in a nice melody, show a D3.js based visualisation of the transitions between digits, you can stream the Pi digits, and more. And you can learn about how it's been [developed on the Google Cloud Platform](https://pi.delivery/#howcalculating-pi).

Ray pinged me to see if we could also create an assistant you can invoke on Google Home, to ask for digits of Pi, as I recently played with [Google Home, API.AI and Cloud Functions]({{< ref "/talks/2017/03/13/extending-the-google-assistant-with-actions-on-google" >}})! And I played with the idea: created a new Cloud Function that invokes the Pi's Web API, designed an assistant in API.AI, and submitted this assistant to the Google Assistant.

You'll be able to ask your Google Home:

> Ok Google, talk to Pi Digit Agent.
> What is the 34th digit of Pi?

And it will tell you that it's 2.

How did I do that, let's first have a look at the Cloud Function, implemented in JavaScript / Node.js:

```json
{
  "name": "pi-assistant",
  "version": "0.0.1",
  "private": true,
  "scripts": {
    "start": "node index.js",
    "deploy": "rm -rf node_modules; gcloud alpha functions deploy digit --project digit-of-pi-2017-assistant  --trigger-http --stage-bucket gs://digit-of-pi-2017-assistant/"
  },
  "description": "Ask for the n-th digit of Pi!",
  "main": "index.js",
  "repository": "",
  "author": "Guillaume Laforge",
  "dependencies": {
    "actions-on-google": "^1.0.7",
    "node-fetch": "^1.6.3"
  }
}
```

The key things here are the dependencies: I'm using the actions-on-google Node module to interact more easily with API.AI and the Assistant, and I'm using node-fetch to interact with the Pi Delivery's REST API.

Let's now have a look at the code of our exported digit function in index.js:

```javascript
const ApiAiAssistant = require('actions-on-google').ApiAiAssistant;
const fetch = require('node-fetch');
​
function nthDigit(assistant) {
    let rank = parseInt(assistant.getArgument('rank').replace(/,/g, ''));
    console.log(`${rank}nth digit`);
​
    // 0 -> 3, 1 -> ., 2 -> 1, 3 -> 4, 4 -> 1, ...
    // let's return 3 for 0th / 1st, and the digit otherwise, 
    // to follow natural human numbering and the fact the dot is accounted
​
    let start = rank < 2 ? 0 : rank;
​
    fetch(`https://api.pi.delivery/v1/pi?start=${start}&numberOfDigits=1`)
        .then(response => response.json())
        .then(data => {
            assistant.ask(`Digit ${rank} of Pi is ${data.content}. Do you want to know a different digit of Pi? Or say cancel to exit.`);
        }).catch(err => {
            console.log(err);
            assistant.ask('The ways of Pi are mysterious... Try again, or with another digit? Or say cancel to exit.');
        });
}
​
exports.digit = function (request, response) {
    let assistant = new ApiAiAssistant({request, response});
    let actionMap = new Map();
    actionMap.set('nth-digit-intent', nthDigit);
    assistant.handleRequest(actionMap);
};
```

It's pretty straightforward, we export a digit function, that creates an API.AI assistant, to which we feed an action map pointing at our main intent, for asking for digits. I extract the parameter (ie. the rank of the digit I'm interested in), I call the REST API with a fetch() call, and then I return the result with the assistant.ask() call.

In a nutshell, on API.AI's side, my welcome intent greets you, telling you how to use the assistant:

![](/img/pi-day/pi-welcome-intent.png)

And then the main intent, whose webhook points at my Cloud Function, does the heavy lifting:

![](/img/pi-day/pi-ask-digit-intent.png)

You can try it in the emulator:

![](/img/pi-day/pi-simulator.png)

After that, once the webhook is properly configured, I published my action, through the integrations pane, and the cloud API console. I'll skip the details here, but you can read more on [how to distribution your actions](https://developers.google.com/actions/distribute/).

So again, Happy Pi Day! And hopefully, if you have a Google Home device and when my assistant is officially published, you'll be able to learn more about the digits of Pi!

And let's finish with a video of the assistant running live on my Google Home!

{{< youtube JrqdhpSmNRc >}}
# Extending the Google Assistant with Actions on Google


Last week, in San Francisco, took place the [Google Cloud Next 2017](https://cloudnext.withgoogle.com/) conference, and I had the pleasure to co-present a session on "Extending the Google Assistant with Actions on Google", with Brad Abrams, product manager on the assistant technology at Google.

> The Google Assistant is the conversational user interface that helps you get things done in your world. Actions on Google let you build on this assistance, while your integrations can help you engage users through Google Home on Pixel, Android and many other devices that connect with Google Assistant. In this session, we'll share the latest innovations behind the Google Assistant and how you can leverage those technologies and best practices for Voice User Interface design to build your own custom extensions to Google Assistant.

In this presentation, for our demonstration, we used [API.AI](https://api.ai/) and [Google Cloud Functions](https://cloud.google.com/functions/) (announced as beta during the keynote) to implement our assistant, whose job was to help attendees learn more about the conference schedule and see which talks they'd be interested in attending.

You can watch the video of the talk on YouTube already:

{{< youtube 7e0RGIul8Kk >}}

And you can have a closer look at the slides below:

{{< speakerdeck 87cda359a4ba4718b789286c1be27379 >}}
# Google Cloud Endpoints in General Availability


Today was [announced the general availability](http://cloudplatform.googleblog.com/2017/02/Google-Cloud-Endpoints-now-GA-a-fast-scalable-API-gateway.html) of [Google Cloud Endpoints](https://cloud.google.com/endpoints/)!

Endpoints is the Google Cloud Platform solution for Web API management, which lets you easily protect & secure your API, monitor it, without overhead, and even allows you to implement your API with any language or framework you want.

I've spoken about Endpoints a few times already, at [Devoxx Belgium]({{< ref "/talks/2016/11/15/binge-streaming-web-apis-with-ratpack-cloud-ednpoints-app-engine-flex-and-streamdata-io" >}}), [Nordic APIs summit]({{< ref "/talks/2016/10/27/scaling-a-swagger-based-web-api-on-google-cloud-endpoints" >}}), and APIDays Paris. And you can see the recording of my Nordic APIs appearance, if you want to learn more about Cloud Endpoints:

{{< youtube M1VC5jT-mSU >}}
# A tight development loop for developing bots with API.ai, the Google Cloud Functions emulator, Node.js and Ngrok


For [Google Cloud Next](https://cloudnext.withgoogle.com/) and [Devoxx France](http://devoxx.fr/), I'm working on a new talk showing how to build a conference assistant, to whom you'll be able to ask questions like "what is the next talk about Java", "when is Guillaume Laforge speaking", "what is the topic of the ongoing keynote", etc.

For that purpose, I'm developing the assistant using [API.AI](https://api.ai/). It's a "conversational user experience platform" recently acquired by Google, which allows you to define various "intents" which correspond to the kind of questions / sentences that a user can say, and various "entities" which relate to the concepts dealt with (in my example, I have entities like "talk" or "speaker"). API.AI lets you define sentences pretty much in free form, and it derives what must be the various entities in the sentences, and is able to actually understand more sentences that you've given it. Pretty clever machine learning and natural language process at play. In addition to that, you also have support for several spoken languages (English, French, Italian, Chinese and more), integrations with key messaging platforms like Slack, Facebook Messenger, Twilio, or [Google Home](https://madeby.google.com/home/). It also offers various SDKs so you can integrate it easily in your website, mobile application, backend code (Java, Android, Node, C#...)

When implementing your assistant, you'll need to implement some business logic. You need to retrieve the list of speakers, the list of talks from a backend or REST API. You also need to translate the search for a talk on a given topic into the proper query to that backend. In order to implement such logic, API.AI offers a Webhook interface. You instruct API.AI to point at your own URL that will take care of dealing with the request, and will reply adequately with the right data. To facilitate the development, you can take advantage of the SDKs I mentioned above, or you can also just parse and produce the right JSON payloads. To implement my logic, I decided to use [Google Cloud Functions](https://cloud.google.com/functions/), Google's recent serverless, function-based offering. Cloud Functions is currently is alpha, and supports JavaScript through Node.js.

For brevity sake, I'll focus on a simple example today. I'm going to create a small agent that replies to queries like "what time is it in Paris" or some other city.\
In API.AI, we're going to create an "city" entity with a few city names:

![](/img/tightloop/wtii-01-entity.png)

Next, we're creating the "ask-for-the-time" intent, with a sentence like "what time it is in Paris?":

![](/img/tightloop/wtii-02-intent.png)

Quick remark, when creating my intent, I didn't use the built-in @sys.geo-city data type, I just created my own city kind, but I was pleasantly surprised that it recognized the city name as a potential @sys.geo-city type. Neat!\
With our intent and entity ready, we enable the "fulfillment", so that API.AI knows it should call our own business logic for replying to that query:

![](/img/tightloop/wtii-03-fullfillment.png)

And that's in the URL field that we'll be able to point at our business logic developed as a Cloud Function. But first, we'll need to implement our function.

After having created a project in the Google Cloud console (you might need to request being whitelisted, as at the time of this writing the product is still in alpha), I create a new function, that I'm simply calling 'agent'. I define the function as being triggered by an HTTP call, and with the source code inline.

For the source of my function, I'm using the "actions-on-google" NPM module, that I'm defining in the package.json file:

```json
{
  "name": "what-time-is-it",
  "version": "0.0.1",
  "private": true,
  "scripts": {
    "start": "node server.js",
    "deploy": "gcloud alpha functions deploy agent --project what-time-is-it-157614  --trigger-http --stage-bucket gs://what-time-is-it-157614/"
  },
  "description": "An agent to know the time in various cities around the world.",
  "main": "index.js",
  "repository": "",
  "author": "Guillaume Laforge",
  "dependencies": {
    "actions-on-google": "^1.0.5"
  }
}
```

And the implementation looks like the following:

```javascript
var ApiAiAssistant = require('actions-on-google').ApiAiAssistant;
const ASK_TIME_INTENT = 'ask-for-the-time';  
const CITY = 'city';
function whatTimeIsIt(assistant) {
  var city = assistant.getArgument(CITY);
  if (city === 'Paris') 
    assistant.ask("It's noon in Paris.");
  else if (city === 'London') 
    assistant.ask("It's 11 a.m. in London.");
  else 
    assistant.ask("It's way to early or way too late in " + city);
}
exports.agent = function(request, response) {
    var assistant = new ApiAiAssistant({request: request, response: response});
    var actionMap = new Map();
    actionMap.set(ASK_TIME_INTENT, whatTimeIsIt);
    assistant.handleRequest(actionMap);
};
```

Once my function is created, after 30 seconds or so, the function is actually deployed and ready to serve its first requests. I update the fulfillment details to point at the URL of my newly created cloud function. Then I can use the API.AI console to make a first call to my agent:

![](/img/tightloop/wtii-04-testing.png)

You can see that my function replied it was noon in Paris. When clicking the "SHOW JSON" button, you can also see the JSON being exchanged:

```json
{
  "id": "20ef54be-ee01-4fbe-9e6e-e73305046601",
  "timestamp": "2017-02-03T22:22:08.822Z",
  "result": {
    "source": "agent",
    "resolvedQuery": "what time is it in paris?",
    "action": "ask-for-the-time",
    "actionIncomplete": false,
    "parameters": {
      "city": "Paris"
    },
    "contexts": [
      {
        "name": "_actions_on_google_",
        "parameters": {
          "city": "Paris",
          "city.original": "Paris"
        },
        "lifespan": 100
      }
    ],
    "metadata": {
      "intentId": "b98aaae0-838a-4d55-9c8d-6adef4a4d798",
      "webhookUsed": "true",
      "webhookForSlotFillingUsed": "true",
      "intentName": "ask-for-the-time"
    },
    "fulfillment": {
      "speech": "It's noon in Paris.",
      "messages": [
        {
          "type": 0,
          "speech": "It's noon in Paris."
        }
      ],
      "data": {
        "google": {
          "expect_user_response": true,
          "is_ssml": false,
          "no_input_prompts": []
        }
      }
    },
    "score": 1
  },
  "status": {
    "code": 200,
    "errorType": "success"
  },
  "sessionId": "4ba74fa2-e462-4992-9587-2439b32aad3d"
}
```

So far so good, it worked. But as you start fleshing out your agent, you're going to continue making tests manually, then update your code and redeploy the function, several times. Although the deployment times of Cloud Function is pretty fast (30 seconds or so), as you make even simple tweaks to your function's source code, adding several times 30 seconds, you will quickly feel like you're wasting a bit of time waiting for those deployments. What if... you could run your function locally on your machine, let API.AI point at your local machine somehow through its fulfillment configuration, and make changes live to your code, and test the changes right away without needing any redeployment! We can! We are going to do so by using the Cloud Functions emulator, as well as the very nice ngrok tool which allows you to expose your local host to the internet. Let's install the Cloud Functions emulator, as shown in its documentation:

```bash
npm install -g @google-cloud/functions-emulator
```

Earlier, we entered the code of our function (index.js and package.json) directly in the Google Cloud Platform web console, but we will now retrieve them locally, to run them from our own machine. We will also need to install the actions-on-google npm module for our project to run:

```bash
npm install actions-on-google
```

Once the emulator is installed (you'll need at least Node version 6.9), you can define your project ID with something like the following (update to your actual project ID):

```bash
functions config set projectId what-time-is-it-157614
```

And then we can start the emulator, as a daemon, with:

```bash
functions start
```

We deploy the function locally with the command:

```bash
functions deploy agent --trigger-http
```

If the function deployed successfully on your machine, you should see the following:

![](/img/tightloop/witi-05-function-deployed.png)

Notice that your function is running on localhost at:

```
http://localhost:8010/what-time-is-it-157614/us-central1/agent
```

We want this function to be accessible from the web. That's where our ngrok magic bullet will help us. Once you've signed-up to the service and installed it on your machine, you can run ngrok with:

```bash
ngrok http 8010
```

The command will expose your service on the web, and allow you to have a public, accessible https endpoint:

![](/img/tightloop/wtii-06-ngrok.png)

In the API.AI interface, you must update the fulfillment webhook endpoint to point to that https URL: [https://acc0889e.ngrok.io](https://acc0889e.ngrok.io/). But you must also append the path shown when running on localhost: what-time-is-it-157614/us-central1/agent, so the full path to indicate in the fulfillment URL will be: <https://acc0889e.ngrok.io/what-time-is-it-157614/us-central1/agent>

![](/img/tightloop/wtii-07-new-fulfillment.png)

Then I use the API.AI console to send another test request, for instance what is the time in San Francisco. And it's calling my local function:

![](/img/tightloop/wtii-08-typo.png)

And in the ngrok local console, you can indeed see that it's my local function that has been called in the emulator:

![](/img/tightloop/wtii-09-ngrok.png)

Nice, it worked! We used the Cloud Functions emulator, in combination with ngrok, to route fulfillment request to our local machine. However, the astute reader might have noticed that my bot's answer contained a typo, I wrote "to early", instead of "too early". Damn! I'll need to fix that locally, in a tight feedback loop, rather than having to redeploy all the time my function. How do I go about it? I just open my IDE or text editor, fix the typo, and here you go, nothing to redeploy locally or anything, the change is already applied and live. If I make a call in the API.AI console, the typo is fixed:

![](/img/tightloop/wtii-10-typo-fixed.png)

Thanks to the [Cloud Functions emulator](https://github.com/GoogleCloudPlatform/cloud-functions-emulator) and [ngrok](https://ngrok.com/), I can develop locally on my machine, with a tight develop / test loop, without having to deploy my functions all the time. The changes are taken into account live: no need to restart the emulator, or deploy the function locally. Once I'm happy with the result, I can deploy for real. Then, I'll have to remember to change the webhook fulfillment URL to the real live cloud function.
# My favorite Cloud Next sessions


The [schedule](https://cloudnext.withgoogle.com/schedule) for Google [Cloud Next](https://cloudnext.withgoogle.com/) was unveiled this week, and there's lots of interesting sessions to attend. With the many parallel tracks, it's difficult to make a choice, but I wanted to highlight some of the talks I'd like to watch!

The Google Cloud Platform is a pretty rich one, with many options for your compute needs. How do you choose which one is best for your use case? Brian Dorsey covers this in detail in this session:

["Where should I run my code?" Deciding between Compute Engine, Container Engine, App Engine and more](https://cloudnext.withgoogle.com/schedule#target=where-should-i-run-my-code-deciding-between-compute-engine-container-engine-app-engine-and-more-91e716a3-813e-43c9-a513-27d3365a449b)

To explore a bit further some of the compute options, I'd recommend looking at Container Engine with [ABCs of Google Container Engine: tips and best practices](https://cloudnext.withgoogle.com/schedule#target=abcs-of-google-container-engine-tips-and-best-practices-03ed20df-b6c9-4e0a-911f-b33017f53477) by Piotr Szczesniak, and [Go beyond PaaS with App Engine Flexible Environment](https://cloudnext.withgoogle.com/schedule#target=go-beyond-paas-with-app-engine-flexible-environment-89abaf38-fce4-451c-b0e3-7726013300df) by Justin Beckwith.

The Serverless trend is strong these days, and in this area, I spotted two slots here with Firebase, Cloud Functions: [Live coding a serverless app with Firebase and Google Cloud Platform](https://cloudnext.withgoogle.com/schedule#target=live-coding-a-serverless-app-with-firebase-and-google-cloud-platform-d9026f62-4bfe-4087-b2d8-ffacd52222a2) by Mike McDonald, Jen Tong, Frank van Puffelen, and [Serverless computing options with Google Cloud Platform](https://cloudnext.withgoogle.com/schedule#target=serverless-computing-options-with-google-cloud-platform-1beab0c1-740e-4ee5-82f7-2fc020cdb295) by Bret McGowen.

I've blogged before about Cloud Endpoints, as I'm interested in the world of [Web APIs]({{< ref "/tags/web-apis" >}}), and there are two talks I'd like to attend in this area: [Google Cloud Endpoints: serving your API to the world](https://cloudnext.withgoogle.com/schedule#target=google-cloud-endpoints-serving-your-api-to-the-world-8eaeb271-f0ea-4638-af94-16c0b2b80bf6) by Francesc Campoy Flores and [Authorizing service-to-service calls with Google Cloud Endpoints](https://cloudnext.withgoogle.com/schedule#target=authorizing-service-to-service-calls-with-google-cloud-endpoints-24f2852c-e586-4fe9-8eb6-0e13e8585800) by Dan Ciruli, Sep Ebrahimzadeh.

And in my misc. category, I'd like to highlight this one on the APIs for G Suite: [Developing new apps built for your organization with Google Docs, Slides, Sheets and Sites APIs](https://cloudnext.withgoogle.com/schedule#target=developing-new-apps-built-for-your-organization-with-google-docs-slides-sheets-and-sites-apis-bc17ab71-ce12-4057-bcc6-7fe536f67490) by Ritcha Ranjan. A talk on big parallel data processing with [Using Apache Beam for parallel data processing](https://cloudnext.withgoogle.com/schedule#target=using-apache-beam-for-parallel-data-processing-a7a06ee0-7b93-4559-82e0-1a8dfd515771) by Frances Perry.

And to finish, I have to mention my own talk, that I'll be presenting with Brad Abrams: [Talking to your users: Build conversational actions for Google Assistant](https://cloudnext.withgoogle.com/schedule#target=talking-to-your-users-build-conversational-actions-for-google-assistant-5a780cf1-4cc2-4ce4-824d-4ff7b7c7a14c). It should be fun!

What talks are you going to attend?
# Deploy a Ratpack App on Google App Engine Flex


The purpose of this article is to deploy a [Ratpack](https://ratpack.io/) web application on [Google App Engine Flex](https://cloud.google.com/appengine/docs/flexible/).

For my demos at conferences, I often use frameworks like [Ratpack](https://ratpack.io/), [Grails](https://grails.org/) or [Gaelyk](http://gaelyk.appspot.com/), which are based on the [Apache Groovy](http://www.groovy-lang.org/) programming language. In a [previous article]({{< ref "/talks/2016/11/15/binge-streaming-web-apis-with-ratpack-cloud-ednpoints-app-engine-flex-and-streamdata-io" >}}), I already used Ratpack, but on a slightly more complex use case, but this time, I want to share a quick Ratpack hello world, and deploy it on [Flex](https://cloud.google.com/appengine/docs/flexible/).

I started with a hello world template generated by [Lazybones](https://github.com/pledbrook/lazybones) (a simple project creation tool that uses packaged project templates), that I had installed with [SDKman](http://sdkman.io/) (a tool for managing parallel versions of multiple Software Development Kits). But you can go ahead with your own Ratpack apps obviously. Feel free to skip the next section if you already have an app.

## Create a Ratpack project

```
# install SDKman
curl -s "https://get.sdkman.io" | bash
# install lazybones with sdkman
sdk install lazybones
# create your hello world Ratpack app from a template
lazybones create ratpack flex-test-1
```

You can then quickly run your app with:

```
cd flex-test-1
./gradlew run
```

And head your browser to http://localhost:5050 to see your app running.

We'll use the distTar task to create a distribution of our app, so build it with:

```bash
./gradlew distTar
```

## Get ready for Flex

To run our app on App Engine Flex, we'll need to do two things: 1) to containerize it as a Docker container, and 2) to create an app.yaml app descriptor. Let's start with Docker. Create a Dockerfile, and adapt the path names appropriately (replace "flex-test-1" by the name of the directory you created your project in):

```dockerfile
FROM gcr.io/google_appengine/openjdk8
VOLUME /tmp
ADD build/distributions/flex-test-1.tar /
ENV JAVA_OPTS='-Dratpack.port=8080 -Djava.security.egd=file:/dev/./urandom'
ENTRYPOINT ["/flex-test-1/bin/flex-test-1"]
```

I'm using Open JDK 8 for my [custom runtime](https://cloud.google.com/appengine/docs/flexible/custom-runtimes/). I add my tarred project, and specify port 8080 for running (as requested by Flex), and I define the entry point to my generated startup script.

My app.yaml file, for App Engine Flex, is pretty short, and expresses that I'm using the Flexible environment:

```yaml
runtime: custom
env: flex
threadsafe: true
```

## Create and deploy your project on Google Cloud Platform

Create an App Engine project on the [Google Cloud Platform console](https://console.cloud.google.com/appengine). And note the project name. You should also [install the gcloud SDK](https://cloud.google.com/sdk/downloads) to be able to deploy your Ratpack app from the command-line. Once done, you'll be able to go through the deployment with:

```bash
gcloud app deploy
```

After a little while, your Ratpack should be up and running!
# New Features in the Google Cloud Natural Language Api Thanks to Your Feedback


**The GA release of Cloud Natural Language API is easier to use, better at recognizing language nuances and adds additional support for Spanish and Japanese**

Earlier in November, we announced [general availability for the Cloud Natural Language API](https://cloudplatform.googleblog.com/2016/11/Cloud-Machine-Learning-family-grows-with-new-API-editions-and-pricing.html) and highlighted the [key new improvements](https://cloud.google.com/blog/big-data/2016/11/the-evolution-of-cloud-natural-language-api). This launch included many additions to the API like expanded entity recognition, granular sentiment analysis with expanded language support, improved syntax analysis with additional morphologies and more.

Many of these improvements were the result of feedback from beta users, so thank you for your contributions! But concretely, what do these updates mean? Let's take a closer look.

## Granular sentiment analysis

When analyzing the [sentiment of the White House speeches](http://glaforge.appspot.com/article/natural-language-api-and-javascript-promises-to-bind-them-all), we were interested in the flow of phrases and how sentiment evolves throughout the text. We were looking at each sentence one at a time, making an API call for every sentence! This is obviously not the most efficient way to analyze a long document.

With this new version of the Cloud Natural Language API, you still have the overall sentiment of the article but you also get individual, per-sentence sentiment with a score (ranging between -1 and +1, from negative to positive) and a magnitude. In cases where a sentence or document's score is close to zero, it's helpful to look at magnitude to distinguish between neutral or mixed text. Text with both positive and negative sentiment will have a higher magnitude, whereas text with neutral sentiment will have a magnitude closer to zero. Unlike score, magnitude is not normalized and shows the total amount of sentiment in the text.

Let's look at a few sentences from Mrs. Obama's [address](https://www.whitehouse.gov/the-press-office/2016/11/15/remarks-first-lady-national-arts-and-humanities-youth-program-awards) at the National Arts and Humanities Youth Program Awards:

### This kind of work is hard. Too often it's thankless. But you all do it because you see firsthand the transformative impact that the arts can have on our young people. And we're grateful to you all for doing this kind of work.

In addition to an overall score of 0.3 and magnitude of 1.7, we also get the sentiment for each sentence:

![/img/nlp/new-features-NL-API-16utb.max-1000x1000.png](/img/nlp/new-features-NL-API-16utb.max-1000x1000.png)

Notice how the first sentences establish a somewhat difficult context with neutral or slightly negative sentiment. The following sentences are much more positive, and with stronger magnitude. Sentiment analysis helps us understand how sentiment evolves throughout our document.

With fine-grained per-sentence, sentiment analysis, there's no need to fire multiple calls to the API --- just one per document. A large document can have widely varying sentiment, and a more detailed analysis of the tone at a granular level provides more insight into the understanding of the text.

For a deep dive on using sentiment analysis on tweets, take a look at [this blog post](https://cloud.google.com/blog/big-data/2016/09/parsing-our) about analyzing tweets during the 2016 Rio Olympics. Y Media Labs also published a [post](https://www.ymedialabs.com/google-sentiment-analysis-api/) recently about using the Cloud Natural Language API to compare the sentiment of ridesharing apps.

## Expanded entity recognition

In a sentence like "Adele is an English singer-songwriter," we naturally know that "Adele" and the "English singer-songwriter" are the one and only person. But it's not necessarily that trivial for computers. Let's see what the API tells us, when you [try it online](https://cloud.google.com/natural-language/):

![/img/nlp/new-features-NL-API-2w377.max-800x800.png](/img/nlp/new-features-NL-API-2w377.max-800x800.png)

Not only does the API point you at the Wikipedia [entry](http://en.wikipedia.org/wiki/Adele) about Adele, but it also managed to figure out that both the name and description were about the same person (i.e., entity #1 in red).

If you look at the JSON payload returned:

```json
"entities": [
    {
        "name": "Adele",
        "type": "PERSON",
        "metadata": {
            "mid": "/m/02z4b_8",
            "wikipedia_url": "http://en.wikipedia.org/wiki/Adele"
        },
        "salience": 0.86802435,
        "mentions": [
        {
            "text": {
                "content": "Adele",
                "beginOffset": 0
            },
            "type": "PROPER"
        },
        {
            "text": {
                "content": "singer-songwriter",
                "beginOffset": 20
            },
            "type": "COMMON"
            }
        ]
    }...
```


Only one entity is returned, but two mentions are given, including the offset where those two mentions appear. The first mention is a proper name, while the second one is just a common name, but still referring to Adele.

Understanding how the various elements of a sentence refer to others is a powerful capability that can now be practiced by software, not just by humans!

## Improved syntax analysis

Interested in getting into the nitty-gritty linguistic details of a piece of text? The Cloud Natural Language API's syntax-analysis response now includes much more syntactic data for each word. Let's take this sentence as an example:

![/img/nlp/new-features-nl-api-5vanr.max-1100x1100.png](/img/nlp/new-features-nl-api-5vanr.max-1100x1100.png)

In addition to getting the dependency (the arrows in the image above) and part of speech tag for each word, the API returns all sorts of other linguistic info.

Here's the JSON response we get for the word "We" in the above sentence:

```json
{
    "text": {
       "content": "We",
        "beginOffset": 0
    },
    "partOfSpeech": {
        "tag": "PRON",
        "case": "NOMINATIVE",
        "number": "PLURAL",
        "person": "FIRST",
    ...
    },
    "dependencyEdge": {
        "headTokenIndex": 2,
        "label": "NSUBJ"
    },
    "lemma": "We"
}
```

Let's dive deeper into the new values. The token JSON response tells us whether the word is plural or not, indicated by the `number` value. `person` tells us that this word is written in the first person. `case` is a bit more complex, and reveals the function performed by nouns or pronouns in a sentence. "We" is nominative because it's the subject of the verb "are." If the subjects and verbs in the sentence were reversed ("They taught us"), "us" would return a value of `ACCUSATIVE` for case.

The word "are" in the sentence above returns two more new values:

```json
{
    "mood": "INDICATIVE",
    "tense": "PRESENT"
}
```

`mood`, not to be confused with sentiment, refers to the *modality* of the word or the way in which something is done. The indicative modality in this example shows that this is a statement of fact. Imperative modality, in contrast, describes direct commands. In the sentence "Go learn the Natural Language API," the word "Go" is imperative. This `mood` value is useful if you're building a bot or automated tool, where you need to understand if something is a statement or command.

The word "linguistics" in our example also returns a number value of `SINGULAR`. Even though "linguistics" could be misinterpreted as a plural form of the word linguistic since it ends in "s," the API is able to pick up contextual clues that "linguistics" here refers to the singular field of linguistics. Finally, the API is able to identify "Natural Language API" as a proper noun.

## Improved support for Spanish and Japanese

The updated API now supports sentiment and additional morphology analysis for Spanish and Japanese. Let's see a couple examples in these languages!

In his poem "Canción otoñal" from *Libro de Poemas*, the Spanish poet Federico García Lorca writes: *La luz me troncha las alas y el dolor de mi tristeza* (which translates to "The light shatters my wings and the pain of my sadness.") If you look at the verb "troncha" (to shatter), the API gives some interesting details:

```json
"partOfSpeech": {
    "tag":    "VERB",
    "aspect": "IMPERFECTIVE",
    "mood":   "INDICATIVE",
    "number": "SINGULAR",
    "person": "THIRD",
    "proper": "NOT_PROPER",
    "tense":  "PRESENT",
    "voice":  "ACTIVE",
 ...
}
```

The verb has an "imperfective" aspect, an "indicative" mood, is "singular," at the "third person" and uses an "active" voice at the "present" tense. The API knows the Spanish grammar perhaps better than you can remember it!

The Cloud Natural Language API is just as happy to analyze your Japanese content. Let's look at this sentence, which means "We are learning more about language through the NL API." What does its structure looks like?

![/img/nlp/new-features-NL-API-34u8u.max-800x800.png](/img/nlp/new-features-NL-API-34u8u.max-800x800.png)

## Try it in the browser!

The new Cloud Natural Language API features provide:

-   Granular sentiment analysis: you get sentiment data for each sentence in your document so you don't need an API call for each sentence. This makes your code more streamlined without requiring costly round-trips to our servers.
-   Additional morphology details: the subtleties of the language are clearly depicted with more detailed parts of speech tags for each token.
-   Improved entity recognition: the API now recognizes multiple mentions of the same entity.
-   Multi-language support: the API added sentiment analysis for Spanish and Japanese along with new morphology details for both languages.

Head over to the Google Cloud [Natural Language API page](https://cloud.google.com/natural-language/#nl_demo_section) and try these enhancements to the API for yourself in your browser. You'll be able to look-up entities, discover the sentiment of the text and understand the fine-grained details of the structure of the text with hierarchical graphics. You'll notice in the syntax visualization that some words are blue; hover over these words for more morphology details.

## Next steps

Want to start using the Cloud Natural Language API in your own apps? Try these next steps:

-   Follow the [quickstart guide](https://cloud.google.com/natural-language/docs/getting-started)
-   Let us know what you think in the comments
-   Use the [google-cloud-nl](http://stackoverflow.com/questions/tagged/google-cloud-nl) tag on Stack Overflow
-   Learn more about [other Cloud APIs for machine learning](https://cloud.google.com/products/machine-learning/)
-   Get trained on Cloud ML at a Next '17 [technical bootcamp](https://cloudnext.withgoogle.com/bootcamps/cloud-ml) on March 6-7 in San Francisco

We're excited to see what you build!
# A poor-man assistant with speech recognition and natural language processing


All sorts of voice-powered assistants are available today, and chat bots are the new black! In order to illustrate how such tools are made, I decided to create my own little basic conference assistant, using Google's [Cloud Speech API](https://cloud.google.com/speech/) and [Cloud Natural Language API](https://cloud.google.com/natural-language/). This is a demo I actually created for the Devoxx 2016 keynote, when Stephan Janssen invited me on stage to speak about Machine Learning. And to make this demo more fun, I implemented it with a shell script, some curl calls, plus some other handy command-line tools.

So what is this "conference assistant" all about? Thanks for asking. The idea is to ask questions to this assistant about topics you'd like to see during the conference. For example: "Is there a talk about the Google Cloud Vision API?". You send that voice request to the Speech API, which gives you back the transcript of the question. You can then use the Natural Language API to process that text to extract the relevant topic in that question. Then you query the conference schedule to see if there's a talk matching the topic.

Let's see this [demo into action](https://asciinema.org/a/95040), before diving into the details.

So how did I create this little command-line conference assistant? Let's start with a quick diagram showing the whole process and its steps:

![](/img/misc/assistant-diagram.png)

-   First, I record the audio using the [sox](http://sox.sourceforge.net/) command-line tool.
-   The audio file is saved locally, and I upload it to Google Cloud Storage (GCS).
-   I then call the Speech API, pointing it at my recorded audio file in GCS, so that it returns the text it recognized from the audio.
-   I use the [jq](https://stedolan.github.io/jq/) command line tool to extract the words from the returned JSON payload, and only the words I'm interested in (basically what appears after the "about" part of my query, ie. "a talk *about* machine learning")
-   Lastly, I'm calling a [custom search engine](https://cse.google.com/) that points at the conference website schedule, to find the relevant talks that match my search query.

Let's have a look at the script in more details (this is the simplified script without all the shiny terminal colors and logging output). You should create a project in the Google Cloud Console, and note its project ID, as we'll reuse it for storing our audio file.

```bash
#!/bin/bash

# create an API key to access the Speech and NL APIs
# https://support.google.com/cloud/answer/6158862?hl=en
export API_KEY=YOUR API KEY HERE

# create a Google Custom Search and retrieve its id
export CS_ID=THE ID OF YOUR GOOGLE CUSTOM SEARCH

# to use sox for recording audio, you can install it with:
# brew install sox --with-lame --with-flac --with-libvorbis
sox  -d -r 16k -c 1 query.flac
# once the recording is over, hit CTRL-C to stop

# upload the audio file to Google Cloud Storage with the gsutil command
# see the documentation for installing it, as well as the gcloud CLI
# https://cloud.google.com/storage/docs/gsutil_install
# https://cloud.google.com/sdk/docs/
gsutil copy -a public-read query.flac gs://devoxx-ml-demo.appspot.com/query.flac

# call the Speech API with the template request saved in speech-request.json:
# {
#  "config": {
#      "encoding":"FLAC",
#      "sample_rate": 16000,
#      "language_code": "en-US"
#  },
#  "audio": {
#      "uri":"gs://YOUR-PROJECT-ID-HERE.appspot.com/query.flac"
#  }
#}
curl -s -X POST -H "Content-Type: application/json" --data-binary @speech-request.json "https://speech.googleapis.com/v1beta1/speech:syncrecognize?key=${API_KEY}" > speech-output.json

# retrieve the text recognized by the Speech API
# using the jq to just extract the text part
cat speech-output.json | jq -r .results[0].alternatives[0].transcript > text.txt

# prepare a query for the Natural Language API
# replacing the @TEXT@ place holder with the text we got from Speech API;
# the JSON query template looks like this:
# {
#  "document": {
#    "type": "PLAIN_TEXT",
#    "content": "@TEXT@"
#  },
#  "features": {
#    "extractSyntax": true,
#    "extractEntities": false,
#    "extractDocumentSentiment": false
#  }
#}
sed "s/@TEXT@/`cat text.txt`/g" nl-request-template.json > nl-request.json

# call the Natural Language API with our template
curl -s -X POST -H "Content-Type: application/json" --data-binary @nl-request.json https://language.googleapis.com/v1beta1/documents:annotateText?key=${API_KEY} > nl-output.json

# retrieve all the analyzed words from the NL call results
cat nl-output.json | jq -r .tokens[].lemma  > lemmas.txt
# only keep the words after the "about" word which refer to the topic searched for
sed -n '/about/,$p' lemmas.txt | tail -n +2 > keywords.txt
# join the words together to pass them to the search engine
cat keywords.txt | tr '\n' '+' > encoded-keywords.txt

# call the Google Custom Search engine, with the topic search query
# and use jq again to filter only the title of the first search result
# (the page covering the talk usually comes first)
curl -s "https://www.googleapis.com/customsearch/v1?key=$API_KEY&cx=$CS_ID&q=`cat encoded-keywords.txt`" | jq .items[0].title
```

And voila, we have our conference assistant on the command-line! We combined the [Speech API](https://cloud.google.com/speech/) to recognize the voice and extract the text corresponding to the query audio, we analyze this text with the [Natural Language API](https://cloud.google.com/nl), and we use a few handy command-line tools to do the glue.


# Machine intelligence at Google scale, vision / speech APIs, Tensorflow, and Cloud Machine Learning


With my colleague [Martin Görner](https://twitter.com/martin_gorner), at the [Devoxx](http://cfp.devoxx.be/2016/talk/HFW-0944/Machine_Intelligence_at_Google_Scale:_Vision%2FSpeech_API,_TensorFlow_and_Cloud_Machine_Learning) conference in Belgium last month, we gave a talk on Machine Learning, on the various APIs provided by Google Cloud, the TensorFlow Machine Learning Open Source project, the Cloud ML service. I didn't get a chance to publish the slides, so it's time I fix that!

Machine Intelligence at Google Scale: Vision/Speech API, TensorFlow and Cloud Machine Learning

The biggest challenge of Deep Learning technology is the scalability. As long as using single GPU server, you have to wait for hours or days to get the result of your work. This doesn't scale for production service, so you need a Distributed Training on the cloud eventually. Google has been building infrastructure for training the large scale neural network on the cloud for years, and now started to share the technology with external developers. In this session, we will introduce new pre-trained ML services such as Cloud Vision API and Speech API that works without any training. Also, we will look how TensorFlow and Cloud Machine Learning will accelerate custom model training for 10x - 40x with Google's distributed training infrastructure.

The video is available on YouTube (in particular, don't miss the cool demos!):

{{< youtube zqWt8oI4gEw >}}

And you can look at the slides here:

{{< speakerdeck b0bf5d296e4941ca89fc78c2efb37561 >}}
# Analyzing half a million Gradle build files


Gradle is becoming the build automation solution of choice among developers, in particular in the Java ecosystem. With the Github archive published as a Google BigQuery dataset, it's possible to analyze those build files, and see if we can learn something interesting about them!

This week, I was at the G3 Summit conference, and [presented]({{< ref "/talks/2018/03/23/what-do-we-learn-from-millions-of-source-files-in-github" >}}) about this topic: I covered the Apache Groovy language, as per my previous [article]({{< ref "/posts/2016/07/06/what-can-we-learn-from-million-lines-of-groovy-code-on-github" >}}), but I expanded my queries to also look at [Grails](https://grails.org/) applications, and [Gradle](https://gradle.org/) build files. So let's see what the dataset tells us about Gradle!

## Number of Gradle build files and repositories

Instead of going through the whole Github dataset, I'm going to restrict the dataset by saving only the Gradle build files in my own, smaller, dataset:

```sql
SELECT * FROM [bigquery-public-data:github_repos.files] 
WHERE RIGHT(path, 7) = '.gradle'
```

This query returns only the files whose extension is .gradle. I'm saving the results in my [github.gradle_build_files] table.

But I also need the content of those files:

```sql
SELECT *
FROM [bigquery-public-data:github_repos.contents]
WHERE id IN (SELECT id FROM [github.gradle_build_files])
```

And I will save the content in the table [github.gradle_build_contents].

Let's start with a simple query to count the Gradle build files on Github:

```sql
SELECT COUNT(*) as count
FROM [github-groovy-files:github.gradle_build_files]
```

There are 488,311 Gradle build files! Roughly half a million.

This is the number of Gradle files: note that a project can contain several build files, that a repository can contain several projects, but also that the Github dataset only provides data on repositories for which it could detect an Open Source license. So it gives an idea of the reach of Gradle, but doesn't necessarily give you the exact number of Gradle-based projects in the wild! (and obviously can't even account for the projects hosted internally and elsewhere)

Since a repository can contain several build files, let's have a look at the number of repositories containing Gradle build files:

```sql
SELECT COUNT(repo_name) as repos
FROM (
  SELECT repo_name
  FROM [github-groovy-files:github.gradle_build_files]
  GROUP BY repo_name
)
```

There are 102,803 repositories with Gradle build files.

I was curious to see the distribution of the number of build files across projects. So I used the quantiles function:

```sql
SELECT QUANTILES(buildFilesCount, 101) 
FROM (
  SELECT repo_name, COUNT(repo_name) as buildFilesCount
  FROM [github-groovy-files:github.gradle_build_files]
  GROUP BY repo_name
  ORDER BY buildFilesCount DESC
)
```

I used a small increment (one percent), as the data was skewed towards some repositories with a huge amount of Gradle build files: essentially repositories like the Udemy course on Gradle for Android, or an online book about Android development, as they had tons of small build files or variations of build files with incremental changes for explanation purpose.

* 22% of the repositories had only 1 build file
* 85% of the repositories had up to 5 build files
* 95% of the repositories had less than 10 build files

The repository with the biggest amount of build files had 1333 of them!

## Gradle vs Maven

You might also be interested in comparing Gradle and Maven, as they are often put against each other in holy build wars. If you look at the number of pom.xml files on Github:

```sql
SELECT count(*) 
FROM [bigquery-public-data:github_repos.files]
WHERE path LIKE '%pom.xml'
```

There are about 1,007,705 pom.xml files vs the 488,311 we counted for Gradle. So roughly twice as many for Maven.

But if you look at the number of repositories with Maven build files:

```sql
SELECT COUNT(repo_name) as repos
FROM (
  SELECT repo_name
  FROM [bigquery-public-data:github_repos.files]
  WHERE path LIKE '%pom.xml'
  GROUP BY repo_name
)
```

There are 131,037 repositories with Maven pom.xml files, compared to the 102,803 repositories with Gradle build files we counted earlier (about only 27% more). It seems Gradle is catching up with Maven!

## Gradle build file names

Bigger projects tend to split their build tasks under different build files. I was curious to see which kind of split developers did by looking at the most frequent build file names:

```sql
SELECT f, COUNT(f) as count
FROM (
  SELECT LAST(SPLIT(path, '/')) AS f
  FROM [github-groovy-files:github.gradle_build_files]
)
GROUP BY f
ORDER BY count DESC
```

![](/img/bigquery-gradle/gh22-1.png)
![](/img/bigquery-gradle/gh22-2.png)

Of course, build.gradle comes first. Followed by settings.gradle. Notice the number of build files which are related to making releases, publishing / deploying the artifacts to a repository. There are also a few checking the quality of the code base, using checkstyle for style violations, JaCoCo for code coverage.

## Gradle versions

Gradle projects often use the Gradle wrapper to help developers use a particular and consistent version of Gradle, without necessiting Gradle to be installed locally. For those developers who decided to commit their Gradle wrapper in Github, we can have a look at the breakdown of Gradle versions currently in the wild:

```sql
SELECT version, COUNT(version) AS count
FROM (
  SELECT REGEXP_EXTRACT(line, r'gradle-(.*)-(?:all|bin).zip') AS version
  FROM (
    SELECT SPLIT(content, '\n') AS line
    FROM [github-groovy-files:github.gradle_wrapper_properties_files]
  )
  WHERE line LIKE 'distributionUrl%'
)
GROUP BY version
ORDER BY count DESC
```

![](/img/bigquery-gradle/gh20a-1.png)
![](/img/bigquery-gradle/gh20a-2.png)

It looks like Gradle 2.4 was a big hit!

## Gradle plugins

Gradle projects often take advantage of third-party plugins. You'll see plugins declared with the "id" syntax or applied with "apply plugin". Let's looked at both:

```sql
SELECT plugin, COUNT(plugin) AS count
FROM (
  SELECT REGEXP_EXTRACT(line, r'apply plugin: (?:\'|\")(.*)(?:\'|\")') AS plugin
  FROM (
    SELECT SPLIT(content, '\n') AS line
    FROM [github-groovy-files:github.gradle_build_contents]
  )
)
GROUP BY plugin
ORDER BY count DESC
```

![](/img/bigquery-gradle/gh23-1.png)
![](/img/bigquery-gradle/gh23-2.png)

Look at the big number of Android related plugins! Clearly, Android adopting Gradle as build solution gave a big boost to Gradle's adoption!

The plugins declared with "id" show another story though:

```sql
SELECT newplugin, COUNT(newplugin) AS count
FROM (
  SELECT REGEXP_EXTRACT(line, r'id (?:\'|\")(.*)(?:\'|\") version') AS newplugin
  FROM (
    SELECT SPLIT(content, '\n') AS line
    FROM [github-groovy-files:github.gradle_build_contents]
  )
)
GROUP BY newplugin
ORDER BY count DESC
```

![](/img/bigquery-gradle/gh24-1.png)
![](/img/bigquery-gradle/gh24-2.png)

Here, we see a big usage of the Bintray plugin and the shadow plugin.

## Build dependencies

Now it's time to look at dependencies. First, the "compile" dependencies:

```sql
SELECT dep, COUNT(dep) AS count
FROM (
  SELECT REGEXP_EXTRACT(line, r'compile(?: |\()(?:\'|\")(.*):') AS dep
  FROM (
    SELECT SPLIT(content, '\n') AS line
    FROM [github-groovy-files:github.gradle_build_contents]
  )
)
GROUP BY dep
ORDER BY count DESC
```

![](/img/bigquery-gradle/gh25-1.png)
![](/img/bigquery-gradle/gh25-2.png)

Again, there's a big usage of Android related dependencies. We also notice Spring Boot, GSON, Guava, SLF4J, Retrofit, Jackson.

For the test dependencies:

```sql
SELECT dep, COUNT(dep) AS count
FROM (
  SELECT REGEXP_EXTRACT(line, r'testCompile(?: |\()(?:\'|\")(.*):') AS dep
  FROM (
    SELECT SPLIT(content, '\n') AS line
    FROM [github-groovy-files:github.gradle_build_contents]
  )
)
GROUP BY dep
ORDER BY count DESC
```

![](/img/bigquery-gradle/gh26-1.png)
![](/img/bigquery-gradle/gh26-2.png)

No big surprise with JUnit coming first. But we have Spock, Mockito's mocking library, AssertJ assertions, Hamcrest matchers.

## Summary

And this wraps up our analysis of Gradle build files, thanks to [Google BigQuery](https://cloud.google.com/bigquery/) and the Github dataset. It's interesting to see that Gradle has gained a very significant market share, coming pretty close to the Maven incumbent, and to see lots of Android projects are on Github with Gradle builds.
# My G3 Summit Apache Groovy Keynote


This week, I'm in Florida for the brand new [G3 Summit](https://g3summit.com/conference/fort_lauderdale/2016/11/home) conference, dedicated to the Apache Groovy ecosystem (Grails, Gradle, and more). I had the chance of giving the keynote, where I gave an overview of the Apache Groovy project's philosophy, history, and where it's heading. In the second part, I'm showcasing the new features, new syntax constructs, already there or coming in Groovy 2.4.x, in the future Groovy 2.5, and in Groovy 3.0 with the new parser.

{{< speakerdeck ceb97d1f87cc4e2b810914178bb692a9 >}}

# Billions of lines of code in a single repository, seriously?


When I joined Google last June, I discovered a new world: tons of new acronyms or project code names to learn about, but also a particular environment for your source code. At Google, engineers work on a huge monolithic source code repository comprising of: 

-   1 billion files
-   9 million source files
-   2 billion lines of code
-   35 million commits
-   86 terabytes of content
-   45 thousands of commits every day.

Rachel Potvin, who's an engineering manager at Google, wrote [an article for ACM](http://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext) about how Google handles such a huge repository, as well as the tools and practices around that. Wired also covered the topic in their article "[Google is 2 billion lines of code and it's all in one place](https://www.wired.com/2015/09/google-2-billion-lines-codeand-one-place)". And Rachel also [presented this topic at the @Scale conference](https://www.youtube.com/watch?v=W71BTkUbdqE).

> Google stores all its source code in one single monolithic repository! Imagine 25,000 software developers working simultaneously on 86 TB of data, including two billion lines of code in 9 million unique source files. Each week, there are as many lines of code changed as there are lines in the full Linux kernel repository. How does Google’s source code works at this scale? What are the advantages and drawbacks of such an approach? Come and learn about what it means to work on such a big mammoth repository.

You can find the slide deck embedded below:

{{< speakerdeck d3714d006f694a9f915b8637bb192eea >}}

And the talk was also recorded, so you can view the video on Devoxx's YouTube channel here:

{{< youtube yM0GQw1zgrA >}}
# Becoming Twitter verified


Probably for vanity sake, or perhaps even out of jealousy seeing friends becoming "[twitter verified](https://support.twitter.com/articles/119135)", I was curious to see if, me too, I could get those little ticks beside my name on my [Twitter profile](https://twitter.com/glaforge).

Generally speaking, verified accounts are accounts of "public interest". It can range from your usual movie stars, to politicians, from well-known artists, to company CEOs, but also persons somehow well known in the twittosphere, including tech luminaries, representative of particular tech communities, etc. So, seeing my tech friends getting the little tick, I thought I should try that out.

And on my first try... I failed...

I didn't completely failed, as I didn't get the usual message saying I failed verification, but that some tweaks could be made to my profile to add some more information. They asked whether the account name reflected the real person's name (in my case 'glaforge' maps well to my name!), and if my government issued photo ID was legible or not (and it was the case too). So I was puzzled, and didn't really get actionable items to pursue.

For my first attempt, I initially scanned my national ID card, but I guess it's not a very well known format, so on my second try, I instead scanned my passport. Even if I'm not feeling safe sending a scan of my ID... but that's for another story.

I didn't change anything, but two months later, I tried again, and this time it worked!

![](/img/misc/glaforge-twitter-verified.png)

After bragging about being verified on Twitter, I got several DM conversations asking for advice. So I'll just repeat some of the advice given by Twitter themselves, and add my own into the loop.

First, be sure to read the following articles from Twitter:

-   [about verified accounts](https://support.twitter.com/articles/119135)
-   [verified accounts](https://support.twitter.com/articles/20174630)
-   [request to verify an account](https://support.twitter.com/articles/20174631)

The last one is the most important of the three.

You should really have:

-   a **verified phone number**: It'll be checked with a text message and a code, pretty easy step.
-   a **confirmed email address**: Same principle, be sure to use a real email address, and a similar verification step takes place.
-   a **bio**: I think the bio is pretty important. It describes the "public" person that you are. So if you're a singer, mention that you're a singer and give a link that proves that you are one, for example the website of your band. During the verification, you'll be asked for up to 5 links confirming who you are, so don't hesitate to reuse one of those links in your bio, or related twitter account, etc.
-   a **header photo**: I don't think the content of the header photo really matters, but verified accounts need to have a header picture. Even if it's just a nice landscape, it should be there, instead of just the colored background.
-   a **birthday**: I'm not sure how important this really is. But if you indicate your birthday, it better be the same date as the one provided on your ID scan obviously!
-   a **website**: For the website, I used the URL of my blog. And this is also one of the URLs I've given in the form to request verification. This URL should point at a place that can prove who you are: on my blog, there's a section about me, describing what I'm doing in life.
-   **public tweets**: your tweets should be publicly visible, otherwise, no point in requesting being verified!

The documentation says it's better if the account name reflects the real name of the person. So it might help. But if you're known with a particular Twitter handle, I don't think you really need to change it for the sake of becoming verified. But it might be harder with a strange Twitter handle than a handle that resembles your name.

When you fill the form for requesting verification, you will be asked for up to five links. In my case, I gave the URL of my blog (which, as I said, has a section explaining who I am, shows my real name, and also a picture of myself, so they can check the Twitter avatar, the photo ID as well). I also gave my LinkedIn profile, my Google+ profile. And I think that's all. Anything that proves you're who you claim to be can be useful.

Last but not least, there's a form field where you have to justify why you request becoming verified. In my case, I wanted cover the two "aspects" of my life: at day, I'm a Developer Advocate for Google, and at night, I'm working on the Apache Groovy open source project. For reference, here's the blurb that I used:

> Leading the Apache Groovy project, I'm a spokesperson for the successful open source project, and for the ecosystem & community around it. In my day life, I'm also a Developer Advocate, at Google, on their Cloud Platform. Having my Twitter account verified would be an additional stamp of approval for my involvement in the Groovy community and with the company's product I advocate for.

After my first attempt two months ago, I tried again over the weekend, and the next day, I got the email confirming my account was verified! Yay!

I hope this article is helpful. Don't hesitate to share your own tricks in the comments. At least, following the advice above, I was able to get verified. I have about 11K followers, but I've seen people with less than half as many followers also become verified. So the number of followers is not everything. But I think paying attention to the quality of your profile is what ultimately pays off. So good luck with your verification process! And don't hesitate to share your own tips in the comments below.
# Binge streaming web APIs with Ratpack, Cloud Ednpoints, App Engine Flex and Streamdata.io


At [Devoxx](https://devoxx.be/) last week, I had the chance to do a joint tools-in-action with my talented friend Audrey Neveu, titled Binge streaming you Web API:

> In a fast-paced fashion, to keep you awake after long University sessions, Audrey and Guillaume will set you up to create a Web API using Google Cloud Endpoints, and stream the content of the API in real-time with Streamdata.io. After a quick introduction to both technologies, they’ll build together both the backend and the front-end to interact live with the audience, through the Web or via a mobile app.

For the impatient, scroll down to the end of the article to access the slides presented, and view a recording of the video!

We split the presentation in two sections: 1) first of all, we obviously need to create and deploy a Web API, and then 2) to configure and use [Streamdata.io](http://streamdata.io/) to stream the updates live, rather than poll the API endlessly.

For the purpose of our demo, Audrey and myself decided to surf on the theme of the conference, by publishing ourselves an API of the conference content, listing all the talks and speakers available.

As the content is pretty much static, we needed some data that would evolve in real-time as well. We added a voting capability, so that users could click on a little smiley to say if they're enjoying the talk or not. With the streaming capability, as soon as votes are taking place, we update the UI with the new vote results.

## Implementing my API with Ratpack

To build the API, I decided to go with the [Ratpack framework](https://ratpack.io/). As the Ratpack website states:

Ratpack is a set of Java libraries for building modern HTTP applications.

It provides just enough for writing practical, high performance, apps.

It is built on Java 8, Netty and reactive principles.

You can use Ratpack with Java 8, but there's also a nice Groovy wrapper. So with my [Apache Groovy](http://www.groovy-lang.org/) hat on, I naturally chose to go with Groovy!

In the Groovy community, there's a tool called [Lazybones](https://github.com/pledbrook/lazybones) which allows you to create template projects easily. And we're also using [SDKman](http://sdkman.io/) for installing various SDKs, including SDKman.

If you don't have lazybones installed (but have SDKman), it's fairly easy to install:

```bash
sdk install lazybones
```

With both installed already on my machine, I just needed to create a new project with the Ratpack template:

```bash
lazybones create ratpack
```

And I had my template project ready!

Gradle to the rescue to build the app

My Gradle script is pretty straightforward, using the Ratpack Groovy plugin, the Shadow plugin, etc. Nothing really fancy:

```groovy
buildscript {
    repositories {
        jcenter()
    }
    dependencies {
        classpath "io.ratpack:ratpack-gradle:1.4.4"
        classpath "com.github.jengelman.gradle.plugins:shadow:1.2.3"
    }
}

apply plugin: "io.ratpack.ratpack-groovy"
apply plugin: "com.github.johnrengelman.shadow"
apply plugin: "idea"
apply plugin: "eclipse"

repositories {
    jcenter()
}

dependencies {
    runtime 'org.slf4j:slf4j-simple:1.7.21'
    testCompile "org.spockframework:spock-core:1.0-groovy-2.4"
}
```

To build this app, I'll use the tar distribution target, which generates startup scripts to be launched from the command-line:

```bash
./gradlew distTar
```

To run the app locally, you can use:

```bash
./gradlew run
```

By default, it runs on port 5050.

The URL paths and methods

For developing my API, I created the following paths and methods:

-   GET /api : to list all the talks available
-   GET /api/{day} : to restrict the list of talks to just one particular day
-   GET /api/talk/{id} : to view the details of a particular talk
-   POST /api/talk/{id}/vote/{vote} : to vote on a particular talk (negative, neutral, positive)
-   POST /import : to import a JSON dump of all the talks, but it's just used by me for uploading the initial content, so it's not really part of my API.

## Implementing the API

My [Ratpack](https://ratpack.io/) app implementing this API (plus a few other URLs) spans a hundred lines of Groovy code or so (including blank lines, imports, and curly braces). The implementation is a bit naive as I'm storing the talks / speakers data in memory, but I should have used a backend storage like [Cloud Datastore](https://cloud.google.com/datastore/) or [Cloud SQL](https://cloud.google.com/sql/), potentially with Memcache in front. So the app won't scale well and data will not be synchronized across multiple instances running in parallel. For the sake of my demo though, that was sufficient!

```groovy
import ratpack.handling.RequestLogger
import org.slf4j.LoggerFactory
import static ratpack.groovy.Groovy.ratpack
import static ratpack.jackson.Jackson.json as toJson
import static ratpack.jackson.Jackson.fromJson
def log = LoggerFactory.getLogger('Devoxx')
def allTalks = []
ratpack {
    handlers {
        all(RequestLogger.ncsa())
        post('import') {
            log.info "Importing talks dump"
            byContent {
                json {
                    parse(fromJson(List)).onError { e ->
                        String msg = "Import failed: $e"
                        log.error msg
                        response.status(400)
                        render toJson([status: "Import failed: $e"])
                    }.then { talks ->
                        allTalks = talks
                        log.info "Loaded ${allTalks.size()} talks"
                        render toJson([status: 'Import successful'])
                    }
                }
            }
        }
        prefix('api') {
            prefix('talk') {
                post(':id/vote/:vote') {
                    def aTalk = allTalks.find { it.id == pathTokens.id }
                    if (aTalk) {
                        def msg = "Voted $pathTokens.vote on talk $pathTokens.id".toString()
                        switch (pathTokens.vote) {
                            case "negative":
                                aTalk.reactions.negative += 1
                                log.info msg
                                render toJson([status: msg])
                                break
                            case "neutral":
                                aTalk.reactions.neutral += 1
                                log.info msg
                                render toJson([status: msg])
                                break
                            case "positive":
                                aTalk.reactions.positive += 1
                                log.info msg
                                render toJson([status: msg])
                                break
                            default:
                                response.status(400)
                                msg = "'${pathTokens.vote}' is not a valid vote".toString()
                                log.info msg
                                render toJson([status: msg])
                        }
                    } else {
                        response.status(404)
                        render toJson([status: "Talk $pathTokens.id not found".toString()])
                    }
                }
                get(':id') {
                    def aTalk = allTalks.find { it.id == pathTokens.id }
                    if (aTalk) {
                        log.info "Found talk: $pathTokens.id"
                        render toJson(aTalk)
                    } else {
                        String msg = "Talk $pathTokens.id not found"
                        log.info msg
                        response.status(404)
                        render toJson([status: msg])
                    }
                }
            }
            get(':day') {
                def talksPerDay = allTalks.findAll { it.day == pathTokens.day }.collect {
                    it.subMap(it.keySet() - 'summary')
                }
                if (talksPerDay) {
                    render toJson(talksPerDay)
                } else {
                    response.status(404)
                    render toJson([status: "Invalid day, or no talks found for: $pathTokens.day".toString()])
                }
            }
            get {
                render toJson(request.queryParams.full ? allTalks : allTalks.collect {
                    it.subMap(it.keySet() - 'summary')
                })
            }
        }
    }
}
```

Some interesting points about this code:

-   use of an NCSA-compliant request logger to log all API calls (following the NCSA usual output pattern) and a dedicated logger for important events, and you're able to watch both those kind of logs in the Stackdriver logging in the cloud console
-   the use of prefix('...') to factor common path parts
-   Jackson is being used both for parsing (the input file containing the initial list of talks) as well as for output for rendering the JSON payloads
-   see how we use byContent / json to handle the requests coming up with content-type of application/json
-   the rest is essentially error handling, collection filtering, etc.

## Containerizing the app

Ratpack requires JDK 8 to run, and it's not based on servlets, I went with [Google App Engine Flex](https://cloud.google.com/appengine/docs/flexible/), which allows me to run JDK 8 / Java 8 apps which can be based on networking toolkits like [Netty](http://netty.io/).

I mentioned we're using the distTar target to build a distribution of the application, and that's what we'll point our Dockerfile at, as App Engine Flex allows you to customize Docker images for bundling and running your app:

```dockerfile
FROM gcr.io/google_appengine/openjdk8
VOLUME /tmp
RUN mkdir -p /app/endpoints
ADD service.json /app/endpoints
ADD build/distributions/devoxx-reactions.tar /
ENV JAVA_OPTS='-Dratpack.port=8080 -Djava.security.egd=file:/dev/./urandom'
ENTRYPOINT ["/devoxx-reactions/bin/devoxx-reactions"]
```

I'm using the dedicated Open JDK 8 image for App Engine, from the [Google Container Registry](https://cloud.google.com/container-registry/). I'm specifying the port for my app, the entry point to the startup scripts. You'll notice the lines about "endpoints" and "service.json", and I'll come to it in a minute: it's because I'm using [Google Cloud Endpoints](https://cloud.google.com/endpoints/) to expose and manage my API!

At this point, to feel safer, you can double check that your app is running under docker with something like:

```bash
./gradlew distTar
docker build -t devoxx-reactions-image .
docker run -p 127.0.0.1:8080:8080 -it devoxx-reactions-image
```

The app is running on port 8080 of your localhost. We'll see later on how to test it with curl, and how to load the sample data that we've prepared in public/data/talks.json.

## GCloud, to set up our projects

As we're going to use Cloud Endpoints on App Engine Flex, it's time that I start setting things up with the gcloud SDK:

```bash
gcloud init
gcloud components update
gcloud components install beta
gcloud config set project [YOUR_PROJECT_ID]
```

## About Google Cloud Endpoints

Google Cloud Platform offers a particular service for managing Web APIs called [Endpoints](https://cloud.google.com/endpoints/). With Endpoints, you're able to monitor your API (see what endpoints, methods, are called, with some nice graphs and stats), to secure your API (with different kind of authentication like Firebase authentication, JSON Web Tokens, API keys, etc.), to scale it.

Speaking of scaling, I'm using App Engine Flex here as my deployment target, but it's possible to use Compute Engine or Container Engine as well. Interestingly, you can use Endpoints API management with an API hosted in a third-party cloud, as well as on premises too!

The management aspect of the API is done thanks to a proxy, called the Endpoints Service Proxy, which is implemented on top of NGINX (and which will be open sourced). And to continue on scaling aspect of the story, it's interesting to note that this proxy is living along your app (in its own container). If your API needs to scale across several machines, instead of one giant middle proxy somewhere, your ESP will be duplicated the same way. So there's no single point of failure with a gigantic proxy, but it also means that the latency is super low (below 1 ms usually), because the proxy is as close as possible to your API, without needing any additional costly network hop.

The last interesting aspect about Cloud Endpoints that I'd like to mention is that your API contract is defined using [OpenAPI Specs](https://openapis.org/) (formerly known as Swagger). So it doesn't matter which language, framework, tech stack you're using to implement your API: as long as you're able to describe your API with an OpenAPI Specification, you're good to go!

## Specifying the contract of our API with OpenAPI Spec

I mentioned before the various resources and methods we're using for our API, and we'll encode these in the form of a contract, using the OpenAPI Spec definition format. In addition to the various resources and methods, we should also define the payloads that will be exchanged: basically, a Talk, a Result, a list of talks. We must define the different status codes for each kind of response. Here's what my specification looks like:

```yaml
---
swagger: "2.0"
info:
  description: "Consult the Devoxx schedule and vote on your favorite talks."
  version: "1.0.0"
  title: "Devoxx Reactions"
  contact: {}
host: "devoxx-reactions.appspot.com"
schemes:
- "http"
paths:
  /import:
    post:
      summary: "Import a dump of the lists of talks"
      operationId: "ImportTalks"
      consumes:
      - "application/json"
      produces:
      - "application/json"
      parameters:
      - name: "talkList"
        in: "body"
        required: true
        schema:
          $ref: "#/definitions/TalkList"
      responses:
        200:
          description: "Status 200"
          schema:
            $ref: "#/definitions/Result"
        400:
          description: "Status 400"
          schema:
            $ref: "#/definitions/Result"
  /api:
    get:
      summary: "Get the list of talks"
      operationId: "GetAllTalks"
      produces:
      - "application/json"
      parameters: []
      responses:
        200:
          description: "Status 200"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/Talk"
  /api/talk/{talk}:
    get:
      summary: "Get a particular talk"
      operationId: "GetOneTalk"
      produces:
      - "application/json"
      parameters:
      - name: "talk"
        in: "path"
        required: true
        type: "string"
      responses:
        200:
          description: "Status 200"
          schema:
            $ref: "#/definitions/Talk"
        404:
          description: "Status 404"
          schema:
            $ref: "#/definitions/Result"
  /api/talk/{talk}/vote/{vote}:
    post:
      summary: "Vote for a talk"
      operationId: "VoteOnTalk"
      produces:
      - "application/json"
      parameters:
      - name: "talk"
        in: "path"
        required: true
        type: "string"
      - name: "vote"
        in: "path"
        description: "The vote can be \"negative\", \"neutral\" or \"positive\""
        required: true
        type: "string"
      responses:
        200:
          description: "Status 200"
          schema:
            $ref: "#/definitions/Result"
        400:
          description: "Status 400"
          schema:
            $ref: "#/definitions/Result"
        404:
          description: "Status 404"
          schema:
            $ref: "#/definitions/Result"
  /api/{day}:
    get:
      summary: "Get the talks for a particular day"
      operationId: "GetTalksPerDay"
      produces:
      - "application/json"
      parameters:
      - name: "day"
        in: "path"
        required: true
        type: "string"
      responses:
        200:
          description: "Status 200"
          schema:
            type: "array"
            items:
              $ref: "#/definitions/Talk"
        404:
          description: "Status 404"
          schema:
            $ref: "#/definitions/Result"
definitions:
  Result:
    type: "object"
    required:
    - "status"
    properties:
      status:
        type: "string"
    description: "Voting results"
  Talk:
    type: "object"
    required:
    - "day"
    - "fromTime"
    - "fromTimeMillis"
    - "id"
    - "reactions"
    - "speakers"
    - "talkType"
    - "title"
    - "toTime"
    - "toTimeMillis"
    - "track"
    properties:
      day:
        type: "string"
      fromTime:
        type: "string"
      fromTimeMillis:
        type: "integer"
        format: "int64"
      id:
        type: "string"
        description: ""
      reactions:
        type: "object"
        properties:
          negative:
            type: "integer"
            format: "int32"
          neutral:
            type: "integer"
            format: "int32"
          positive:
            type: "integer"
            format: "int32"
        required:
        - "negative"
        - "neutral"
        - "positive"
      room:
        type: "string"
      speakers:
        type: "array"
        items:
          type: "string"
      summary:
        type: "string"
      talkType:
        type: "string"
      title:
        type: "string"
      toTime:
        type: "string"
      toTimeMillis:
        type: "integer"
        format: "int64"
      track:
        type: "object"
        properties:
          title:
            type: "string"
          trackId:
            type: "string"
        required:
        - "title"
        - "trackId"
    description: "A talk representation"
  TalkList:
    type: "array"
    items:
      $ref: "#/definitions/Talk"
    description: "A list of talks"
```

You can write your API specifications using either JSON or YAML. I chose YAML because it's a bit easier to read, for the human eye, and still as much readable for the computer as well.

There's one extra step for instructing Cloud Endpoints about our API definition: I needed to convert my OpenAPI Spec into the service definition format used internally by Cloud Endpoints, thanks to the following command:

```bash
gcloud beta service-management convert-config swagger20.yaml service.json
```

## Deploying on App Engine Flex

To deploy on App Engine and use Cloud Endpoints, we're going to use the [gcloud](https://cloud.google.com/sdk/) command-line tool again:

```bash
gcloud beta app deploy
```

After a few minutes, your app / API should be available and be ready for serving.

## Testing our API

I have a JSON file with the bulk of the talks and their details, so I uploaded it with:

```bash
curl -d @src/ratpack/public/data/talks.json -H 'Content-Type: application/json' http://devoxx-reactions.appspot.com/import
```

And then I was able to call my API with:

```bash
curl https://devoxx-reactions.appspot.com/api
curl https://devoxx-reactions.appspot.com/api/monday
curl https://devoxx-reactions.appspot.com/api/talk/HFW-0944
```

And to vote for a given talk with:

```bash
curl -X POST https://devoxx-reactions.appspot.com/api/talk/XMX-6190/vote/positive
```

## Managing your API

When you're visiting your cloud console, you'll be able to see interesting statistics and graphs, about the usage of your API:

![](/img/binge-streaming/endpoints-manage-1.png)
![](/img/binge-streaming/endpoints-manage-2.png)

## Streaming the API

For the streaming part of the story, I'll let Audrey cover it! I focused on the backend, how she focused on the Polymer frontend, with a custom Streamdata component, that used the Streamdata proxy to get the patches representing the difference between consecutive calls to the backend. So when the votes were changing (but the rest of the talk details were left unchanged), Streamdata would send back to the front only the diff. In addition to keeping ongoing data exchanges low (in terms of size), the proxy is also able to take care of caching, so it also helps avoiding hitting the backend too often, potentially helping with scalability of the backend, by keeping the cache at the proxy level.

## Slides and video available!

You can watch the video online on Devoxx' YouTube channel:

{{< youtube VT4xsDCeDxE >}}

And you can also have a closer look at the slides as well:

{{< speakerdeck 87a0f10990e343e29007ea32e49ba0a3 >}}
# Latest features of Google Cloud Platform


When you're following a project, a company, a platform, you're looking for the latest news, about the latest feature announcement, to take advantage of what's coming up.

Last time, I blogged about the [gcloud command line tool]({{< ref "/posts/2016/09/28/gcloud-informative-update-message" >}}), which nicely shows you the latest updates since the last time you updated its components.

If you go to the Google Cloud Platform website, you'll see dedicated release notes pages for pretty much all products. For example, here are the release notes for:

-   [Compute Engine](https://cloud.google.com/compute/docs/release-notes)
-   [Cloud Storage](https://cloud.google.com/storage/release-notes)
-   [BigQuery](https://cloud.google.com/bigquery/release-notes)
-   etc.

I've just discovered a new way to stay updated about what's new. If you go to the [Cloud Console](https://console.cloud.google.com/), click on the little vertical dots, and then preferences:

![](/img/gcp-new-features/gcp-features-1-prefs.png)

Then, in the main panel, you'll see a new "communication" section, and if you click on the "updates & offers", you'll get a chance to select the option "feature announcements":

![](/img/gcp-new-features/gcp-features-2-announcements.png)

You'll receive monthly emails about the feature announcements.
# Quick intro to Google Cloud Platform for the Paris Ansible meetup


Tonight, Google France was hosting the Paris Ansible meetup, and I had the chance to play the Master of Ceremony, by introducing the speakers for the evening, as well as give a brief introduction to the Google Cloud Platform, as well as outlining where Ansible users and DevOps engineers might be interested in learning more.

Here's my quick overview of the Google Cloud Platform:

{{< speakerdeck b35eb9967bc34da9ad36cc66b988ad57 >}}
# Scaling a Swagger-based web API on Google Cloud Endpoints


I had the pleasure of presenting at the [Nordic APIs Platform Summit 2016](http://nordicapis.com/events/2016-platform-summit/) in Stockholm this week. I enjoyed the conference a lot, with great speakers and content, flawless organization, and nice interactions with the audience.

For the last keynote of the conference, I had the chance to present about [Google Cloud Endpoints](https://cloud.google.com/endpoints/), Google's take on API management. I worked on a little "pancake"-powered demo, deploying a [Ratpack](https://ratpack.io/) application, in a Docker container, on [Google Container Engine](https://cloud.google.com/container-engine/). I created an [OpenAPI Specification](https://openapis.org/) describing my Web API that served pancakes. And used the Extensible Service Proxy to receive the API calls for securing (with an API key), monitoring (through the Cloud Console) and scaling my Web API (thanks to the scaling capabilities of Container Engine). This demo will be the topic of some upcoming blog posts.

In the meantime, here is the abstract of my talk:

## Scale a Swagger-based Web API with Google Cloud Endpoints

> Web APIs are and more often specified with API definition languages like Swagger (now named Open API Spec), as it can help you generate nice interactive documentation, server skeletons, and client SDKs, mocks, and more, making it simpler to get started both producing and consuming an API.
>
> In this session, Guillaume will demonstrate how to define a Web API with Swagger / Open API Spec, and scale it using Cloud Endpoints, on the Google Cloud Platform.

And here are the slides I presented:

{{< speakerdeck a06c96a7c36a44cba63031f4146b8fae >}}
# Viewing my Groovy source files in Stackdriver's debug view


As I was working on a demo for one of my talks at [Devoxx](https://devoxx.be/), I was encountering a bug in my [Groovy](http://www.groovy-lang.org/) code (a [Gaelyk](http://gaelyk.appspot.com/) app using [Glide](http://glide-gae.appspot.com/)). I had deployed a new version of my [App Engine](https://cloud.google.com/appengine/) app, changing some code to persist some data in the [Datastore](https://cloud.google.com/datastore/). After those changes, I saw a trace in the logs:

![](/img/sd-debug-groovy/stackdriver-stacktrace.png)

Looks like there's an error in receiveTweet.groovy on line 11. And there's a link! Although I hadn't linked the source code to the application, I was surprised to see this link. But I knew that Stackdriver is able to [pick up sources](https://cloud.google.com/debugger/docs/source-options) in different ways (from uploaded local files, from a Google code source repository, from Github or BitBucket, or with a "source capture").

And actually, clicking that link brought me to the debug view, offering me the different ways to link to or upload the source code. Conveniently, the source capture approach provided a command, using the [gcloud](https://cloud.google.com/sdk/gcloud/) CLI, to link the sources with traces:

![](/img/sd-debug-groovy/stackdriver-gcloud-capture.png)

I then launched that command in my terminal, and I was able to see the trace along with my source code afterwards in the Web console:

![](/img/sd-debug-groovy/stackdriver-code-small.png)

On the left side, I can see my Groovy source files, highlighting the offending script with the bug. In the middle column: at the bottom, the stacktrace, and at the top, the source code, with the line where the exception occurred highlighted in blue.

On the right, there's also the live debugger view! But I haven't played with it yet, but it's pretty powerful, as you can live debug a production app! Let's keep it for another post!

However, now with your Groovy hat on, you'll notice two things:

![](/img/sd-debug-groovy/stackdriver-zoom-code.png)

The Groovy source code is not nicely colored! Syntax coloring is available for languages like Java, Go, Python, JavaScript, but alas, not (yet?) for Groovy!

The other funny thing was the red message on the right as well:

![](/img/sd-debug-groovy/stackdriver-red-message.png)

Although it says only files with .java extension are supported, it was nice to see that it was still showing my Groovy source code!

## Summary

It's pretty neat to be able to associate the code and the logs directly in the web interface, to quickly spot where problems are coming from. Of course, you can go back to your IDE or text editor to find out (and ultimately that's what you'll be doing) but it's pretty handy to quickly visualize the origin of the problem and start figuring out what the problem may be.

Also, as I said, I haven't tried the live production debugger, but it's quite a killer feature in my book to be able to introspect a running app. It's not always easy to figure out some problems locally, as your emulator is not the actually running infrastructure, your tests are mocking things out but are "not like the real thing", so having the ability to dive deeper in the running system is pretty compelling!
# IP filtering access to your VMs on Google Cloud


How do you filter access to your VMs on Google Cloud Platform? During a discussion with a customer, I was asked this question: only certain IP addresses or a range of IP addresses should have access to a particular VM. Let's see that in action!

Let's assume you already have an account on Google Cloud Platform, but if you don't, don't miss the [$300 credits for a free trial](https://cloud.google.com/free-trial/)! I created a new project, then navigated to the Compute Engine section to create a new VM instance. I used all the default parameters, except that I checked the checkbox for "Allow HTTP traffic", at the bottom of the following screenshot:

![](/img/misc/firewall-create-instance.png)

For the purpose of this demo, I went with allowing traffic first, and then updating the firewall rule, but the best approach (since you don't want to let users access this VM) is to not allow HTTP traffic, and add the right rule afterwards. But I wanted to check that the traffic was flowing through normally, and then updated the rule to check that, indeed, the traffic was filtered.

My VM server isn't doing anything useful at this point, so I should at least run some web app on it! Wearing my [Groovy](http://www.groovy-lang.org/) hat on, I decided to write a quick Groovy script with the [Ratpack](https://ratpack.io/) framework. Let's see how to setup our VM to serve a simple hello world!

Once your VM instance is instantiated, you'll see a little SSH link along your instance in the list of running VMs. You can click on it, and you'll be able to SSH into your running system. So what's the recipe to run a little hello world in Ratpack? I installed OpenJDK 8, [SDKMan](http://sdkman.io/) (to install Groovy, but which needed unzip to be installed for itself), and Groovy, with the following steps:

```bash
sudo su -
apt-get update
apt-get install openjdk-8-jdk
apt-get install unzip
curl -s "https://get.sdkman.io" | bash
source "/root/.sdkman/bin/sdkman-init.sh"
sdk install groovy
exit
mkdir ratpack
cd ratpack
vim hello.groovy
```

Then I created the hello.groovy Ratpack server with the following code:

```groovy
@Grab('io.ratpack:ratpack-groovy:1.4.2')
@Grab('org.slf4j:slf4j-simple:1.7.21')
import static ratpack.groovy.Groovy.ratpack

ratpack {
    serverConfig {
        port 80
    }
    handlers {
        get {
            render "Hello World!"
        }
    }
}
```

And then, I was ready to fire it with:

```bash
groovy hello
```

If you go back to your Google Cloud console, in the list of running instance, you certainly noticed the column showing the "External IP" address of your sever? Now you just need to let your browser open it. So head over to `http://123.123.123.123/` (or whichever IP you got), and you should see the infamous `Hello World!` message!

So far so good, but what we really want is to prevent access to this machine from anywhere, except a particular IP or range of IP addresses. Let's see how to do that next.

Let's go to the `Networking > Firewall rules`:

![](/img/ip-filter/firewall-edit-rule.png)

We're going to update the first rule: `default-allow-http`. Instead of `allowing from any source` with the `0.0.0.0/0` IP range, we're going to use our own custom range. In our case, let's say my own external IP address is `111.111.111.111`, so I'll restrict the range to just this IP with entering `111.111.111.111/0` as `Source IP range`. Let's save the firewall, and let the platform apply that change to our deployment. Once the change has taken place, you'll still be able to access your server at `http://123.123.123.123/`, because only your own IP address is white listed basically. But if you try with any other address (from a co-worker's machine, etc.), normally, nobody else will be able to access the sever beside you.

Done!

And now, for the bonus points! I started playing with that last week, and made the mistake of letting my VM instance running, underutilized. And this afternoon, as I resumed working on this article, I watch the list of instances running, and what do I see? The console telling me my VM instance is under-utilized and that I could save money by using a smaller VM instead! Looks like Google Cloud doesn't want me to waste my money! Sweet!

![](/img/ip-filter/firewall-save-cost.png)
# GCloud informative update message


I was playing with the [new IntelliJ IDEA plugin for Google App Engine](https://cloudplatform.googleblog.com/2016/08/never-leave-your-Java-IDE-with-Google-Cloud-Tools-for-IntelliJ-plugin.html) yesterday. The plugin depends on the [gcloud SDK](https://cloud.google.com/sdk/gcloud/) to do its work. And I started exploring gcloud a little bit more.

I was experiencing some odd bug which prevented me to run my application locally with the App Engine's local app server. It was a bug which was present in an old version of gcloud and its App Engine component, so I had to update the SDK and its App Engine Java component to fix it. No big deal, but what I wanted to highlight here was a little detail about that upgrade process.

I love when SDKs give me information about what needs updating and what's new in the new versions I'm using!

I've been using [SDKMan](http://sdkman.io/) for dealing with various SDK installations, like those for Groovy, Grails, Gradle, etc, and I've always liked when it was telling me which SDK updates were available, what was new in SDKMan. And I'm glad to see that gcloud behaves the same, and gives informative details about what's new. So let's see that in action.

First of all, while debugging my problem with a colleague, he asked me which versions of the SDK and the App Engine component I had. So I ran the following command:

```bash
$ gcloud version
Google Cloud SDK 119.0.0
alpha 2016.01.12
app-engine-java 1.9.38
app-engine-python 1.9.38
beta 2016.01.12
bq 2.0.24
bq-nix 2.0.24
core 2016.07.21
core-nix 2016.06.06
gcloud 
gsutil 4.19
gsutil-nix 4.19
```

At the time of this writing, the latest version of gcloud was actually 127.0.0, but I had 119.0.0. And for the app-engine-java component, I had version 1.9.38 although 1.9.42 was available. So it was time to update!

```bash
$ gcloud components update

Your current Cloud SDK version is: 119.0.0
You will be upgraded to version: 127.0.0
┌──────────────────────────────────────────────────────────┐
│            These components will be updated.             │
├─────────────────────────────────┬────────────┬───────────┤
│               Name              │  Version   │    Size   │
├─────────────────────────────────┼────────────┼───────────┤
│ BigQuery Command Line Tool      │     2.0.24 │   < 1 MiB │
│ Cloud SDK Core Libraries        │ 2016.09.20 │   4.9 MiB │
│ Cloud Storage Command Line Tool │       4.21 │   2.8 MiB │
│ gcloud app Java Extensions      │     1.9.42 │ 135.6 MiB │
│ gcloud app Python Extensions    │     1.9.40 │   7.2 MiB │
└─────────────────────────────────┴────────────┴───────────┘
The following release notes are new in this upgrade.
Please read carefully for information about new features, breaking changes,
and bugs fixed.  The latest full release notes can be viewed at:
  https://cloud.google.com/sdk/release_notes
127.0.0 (2016/09/21)
  Google BigQuery
      - New load/query option in BigQuery client to support schema update
        within a load/query job.
      - New query option in BigQuery client to specify query parameters in
        Standard SQL.
  Google Cloud Dataproc
      - gcloud dataproc clusters create flag
        --preemptible-worker-boot-disk-size can be used to specify future
        preemptible VM boot disk size.
  Google Container Engine
      - Update kubectl to version 1.3.7.
  Google Cloud ML
      - New gcloud beta ml predict command to do online prediction.
      - New gcloud beta ml jobs submit prediction command to submit batch
        prediction job.
  Google Cloud SQL
      - New arguments to beta sql instances create/patch commands for Cloud
        SQL Second Generation instances:
        ◆ --storage-size Sets storage size in GB.
        ◆ --maintenance-release-channel Sets production or preview channel
          for maintenance window.
        ◆ --maintenance-window-day Sets day of week for maintenance window.
        ◆ --maintenance-window-hour Sets hour of day for maintenance window.
        ◆ --maintenance-window-any (patch only) Clears maintenance window
          setting.
[...]

```

I snipped the output to just show the details of the changes for the latest version of gcloud, but it showed me the actual changelog up until the version I had... and as I hadn't updated in a while, there was lots of improvements and fixes! But it's really nice to see what had changed, and sometimes, you can discover some gems you weren't even aware of!

So if you're working on some kind of SDK, with auto-update capabilities, be sure to provide a built-in changelog facility to help your users know what's new and improved!
# JavaOne 2016 sessions


Next week will be this time of the year where tons of Java developers are gathering & meeting in San Francisco for [JavaOne](https://www.oracle.com/javaone/index.html). It'll be my 10th edition or so, time flies!   
This year, I'll participate to a couple sessions:  

*   **Java and the Commoditization of Machine Intelligence** \[CON2291\]  
    It's a panel discussion with representative from IBM, Microsoft and Google to talk about Machine Learning APIs. I'll be covering the ML APIs from Google Cloud Platform: Vision, Speech, Natural Language.
*   **A Groovy Journey in Open Source** \[CON5932\]  
    In this session, I'll cover the history of the Apache Groovy project, and talk about the latest developments and new features.

Google colleagues will also be present to speak about: 

*   **gRPC 101 for Java Developers** \[CON5750\] by Ray Tsang
*   **Managing and Deploying Java-Based Applications and Services at Scale** \[CON5730\] by Ray Tsang
*   **Hacking Hiring** \[BOF1459\] by Elliotte Harold
*   **The Ultimate Build Tools Face-off** \[CON2270\] with Dmitry Churbanau and Baruch Sadogursky
*   **RIA Technologies and Frameworks Panel** \[CON4675\] with Kevin Nilson

There are quite a few interesting Groovy ecosystem related talks on the agenda: 

*   **Improving Your Groovy Kung-Fu** \[CON1293\] by Dierk König
*   **Groovy and Java 8: Making Java Better** \[CON3277\] by Ken Kousen 
*   **Spock: Test Well and Prosper** \[CON3273\] by Ken Kousen
*   **Writing Groovy AST Transformations: Getting Practical in an Hour** \[CON1238\] by Baruch Sadogursky
*   **Juggling Multiple Java Platforms and Jigsaw with Gradle** \[CON4832\] by Cédric Champeau
*   **Maven Versus Gradle: Ready...Steady...Go!** \[CON2951\] by Mert Caliskan & Murat Yener
*   **Meet the Gradle Team** \[BOF6209\] with Sterling Greene & Cédric Champeau
*   **Faster Java EE Builds with Gradle** \[CON4921\] by Ryan Cuprak
*   **Lightweight Developer Provisioning with Gradle** \[BOF5154\] by Mario-Leander Reimer
*   **Making the Most of Your Gradle Build** \[CON6468\] by Andrés Almiray
*   **Gradle Support in NetBeans: A State of the Union** \[CON6253\] with Sven Reimers & Martin Klähn
*   **A Practical RxJava Example with Ratpack** \[CON4044\] by Laurent Doguin

Lots of interesting content! I'm really looking forward to meeting you there, in the hallways, to chat about [Google Cloud Platform](https://cloud.google.com/) and [Apache Groovy](http://www.groovy-lang.org/)!
# Natural language API and JavaScript promises to bind them all


A bit of [web scraping with Jsoup and REST API calls with groovy-wsclient]({{< ref "/posts/2016/07/27/web-scraping-and-rest-api-calls-on-app-engine-with-jsoup-and-groovy-wslite" >}}) helped me build my latest demo with [Glide](http://glide-gae.appspot.com/) / [Gaelyk](http://gaelyk.appspot.com/) on [App Engine](https://cloud.google.com/appengine/), but now, it's time to look a bit deeper into the analysis of the White House speeches:

![](/img/misc/whitehouse-speeches-630.png)

I wanted to have a feel of how positive and negative sentences flow together in speeches. Looking at the rhetoric of those texts, you'd find some flows of generally neutral introduction, then posing the problem with some negativity connotation, then the climax trying to unfold the problems with positive solutions. Some other topics might be totally different, though, but I was curious to see how this played out on the corpus of texts from the speeches and remarks published by the [White House press office](https://www.whitehouse.gov/briefing-room/speeches-and-remarks).

## The Cloud Natural Language API

For that purpose, I used the [Cloud Natural Language API](https://cloud.google.com/natural-language/docs/):

*   [Split the text into sentences](https://cloud.google.com/natural-language/docs/basics#sentence-extraction) thanks to the [text annotation](https://cloud.google.com/natural-language/reference/rest/v1beta1/documents/annotateText) capability. The API can split sentences even further, of course, by word, to figure out verbs, nouns, and all components of sentences (POS: Part Of Speech tagging).
*   Define the [sentiment](https://cloud.google.com/natural-language/docs/sentiment-tutorial) of sentences, with a polarity (negative to positive), and a magnitude (for the intensity of the sentiment expressed).
*   [Extract entities](https://cloud.google.com/natural-language/docs/basics#entity_analysis), ie. finding people / organization / enterprise names, place locations, etc.

Text annotation is important for better understanding text, for example to create more accurate language translations. Sentiment analysis can help brands track how their customers appreciate their products. And entity extraction can help figure out the topics of articles, who's mentioned, places where the action takes places, which is useful for further contextual search, like finding all the articles about Obama, all the speeches about Europe, etc. There's a wide applicability of those various services to provide more metadata, a better understanding for a given piece of text.

## Asynchronously calling the service and gathering results

Let's look back at my experiment. When I scrape the speeches, I actually get a list of paragraphs (initially enclosed in \<p> tags basically). But I want to analyze the text sentence by sentence, so I need to use the text annotation capability to split all those paragraphs into sentences that I analyze individually.

Currently, the sentiment analysis works on one piece of text at a time. So you have to make one call per sentence! Hopefully an option might come to allow to send several pieces of text in a batch, or giving the sentiment per sentence for a big chunk of text, etc. But for now, it means I'll have to make p calls for my p paragraphs, and then n calls for all the sentences. those p + n calls might be expensive in terms of network traffic, but on the other hand, I can make the sentence coloring appear progressively, and asynchronously, by using JavaScript Promises and Fetch API, as I'm making those calls from the client side. But it seems it's possible to [batch requests with the Google API Client](https://developers.google.com/api-client-library/java/google-api-java-client/batch), but I haven't tried that yet.

First of all, to simplify the code a bit, I've created a helper function that calls my backend services calling the NL API, that wraps the usage of the Fetch API, and the promise handling to gather the JSON response:

```javascript
var callService = function (url, key, value) {
    var query = new URLSearchParams();
    query.append(key, value);
    return fetch(url, {
        method: 'POST',
        body: query
    }).then(function (resp) {
        return resp.json();
    })
};
```

I use the URLSearchParams object to pass my query parameter. The handy json() method on the response gives me the data structure resulting from the call. I'm going to reuse that callService function in the following snippets:

```javascript
callService('/content', 'url', e.value).then(function (paragraphs) {
    paragraphs.forEach(function (para, paraIdx) {
        z('#output').append('<p id="para' + paraIdx + '">' + para + '</p>');
        callService('/sentences', 'content', para).then(function (data) {
            var sentences = data.sentences.map(function (sentence) {
                return sentence.text.content;
            });
            return Promise.all(sentences.map(function (sentence) {
                return callService('/sentence', 'content', sentence).then(function (sentenceSentiment) {
                    var polarity = sentenceSentiment.documentSentiment.polarity;
                    var magnitude = sentenceSentiment.documentSentiment.magnitude;
                    return {
                        sentence: sentence,
                        polarity: polarity,
                        magnitude: magnitude
                    }
                });
            }));
        }).then(function (allSentiments) {
            var coloredSentences = allSentiments.map(function (sentiment) {
                var hsl = 'hsl(' +
                    Math.floor((sentiment.polarity + 1) * 60) + ', ' +
                    Math.min(Math.floor(sentiment.magnitude * 100), 100) + '%, ' +
                    '90%) !important';
                return '<span style="background-color: ' + hsl + '">' + sentiment.sentence + '</span>';
            }).join('&nbsp;&nbsp;');
            z('#para' + paraIdx).html(coloredSentences);
        });
    });
});
```

The first call will fetch the paragraphs from the web scraping service. I display each paragraph right away, uncolored, with an id so that I can then later update each paragraph with colored sentences with their sentiment.

Now for each paragraph, I call the sentences service, which calls the NL API to get the individual sentences of each paragraph. With all the sentences in one go, I use the Promise.all(iterable) method which returns a promise that resolves when all the promises of sentiment analysis per sentence have resolved. This will help me keep track of the order of sentences, as the analysis can give me results in a non predictable order.

I also keep track of the paragraph index to replace all the sentences of each paragraph, once all the promises for the sentences are resolved. I update the paragraph with colored sentences once all sentences of a paragraph are resolved, joining all colored sentences together.
# Web scraping and REST API calls on App Engine with Jsoup and groovy-wslite


After my [Twitter sentiment article]({{< ref "/posts/2016/07/20/sentiment-analysis-on-tweets" >}}), those past couple of days, I've been playing again with the [Cloud Natural Language API](https://cloud.google.com/natural-language/docs/). This time, I wanted to make a little demo analyzing the text of speeches and remarks published by the press office of the White House. It's interesting to see how speeches alternate negative and positive sequences, to reinforce the argument being exposed.  

![](/img/misc/whitehouse-speeches-630.png)  

As usual, for my cloud demos, my weapons of choice for rapid development are [Apache Groovy](http://www.groovy-lang.org/), with [Glide](http://glide-gae.appspot.com/) & [Gaelyk](http://gaelyk.appspot.com/) on [Google App Engine](https://cloud.google.com/appengine/)! But for this demo, I needed two things:

*   a way to scrape the content of the [speeches & remarks](https://www.whitehouse.gov/briefing-room/speeches-and-remarks) from the White House press office
*   a library for easily making REST calls to the [Natural Language API](https://cloud.google.com/natural-language/docs/)

In both cases, we need to issue calls through the internet, and there are some limitations on App Engine with regards to such [outbound networking](https://cloud.google.com/appengine/docs/java/outbound-requests). But if you use the plain Java HTTP / URL networking classes, you are fine. And under the hood, it's using App Engine's own [URL Fetch service](https://cloud.google.com/appengine/docs/java/issue-requests).  
I used [Jsoup](https://jsoup.org/) for web scraping, which takes care itself for connecting to the web site.  
For interacting with the REST API, [groovy-wslight](https://github.com/jwagenleitner/groovy-wslite) came to my rescue, although I could have used the Java SDK like in my previous article.  
Let's look at Jsoup and scraping first. In my controller fetching the content, I did something along those lines (you can run this script in the Groovy console):

```groovy
@Grab('org.jsoup:jsoup:1.9.2') import org.jsoup.\*   
def url = 'https://www.whitehouse.gov/the-press-office/2016/07/17/statement-president-shootings-baton-rouge-louisiana' def doc = Jsoup.connect(url) .userAgent('Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0') .get() println doc.select('.forall-body .field-item p').collect { it.text() }.join('\\n\\n')
```

Now I'm gonna make a call with groovy-wslight to the NL API:

```groovy
@Grab('com.github.groovy-wslite:groovy-wslite:1.1.3')  
import wslite.rest.*   

def apiKey = 'MY_TOP_SECRET_API_KEY'   
def client = new RESTClient('https://language.googleapis.com/v1beta1/')  
def result = client.post(path: 'documents:annotateText', query: [key: apiKey]) {  
    type ContentType.JSON  
    json document: [  
        type : 'PLAIN_TEXT',  
        content: text  
    ], features: [  
        extractSyntax : true,  
        extractEntities : true,  
        extractDocumentSentiment: true  
    ]  
}  
// returns a list of parsed sentences  
println result.json.sentences.text.content  
// prints the overall sentiment of the speech  
println result.json.documentSentiment.polarity
```
  
Groovy-wslight nicely handles XML and JSON payloads: you can use Groovy maps for the input value, which will be marshalled to JSON transparently, and the GPath notation to easily access the resulting JSON object returned by this API.  

It was very quick and straightforward to use Jsoup and groovy-wslight for my web scraping and REST handling needs, and it was a breeze to integrate them in my App Engine application. In a follow-up article, I'll tell you a bit more about the sentiment analysis of the sentences of the speeches, so please stay tuned for the next installment!
# Sentiment analysis on tweets


What’s the mood on Twitter today? Looking at my little [twitter demo]({{< ref "/posts/2016/07/11/getting-started-with-glide-and-gaelyk-on-google-app-engine" >}}) from a few weeks ago (using [Glide](http://glide-gae.appspot.com/) & [Gaelyk](http://gaelyk.appspot.com/) on [Google App Engine](https://cloud.google.com/appengine/)), I thought I could enrich the visualization with some sentiment analysis to give more color to those tweets. Fortunately, there’s a new API in Google-town, the [Cloud Natural Language API](https://cloud.google.com/natural-language/docs/) (some more info in the [announcement](https://cloudplatform.googleblog.com/2016/07/the-latest-for-Cloud-customers-machine-learning-and-west-coast-expansion.html) and a great post showing textual [analysis of Harry Potter and New York Times](https://cloud.google.com/blog/big-data/2016/07/using-the-cloud-natural-language-api-to-analyze-harry-potter-and-the-new-york-times))!



The brand-new Cloud Natural Language API provides three key services:

*   **Sentiment analysis**: inspects the given text and identifies the prevailing emotional opinion within the text, especially to determine a writer's attitude as positive, negative, or neutral.

*   **Entity recognition**: inspects the given text for known entities (proper nouns such as public figures, landmarks, etc.) and returns information about those entities.

*   **Syntax analysis**: extracts linguistic information, breaking up the given text into a series of sentences and tokens (generally, word boundaries), providing further analysis on those tokens.


I’m going to focus only on the sentiment analysis in this article. When analyzing some text, the API tells you whether the content is negative, neutral or positive, returning “polarity” values ranging from -1 for negative to +1 for positive. And you also get a “magnitude”, from 0 to +Infinity to say how strong the emotions expressed are. You can read more about [what polarity and magnitude mean](https://cloud.google.com/natural-language/docs/basics#interpreting_sentiment_analysis_values) for a more thorough understanding.

## Let’s get started!

With the code base of my [first article]({{< ref "/posts/2016/07/11/getting-started-with-glide-and-gaelyk-on-google-app-engine" >}}), I will add the sentiment analysis associated with the tweets I’m fetching. The idea is to come up with a colorful wall of tweets like this, with a range of colors from red for negative, to green for positive, through yellow for neutral:

![](/img/misc/tweetmood-final-small.png)

I’ll create a new controller (mood.groovy) that will call the Cloud NL service, passing the text as input. I’ll take advantage of App Engine’s Memcache support to cache the calls to the service, as tweets are immutable, their sentiment won’t change. The controller will return a JSON structure to hold the result of the sentiment analysis. From the index.gtpl view template, I’ll add a bit of JavaScript and AJAX to call my newly created controller.

## Setting up the dependencies

You can either use the Cloud NL REST API or the Java SDK. I decided to use the latter, essentially just to benefit from code completion in my IDE. You can have a look at the [Java samples](https://cloud.google.com/natural-language/docs/samples) provided. I’m updating the glide.gradle file to define my dependencies, including the google-api-services-language artifact which contains the Cloud NL service. I also needed to depend on the Google API client JARs, and Guava. Here’s what my Gradle dependencies ended up looking like:

```groovy
dependencies {
    compile "com.google.api-client:google-api-client:1.21.0"
    compile "com.google.api-client:google-api-client-appengine:1.21.0"
    compile "com.google.api-client:google-api-client-servlet:1.21.0"
    compile "com.google.guava:guava:19.0"
    compile "com.google.apis:google-api-services-language:v1beta1-rev1-1.22.0"
    compile "org.twitter4j:twitter4j-appengine:4.0.4" }
```

## Creating a new route for the mood controller

First, let’s create a new route in \_routes.groovy to point at the new controller:

```groovy
post "/mood", forward: "/mood.groovy"
```

## Coding the mood controller

Now let’s code the mood.groovy controller!

We’ll need quite a few imports for the Google API client classes, and a couple more for the Cloud Natural Language API:

```groovy
import com.google.api.client.googleapis.json.GoogleJsonResponseException
import com.google.api.client.http.*
import com.google.api.client.googleapis.auth.oauth2.GoogleCredential
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport
import com.google.api.client.json.jackson2.JacksonFactory
import com.google.api.services.language.v1beta1.*
import com.google.api.services.language.v1beta1.model.*
```


We’re retrieving the text as a parameter, with the params map:

```groovy
def text = params.txt
```

We’ve set up a few local variables that we’ll use for storing and returning the result of the sentiment analysis invocation:

```groovy
def successOutcome = true
def reason = ""
def polarity = 0
def magnitude = 0
```

Let’s check if we have already got the sentiment analysis for the text parameter in Memcache:

```groovy
def cachedResult = memcache[text]
```

If it’s in the cache, we’ll be able to return it, otherwise, it’s time to compute it:

```groovy
if (!cachedResult) {
    try {
        // the sentiment analysis calling will be here
    } catch (Throwable t) {
        successOutcome = false
        reason = t.message
    }
}
```

We’re going to wrap our service call with a bit of exception handling, in case something goes wrong, we want to alert the user of what’s going on. And in lieu of the comment, we’ll add some logic to analyze the sentiment We must define the Google credentials allowing us to access the API. Rather than explaining the whole process, please follow the [authentication process](https://cloud.google.com/natural-language/docs/common/auth) explained in the documentation to create an API key and a service account:

```groovy
def credential = GoogleCredential.applicationDefault.createScoped(CloudNaturalLanguageAPIScopes.all())
```

Now we can create our Cloud Natural Language API caller:

```groovy
def api = new CloudNaturalLanguageAPI.Builder(
    GoogleNetHttpTransport.newTrustedTransport(),
    JacksonFactory.defaultInstance,
    new HttpRequestInitializer() {
        void initialize(HttpRequest httpRequest) throws IOException {
            credential.initialize(httpRequest)
        }
    })
    .setApplicationName('TweetMood')
    .build()
```

The caller requires some parameters like an HTTP transport, a JSON factory, and a request initializer that double checks that we’re allowed to make those API calls. Now that the API is set up, we can call it:

```groovy
def sentimentResponse = api.documents().analyzeSentiment(
    new AnalyzeSentimentRequest(document: new Document(content: text, type: "PLAIN\_TEXT"))
).execute()
```

We created an `AnalyzeSentimentRequest`, passing a `Document` to analyze with the text of our tweets. Finally, we execute that request. With the values from the response, we’re going to assign our polarity and magnitude variables:

```groovy
polarity = sentimentResponse.documentSentiment.polarity
magnitude = sentimentResponse.documentSentiment.magnitude
```

Then, we’re going to store the result (successful or not) in Memcache:

```groovy
    cachedResult = [
            success: successOutcome,
            message: reason,
            polarity: sentiment?.polarity ?: 0.0,
            magnitude: sentiment?.magnitude ?: 0.0
    ]
    memcache[text] = cachedResult
}
 ````

Now, we setup the JSON content type for the answer, and we can render the cachedResult map as a JSON object with the Groovy JSON builder available inside all controllers:

```groovy
response.contentType = 'application/json'
json.result cachedResult
```

## Calling our controller from the view

A bit of JavaScript & AJAX to the rescue to call the mood controller! I wanted something a bit lighter than jQuery, so I went with [Zepto.js](http://zeptojs.com/) for fun. It’s pretty much the same API as jQuery anyway. Just before the end of the body, you can install Zepto from a CDN with:

```html
<script src="https://cdnjs.cloudflare.com/ajax/libs/zepto/1.1.6/zepto.min.js"></script>
```

Then, we’ll open up our script tag for some coding:

```html
<script language="javascript">
Zepto(function(z) {
    // some magic here!
});
</script>
```

As the sentiment analysis API call doesn’t support batch requests, we’ll have to call the API for each and every tweet. So let’s iterate over each tweet:

```javascript
z('.tweet').forEach(function(e, idx) {
    var txt = z(e).data('text');
    // ....
}
```

Compared to the previous article, I’ve added a data-text attribute to contain the text of the tweet, stripped from hashtags, twitter handles and links (I’ll let you use some regex magic to scratch those bits of text!).

Next, I call my mood controller, passing the trimmed text as input, and check if the response is successful:

```javascript
 z.post('/mood', { txt: txt }, function(resp) {
    if (resp.result.success) {
        // …
    }
}
```

I retrieve the polarity and magnitude from the JSON payload returned by my mood controller:

```javascript
var polarity = resp.result.polarity;
var magnitude = resp.result.magnitude;
```

Then I update the background color of my tweets with the following approach. I’m using the HSL color space: Hue, Saturation, Lightness.

The hue ranges from 0 to 360°, and for my tweets, I’m using the first third, from red / 0°, through yellow / 60°, up to green / 120° to represent the polarity, respectively with negative / -1, neutral / 0 and positive / +1.

The saturation (in percents) corresponds to the magnitude. For tweets which are small, the magnitude rarely goes beyond 1, so I simply multiply the magnitude by 100 to get percentages, and floors the results to 100% if it goes beyond.

For the lightness, I’ve got a fixed value of 80%, as 100% would always be full white!

Here’s a more explicit visualization of this color encoding with the following graph:

![](/img/misc/mood-color-scheme-small.png)

So what does the code looks like, with the DOM updates with Zepto?

```javascript
 var hsl = 'hsl(' +  Math.floor((polarity + 1) \* 60) + ', ' +  Math.min(Math.floor(magnitude \* 100), 100) + '%, ' +  '80%) !important';

 z(e).css('background-color', hsl)
    .data('polarity', polarity)
    .data('magnitude', magnitude);
```

For the fun, I’ve also added some smileys to represent five buckets of positivity / negativity (very negative, negative, neutral, positive, very positive), and from 0 to 3 exclamation marks for 4 buckets of magnitude. That’s what you see in the bottom of the tweet cards in the final screenshot:

![](/img/misc/example-colored-tweet-small.png)

## Summary

But we’re actually done! We have our controller fetching the tweets forwarding to the view template from the last article, and we added a bit of JavaScript & AJAX to call our new mood controller, to display some fancy colors to represent the mood of our tweets, using the brand new [Cloud Natural Language API](https://cloud.google.com/natural-language/docs/).

When playing with sentiment analysis, I was generally on the same opinion regarding sentiment of the tweets, but I was sometimes surprised by the outcome. It’s hard for short bursts of text like tweets to decipher things like irony, sarcasm, etc, and a particular tweet might appear positive when reality it isn’t, and vice versa. Sentiment analysis is probably not an exact science, and you need more context to decide what’s really positive or negative.

Without even speaking of sarcasm or irony, sometimes certain tweets were deemed negative when some particular usually negative words appeared: a “no” or “not” is not necessarily negative when it’s negating something already negative, turning it into something more positive (“it’s not uncool”). For longer text, the general sentiment seems more accurate, so perhaps it’s more appropriate to use sentiment analysis in such cases than on short snippets.
# Getting started with Glide and Gaelyk on Google App Engine


Back in 2009, I created [Gaelyk](http://gaelyk.appspot.com/), a lightweight toolkit for developing [Google App Engine](https://cloud.google.com/appengine)apps using the [Apache Groovy](http://groovy-lang.org/)programming language. I even had the chance to [speak at Google I/O 2009](https://www.youtube.com/watch?v%3DNEnniZTdOYk)about it! Good times, good times… [Vladimír Oraný](https://twitter.com/musketyr)later joined me in maintaining and evolving Gaelyk, and [Kunal Dabir](https://twitter.com/kdabir)created the fun [Glide](http://glide-gae.appspot.com/) project, which is a thin wrapper around Gaelyk to further streamline the development of small to mid-sized apps for Google App Engine.

Today, I want to share with you a quick start guide to develop a little app, that shows some tweets from selected accounts with the [Twitter API](https://dev.twitter.com/rest/public)(thanks to [Twitter4J](http://twitter4j.org/en/)), and using the [Material Design Light](https://getmdl.io/) template for the look’n feel (I used the “[dashboard](https://getmdl.io/templates/dashboard/index.html)” template). I won’t list all the exact steps, all the precise changes made to the templates, etc, but I want to give you the keys for having a productive experience with Glide and Gaelyk on App Engine. And here’s a screenshot of what we’ll be building:

![](/img/misc/tweet-glide.png)

Ready? Let’s start!

## Installing Glide

In the Groovy community, most developers these days are using [SDKMan](http://sdkman.io/) to install SDKs for Groovy, Gradle, Grails, and more. Glide also comes in the form of an SDK, with a command-line, and is available via SDKMan. So, first step, let’s install SDKMan from your shell (there’s also a Windows-friendly version):

```bash
$ curl -s "https://get.sdkman.io" | bash
```

It will automatically install the SDK manager. Then, either you just open up a new terminal, or you run the following command, to have access to SDKMan in your current session:

```bash
$ source "$HOME/.sdkman/bin/sdkman-init.sh"
```

To check the installation succeeded, you can run it with the sdk command, for example by printing the current version of SDKMan:

```bash
$ sdk version
```

Now that SDKMan is installed, it’s time to install Glide as well:

```bash
$ sdk install glide
```

You can then check that glide is indeed functioning correctly by executing:

```bash
$ glide
```

If you’re on Windows or if you’re not planning to keep SDKMan around, you can also [install Glide by other means](http://glide-gae.appspot.com/docs/installing), manually, as explained in the documentation.

## Creating the skeleton of our application

Okay, we’re ready to create our first Glide / Gaelyk application! (You can also check out the Glide [tutorial](http://glide-gae.appspot.com/docs/quick-start) as well)

```bash
$ glide --app tweetapp create 
$ cd tweetapp 
$ glide run
```

Head over to your browser at http://localhost:8080/, and you’ll see a brilliant “hello glide” message showing up. So far so good, the app is running locally, transparently thanks to the App Engine SDK, now let’s tweak this skeleton!

The project structure is pretty simple, in the directory, you’ll see a glide.groovy file at the root, and an “app” sub-folder containing index.groovy and `_routes.groovy`:

*   `glide.groovy` — the configuration file for your app
*   `index.groovy` — the default controller
*   `_routes.groovy` — listing the mappings between URLs and controllers, and more

## Configuring our application  

In `glide.groovy`, you’ll have the app name and version name defined:

```groovy
app { 
    name="my-tweet-demo" 
    version="1" 
}
```

You might have to change the application name, as we shall see later on, when we deploy the application.

To use the latest version of the App Engine SDK, you can append the following to explicitly ask for a specific version of the SDK:

```groovy
glide { 
    versions { 
        appengineVersion = "1.9.38" 
    } 
}
```

## Defining library dependencies

At the root of our project, we’ll actually add a new configuration file: glide.gradle. This file will allow us to define library dependencies. It’s basically a fragment of a [Gradle](https://gradle.org/)build configuration, where you can define those dependencies using the usual Gradle [syntax](https://docs.gradle.org/current/userguide/artifact_dependencies_tutorial.html). In our glide.gradle file, we’ll add the following dependency, for our Twitter integration:

```groovy
dependencies { 
    compile "org.twitter4j:twitter4j-appengine:4.0.4" 
}
```

## Using the Material Design Lite template

To make things pretty, we’ll be using the [Material Design Lite dashboard sample](https://getmdl.io/templates/index.html), but feel free to skip this part if you want to go straight to the coding part! Download the ZIP archive. It comes with an index.html file, as well as a style.css stylesheet. We’ll copy both files to the app/ folder, but we’ll rename index.html into index.gtpl (to make it a Groovy template file).

When you have a bigger project, with more assets, it’s obviously better to organize these views, stylesheets, JavaScript files, images, etc, in their own respective sub-folders. But for the purpose of my demo, I’ll keep everything in the same place.

You’ll see the template installed and visible if you go to this local URL:

[http://localhost:8080/index.gtpl](http://localhost:8080/index.gtpl)

I won’t detail all the changes to make to the template, and I’ll let you clean the template yourselves, but we can already remove everything that’s inside the inner div of the main tag: that’s where we’ll display our tweets!

## Let's make pretty URLs!

We’d like to have some nice URLs for our app. For that, we’ll now have a look at the \_routes.groovy file where you can define your URL mappings, to point at templates (\*.gtpl files) or at controllers (\*.groovy files, that can render some output directly or forward to templates for rich views). What shall we put in our routes definitions?

```groovy
get "/", redirect: "/u/glaforge"  
get "/u/@who", forward: "/index.groovy?u=@who", 
    validate: { request.who ==~ /[a-zA-Z0-9_]{1,15}/ },  
    cache: 1.minute  
get "/u/@who", forward: "/index.groovy?u=@who&error=invalid"
```

You can have a look at the Gaelyk documentation that defines the [routes definition syntax](http://gaelyk.appspot.com/tutorial/url-routing%23route-definition) for further explanations on what’s possible.

The root of the app, `/`, will redirect to /u/glaforge, to visualize my latest tweets. And all URLs like `/u/*` will forward to our index.groovy controller, that will fetch the tweets for that Twitter user, and forward them to the index.gtpl view for rendering the result.

```
/u/glaforge → /index.groovy?u=glaforge → /index.gtpl
```

The routing syntax is using the `@foo` notation to denote query path variables, that we can then reuse in the forwarding part.

The routing rules are evaluated in order, and the first one that matches the URL will be chosen. We have two get `/u/@who` routes, in the first case, we have a validation rule that checks that the @who path variable is a valid Twitter handle (using Groovy’s [regular expression matching](http://docs.groovy-lang.org/latest/html/documentation/index.html%23_regular_expression_operators) operator). If the validation fails, this route isn’t chosen, and the chain will continue, and it will fall back to the following route that forwards to the template with an error query parameter.

Also interesting to note is the use of caching, with:

```groovy
cache: 1.minute
```

The output of this URL will be put in App Engine’s Memcache so that for the next minute, all requests to the same URL will be fetched from the cache, rather than having to call again the controller and the Twitter API, thus saving on computation and on third-party API call quota.

For the purpose of development, you might want to comment that caching configuration, as you do want to see changes to that template or controller as you’re making changes.

## Time to code our tweet fetching controller

To user the Twitter API, you’ll have to register a new application on the [Twitter Apps page](https://apps.twitter.com/). Twitter will give you the right credentials that you’ll need to connect to the API. You’ll need the four following keys to configure the Twitter4J library:

*   the consumer API key
*   the secrete consumer API key
*   the access token
*   and the secret access token

Let’s configure Twitter4J with that information. I’ll implement the “happy path” and will skip part of the proper error handling (an exercise for the reader?), to keep the code short for this article.

```groovy
import twitter4j.* 
import twitter4j.conf.*   

def conf = new ConfigurationBuilder(
    debugEnabled: true, 
    OAuthAccessToken: "CHANGE_ME", 
    OAuthAccessTokenSecret: "CHANGE_ME", 
    OAuthConsumerKey: "CHANGE_ME", 
    OAuthConsumerSecret: "CHANGE_ME")
.build()   

def twitter = new TwitterFactory(conf).instance
```

The API is configured with your credentials. Be sure to replace all the `CHANGE_ME` bits, obviously!

Let’s lookup the Twitter handle coming through the query parameter, thanks to the user ‘u’ attribute on the params map:

```groovy
def accounts = twitter.lookupUsers(params.u)
```

There should only be two cases (that’s where there may be some more error handling to do!): 1) there’s no user found, or there’s only one. Let’s start with no user found:

```groovy
if (accounts.isEmpty()) { 
    request.errorMessage = "Account '${params.u}' doesn't exist." 
}
```

If no user account was found, we’ll put an error message in the request that’ll be forwarded to our view template.

In the else branch, we’ll handle the the normal case where the user was found:

```groovy
} else { 
    User userAccount = accounts[0] 
    def tweets = twitter.search(new Query("from:${params.u}"))
        .tweets.findAll { !it.isRetweet() }
```

We get the first account returned, and issue a search request for the latest tweets from that account. We filter out the retweets to keep only the user’s original tweets (but it’s up to you if you want to keep them).

In the request for the view, we’ll add details about the account:

```groovy
request.account = [ 
    name : userAccount.name, 
    handle: userAccount.screenName, 
    avatar: userAccount.biggerProfileImageURL  
]
```

And we’ll also add the list of tweets:

```groovy
request.tweets = tweets.collect { Status s -> [  
        id : s.id, 
        timestamp: s.createdAt.time,  
        content : s.text
    ]
}
```

And to finish our controller, we’ll forward to the view:

```groovy
forward 'index.gtpl'
```

Now that our controller is ready, we’ll have to surface the data into the view template.

## Modify the view template

Wherever the template displays the “Home” label, we’ll replace these with the Twitter handle. For that, we can use String interpolation in the template with the ${} notation. If there’s no error message, there should be an account, and we display that handle.

```groovy
${ request.errorMessage ? 'Home' : '@' +request.account.handle }
```

Let’s display the list of tweets, or the error message if there’s one. We’ll iterate over the tweets from the request attributes, and add the following in the inner div of the main tag (fore brevity sake, I'll remove the divs and css needed to make things pretty):

```groovy
<% 
if (request.tweets) { 
    request.tweets.each { tweet -> %> ${tweet.content} <% } 
} else { %> 
    ${request.errorMessage}  
<% 
} %>
```

And voila, our app is ready! Well, at least, it works locally on our app server, but it’s time to deploy it for real on App Engine!

## Deploying to Google App Engine

Let’s login in the [Google Cloud Platform console](https://console.cloud.google.com)to create our application project. If you don’t already have an account, you can benefit from the [free trial which offers $300 of credits](https://cloud.google.com/free-trial/) for the full platform.

![](/img/src/app-engine-project-creation.png)

Be sure to pay attention to the actual project ID that will have been created, it may be slightly different than the project name itself. This project ID is also called the app ID, and that’s the actually what you have to put in the glide.groovy file, in the app.name field (right, it’s a bit confusing, isn’t it?)

When the project is created, you’re able to use the glide command-line to deploy the application:

```bash
$ glide upload
```

If you see an error like below in the logs, it might mean that there’s a problem with your app ID, so be sure to double check it’s correct:

> 403 Forbidden You do not have permission to modify this app (app_id=u's~my-tweet-demo').

Another occurrence of this error message is when you are using different accounts with Google Cloud Platform. For instance, in my case, I have both a personal gmail account for my personal apps, and a google.com account for my work related apps. I had to zap `~/.appcfg_oauth2_tokens_java` to let the upload logic to use the correct account, and ask me to authentication with OAuth2.

Once the upload succeeded, you can access your app here:

[http://my-tweet-demo.appspot.com](http://my-tweet-demo.appspot.com)

Hooray, you’ve done it! :-)
# What can we learn from million lines of Groovy code on Github?


Github and Google recently announced and released the Github archive to BigQuery, liberating a huge dataset of source code in multiple programming languages, and making it easier to query it and discover some insights.

Github explained that [the dataset comprises over 3 terabytes](https://github.com/blog/2201-making-open-source-data-more-available) of data, for 2.8 million repositories, 145 million commits over 2 billion file paths! The [Google Cloud Platform blog](https://cloudplatform.googleblog.com) gave some [additional pointers](https://cloudplatform.googleblog.com/2016/06/GitHub-on-BigQuery-analyze-all-the-open-source-code.html) to give hints about what’s possible to do with the querying capabilities of BigQuery. Also, you can have a look at the [getting started guide](https://cloud.google.com/bigquery/public-data/github) with the steps to follow to have fun yourself with the dataset.

My colleagues Felipe gave some [interesting stats](https://medium.com/@hoffa/github-on-bigquery-analyze-all-the-code-b3576fd2b150#.hxdz073uu) about the top programming languages, or licenses, while Francesc did some interesting [analysis of Go repositories](https://medium.com/google-cloud/analyzing-go-code-with-bigquery-485c70c3b451#.7qw4hmvly). So I was curious to investigate myself this dataset to run some queries about the [Groovy programming language](http://groovy-lang.org/)!

Without further ado, let’s dive in!

If you don’t already have an account of the Google Cloud Platform, you’ll be able to get the [free trial](https://cloud.google.com/free-trial), with $300 of credits to discover and have fun with all the products and services of the platform. Then, be sure to have a look at the [Github dataset getting started guide](https://cloud.google.com/bigquery/public-data/github#github) I’ve mentioned above which can give you some ideas of things to try out, and the relevant steps to start tinkering with the data.

In the Google Cloud Platform [console](https://console.cloud.google.com/), I’ve created an empty project (for me, called “github-groovy-files”) that will host my project and the subset of the whole dataset to focus on the Groovy source files only.

Next, we can go to the Github public dataset on BigQuery:  
[https://bigquery.cloud.google.com/dataset/bigquery-public-data:github\_repos](https://bigquery.cloud.google.com/dataset/bigquery-public-data:github_repos)

I created a new dataset called “github”, whose location is in the US (the default). Be sure to keep the default location in the US as the Github dataset is in that region already.

![](/img/bq-groovy/create-new-dataset-1.png)

![](/img/bq-groovy/create-new-dataset-2.png)

I launched the following query to list all the Groovy source files, and save them in a new table called “files” for further querying:

```sql
SELECT * 
FROM [bigquery-public-data:github_repos.files] 
WHERE RIGHT(path, 7) = '.groovy' 
```

Now that I have my own subset of the dataset with only the Groovy files, I ran a count query to know the number of Groovy files available:

```sql
SELECT COUNT(*) 
FROM [github-groovy-files:github.files] 
```

There are 743 070 of Groovy source files!

I was curious to see if there were some common names of Groovy scripts and classes that would appear more often than others:

```sql
SELECT TOP(filename, 24), COUNT(\*) as n 
FROM ( 
    SELECT LAST(SPLIT(path, '/')) as filename 
    FROM [github.files] 
) 
```

![](/img/bq-groovy/frequent-name-1.png) ![](/img/bq-groovy/frequent-name-2.png)

I was surprised to see A.groovy being the most frequent file name! I haven’t dived deeper yet, but I’d be curious to see what’s in those A.groovy files, as well as B.groovy or a.groovy in 4th and 13th positions respectively.

[Apache Groovy](http://groovy-lang.org/) is often used for various automation tasks, and I’ve found many Maven or Jenkins scripts to check that a certain task or job terminated correctly thanks to scripts called verify.groovy.

Files like `BuildConfig.groovy`, `Config.groovy`, `UrlMappings.groovy`, `DataSource.groovy`, `BootStrap.groovy` clearly come from the usual files found in [Grails framework](https://grails.org/) web applications.

You can also see configuration files like `logback.groovy` to configure the Logback logging library.

You don’t see usage of the [Gradle](https://gradle.org/) build automation tool here, because I only selected files with a .groovy extension, and not files with the .gradle extension. But we’ll come back to Gradle in a moment.

So far, we’ve looked at the file names only, not at their content. That’s where we need another table, coming from the “contents” table of the dataset, that we’ll filter thanks to the file names we’ve saved in our “files” table, thanks to this query:

```sql
SELECT * 
FROM [bigquery-public-data:github_repos.contents] 
WHERE id IN (
    SELECT id 
    FROM [github.files]
)
``` 

As this is a lot of content, I had to save the result of the query in a new table called “contents”, and I had to check the box “allow large results” in the options pane that you can open thanks to the “Show options” button below the query editor.

From the 743 070 files, how many lines of Groovy code do you think there are in them? For that purpose, we need to split the raw content of the files per lines, as follows:

```sql
SELECT COUNT(line) total_lines 
FROM ( 
    SELECT SPLIT(content, '\n') AS line 
    FROM [github-groovy-files:github.contents] 
) 
```

We have 16,464,376 lines of code over the our 743,070 Groovy files. That’s an average of 22 lines per file, which is pretty low! It would be more interesting to draw some histogram to see the distribution of those lines of code. We can use [quantiles](https://en.wikipedia.org/wiki/Quantile) to have a better idea of the distribution with this query with 10 quantiles:

```sql
SELECT QUANTILES(total_lines, 10) AS q 
FROM ( 
    SELECT COUNT(line) total_lines 
    FROM ( 
        SELECT SPLIT(content, '\n') AS line, id 
        FROM [github-groovy-files:github.contents] 
    ) 
    GROUP BY id
) 
```

Which gives this resulting table:

![](/img/bq-groovy/quantiles-lines.png)

There are files with 0 lines of code! And the biggest one is 9506 lines long! 10% are 11 lines long or less, half are 37 lines or less, etc. And 10% are longer than 149 lines.

Let’s now have a look at packages and imports for a change.

Do you know what are the most frequent packages used?

```sql
SELECT package, COUNT(*) count 
FROM ( 
    SELECT REGEXP_EXTRACT(line, r' (\[a-z0-9\\.\_\]\*)\\.') package, id 
    FROM ( 
        SELECT SPLIT(content, '\n') line, id 
        FROM [github-groovy-files:github.contents] 
        WHERE content CONTAINS 'import' 
        HAVING LEFT(line, 6)='import' 
    )
    GROUP BY package, id 
) 
GROUP BY 1 
ORDER BY count DESC 
LIMIT 30;
```

![](/img/bq-groovy/package-name-1.png) ![](/img/bq-groovy/package-name-2.png) ![](/img/bq-groovy/package-name-3.png)

The [Spock](http://docs.spockframework.org/) and JUnit testing frameworks are the most widely used packages, showing that Groovy is used a lot for testing! We also see a lot of [Grails](https://grails.org/) and [Gradle](https://gradle.org/) related packages, and some logging, some Spring, Joda-Time, Java util-concurrent or servlets, etc.

We can zoom in the `groovy.*` packages with:

```sql
SELECT package, COUNT(*) count 
FROM ( 
    SELECT REGEXP_EXTRACT(line, r' ([a-z0-9\._]\*)\.') package, id 
    FROM ( 
        SELECT SPLIT(content, '\n') line, id 
        FROM [github-groovy-files:github.contents] 
        WHERE content CONTAINS 'import' 
        HAVING LEFT(line, 6)='import' 
    ) 
    GROUP BY package, id 
) 
WHERE package LIKE 'groovy.%' 
GROUP BY 1 
ORDER BY count DESC 
LIMIT 10; 
```

And `groovy.transform` is unsurprisingly the winner, as it’s where all Groovy AST transformations reside, providing useful code generation capabilities saving developers from writing tedious repetitive code for common tasks (`@Immutable`, `@Delegate`, etc.) After transforms come `groovy.util.logging` for logging, `groovy.json` for working with JSON files, `groovy.sql` for interacting with databases through JDBC, `groovy.xml` to parse and produce XML payloads, and `groovy.text` for templating engines:

![](/img/bq-groovy/groovy-packages.png)

With Groovy AST transformations being so prominent, we can also look at the most frequently used AST transformations with:

```sql
SELECT TOP(class_name, 10) class_name, COUNT(*) count 
FROM ( 
    SELECT REGEXP_EXTRACT(line, r' [a-z0-9\._]*\.([a-zA-Z0-9_]*)') class_name, id 
    FROM ( 
        SELECT SPLIT(content, '\n') line, id 
        FROM [github-groovy-files:github.contents] 
        WHERE content CONTAINS 'import' 
    ) 
    WHERE line LIKE '%groovy.transform.%' 
    GROUP BY class_name, id 
) 
WHERE class_name != 'null' 
```

And we get:

![](/img/bq-groovy/frequent-ast-xforms.png)

The `@CompileStatic` transformation is the king! Followed by `@ToString` and `@EqualsAndHashCode`. But then `@TypeChecked` is fourth, showing that the static typing and compilation support of Groovy is really heavily used. Other interesting transforms used follow with `@Canonical`, `@PackageScope`, `@InheritConstructors`, `@Immutable` or `@TupleConstructor`.

As I was exploring imports, I also wondered whether aliased imports was often seen or not:

```sql
SELECT aliased, count(aliased) total 
FROM ( 
    SELECT REGEXP\_MATCH(line, r'.* (as) .*') aliased 
    FROM ( 
        SELECT SPLIT(content, '\n') AS line 
        FROM [github-groovy-files:github.contents] 
    ) 
    WHERE line CONTAINS 'import ' 
) 
GROUP BY aliased 
LIMIT 100 
```

Interestingly, there are 2719 aliased imports over 765281 non aliased ones, that’s about 0.36%, so roughly 1 `import … as …` for 300 normal imports.

And with that, that rounds up my exploration of Groovy source files on Github! It’s your turn to play with the dataset, and see if there are interesting findings to be unveiled! Did you find anything?
# Tale of a Groovy Spark in the Cloud


As I recently [joined Google]({{< ref "/posts/2016/06/02/joining-google-as-a-developer-advocate-for-the-google-cloud-platform" >}})’s developer advocacy team for [Google Cloud Platform](https://cloud.google.com/), I thought I could have a little bit of fun with combining my passion for [Apache Groovy](http://groovy-lang.org/) with some cool cloudy stuff from Google! Incidentally, Paolo Di Tommaso tweeted about his own [experiments with using Groovy with Apache Spark](https://twitter.com/PaoloDiTommaso/status/741290125947240448), and shared his [code on Github](https://github.com/pditommaso/gspark/blob/master/src/main/groovy/org/apache/spark/examples/GroovySparkPi.groovy):  

![](/img/spark-groovy/gspark-01.png)

I thought that would be a nice fun first little project to try to use Groovy to run a Spark job on Google Cloud [Dataproc](https://cloud.google.com/dataproc/)! Dataproc manages Hadoop & Spark for you: it’s a service that provides managed Apache Hadoop, Apache Spark, Apache Pig and Apache Hive. You can easily process big datasets at low cost, control those costs by quickly creating managed clusters of any size and turning them off where you’re done. In addition, you can obviously use all the other Google Cloud Platform services and products from Dataproc (ie. store the big datasets in Google Cloud Storage, on HDFS, through BigQuery, etc.)
  
More concretely,, how do you run a Groovy job in Google Cloud Dataproc’s managed Spark service? Let’s see that in action!

To get started, I checked out Paolo’s [samples](https://github.com/pditommaso/gspark) from Github, and I even groovy-fied the Pi calculation example (based on this [approach](https://en.wikipedia.org/wiki/Approximations_of_%CF%80#Summing_a_circle.27s_area)) to make it a bit more idiomatic:

```groovy
package org.apache.spark.examples

import groovy.transform.CompileStatic
import org.apache.spark.SparkConf
import org.apache.spark.api.java.JavaSparkContext
import org.apache.spark.api.java.function.Function
import org.apache.spark.api.java.function.Function2
import scala.Function0

@CompileStatic
final class GroovySparkPi {
 static void main(String[] args) throws Exception {
   def sparkConf = new SparkConf().setAppName("GroovySparkPi")
   def jsc = new JavaSparkContext(sparkConf)
   int slices = (args.length == 1) ? Integer.parseInt(args[0]) : 2
   int n = 100000 * slices
   def dataSet = jsc.parallelize(0..
   def mapper = {
     double x = Math.random() * 2 - 1
     double y = Math.random() * 2 - 1
     return (x * x + y * y < 1) ? 1 : 0
   }
   int count = dataSet
           .map(mapper as Function)
           .reduce({int a, int b -> a + b} as Function2)
   println "Pi is roughly ${4.0 * count / n}"
   jsc.stop()
 }
}
 
```
  
You can also use a Groovy script instead of a full-blown class, but you need to make the script serializable with a little trick, by specifying a custom base script class. You need a custom Serializable Script:

```groovy
import groovy.transform.BaseScript

@BaseScript SerializableScript baseScript
```
  
And in your job script, you should specify this is your base script class with: 

```groovy
abstract class SerializableScript extends Script implements Serializable {}
```

The project comes with a Gradle build file, so you can compile and build your project with the gradle jar command to quickly create a JAR archive.

Now let’s focus on the Cloud Dataproc part of the story! I basically simply followed the [quickstart guide](https://cloud.google.com/dataproc/quickstarts/quickstart-console). I used the Console (the UI web interface), but you could as well use the [gcloud](https://cloud.google.com/sdk/gcloud/) command-line tool as well. You’ll need an account of course, and enable billing, as running Spark jobs on clusters can be potentially expensive, but don’t fear, there’s a [free trial](https://cloud.google.com/free-trial) that you can take advantage of! You can also do some quick computation with the [calculator](https://cloud.google.com/products/calculator) to estimate how much a certain workload will cost you. In my case, as a one time off job, this is a sub-dollar bill that I have to pay.
  
Let’s create a brand new project: 

![](/img/spark-groovy/gspark-02.png)  

We’re going to create a Spark cluster, but we’ll need to enable the Compute Engine API for this to work, so head over to the hamburger menu, select the API manager item, and enable it:

![](/img/spark-groovy/gspark-04.png)  

Select the Dataproc menu from the hamburger, which will allow you to create a brand new Spark cluster:

![](/img/spark-groovy/gspark-03.png)

Create a cluster as follows (the smallest one possible for our demo):

![](/img/spark-groovy/gspark-05.png) 

Also, in case you have some heavy & expensive workloads, for which it doesn’t matter much if they can be interrupted or not (and then relaunched later on), you could also use [Preemptible VMs](https://cloud.google.com/preemptible-vms/) to further lower the cost.
  
We created a JAR archive for our Groovy Spark demo, and for the purpose of this demo, we’ll push the JAR into Google Cloud Storage, to create Spark jobs with this JAR (but there are other ways to push your job’s code automatically as well). From the menu again, go to Cloud Storage, and create a new bucket:  

![](/img/spark-groovy/gspark-14.png)  

Create a bucket with a name of your choice (we’ll need to remember it when creating the Spark jobs):  

![](/img/spark-groovy/gspark-15.png)  

Once this bucket is created, click on it, and then click on the “upload files” button, to upload your JAR file:  

![](/img/spark-groovy/gspark-16.png)  

We can come back to the Dataproc section, clicking on the Jobs sub-menu to create a new job:  

![](/img/spark-groovy/gspark-26.png)  

We’ll create a new job, using our recently created cluster. We’ll need to specify the location of the JAR containing our Spark job: we’ll use the URL `gs://groovy-spark-demo-jar/spark-groovy-1.1.jar`. The `gs://` part corresponds to the Google Cloud Storage protocol, as that’s where we’re hosting our JAR. Then groovy-spark-demo-jar/ corresponds to the name of the bucket we created, and then at the end, the name of the JAR file. We’ll use an argument of 1000 to specify the number of parallel computations of our Pi approximation algorithm we want to run:
  
![](/img/spark-groovy/gspark-27.png)  

Click `Submit`, and here we go, our Groovy Spark job is running in the cloud on our 2-node cluster!  

![](/img/spark-groovy/gspark-28.png) 

Just a bit of setup through the console, which you can also do from the command-line, and of course a bit of Groovy code to do the computation. Be sure to have a look at the [quick start guide](https://cloud.google.com/dataproc/quickstarts/quickstart-console), which gives more details than this blog post, and you can look at some other [Groovy Spark samples](https://github.com/pditommaso/gspark/tree/master/src/main/groovy/org/apache/spark/examples) thanks to Paolo on his Github project.
# Joining Google as a Developer Advocate for the Google Cloud Platform


The cat is out the bag: I'm joining Google on June 6th, as a **Developer Advocate** for the **Google Cloud Platform** team!

My Groovy friends will likely remember when I launched [Gaelyk](http://gaelyk.org/), a lightweight toolkit for developing Groovy apps on Google App Engine? Since then, I've always been a big fan of the [Google Cloud Platform](https://cloud.google.com/) (although it wasn't called that way then) and followed the latest developments of the whole platform. And wohhh, so many new[ services and products](https://cloud.google.com/products/) have seen the light of day since my early experiments with App Engine! So there will be a lot to learn, a lot to do, and thus, a lot to advocate! 

I'm really happy and excited to join the [Google Cloud Platform](https://cloud.google.com/solutions/) team! I'm looking forward to working with my new team, and join some good old Googler friends I've came to know throughout my career.

I've been really pleased to work with my friends at [Restlet](https://restlet.com/) for the past year and a half, made friends, and learnt a lot along the way working with my colleagues. I wish them luck for their great [Web API platform](https://restlet.com/platform/), and I'll continue to follow their progress!
# A Groovy journey in Open Source land (GR8Conf Europe)


Direct live from [GR8Conf Europe 2016](http://gr8conf.eu/#/), in Copenhagen, Denmark! This morning, I presented my latest [update about the Apache Groovy history, and the latest developments](https://speakerdeck.com/glaforge/a-groovy-journey-in-open-source-land) in the 2.4.x and future 2.5 branches.  
Abstract:  

> In dog years... err... Open Source years, the Groovy programming language project is a very mature and successful one, as its 12 million downloads a year can attest. The Groovy language is certainly the most widely deployed alternative language of the JVM today. But how do we go from a hobby night & week-end project to professionally company sponsored? And back again to hobby mode but joining the wider Apache Software Foundation community?  
>
> Guillaume will guide you through the history of the project, its latest developments, and its recent news, outlining the importance of a community around an Open Source project.  
>
> Also, we'll discuss what it means to contribute, when it's your hobby or as a paid committer -- what does it change? What it means to join the Apache community, what the impact of professional Open Source is, and more.

And here are the slides:

{{< speakerdeck beca9cd406a84e7c8f4a34374cdb458c >}}
# Get in the flow! The API developer workflow!


What are the activities of the Web API developer? How API tooling should not get in the way of developer's productivity? I presented a talk on this topic at the GlueCon conference:  

> The API ecosystem provides powerful tools, online services and definition formats for designing, testing, running, or managing APIs. All share common purposes: improve our productivity when developing an API, allow us to collaborate more effectively, or share our creations with the world!  
>
> But developers have already invented efficient tactics to streamline their development, gathered experience with and sharpened their tools of trade. The result is that the services or formats mentioned before can actually also get in their way, and interrupt their development flow, as they have to resort to get out of their routine and processes, to use them.  
> 
> What can API tooling vendors do to reconcile the habits of developers with their tools? In this session, Guillaume Laforge, Restlet's Product Ninja & Advocate, will talk about building, versioning & dependency management of API artifacts, scenario & conformance testing, API documentation, continuous integration, multi-environment continuous deployment, and team collaboration! Let’s get back into the development flow!

{{< speakerdeck 66dea0c6069e42969fd55002089b11f7 >}}

# A five-sided prism polarizing Web API development


At GlueCon, I presented about the 5-sided prism that polarizes Web API development:  

> How do you tackle your API development? Are you diving head-first in the code to get something quickly out the door? Do you start by defining the API contract, that you'll share between your teams and the consumers? Perhaps you prefer to describe your acceptance tests, explaining the behavior you expect from your API. But if you're a storyteller, you'll probably write some use cases, scenarios, to have a better feel for what your API is all about, and how your users will take advantage of it. Or simply, you already have data lying around that wants to set free, and be exposed restfully to the world.  
>
> In this session, Guillaume Laforge, Restlet's Product Ninja & Advocate, will highlight different approaches to Web API development, along with their pros & cons. Whether you're starting with code, a contract, tests, documentation, or data, you'll get a glimpse of light into the tasty book of API development recipes.

{{< speakerdeck 52db3b6495bf4d7c8a298193fa350284 >}}

# A web API for each API consumer?


At our disposal, we have so many ways to interact with an API: from a mobile on iOS or Android, from a web application, or from other services or microservices. And all of them have different needs: one wants only a shallow overview of the data, while the other desires a detailed view of a certain resource and all its sub-resources. It's becoming difficult to design an API that caters to the needs of those varied consumers.  

So what can we do? There's a trend around providing different API facades for each consumer, as Netflix does with its [experience and ephemeral APIs](http://www.infoq.com/articles/api-facades), or how Sam Newman described it in its [Backends for Frontends](http://samnewman.io/patterns/architectural/bff/) pattern. But such an approach increases the maintenance burden and complexity, and might only really make sense for big enough teams.  

Other approaches exist for customizing payloads for different consumers, without really providing as many derived API facades as you have API consumers. You can take advantage of the Prefer header, fields filtering, custom Mime media types, hypermedia, or Facebook's GraphQL approach.  

I've written an article for InfoQ that dives into this topic, and covers all those subjects: "[One API, many facades](http://www.infoq.com/articles/api-facades)".
# How far should API definition languages go?


I had the pleasure of writing an [article](http://nordicapis.com/how-far-should-api-definition-languages-go/) for Nordic APIs on Web API definition languages.  

If you're into the world of Web APIs, you've probably heard of formats like [Swagger](http://swagger.io/), [RAML](http://raml.org/) or [API Blueprint](https://apiblueprint.org/). They allow developers to define the contract of the API, with its endpoints, its resources, its representations, allowed methods, the kind of payloads it understands, the status codes returned, and more.  

With the contract of your Web API, you can generate code for your backend implementation or client kits, documentation for publishing the details of your API for your API consumers. This contract becomes a key element of your API strategy: a contract between the frontend team and backend team to be sure to work on the same ground, between your tech team implementing the public API of your company and all the API consumers that will interact with it.  

But API definition languages don't necessarily denote all the fineness of your API, in particular its business rules, or how to check that an implementation conforms to a contract or if the implementation follows the style guides of your company, what tests could exhibit the behavior of the API, and more. So the questions I asked myself was [how far should API definition languages go](http://nordicapis.com/how-far-should-api-definition-languages-go/)!
# How far should API definition languages go


![How-far-should-api-definition-languages-go](https://nordicapis.com/wp-content/uploads/How-far-should-api-definition-languages-go-1.png)

The most common API definition languages we spot in the wild are [Swagger](https://swagger.io/) / [OpenAPI Spec](https://openapis.org/), [RAML](https://raml.org/) and [API Blueprint](https://apiblueprint.org/). All three let you define your endpoints, your resources, your query or path parameters, your headers, status codes, security schemes, and more.

In a nutshell, these definition languages define the **structure** of your API, and allow you to describe many **elements**. As standards in the API industry evolve, however, their purpose and design are under continuous scrutiny. Specifically, the extensibility of API specifications with additional elements and feature sets comes into question.

Recently, a discussion sparked on the [Open API Specification](https://nordicapis.com/open-api-initiative-means-api-space/) issue tracker about the [Open World vs Closed World principles](https://nordicapis.com/evolution-openapi-specification-openapi-mean-open-world/). In a nutshell, the question is whether an API definition is supposed to describe an API fully (including, for example, the paths that you're not allowed to access, all the possible status codes, etc.) or whether it is just a best effort to describe what's usable and needed by most API consumers --- not necessarily covering the whole scope of the API.

All the recent conversation has us thinking --- **how detailed should API definitions be**?. One can dream up many other uses for an API definition language:

-   API definitions could bring additional information or documentation, with a narrative and more metadata describing the flow of API calls, how the callers will be able to interact with the API.
-   API providers can bring such extra metadata for the purpose of API discovery, to give credits (about IP or copyright information), perhaps residing in external descriptors like [APIs.json](https://apisjson.org/) (a format to help discover metadata about an API).
-   JSON payloads comply with JSON schemas, but data models could be defined regardless of the media types being chosen by the consumer, so that the consumer could actually request any output format, but still understand the intrinsic nature of the resources which are dealt with.
-   There are often common traits spreading across an API, for example how to do pagination, and some API definitions are able to factor this common aspect in a reusable and referenceable fashion.
-   Hypermedia APIs are not necessarily well covered in terms of modeling throughout the most common API specifications, there's certainly something to be improved here.
-   Another interesting topic is also about how to ensure that an API implementation conforms with its API definition, or follows some some good conventions or company guidelines. Tooling could be provided to help with this task.

[RAML is approaching 1.0](https://raml.org/blogs/update-raml-10-current-status), [OpenAPI Spec is being worked on](https://github.com/OAI/OpenAPI-Specification/issues?q=is%3Aissue+is%3Aopen+label%3A%22OpenAPI.Next+Proposal%22) with a list of issues detailing what to expect, and [API Blueprint published its roadmap](https://github.com/apiaryio/api-blueprint/wiki/Roadmap). As our favorite specifications will soon see interesting evolutions, it's a great time to revisit the dialectic on API definition language design.

Let's look a little bit closer at some of the propositions above to see if API definitions provide solutions, and discuss if it's even the purpose of an API definition language to do these sort of things. What could we build into the next generation of API specifications to make them truly remarkable?

## API Storytelling: Modeling Multi-Step Transactions within Documentation

API providers need to be storytellers. When you design an API for a user base, you want to tell them a story --- how they access the API with an API key, how they interact with the API, and what the common traits for various resources are (pagination).

Often, to conduct a certain business use case you must issue several calls in a row: first you get the details of an order, then you ask for the details of the customer, and lastly perhaps their delivery address. So you **chain calls**, using elements of the response of the previous call to craft the subsequent request. Sometimes, you have different payloads, with or without embedded entities; an order call may contain all the details of the customer and its address, or it may not.

How can a provider explain the logical scenario of calls? A page published within the API documentation should describe such scenarios, and regroup logical series of calls together in a coherent story --- the use cases of the API. Though you can provide descriptions of API parameters using current definition languages, there is no way to tie elements together in a cohesive **workflow**. An API definition with the power to tell **API stories** that describe common instances of multi-step transactions could be very powerful.

## Test Scenarios

Related to these use cases, having **tests** corresponding to those scenarios would be handy. For instance, [DHC by Restlet](https://nordicapis.com/10-continuous-integration-tools-spur-api-development/#dhc) has its own test scenario definition format that you can use to run tests from a Maven plugin, or within your [Continuous Integration pipeline](https://nordicapis.com/reach-devops-zen-with-these-continuous-integration-tools/) with the Jenkins server. Could such scenario tests be derived from the API definition, or embedded within the API definition itself? Interestingly, the [API Blueprint roadmap lists scenarios and testing](https://github.com/apiaryio/api-blueprint/issues/21), so this might be coming sooner than later.

## Documentation vs Specification

It's easy to mix up the difference between the **API definition format** with the published **API documentation**. Though they *are* different entities, you can generate the documentation from the definition --- there's no denying the two are intimately linked. If they were completely separate, API definition formats wouldn't even have any description tags at all, as the format would probably only be used for [machine-consumption](https://nordicapis.com/designing-apis-machines/), and not for [human-consumption](https://nordicapis.com/designing-apis-humans/).

Using API definitions, you can derive implementation for skeletons for your [API or client SDKs](https://restlet.com/blog/2015/04/28/easy-client-sdk-and-server-skeleton-generation-for-your-apis/). But you can also generate beautiful and comprehensive documentation: perhaps just static HTML documentation, or spiced up with sprinkles of JavaScript to provide an interactive playground to try out the API directly, or go full steam with hosting that definition in a full-blown [API developer portal](https://nordicapis.com/beautiful-ui-design-for-api-developer-portals/) where you could add collaboration capabilities, versioning information, and more. As the end user documentation as well as [SDKs and libraries](https://nordicapis.com/description-agnostic-api-development-with-api-transformer/) can be derived form the core API definition, the two are inherently linked.

## Style Guide, Conformance and Tooling

In designing an API, your company probably has already created a set of guidelines, or **best practices** to follow. For instance, look at [Paypal's API style guide](https://github.com/paypal/api-standards/blob/master/api-style-guide.md). The document describes the general structures of URIs, a mandatory namespace element, a paging method that should remain consistent, and more. Your own guidelines might specify naming conventions, like the use of camel-case.

**It would be handy to automatically assess if the API actually conforms to those guidelines**. Maintaining this type of conformance could be part of the API definition itself, or exist as an external document that is referenced from the API definition. This could require a new format that describes these conventions rules, leading one to consider if such guidelines should be declaratively-defined, or if a scripting language could be used for more advanced validation needs.

Along with having a special guideline description file, tools would be needed to check that the implementation of the API really conforms to those guidelines! This tooling would likely not be part of an API definition format, but could accompany it, and be offered in various languages and technology stacks that anyone can feel at home with.

## Hypermedia

One of the key tenets of the **REST** architectural style coined by Roy Fielding is hypermedia, with hypermedia as the engine of application state (HATEOAS). More APIs are conforming to this constraint, and several approaches exist to define those hypermedia links --- [we've defined HAL, JSON-LD, and Siren hypermedia types in a past blog post](https://nordicapis.com/designing-evolvable-apis-for-the-web-formats/#hypermediatypesforwebapis).

Even though the concept is popular, API languages often don't let you easily describe such hypermedia-driven APIs. Shouldn't they help users describe such metadata and hyperlinks? Zdenek Nemec of Apiary gave an example [implementation of HAL for an API](https://gist.github.com/zdne/988a54c03609655f47b7#file-rendered-md), using the new MSON modeling capabilities of API Blueprint. Perhaps in the near future, API languages will support a particular flag to denote what hypermedia approach the API is using.

## Data and Payload Modeling

Speaking of [MSON](https://github.com/apiaryio/mson) (Markdown Syntax for Object Notation), it's also an interesting take on modeling your API payloads. With a convenient and readable format, which is neither JSON schema nor XML schema, you can describe what your data will look like, regardless of the underlying media type being used.

This beckons the question whether any possible payload can be supported that way. After all, esoteric APIs will probably not conform with JSON schema, XML schema, or MSON. There are likely going to be expressivity differences between them all. Should API definition languages be prescriptive, and limit to the 80/20 sane use cases of data modeling?

Another example is Apigee's recent [Rapier API specification](https://apigee.com/about/blog/developer/rapier-cut-through-tedium-api-specification), whose goal is to describe data-oriented APIs with entities and their relationships. Rapier might possibly be contributed to the OpenAPI Specification at some point, but there are clear limits in terms of expressivity.

## API Definition Extensions

Although API definition languages don't necessarily provide all those bells and whistles, an important aspect is **extension**. For example, [Swagger / OpenAPI Spec provides the notion of extensions](https://swagger.io/specification/#vendorExtensions). API designers have the ability to define custom fields (following a convention) within which they can stuff any data or metadata they want! So if you want to add guideline documentation pointers, or associated tests, you could very well add them as custom extensions. Then, your own tools can grok those specific extensions and deal with them however you like.

For instance, [tools translating from one API language to another](https://restlet.com/blog/2015/10/26/importing-and-translating-raml-api-definition/) can store custom extensions that describe how to best do the translation, in particular in the case that one specification doesn't support certain metadata that the other supports. Let's keep in mind one downside of custom extensions though: They are not understood by all the tools and vendors, and are somewhat proprietary and non portable. So use at your own risk!

## Final Thoughts

Right, so shoud API definition languages provide everything and the kitchen sink? If so, what's the threshold? Where do we put the cursor? Or --- should an API definition simply stick to describing the various API elements, and then leverage a complementary format like [APIs.json](https://apisjson.org/) to add and link to additional resources?

It is apparent that there are benefits to pushing API definition languages a bit further and providing more information than they do. Extensions are the way to go, as long as we define, publish and share such extensions in a somewhat standardized fashion. But some definitely feel the need for going further than what is offered today. What's your take on that? Where would you put the cursor?
# One API, many facades?


An interesting trend is emerging in the world of Web APIs, with various engineers and companies advocating for dedicated APIs for each consumer with particular needs. Imagine a world where your system needs to expose not only one API for iOS, one API for Android, one for the website, and one for the AngularJS app front end, but also APIs for various set-top boxes and exotic mobile platforms or for third-party companies that call your API. Beyond any ideal design of your API, reality strikes back with the concrete and differing concerns of varied API consumers. You might need to optimize your API accordingly.

## Experience APIs

On InfoQ, Jérôme Louvel (chief geek and co-founder of [Restlet](http://restlet.com/)) interviewed Daniel Jacobson (vice president of edge engineering at [Netflix](http://www.netflix.com/)) about Netflix's e[xperience APIs and ephemeral APIs](http://www.infoq.com/news/2015/11/daniel-jacobson-ephemeral-apis). Daniel's team is responsible for handling all traffic for signup, discovery, and playback of videos on devices around the world. With the concept of experience APIs, Netflix creates special APIs to handle optimized responses for a given requesting agent. With ephemeral APIs, Netflix engineers iteratively transition and evolve those experience APIs.

The goal of experience APIs is to solve problems Netflix has encountered while scaling its platform to more than 60 million consumers on dozens of devices with different characteristics. Offering such dedicated APIs allowed Netflix to provide the best user experiences possible across all devices and to optimize bandwidth according to a device's screen size for less latency and data consumption. It let Netflix engineers progress rapidly and independently from the core back-end teams, in isolation, with their own versioning scheme and orchestrating their own deployments.

At Netflix, dedicated teams take care of those experience APIs. It's not the central or core API team that is responsible for all the APIs derived for each and every possible client. There aren't many companies with the same scale as Netflix, and just because Netflix builds dedicated APIs for all API consumers doesn't mean it makes sense for your own context. For small shops, maintaining and evolving too many API front ends could be ineffective or even an anti-pattern, as the cost would be pretty high. Netflix had to build a special API platform to support this approach.

## Microservices architectures

With the trend towards microservices-based architectures, the [API gateway](http://microservices.io/patterns/apigateway.html) or API facade is making a resurgence. Your architecture is scattered among several small services and you need to have front-facing services responsible for exposing an API to consumers. So it's not all that surprising that by having many microservices you can also have multiple facades for your consumers.

A gateway or facade will let a consumer make just one call instead of forcing the consumer to make multiple calls to several underlying microservices. This alone is easier for the API consumer and the benefit increases with a smarter gateway or façade that takes advantage of caching (because multiple calls still need to be made), applies security concerns (authentication, authorization), or implements rules (rate limitation, IP filtering). The API provider can control how the consumers use its API.

Gateways, from vendors or built in-house like Netflix's, also add complementary value like edge services (an API infrastructure in the DMZ of the company can be used in novel and interesting ways, like how Netflix uses Zuul for multiregion resiliency) or pipelining or filter chaining (which help extract crosscutting concerns and implement enterprise-wide patterns).

Back ends for front ends
------------------------

In a [recent article](http://www.infoq.com/news/2015/12/bff-backend-frontend-pattern), Sam Newman looks at this approach of dedicated consumer APIs as a pattern named "[Backends for Frontends](http://samnewman.io/patterns/architectural/bff/)" (BfFs). Instead of a general-purpose API for all clients, you can have several BfFs: one for a Web front end, one for mobile clients (or even one for iOS and one for Android), and more.

[SoundCloud adopted the BfF pattern](https://www.thoughtworks.com/insights/blog/bff-soundcloud), with API front ends for the iOS platform, the Android platform, the website, and for web-embedding. As is the case at Netflix, it seems that this technique works best when there are dedicated teams responsible for those front ends. If you have only one team taking care of the back end and its API, you'd better not overload them with a large number of variations for different consumers.

Getting back to microservices, BfF can also make sense for migration: when migrating a monolith to microservices, one BfF can call into the monolith while other BfFs could call the new microservices instead, following the [Strangler pattern](http://www.martinfowler.com/bliki/StranglerApplication.html) where you progressively move away from the legacy code to adopt newer evolutions.

A monolith is complex, easily accumulates technical debt, and mixes too many concerns at the same time, while microservices help you focus on one particular concern at a time. But microservices architectures also have drawbacks. You have to operate and orchestrate them, and they may have to evolve at a different pace from one big monolith. Maintaining consistency between all services in such distributed systems is not easy, either. Communication among many microservices might introduce additional latency because of communication delay. The consensus around the duplication and denormalization of data for each microservice can also complicate data management and consistency. [Microservices are not a free lunch](http://highscalability.com/blog/2014/4/8/microservices-not-a-free-lunch.html), and you can read more on some microservices anti-patterns with Vijay Alagarasan's [anti-patterns article](http://www.infoq.com/articles/seven-uservices-antipatterns), or on Tareq Abedrabbo's "[The 7 Deadly Sins of Microservices](https://www.opencredo.com/2014/11/19/7-deadly-sins-of-microservices/)".

The deciding factor for choosing to use experience APIs or BfF could very well be having dedicated teams for them or not. If you're small and have only one team to take care of the back end and the front-facing or edge Web APIs, it might be more complicated for you to take care of the many variants (think maintenance costs) but if you're large enough, teams can more easily take ownership of these front-end APIs and evolve them at their own pace.

## APIs as a team-communication pattern

While companies are organized as teams, I see more and more instances where developers are separated into front-end developers (whether Web or mobile) and back-end developers who implement the APIs needed for the Web or mobile devices. Web APIs have become central to the way projects are delivered: APIs are the contract that binds the different teams together and allows them to collaborate efficiently.

When developing an API that is going to be used by others, it's important not to break that contract. Often, frameworks and tools allow you to generate an API definition from the codebase --- for example, with an annotation-driven approach where you label your endpoints, query parameters, etc. with annotations. But sometimes, even if your own test cases still pass, the smallest code refactoring could very well break the contract. Your codebase might be fine, but the refactoring might have broken the code of your API consumers. To collaborate more effectively, consider going with an API-contract-first approach and make sure your implementation still conforms with the shared agreement: the API definition. There are different API definition languages available and popular these days, like [Swagger](http://swagger.io/) ([Open API specification](https://github.com/OAI/OpenAPI-Specification)), [RAML](http://raml.org/), or [API Blueprint](https://apiblueprint.org/). Pick one you're comfortable with.

Working with an API definition has a few advantages. First of all, it should make it more difficult to break compatibility as your implementation has to conform to the API definition. Secondly, API definitions are pretty well equipped in terms of tooling. From API definitions, you can generate client SDKs that your API consumers can integrate in their projects to call your API or even server skeletons to generate the initial implementation of your service. You can also create mocks of your APIs, which developers can easily call while the underlying API is being built, without juggling the different development cycles of the producers and consumers of APIs. Each team can work at its own pace! However, it's not just about code or compatibility but also about documentation. API-definition languages also help when documenting your API, with nicely generated documentation that shows the various endpoints, query parameters, etc., as well as (sometimes) offering an interactive console, which allows you to easily craft calls to the API.

## Different payloads for different consumers

Adopting an API-contract-first approach is certainly helpful and provides benefits, but what can you do when different clients have different API needs? Particularly, if you don't have the luxury of dedicated teams taking ownership of different API facades, how can you make your API meet the needs of all your API consumers?

In a recent article on InfoQ, Jean-Jacques Dubray explained why he [stopped using MVC frameworks](http://www.infoq.com/articles/no-more-mvc-frameworks). In the introduction, he explained how mobile or front-end developers frequently asked for APIs tailored for their UI needs, regardless of a sound data model for the underlying business concepts. The state-action-model (SAM) pattern that Dubray described nicely supports the BfF approach. SAM is a new, reactive functional pattern which simplifies fronted architectures by clearly separating the business logic from the effects, in particular decoupling back-end APIs from the view. As the state and model are separate from actions and views, the actions can be specific for a given front end or not appear at all: it's up to you to decide where to put the cursor. You may also generate the state representation or view from the central back end or by those intermediary facades.

A website or single-page application might need to display a detailed view of a product and all its reviews, but perhaps a mobile device will only show the product details and its rating, letting the mobile user tap to load the reviews afterwards. Depending on the UI, the flow, the actions available, the level of detail, and the entities retrieved might be different. Typically, you'd like to diminish the number of API calls to retrieve data on a mobile device because of connectivity and bandwidth constraints, and you want the payload returned to contain only what's required and nothing more. But this doesn't matter that much for the Web front end, and with asynchronous calls, you're totally fine with loading more content or resources lazily. In either case, APIs should obviously respond rapidly, and have a good service-level agreement. But what are the options for delivering multiple customized APIs to different consumers?

## Specific endpoints, query parameters, and fields filtering

A basic approach could be to provide different endpoints (`/api/mobile/movie` versus `/api/web/movie`) or even simply query parameters (`/api/movie?format=full` or `/api/movie?format=mobile`), but there are perhaps more elegant solutions.

Similar to query parameters, your API might be able to customize returned payloads by letting the consumer decide which fields he or she wants, like: `/api/movie?fields=title,kind,rating`, or `/api/movie?exclude=actors`.

With fields filtering, you may decide also if you want to get related resources in response: `/api/movie?includes=actors.name`.

## Custom MIME media types

As the implementor of the API, you have options. You might decide not to offer any customization at all! Consumers will either have to go with what you offer or wrap your API inside their own facade into which they've built the customization they want. But since you're a great person, you could offer them profiles: you can be creative with media types and offer a leaner or richer payload depending on the media type a consumer requests. For instance, if you look at the [GitHub API](https://developer.github.com/v3/media/), you'll notice types like: `application/vnd.github.v3.full+json`

Along with a "full" profile that offers the whole payload and related entities, you can provide a "mobile" variant, and perhaps a "minimal" one too.

The API consumer makes a call that requests the media type that fits his/her use case the most.

## Prefer header

Irakli Nadareishvili wrote about [client-optimized resource representations in APIs](http://www.freshblurbs.com/blog/2015/06/25/api-representations-prefer.html), mentioning a lesser-known header field: the Prefer header ([RFC 7240](https://tools.ietf.org/html/rfc7240)).

As with custom media types, a client would request a certain profile using the Prefer header: using `Prefer: return=mobile` would have the API reply with a customized payload and the header `Preference-Applied: return=mobile`. Note that the Vary header should also mention that the Prefer header is available.

Depending on whether you, the API developer, want to be in charge of deciding what kind of payloads you support, you might like the custom media type, the Prefer header, or dedicated endpoints. If you want to let clients decide more explicitly what kind of fields and relationships to retrieve, you could opt for field filtering or query parameters.

## GraphQL

With its [React](https://facebook.github.io/react/) view framework, Facebook [introduced](https://facebook.github.io/react/blog/2015/05/01/graphql-introduction.html) developers to [GraphQL](https://facebook.github.io/graphql/). Here, consumers are in total control of what they'll receive: the fields and relationships. The consumer issues a call that specifies what the return payload should look like:

```graphql
{
  user(id: 3500401) {
    id,
    name,
    isViewerFriend,
    profilePicture(size: 50)  {
      uri,
      width,
      height
    }
  }
}
```

And the API should reply with the following payload:

```json
{
  "user" : {
    "id": 3500401,
    "name": "Jing Chen",
    "isViewerFriend": true,
    "profilePicture": {
      "uri": "http://someurl.cdn/pic.jpg",
      "width": 50,
      "height": 50
    }
  }
}
```

GraphQL is at the same time a query and a description of what you'd like the answer to this query to be. GraphQL lets API consumers totally control what they'll get in return, offering the highest level of flexibility.

A similar approach exists in specifications like OData, which lets you customize the payloads with [$select, $expand, and $value parameters](http://www.asp.net/web-api/overview/odata-support-in-aspnet-web-api/using-select-expand-and-value). But OData has not really caught on and might be on the verge of abandonment; [Netflix and eBay stopped supporting OData](http://www.ben-morris.com/netflix-has-abandoned-odata-does-the-standard-have-a-future-without-an-ecosystem/) a while ago. That said, other actors like Microsoft and SalesForce do still support it.

## Hypermedia APIs

One last option to explore is hypermedia APIs. When thinking of hypermedia APIs, you often think of all the additional hyperlinks that clutter responses and that could easily double the payload size. Payload size and number of calls really matter to a mobile device. Despite that, it's important to think of hypermedia through HATEOAS (Hypermedia as the engine of application state), a core tenet of REST APIs that is often overlooked. It's about the capabilities offered by the API. A consumer will have access to related resources, but links offered through those hypermedia relations can also be about giving different profiles to choose from, like:

```json
{
    "_links": {
        "self": { "href": "/movie/123" },
        "mobile": { "href": "/m/movie/123" },
    }
}
```

Additionally, certain hypermedia approaches fully embrace the notion of embedding related entities. Hydra, HAL, and SIREN provide the ability to embed sub-entities, so that you could retrieve a particular movie and the embedded list of all the actors in that movie.

From an article on [how to choose a hypermedia format](http://sookocheff.com/post/api/on-choosing-a-hypermedia-format/), Kevin Sookocheff gives an example showing how accessing a "player's list of friends" resource also embeds the actual representations of those friends and not just links to those individual resources, thus eliminating calls to each friend resource:

```json
{
  "_links": {
    "self": { "href":
        "https://api.example.com/player/1234567890/friends"
    },
    "size": "2",
    "_embedded": {
      "player": [
        {
          "_links": {
            "self": { "href":
                "https://api.example.com/player/1895638109" },
            "friends": { "href":
                "https://api.example.com/player/1895638109/friends" }
          },
          "playerId": "1895638109",
          "name": "Sheldon Dong"
        },
        {
          "_links": {
            "self": { "href":
              "https://api.example.com/player/8371023509" },
            "friends": { "href":
                "https://api.example.com/player/8371023509/friends" }
            },
            "playerId": "8371023509",
            "name": "Martin Liu"
      }
    ]
  }
}

```

## Summary

Web APIs increasingly have several kinds of consumers with different needs. Microservice architectures can encourage us to deploy fine-grained API facades for those needs (the so-called experience APIs or BfF patterns), but this can become an anti-pattern if you have too many distinct consumers to please, especially if you've got only a small team to take care of all those front ends.

Be sure to do the math! Before going one way or another, you have to study the cost of your options and whether or not you can support them. [Creating different variants of an API has a cost](http://www.ebpml.org/blog15/2013/11/understanding-the-costs-of-versioning-an-api-or-a-service/), for the implementor as well as for the consumer, that depends on the adopted strategy. Also, once you've unleashed your API and given it to its consumers, perhaps it's also time to rethink  and refactor this API, as maybe you didn't take those special device or consumer requirements well enough into account during the design phase.

If you have dedicated teams for these API facades, then it's an option to consider. When you don't have that luxury, there are other ways to customize payloads for your consumers without the induced complexity, with simple tricks like field filtering or the Prefer header up to full-blown solutions like custom media types or specifications like GraphQL.

But you don't necessarily need to fire the big guns, and could opt for a middle path: one main, full API plus one or two variants for mobile devices, and you are likely going to meet the requirements of all your consumers. Consider including a pinch of field filtering, and everybody will be happy with your APIs!
# Groovy default params to avoid one-argument methods being called without params


Recently, I saw an interesting [tweet](https://twitter.com/djsmith42/status/679018096334675968), mentioning a JavaScript trick using default parameters to make a parameter mandatory.  

![](/img/misc/default-param-mandatory-javascript-trick.png)  

In a language like [Apache Groovy](http://www.groovy-lang.org), when statically compiled, you'd get a compilation error if you forgot a parameter, because the signature couldn't be found by the compiler. In dynamic mode, you'd get a runtime error though, with a MissingMethodException (and the error message should give you a hint as to which method you should actually call instead).  

But there's a particular case of the Groovy method dispatch that's a bit special (and actually something we might be removing at some point in a breaking version of the language, but it's been there since 1.0). When you have single-argument methods, you're allowed to call those methods without passing a parameter! And the parameter is filled simply with null. So you might have made a mistake in your code, forgetting to pass an actual parameter value, but you'd get neither a compilation error nor a runtime exception, but a null value.  

So I thought about that JavaScript trick, and adapted to this situation, to ensure that you can't call a one-argument method without an argument.  

```groovy
String up(String s) {
    s?.toUpperCase()
}

assert up('groovy') == 'GROOVY'

// a strange aspect of Groovy is that 
// you can call a one-argument method without passing any actual argument
// as if you were passing null, as in up(null)

assert up() == null

// let's use the JavaScript trick with mandatory default params:
// https://twitter.com/djsmith42/status/679018096334675968

String up2(String s = mandatory('s')) {
    s?.toUpperCase()
}

void mandatory(String paramName) {
    throw new Exception("Please provide an actual value for '$paramName'")
}

assert up2('groovy') == 'GROOVY'

try {
    up2()
} catch(emAll) {
    assert emAll.message == "Please provide an actual value for 's'"
}

// another approach with using a closure call as default value

String up3(String s = { -> throw new Exception("Please provide an actual value for 's'") }() ) {
    s?.toUpperCase()
}

assert up3('groovy') == 'GROOVY'

try {
    up3()
} catch(emAll) {
    assert emAll.message == "Please provide an actual value for 's'"
}
```

I've also pushed that example on the [Groovy Web Console](http://groovyconsole.appspot.com/script/5094328489738240), if you wanna play with it.
# Groovy Weekly #77


It’s literally the eve of [SpringOne2GX](http://springone2gx.com/), in Washington DC! I’m flying tomorrow, for 9+ hours above the Atlantic, to gather with the cool kids of the Groovy ecosystem. I’m impatient to see some of my fellow readers and Groovy users around there.

And let me wish the [Griffon framework and its team a Groovy birthday](http://griffon-user.74797.x6.nabble.com/Happy-Birthday-Griffon-td48.html)!

## Releases

*   [Ratpack 1.0-rc-2](http://ratpack.io/versions/1.0.0-rc-2), a second release candidate
*   [Gradle 2.7-rc-2](https://twitter.com/gradle/status/640174805958856705) released
*   [Grails 3.0.5](https://twitter.com/grailsframework/status/639813351988662272) released with the new Web API profile
*   [Grails 3.0.6](https://twitter.com/grailsframework/status/641593634530443264) released
*   [Spring Boot 1.3.0.M5](http://spring.io/blog/2015/09/04/spring-boot-1-3-0-m5-available-now) released
    
## Articles

*   [Grails 3 Web profile vs the new Web API profile](http://sergiodelamo.es/grails-3-webapi-vs-web-profiles/)
*   How to [deploy a Grails 3 app to AWS Beanstalk and CloudFront CDN](https://medium.com/@benorama/how-to-deploy-grails-3-app-to-aws-elastic-beanstalk-with-gradle-and-travis-318d084c0f7d) by Benoit Hédiard
*   MrHaki's Groovy Goodness
    *   [Removing elements from a collection](http://mrhaki.blogspot.fr/2015/09/groovy-goodness-removing-elements-from.html)
    *   [Inspect method returns nicely formatted object values](http://mrhaki.blogspot.fr/2015/09/groovy-goodness-inspect-method-returns.html)
    *   [Operator overloading in reverse](http://mrhaki.blogspot.fr/2015/09/groovy-goodness-operator-overloading-in.html)
*   MrHaki's Spocklight
    *   [Only run specs based on conditions](http://mrhaki.blogspot.fr/2015/09/spocklight-only-run-specs-based-on.html)
    *   [Undo MetaClass changes](http://mrhaki.blogspot.fr/2015/09/spocklight-undo-metaclass-changes.html)
*   Philip Heath writes about [Spock, the logical choice for testing](http://www.thattestingguy.com/spock-the-logical-choice-for-testing-java/)
*   Paul Gross' team has [migrated from Gradle to Bazel](https://www.pgrs.net/2015/09/01/migrating-from-gradle-to-bazel/)

## Screencasts

*   Screencast of [NetBeans' Gradle integration](https://twitter.com/netbeans/status/640283206789562368)

## Interviews

*   An interview by JaxEnter of Dierk König in German, where he says that [Groovy is a pioneer language](https://jaxenter.de/groovy-ist-ein-pionier-fuer-neue-ideen-26638) where innovative changes help shape the future of Java and other languages

## Mailing-list posts

*   [Griffon celebrates the 7th anniversary](http://griffon-user.74797.x6.nabble.com/Happy-Birthday-Griffon-td48.html) of the project!

## Tweets

*   The Mars rover has a state called "[Solar Groovy](https://twitter.com/mittie/status/641371571915988992)" noticed Dierk König
*   Marco Vermeulen is excited about the upcoming [new website for SDKmanager](https://twitter.com/marc0der/status/640609521531011073) (aka GVM), based off the Groovy website code and look
*   [Grails 3.0.5](https://twitter.com/sdkmanager/status/639812197833703424) available on GVM
*   [Grails 3.0.6](https://twitter.com/sdkmanager/status/641589310110740480) available on GVM
*   [Spring Boot 1.3.0.M5](https://twitter.com/sdkmanager/status/639620148576559104) available in GVM
*   [Gradle 2.7-rc-2](https://twitter.com/sdkmanager/status/640167344459939841) available through GVM
*   Bertrand Goetzman working on a Groovy/Grails training is using a [Groovy DSL with Grain to generate dynamic HTML documentation](https://twitter.com/bgoetzmann/status/639558195476869120) from Markdown documents
*   The [Gradle plugin for the Grain](https://twitter.com/grainframework/status/641197859644305408) static site generator is available on the Gradle plugin portal
*   Benoit Hédiard created a [French-speaking channel in the Grails Slack](https://twitter.com/benorama/status/641512438416953344) community
*   Roman Shaposhnik is reminded he loves Groovy when looking at how it can make the [Apache BigTop project DSL](https://twitter.com/rhatr/status/641762008786825217) easy to grok
*   Matt Sheehan brings our attention to the [new auto-generated Groovy DSL documentation for the Jenkins Job DSL](https://twitter.com/sheehan00/status/641622945043980288)

## News

*   Jacob Aae Mikkelsen's [Grails Diary](http://grydeske.net/news/show/108) week 36

## Jobs

*   SmartThings is hiring a cloud engineer with [Ratpack experience](https://twitter.com/danveloper/status/639622402205425665)
*   Gilles Laborderie is recruiting for a [Grails job in Paris](https://twitter.com/g_laborderie/status/639465486116331520)

## Books

*   MrHaki's [Spocklight notebook updated](http://mrhaki.blogspot.fr/2015/09/spocklight-notebook-is-updated.html)

## Events

*   Only [a few days left before the end of the Groovy/Grails eXchange call for paper](https://twitter.com/pledbrook/status/639811956765913090)
*   [Guillaume Laforge is a JavaOne featured speaker](https://twitter.com/JavaOneConf/status/641000355740942336)
*   Guillaume Laforge [relaunched the Paris Groovy Grails User Group](https://twitter.com/MrsCaroline_C/status/641332943802269696) introducing talks on the Grails 3 novelties and Groovy in a VoIP context
# Groovy Weekly #76


Is it really already September? Time flies so fast in the Groovy ecosystem, and although the northern hemisphere was taking some Summer vacation breaks (at least that’s what I did!) there was quite a bit of interesting content published!

Regarding events, after successful and busy Greach, GR8Conf US/EU conferences, we’re getting ready for September’s [SpringOne2GX](http://springone2gx.com/) in Washington! There’s still time to register and join the Groovy ecosystem affictionados! And I’m really eager to seeing you there.

The Call for Papers for [Grails India](https://twitter.com/farjinaarad/status/633979624733601792) and [Groovy Grails eXchange](https://twitter.com/pledbrook/status/637255460643581952) London are also open, for those who wish to submit presentations.

If you’re using Gradle for build automation, check out all the videos of the [presentations of the recent Gradle Summit](http://gradle.org/category/video/) which should all be available online.

Happy 3rd birthday to [GrooScript](http://grooscript.org/)!

Congrats to the Griffon team for the [2.4](https://twitter.com/theaviary/status/638545829826023424) release and Ratpack for its [RC](http://ratpack.io/versions/1.0.0-rc-1) before 1.0!

And check out the updated books from MrHaki on [Groovy](http://mrhaki.blogspot.fr/2015/08/groovy-goodness-notebook-is-updated.html), [Grails](http://mrhaki.blogspot.fr/2015/08/grails-goodness-notebook-updated.html) and [Gradle](http://mrhaki.blogspot.fr/2015/08/gradle-goodness-notebook-updated.html), and Duncan Dickinson’s updated [Groovy 2 tutorial](https://leanpub.com/groovytutorial) on LeanPub.

## Releases

*   [Griffon 2.4.0](https://twitter.com/theaviary/status/638545829826023424) released
*   [Ratpack 1.0.0-rc-1](http://ratpack.io/versions/1.0.0-rc-1) released, the last step before the final 1.0!
*   [Gradle 2.7-rc-1](https://discuss.gradle.org/t/gradle-2-7-rc-1-is-now-available-for-testing/11382) available for testing
*   [Grengine 1.0.4](http://www.grengine.ch/) released
*   [Spock Reports 1.2.6](https://groups.google.com/forum/#!topic/spockframework/dkw0uHmOpuM) released
*   [Grain 0.6.6](https://twitter.com/grainframework/status/637193955512315904) released
*   [Geb 0.12.2](https://groups.google.com/forum/#!topic/geb-user/ac_DvJzNr0A) released

## Articles

*   Keegan Witt, Groovy committer and author of the GMavenPlus Maven plugin, [contrasts Maven and Gradle](http://wittykeegan.blogspot.fr/2015/08/a-maven-plugin-developers-thoughts-on.html)
*   [Custom configuration script ASTs](http://wittykeegan.blogspot.dk/2015/07/custom-configuration-script-asts.html) by Keegan Witt
*   The tale of Cédric Champeau [fighting PermGen leaks](http://melix.github.io/blog/2015/08/permgenleak.html) with Gradle, Groovy, CodeNarc
*   Kyle Boon shares part 2 of his [Zero to Ratpack](http://kyleboon.org/blog/2015/08/14/zero-to-ratpack-part-2/) series
*   Ted Vinke writes about [splitting and collating lists in Groovy](https://tedvinke.wordpress.com/2015/08/15/groovy-weekend-collections-splitting-or-collating-a-list/)
*   [Deploying Gradle apps to Heroku with Docker](http://jkutner.github.io/2015/08/17/deploy-gradle-ratpack-heroku-docker.html) by Joe Kutner
*   André Steingreß [mixes GPars, Grails and Hibernate](http://blog.andresteingress.com/2015/08/21/grails-gpars-and-hibernate/) together
*   Andrés Almiray on [using webfonts icons in Griffon](http://www.jroller.com/aalmiray/entry/griffon_webfont_icons_on_desktop)
*   Andrés Almirays shows how to [stack web font icons in Griffon](http://www.jroller.com/aalmiray/entry/griffon_stacking_webfont_icons)
*   [Sharing Grails HAL and JSON renderers](https://objectpartners.com/2015/08/13/sharing-grails-hal-and-json-renderers/) by Patrick Double
*   Søren Berg Glasius demonstrates using [Grails' RestClientBuilder for digest auth](http://sbglasius.tumblr.com/post/126896829137/digetauthwithrestclientbuilder)
*   Android and [Gradle at TicketMaster](http://tech.ticketmaster.com/2015/07/24/2015-year-of-the-android/)
*   MrHaki's Spocklight
    *   [optimize run order test methods](http://mrhaki.blogspot.fr/2015/08/spocklight-optimize-run-order-test.html)
    *   [include or exclude specifications based on class or interface](http://mrhaki.blogspot.fr/2015/08/spocklight-include-or-exclude.html)
    *   [including or excluding specifications based on annotations](http://mrhaki.blogspot.fr/2015/08/spocklight-including-or-excluding.html)
    *   [auto cleanup resources](http://mrhaki.blogspot.fr/2015/09/spocklight-auto-cleanup-resources.html)
*   MrHaki's Gradle goodness:
    *   [quickly open test report in IntelliJ IDEA](http://mrhaki.blogspot.fr/2015/08/gradle-goodness-quickly-open-test.html)
    *   [using the continuous build feature](http://mrhaki.blogspot.fr/2015/08/gradle-goodness-using-continuous-build.html)
    *   [Show Logback configuration status with Groovy configuration](http://mrhaki.blogspot.fr/2015/08/show-logback-configuration-status-with.html) by MrHaki
*   IntelliJ IDEA 15 EAP features [support for the Groovy @Builder](http://blog.jetbrains.com/idea/2015/08/intellij-idea-15-eap-groovy-builder-ast-transformation-support/) AST transformation
*   A [Groovy election](http://codereview.stackexchange.com/questions/96824/a-groovy-election), a Groovy implementation of a programming challenge

## Presentations

*   You can find all the [Gradle Summit 2015 videos](http://gradle.org/category/video/) on the Gradle website

## Mailing-list posts

*   A post from Russel Winder on the [status of the GPars project](http://groovy.329449.n5.nabble.com/What-is-the-status-of-Gpars-tp5727389p5727403.html)

## Tweets

*   The [Grooscript project is looking for feedback](https://twitter.com/grooscript/status/633728580309118976) if you're using it in your company
*   Happy [3rd birthday to GrooScript](https://twitter.com/jfrancoleza/status/636794537751511040)!
*   Jenn Strater heard of [Groovy undergraduate courses](https://twitter.com/JennStrater/status/637813075370995713) but wonders if universities use Groovy at graduate or research levels
*   Delivering a Groovy course reminds Dierk König how much [he loves the language for its practical nature](https://twitter.com/mittie/status/638659372789465088)
*   The IntelliJ IDEA developers are looking for [feedback for the Grails 3 support in IDEA](https://twitter.com/grailsframework/status/638455090068586496)
*   Ken Kousen's [O'Reilly learning path is half the price](https://twitter.com/kenkousen/status/638399868315246593) till tomorrow
*   The [Geb website has been updated with the latest version of Ratpack](https://twitter.com/GebFramework/status/633702178813800449)
*   Jen Stratter shares her [ReGinA selfie](https://twitter.com/JennStrater/status/634718571919220736)! Have you shared yours?
*   Eugene Kamenev's [OrientDB Groovy entity mapper was added to the OrientDB documentation](https://twitter.com/eugenekamenev/status/634613381354401792)
*   The [Golo programming language is switching to Gradle](https://twitter.com/golo_lang/status/637171327091253248) for its build system
*   Are you following the [GradlEphant twitter account](https://twitter.com/Gradlephant/status/634768293673484289)?
*   Ted Naleid is working on [Spackle, a replacement of the build-test-data Grails plugin](https://twitter.com/tednaleid/status/635647401483612160)
*   Peter Ledbrook reminds that if the new [Gradle publishing plugin](https://twitter.com/pledbrook/status/638251832721154048) hasn't worked for you, its source code is available on Github
*   Lukas Bradley highlighted [Gradle's new hourly 1:1 consulting offer](https://twitter.com/lukasbradley/status/638368466542555137)
*   Peter Ledbrook notes that to [understand the background of Gradle's new model](https://twitter.com/pledbrook/status/638302250633428993) and an overview of how it works, one should watch Luke Daley's presentation at Gradle Summit

## News

*   Peter Ledbrook started a [Groovy syntax quick reference guide](https://twitter.com/pledbrook/status/636533443980083200) and is interested in feedback
*   The August 2015 [Gradle newsletter](http://gradle.org/august-2015-newsletter/)
*   Jacob Aae Mikkelsen's [Grails Diary](http://grydeske.net/news/show/105) week 33
*   Jacob Aae Mikkelsen's [Grails Diary](http://grydeske.net/news/show/106) week 34
*   Jacob Aae Mikkelsen's [Grails Diary](http://grydeske.net/news/show/107) week 35
*   A new release of the [Groovy Calamari column](http://groovycalamari.com/)
*   Graeme Rocher shares the [Grails 3.1 roadmap](https://github.com/grails/grails-core/wiki/Roadmap)

## Jobs

*   [Gradle Inc. is hiring](https://twitter.com/gradle/status/634741590771245056) services and R&D engineers
*   [OCI is hiring](https://twitter.com/jeffscottbrown/status/638430257670828032) for the Grails team

## Code snippets

*   Ben Boggess shows how to use [Groovy's combination() method to create all the combinations of variables in a Spock specification](https://twitter.com/benboggess/status/636987319900352512)

## Books

*   Duncan Dickinson updated his [Groovy 2 tutorial book](https://leanpub.com/groovytutorial) on LeanPub
*   MrHaki published an update of the [Groovy Goodness Notebook](http://mrhaki.blogspot.fr/2015/08/groovy-goodness-notebook-is-updated.html)
*   MrHaki published an update to the [Gradle Goodness Notebook](http://mrhaki.blogspot.fr/2015/08/gradle-goodness-notebook-updated.html)
*   MrHaki published an update to the [Grails Goodness Notebook](http://mrhaki.blogspot.fr/2015/08/grails-goodness-notebook-updated.html)

## Podcasts

*   Audio and video of the [Groovy Podcast episode 18](https://twitter.com/groovypodcast/status/634410345814228995) are available

## Events

*   The [Groovy Grails eXchange Call for Paper](https://twitter.com/pledbrook/status/637255460643581952) is open
*   [Paul King will be speaking at ApacheCon Europe](https://twitter.com/paulk_asert/status/633959787286233088) in Budapest about the awesome parts of Groovy
*   [Guillaume Laforge is a featured speaker at JavaOne](https://twitter.com/restlet/status/634736986272727040) 2015
*   Dierk König announces some upcoming [Groovy & Grails courses in Essen](https://twitter.com/mittie/status/638584905694359553), Germany
*   The [Call for Paper for GrailsConf India](https://twitter.com/farjinaarad/status/633979624733601792) 2016 is open
*   The [Paris Groovy user group is back on September 8th](https://docs.google.com/forms/d/1ACjCltUodSwZ2u_0X22IeCujV3UGEq3oqp-dMmqmBeo/viewform) in Paris, to talk about the novelties of Grails 3 and Groovy in the context of telephony and VoIP
*   An avalanche of SpringOne2GX talks announcements
    *   Cédric Champeau will dive into the [Groovy compiler internals](https://twitter.com/springone2gx/status/638365711815938051) at SpringOne2GX
    *   Dan Woods will be speaking about [Ratpack](https://twitter.com/danveloper/status/637662873930571776)
    *   Owen Rubel will speak about [scalable APIs with Grails](https://twitter.com/owenrubel/status/638771331295760384)
    *   Allison Figus will be speaking about [functional automated testing with Geb](https://twitter.com/springone2gx/status/638426112394072064)
    *   Michael Plöd will speak about [migrating from Grails 2 to 3](https://twitter.com/springone2gx/status/638743172806406145)
    *   Guillaume Laforge will be speaking about [Groovy and REST](https://twitter.com/springone2gx/status/638758243599171584)
    *   Guillaume Laforge will be presenting [Groovy with Style](https://twitter.com/springone2gx/status/638410980284731392)
    *   Iván López will be speaking about [Spock](https://twitter.com/ilopmar/status/638628617740681216)
    *   Jorge Franco Leza will be speaking about [GrooScript](https://twitter.com/springone2gx/status/638395906753064961)
# Groovy Weekly #75


The not-so-weekly Groovy column is back for a summer edition on the shores of the Atlantic ocean (at least, that’s where I am now!) and there was a lot to catch up with in terms of news!

Ratpack is almost at 1.0, only a couple of weeks to go for the mythical release, whereas Gradle arrived in version 2.6, and some updates to the two main Grails lines were out too.

You’ll notice lots of delightful content from GR8Conf US 2015! So many talks to watch (and slides to look at), if you didn’t get a chance to attend the conference.

## Releases

*   [Ratpack 0.9.19](http://ratpack.io/versions/0.9.19) released, the last milestone before 1.0!
*   [Gradle 2.6](https://discuss.gradle.org/t/gradle-2-6-released/11092) released
*   [Grails 3.0.4](https://github.com/grails/grails-core/releases/tag/v3.0.4) released
*   [Grails 2.5.1](https://github.com/grails/grails-core/releases/tag/v2.5.1) released
*   [Geb 0.12.1](https://twitter.com/GebFramework/status/628475584092377089) released
*   [GrooScript 1.2.0](http://grooscript.org/) released
*   [Grain 0.6.5](https://twitter.com/grainframework/status/628862549916839936) released with improved Asciidoctor support
*   [Windows installer for Groovy 2.4.4](https://twitter.com/keeganwitt/status/630918051425353728) made available by Keegan Witt
*   [Grails GrooScript 1.1.1](https://twitter.com/grooscript/status/631151629845327872) plugin released
*   [OrientDB Groovy 0.1.0](https://twitter.com/eugenekamenev/status/626623038931488768) released
*   [TypeScript Gradle plugin 1.5](https://twitter.com/sothmann/status/625756046674497536) released with all the new TypeScript 1.5 compiler options

## Articles

*   Open-sourcing the [LinkedIn Gradle plugin and DSL for Apache Hadoop](https://engineering.linkedin.com/hadoop/open-sourcing-linkedin-gradle-plugin-and-dsl-apache-hadoop) by Alex Bain
*   [Groovy: Java's gateway drug](https://www.linkedin.com/pulse/groovy-javas-gateway-drug-owen-rubel), by Owen Rubel
*   A [Scala vs Groovy functional programming showdown](https://www.linkedin.com/pulse/scala-vs-groovy-functional-programming-showdown-owen-rubel) by Owen Rubel
*   A [curated list of awesome Groovy libraries](https://github.com/kdabir/awesome-groovy), frameworks, resources, collected by Kunal Dabir
*   [Feature matrix comparison between Gradle and Maven](http://gradle.org/maven_vs_gradle/), on Gradle's site
*   On InfoQ, Abel Avram writes about [Gradle 2.5's continuous build](http://www.infoq.com/news/2015/07/gradle-2-5) feature
*   Julien Ponge, creator of the Golo dynamic language, [compares a non trivial Maven build and a Gradle approach](https://julien.ponge.org/blog/an-experiment-in-maven-to-gradle-migration/)
*   [Have a Groovy Spring](https://www.accelebrate.com/blog/have-a-groovy-spring/) by Ken Kousen
*   [Zero to Ratpack](http://kyleboon.org/blog/2015/08/05/zero-to-ratpack/), by Kyle Boon, on more concrete use cases & examples for Ratpack
*   [Stubbing external service interactions using Ratpack](http://kyleboon.org/blog/2015/07/18/stubbing-service-interactions-when-testing-microservices/) by Kyle Boon
*   [Build high performance JVM microservices with Ratpack and Spring Boot](http://www.infoq.com/articles/Ratpack-and-Spring-Boot) by Dan Woods on InfoQ
*   [GR8Conf US 2015 recap](https://objectpartners.com/2015/08/03/gr8conf-us-2015-conference-recap/) by Craig Atkinson from Object Partners
*   Peter Ledbrook on [exploring Grails 3](http://blog.cacoethes.co.uk/groovyandgrails/exploring-grails-3)
*   [Getting started with Asciidoctor and Gradle](http://jworks.nl/2015/07/31/getting-started-with-asciidoctor/) by Erik Pragt
*   [Grails Filter at top of Filter invocation chain](http://www.tothenew.com/blog/grails-filter-at-top-of-filter-invocation-chain/) by Sandeep Poonia
*   Lovin Saini on [when details in principal object of Spring Security in Grails are not sufficient](http://www.tothenew.com/blog/when-details-in-principal-object-of-spring-security-are-not-sufficient/)
*   [Integrating Amazon S3 in a Grails application](http://www.tothenew.com/blog/integrating-amazon-s3-in-grails-application/) by Komal Jain
*   [Creating Android applications with Groovy](http://www.tothenew.com/blog/creating-android-application-with-groovy/) by Simranjit Kour
*   [Closure delegate using Groovy “with” method and decorating code with multiple assignments](http://www.tothenew.com/blog/closure-delegate-using-groovy-with-method-and-decorating-code-with-multiple-assignments/) by Tarun Pareek
*   [Upgrading a Grails app from version 1.3.7 to 2.4.4](https://dzone.com/articles/upgrading-a-grails-app-from-version-137-to-version) by Manvendra Singh on DZone
*   André Steingreß blogged about [reconnecting JDBC connections with Grails](http://blog.andresteingress.com/2015/08/14/grails-hibernate-jdbc-connection/)

## Interviews

*   A slice of [Groovy's hip use of JFrog's Artifactory & Bintray, and of Gradle & TeamCity](http://devops.com/2015/08/13/slice-groovys-hip-use-jfrog-artifactory-bintray-gradle-teamcity/), from an interview of Guillaume Laforge on DevOps.com
*   [Luke Daley interviewed for Voxxed about Ratpack](https://www.voxxed.com/blog/2015/08/ratpack-the-java-8-web-framework-for-independent-thinkers/), the “Java 8 web framework for independent thinkers”

## Presentations

*   GR8Conf US 2015
    *   [Vert.x](https://www.youtube.com/watch?v=Xeh2IExt8rA) presented by Ryan Applegate ([slides](https://speakerdeck.com/rappleg/getting-groovy-with-vert-dot-x))
    *   [RESTful Web Services in Grails 3](https://www.youtube.com/watch?v=2tXoPTZmB_4) presented by Jenn Strater ([slides](http://jlstrater.github.io/restful-grails3/#/))
    *   [Practical and Stupidly Impractical Groovy DSLs](https://www.youtube.com/watch?v=NuL3QkSSXy8) presented by Craig Burke ([slides](http://www.craigburke.com/practical-groovy-dsl/))
    *   [Richer Data History with Event Sourcing](https://www.youtube.com/watch?v=QWnuhlBwNh8) presented by Stephen Pember
    *   [Groovy Goodness](https://www.youtube.com/watch?v=ugy4wSEy_A0), presented by Hubert Klein Ikkink ([slides](https://github.com/mrhaki/gr8conf2015us/tree/master/groovy-goodness))
    *   [Groovy DevOps in the Cloud](https://www.youtube.com/watch?v=7G6z7Lqxqtw) presented by Andrey Adamovich ([slides](http://www.slideshare.net/aestasit/groovy-devops-in-the-cloud-for-gr8conf-us-2015))
    *   [GVM: The Groovy enVironment Manager](https://www.youtube.com/watch?v=i6WOnN8uJdM), presented by Marco Vermeulen ([slides](http://marcovermeulen.github.io/gvm-talk/#/))
    *   [Jenkins + Groovy with the Job DSL Plugin](https://www.youtube.com/watch?v=SSK_JaBacE0) presented by Matt Sheehan ([slides](http://sheehan.github.io/job-dsl-slides/))
    *   [Asset Pipeline](https://www.youtube.com/watch?v=iodl0QXkVag) presented by David Estes ([slides](https://github.com/GR8conf/GR8ConfUS2015/tree/master/asset-pipeline))
    *   [The support tools necessary to effectively build a Microservice Architecture](https://www.youtube.com/watch?v=Ey7sGdmCX2Y) presented by Cameron Fieber from Netflix
    *   [Microservices: The Right Way](https://www.youtube.com/watch?v=yk_VlKUDKMA) presented by Dan Woods ([slides](http://www.slideshare.net/danveloper/microservices-the-right-way))
    *   [Idiomatic Spock](https://www.youtube.com/watch?v=jxGQrJxjF-s) presented by Rob Fletcher ([slides](https://github.com/robfletcher/spock-katas))
    *   [Automated Strategies for deploying Grails from Dev to Prod](https://www.youtube.com/watch?v=9I8fyX7qnoU) presented by Eric Helgeson ([slides](https://github.com/erichelgeson/GR8ConfUS2015/blob/585814b5abd383deee512a2f4767d305fa364e18/presentations/Automation%20strategies%20for%20deploying%20your%20Grails%20app%20from%20Dev%20to%20Prod/Automation-Strategies-Eric-Helgeson-gr8-2015.pdf))
    *   [Grails Mocking on Steroids](https://www.youtube.com/watch?v=YdrqW22kHS4) presented by Christian Oestreich ([slides](http://grails-plugin-consortium.github.io/mocking-on-steroids-presentation/?full#1))
    *   [Geb Functional Testing Unleashed](https://www.youtube.com/watch?v=rpepX441E5g) presented by Craig Atkinson ([slides](http://craigatk.github.io/geb/#/))
    *   [Nebula: Netflix's OSS Gradle Plugins](https://www.youtube.com/watch?v=qWPMYysLgis) presented by Rob Spieldenner ([slides](https://speakerdeck.com/rspieldenner/nebula-netflixs-oss-gradle-plugins))
    *   [Securing Ratpack](https://www.youtube.com/watch?v=e5erGrh7n_s) presented by Jeff Beck ([slides](http://beckje01.com/talks/gr8us-2015-sec-ratpack.html#/))
    *   [Cassandra and Grails](https://www.youtube.com/watch?v=rU0kCAyxSfQ) presented by Jeff Beck ([slides](http://beckje01.com/talks/gr8us-2015-cassandra-grails.html#/))
    *   [Spock on Android](https://www.youtube.com/watch?v=onwoLeHRxl0) by Andrew Reitz ([slides](http://andrewreitz.com/gr8conf-us-spock-android-2015/#/))
    *   [Groovy and Scala: Friends or Foes](https://www.youtube.com/watch?v=ymbvs4qoQJU) presented by Marco Vermeulen ([slides](http://marcovermeulen.github.io/groovy-and-scala-talk/#/))
    *   [Getting Groovy on Android](https://www.youtube.com/watch?v=U_p2L47gvgk) presented by Andrew Reitz ([slides](https://onedrive.live.com/view.aspx?resid=29181012CB08492E!882&ithint=file%2cpptx&app=PowerPoint&authkey=!AGwH3YhuhRS1P2s))
    *   [Source to Deployment with Gradle and Docker](https://www.youtube.com/watch?v=vY5mYcw3XHk) presented by John Engelman ([slides](https://speakerdeck.com/johnrengelman/source-to-deployment-with-gradle-and-docker))
    *   [Learn how to get Groovy on Google Glass and Android Wear](https://www.youtube.com/watch?v=-49ng22DHkw) presented by Ryan Vanderwerf
    *   [Little Did He Know...](https://www.youtube.com/watch?v=NBv5y2O1oTY) presented by Burt Beckwith
    *   [Gradle: State of the Build](https://www.youtube.com/watch?v=_FFpngCk52c) presented by Luke Daley
    *   [Hacking the Grails Spring Security 2.0 Plugin](https://www.youtube.com/watch?v=4-f0vEWQ9Os), presented by Burt Beckwith
    *   [Ratpack: Under the Hood](https://www.youtube.com/watch?v=WT8S-dMLSVM) presented by Luke Daley ([slides](https://github.com/ratpack/presentation-ratpack-under-the-hood-gr8conf-us-2015))
    *   Slides on [GrooScript](https://github.com/jondejong/GR8confUS-Grooscript) by Jon DeJong
    *   Slides on [introduction to event sourcing](http://www.slideshare.net/StevePember/gr8conf-us-2015-intro-to-event-sourcing-with-groovy) by Steve Pember
    *   Slides on [Java 8 functional programming for Groovy developers](https://speakerdeck.com/johnrengelman/java-8-functional-programming-for-groovy-developers) by John Engelman
    *   Slides on [reactive options for Groovy](http://www.slideshare.net/StevePember/gr8conf-us-2015-reactive-options-for-groovy) by Steve Pember
    *   Slides on [Angular.JS in a Groovy world](http://www.craigburke.com/angular-groovy-world/) by Craig Burke
    * Slides on [infrastructure automation with Gradle and Puppet](http://www.slideshare.net/aestasit/infrastructure-automation-with-gradle-and-puppet-for-gr8conf-us-2015) by Andrey Adamovitch
*   [Eclipse & Gradle, the best of both worlds](http://www.infoq.com/presentations/eclipse-gradle), at EclipseCon, by Hans Dockter and Etienne Studer
*   Dan Woods [Ratpack web framework](http://fr.slideshare.net/danveloper/ratpack-web-framework) presentation at UberConf

## Tweets

*   Keegan Witt morphed a [3 hour running Bash script of HDFS commands into a 10 seconds Groovy script](https://twitter.com/keeganwitt/status/613718739217948672) using the Java APIs
*   The [killer app for Groovy is Gradle](https://twitter.com/danveloper/status/626768428498579456), says Ken Kousen
*   Erik Pragt spotted a [nice Groovy in Action, 2nd edition, review](https://twitter.com/epragt/status/631440665981923328) by Andrew Binstock, on Oracle's Java Magazine
*   [Redis session storage coming to Ratpack](https://twitter.com/ratpackweb/status/631781599621677056) courtesy of Jeff Beck
*   [Gradle 2.6](https://twitter.com/sdkmanager/status/630732523706949632) available on GVM
*   [GrooScript's source code evolution](https://twitter.com/grooscript/status/630094999091343360) video
*   A video of a [Groovy ecosystem variant of the 2048](https://twitter.com/dhirajmahapatro/status/630030753758343168) game
*   Iván López is working on a [Grails framework postgres-extensions plugin](https://twitter.com/ilopmar/status/627801822347022336)
*   Dan Woods learned that [Bintray is using Ratpack](https://twitter.com/danveloper/status/627350450870820864)
*   Marco Vermeulen is excited with the [Gradle continuous build feature](https://twitter.com/marc0der/status/627264041677901824)
*   [Another Groovy in Action 2nd edition picture](https://twitter.com/monzdrpower/status/627150274453487616), from Epam Systems in Saint-Petersburg
*   [GVM is going to be renamed SDKman](https://twitter.com/javazquez/status/627147102779367424)
*   Robert Fletcher discovered [Spock's @Use annotation](https://twitter.com/rfletcherEW/status/626889088738664449) for using extension methods in tests
*   MrHaki shares a link to a [LiveReload integration with Gradle](http://asciidoctor.github.io/asciidoctor-gradle-examples/#_livereload_html_example)
*   Colin Harrington shares the ingredients of an [awesome sauce for Android development](https://twitter.com/ColinHarrington/status/626784519475965952): SwissKnife + Android Spock + Grooid tools
*   [Grails 3.0.4](https://twitter.com/sdkmanager/status/626321911056887808) available on GVM
*   [Grails 2.5.1](https://twitter.com/sdkmanager/status/626361104114053120) available on GVM
*   Burt Beckwith uploaded the [documentation for the Grails Spring Security Core plugin](https://twitter.com/burtbeckwith/status/632590650442129408) v3.0.0.M1
*   Victor Mrtez believes Groovy rocks and is going to code another [Jenkins CI plugin with Groovy and Gradle](https://twitter.com/AnInfinite/status/626444888452808704)
*   At [GR8Conf US 2015, the Ratpack team gathered](https://twitter.com/rfletcherEW/status/626599837421686784) to drink Sinatra's favorite drink!

## News

*   [Keegan Witt joined the Groovy team](https://twitter.com/glaforge/status/632669415876763648) as a committer
*   Do you want a [Gradle.com sneak peek](http://gradle.org/gradle-com-sneak-peek/)?
*   Jacob Aae Mikkelsen’s [Grails Diary](http://grydeske.net/news/show/102) week 30
*   Jacob Aae Mikkelsen’s [Grails Diary](http://grydeske.net/news/show/103) week 31
*   Jacob Aae Mikkelsen's [Grails Diary](http://grydeske.net/news/show/104) week 32
*   The 11th edition of the weekly [Groovy Calamari](http://groovycalamari.com/)
*   Marco Vermeulen has started a [Groovy extension module for Scala interop](https://github.com/marcoVermeulen/groovy-scala-extension-module)
*   The [Scriptom](https://github.com/groovy/scriptom) project moved to the Groovy Github organization

## Code snippets

*   A [Groovy STOMP client](https://github.com/bertramdev/gSTOMP-client) by David Estes
*   Russell Hart's [Ratpack workshop code base](https://github.com/ratpack/hands-on-ratpack)
*   Kyle Boon [open sourced his Cellar HQ Ratpack application](https://twitter.com/kyleboon/status/626169879444504576)
*   [Utilize Gradle's idea plugin to set git as your default VCS](https://gist.github.com/danhyun/980319864f75967ccd8a) and to enable the Gradle tool from IntelliJ IDEA, by Danny Hyun
*   Václav Pech [counts wagons in Groovy](http://www.jroller.com/vaclav/entry/wagons_counted) in this algorithmic teaser
*   Circle Stacker [demo app using Groovy, Swiss Knife](https://github.com/pieces029/circle-stacker), and built with Gradle

## Books

*   [Free Gradle books](https://twitter.com/werner_cjd/status/632362950200819712) from O'Reilly
*   Dierk König says that [Groovy in Action, 2nd edition, was #5 in Manning print book bestsellers](https://twitter.com/mittie/status/625320234778525696) a month after appearing

## Podcasts

*   [Groovy Podcast episode 17](https://www.youtube.com/watch?v=ii693nUQwV0), recorded at GR8Conf US 2015

## Events

*   [Groovy 2 and Java 8, gotchas & future](http://www.meetup.com/Austin-Groovy-and-Grails-Users/events/224611516/), at the Groovy user group in Austin on August 27th
# Groovy Weekly #74


Although on a more irregular schedule, Groovy Weekly continues in the summer with its 74th edition, crossing the bar of the 3000 total news items tracked since it all started!

Some interesting releases for this edition, like the [Groovy 2.4.4](http://groovy-lang.org/changelogs/changelog-2.4.4.html) release under the Apache umbrella! After a failed attempt, our second try was succesful, and it was particularly important to get it right out the door, as an [important security issue](http://groovy-lang.org/security.html) uncovered was fixed in this release, and all Groovy users (and frameworks and libraries using Groovy) should upgrade as soon as possible — especially as no older version will be released with the patch.

In the release section, last time, I had forgotten [Griffon 2.3.0](http://griffon-framework.org/releasenotes/griffon_2.3.0.html) which was released on stage at GR8Conf Europe by Andrés Almiray. And in other releases, we also have [Grails 3.0.3](https://twitter.com/grailsframework/status/619082386320572416) with important reloading improvements, [Geb 0.12.0](https://groups.google.com/forum/#!topic/geb-user/2LXtg0pP4Do) which celebrated its 5th anniversary, and also [Codenarc 0.24](https://github.com/CodeNarc/CodeNarc/blob/master/CHANGELOG.txt) that I had forgotten the previous edition as well.

It looks like Slack is really becoming very popular as both [Grails](https://twitter.com/grailsframework/status/621780975870152704) and [Ratpack](https://twitter.com/ratpackweb/status/621103100619681792) opened Slack channels!

## Releases

*   [Groovy 2.4.4](http://groovy-lang.org/changelogs/changelog-2.4.4.html) released its first version under the Apache umbrella
*   [Griffon 2.3.0](http://griffon-framework.org/releasenotes/griffon_2.3.0.html) released
*   [Grails 3.0.3](https://twitter.com/grailsframework/status/619082386320572416) released with improvements to reloading
*   [Geb 0.12.0](https://groups.google.com/forum/#!topic/geb-user/2LXtg0pP4Do) released
*   [Codenarc 0.24](https://github.com/CodeNarc/CodeNarc/blob/master/CHANGELOG.txt) released
*   [Deck2PDF 0.3](https://twitter.com/CedricChampeau/status/623453951116070912) released by Cédric Champeau allowing HTML/JavaScript presentations to be saved as PDF or images

## Articles

*   JaxEnter covers the [Groovy 2.4.4 release](https://jaxenter.com/groovy-2-4-4-has-landed-under-the-apache-foundation-119018.html) under the Apache umbrella
*   Ryan Vanderwerf on [publishing Grails 3 plugin snapshots to your local Artifactory](http://rvanderwerf.blogspot.fr/2015/07/how-to-publish-grails-3-plugin.html) server
*   [Grails 3 and JaCoCo](http://beckje01.com/blog/2015/07/12/grails-3-and-jacoco/) by Jeff Beck
*   Graeme Rocher announces the [creation of a Grails Slack channel](http://grails.io/post/124146177848/join-grails-community-on-slack)
*   First look at the new [Android Gradle build tools](http://inthecheesefactory.com/blog/new-gradle-build-tools-with-gradle-2.5/en): the new DSL structure and Gradle 2.5
*   Benjamin Muschko's Gradle in the trenches on [defining versioning strategies](https://gradle.org/tales-from-the-trenches-defining-versioning-strategies/)
*   [Gradle task ordering tip](http://trickyandroid.com/gradle-tip-3-tasks-ordering/) by Pavel Dudka
*   [Spock-Reports plugin for Grails 3](https://rdmueller.github.io/Spock-Reports-with-Grails-3.0/) by R.D. Müller

## Presentations

*   Bogdan Danilyuk presented on [modularity with Grails](https://vimeo.com/131395565) at GeekOut from real-life usage at TransferWise
*   [Advanced dependency management with Gradle](https://speakerdeck.com/bmuschko/advanced-dependency-management-with-gradle) by Benjamin Muschko

## Tweets

*   Original Groovy co-founder [James Strachan states that Groovy is the language of Continuous Integration and Continuous Delivery](https://twitter.com/jstrachan/status/622020452886663168), and enjoys using it with Jenkins Flow and Docker workflows
*   [Groovy 2.4.4](https://twitter.com/sdkmanager/status/621639983217119232) available on GVM
*   Gradle 2.6 will be featuring a [test kit for functionally testing Gradle plugins](https://twitter.com/gradle/status/621458781273128960)
*   Andrés Almiray developed two [new Griffon AST transformations targeting JavaFX](https://twitter.com/aalmiray/status/621059717557821441) with @ListChangeListener and @MapChangeListener
*   [5th anniversary of Geb](https://twitter.com/GebFramework/status/619234577849028608)
*   Jennifer Strater has a [visualization of gender ratios in the Groovy community](https://twitter.com/JennStrater/status/620692583182790656)
*   Vladimír Oraný is doing heavy [refactorings with confidence thanks to the Spock framework test coverage](https://twitter.com/musketyr/status/621969659982647296)
*   A [Groovy Grape tour bus](https://twitter.com/alvaro_sanchez/status/623477231050862592) in Australia spotted by Álvaro Sánchez!
*   Ryan Vanderwerf forked [grooid-templates to create a ready-made Glass or Android Wear app](https://twitter.com/RyanVanderwerf/status/622978045490507780) template
*   Mario García made a new version of [Grooid-templates with Spock framework support](https://twitter.com/marioggar/status/621943669550149632) for testing
*   A [Gradle plugin for Dockerized tests](https://plugins.gradle.org/plugin/com.github.pedjak.dockerized-test/0.3.3)
*   [GVM adds JBoss Forge](https://twitter.com/sdkmanager/status/623355138699317248) as new candidate
*   [Grails 3.0.3](https://twitter.com/sdkmanager/status/619076452978442240) available on GVM
*   [Vert.x 3.0](https://twitter.com/sdkmanager/status/619053543048278016) available on GVM
*   [Gradle 2.5](https://twitter.com/sdkmanager/status/619050062354771968) available on GVM
*   The [Gradle dexinfo plugin](https://twitter.com/djensen47/status/622090181861113856) adds a new task to print out the dex method count of your Android projects without having to install separate tools
*   Danny Hyun reminds us about the [Ratpack Slack channel](https://twitter.com/Lspacewalker/status/621120598446575616)
*   You can [sign-up for the Ratpack Slack channel](https://twitter.com/ratpackweb/status/621103100619681792)
*   300 persons have joined the [Grails Slack channel](https://twitter.com/grailsframework/status/621780975870152704)
*   Graeme Rocher announces that [dynamic scaffolding will make a come back in the next Grails 3 release](https://twitter.com/graemerocher/status/620944698140704768)
*   Claus Ibsen [upgraded Apache Camel to Groovy 2.4.4](https://twitter.com/davsclaus/status/621668001050415104) right after its release under the Apache flag

## News

*   Groovy 2.4.3 and below was affected by a [security issue](http://groovy-lang.org/security.html) that has been fixed in Groovy 2.4.4. Projects should upgrade to 2.4.4 as soon as possible to avoid this security issue to be leveraged by malicious attackers.
*   Jacob Aae Mikkelsen [Grails Diary](http://grydeske.net/news/show/101) week 25 to 28
*   Jacob Aae Mikkelsen's [Grails Diary](http://grydeske.net/news/show/101) week 29
*   Mockito is bringing some [better support for Groovy classes](https://github.com/mockito/mockito/pull/266)

## Screencasts

*   Bertrand Goetzmann recorded a video of a [lunar lander game he developed with GroovyFX](https://twitter.com/bgoetzmann/status/623237871865040901), JavaFX and a bit of reactive programming

## Podcasts

*   Audio of [Groovy podcast](https://twitter.com/groovypodcast/status/620708302142459904) episode 15
*   [Groovy Podcast](https://plus.google.com/events/cs8io51q6nqdd0iafel0s0p0pjs) episode 16

## Mailing-list posts

*   [Groovy 2.4.4 release announcement](http://mail-archives.apache.org/mod_mbox/incubator-groovy-users/201507.mbox/%3CCADQzvmk=3TwWzeGMN-HXwv4CUkbPBENusioviPf29_uJ=zLi0w@mail.gmail.com%3E) on the Groovy mailing-list by Cédric Champeau
# Groovy Weekly #73


It’s definitely not Tuesday, but nonetheless, lots of accumulated great and Groovy content to share with you all! It’s not easy to keep up the pace, sorry for the irregular timing of this column — I might have to remove the “Weekly” part of the name! But you won’t regret this edition, packed with so much content!

Already one month gone by since GR8Conf Europe 2015, but we have content to share about the event! And GR8Conf US 2015 is happening soon too! We also have presentations and videos from Gradle Summit and Greach 2015.

Guillaume Laforge tweeted about the recent download numbers of the Groovy project: for the first 6 monts of the year, Groovy was downloaded 4.5 million times (1 million through Bintray and 3.5 millions through Maven Central). In 6 months, Groovy was downloaded as much as the full year of 2014!

Another big milestone is the release in print of the second edition of Groovy in Action! Lots of fans tweeted their “ReGinA selfies!

## Releases

*   [Ratpack 0.9.18](http://ratpack.io/versions/0.9.18) released
*   [Vert.x 3.0](https://groups.google.com/forum/?fromgroups=#!topic/vertx/xgGgQcDeX04) released
*   [Gradle 2.5](https://discuss.gradle.org/t/gradle-2-5-released/10490) released with continuous build and dependency substitution rules
*   [Grails 3.0.2](https://twitter.com/grailsframework/status/610790605980045312) released with lots of improvements, and the first release under OCI's leadership
*   [GrooScript 1.1.2](https://twitter.com/grooscript/status/617354776897056768) released
*   [GrooScript Grails 3 plugin](https://twitter.com/grooscript/status/614796850395283456) released in version 1.0.0
*   [GVM 2.4.2](https://twitter.com/sdkmanager/status/611213808569335808) released with key security patches
*   [Groovy VFS 1.0-beta-3](https://twitter.com/ysb33r/status/613705160238370818) released
*   [Groovy VFS command-line 1.0-beta-3](https://twitter.com/ysb33r/status/613711977240657927) released
*   [Buildship Gradle plugin support](https://marketplace.eclipse.org/content/buildship-gradle-integration) released
*   [Glu 5.6.1](http://glu.977617.n3.nabble.com/ANN-glu-5-6-1-released-td4026928.html) released
*   [Spring Boot 1.2.5](http://spring.io/blog/2015/07/02/spring-boot-1-2-5-released) released
*   [Gradle 2.5-rc-2](http://gradle.org/release-candidate/) released
*   [Grain 0.6.4](https://twitter.com/grainframework/status/613008570691420160) released with updated Asciidoctor support for include macros
*   [SonarQube Gradle 1.0](https://twitter.com/SonarSource/status/610725375400935424) makes it easier to cover more versions of both Gradle and Sonar
*   [ElasticSearch Groovy client 1.6.0](https://twitter.com/pickypg/status/610534606425735168) released with improved closure conversion

## Articles

*   Graeme Rocher sums up his [first week at his new job at OCI](http://grails.io/post/120598713483/grails-at-oci-week-1)
*   [Grails Spring Security filter for professional 2 factor authentication](http://www.aurorasolutions.io/blog/grails-spring-security-filter-2fa-yubico-example/) with Yubico
*   Pavel Dudka shares a tip on [understanding the Groovy syntax for working with Gradle](http://trickyandroid.com/gradle-tip-2-understanding-syntax/)
*   [Day one coverage of GR8Conf Europe](http://www.tothenew.com/blog/day-1-gr8conf-eu-2015/) 2015 by To The New Digital
*   [Day two coverage of GR8Conf Europe](http://www.tothenew.com/blog/day-2-gr8conf-eu-2015/) 2015 by To The New Digital
*   [Publishing to Maven Central using Gradle](http://nemerosa.ghost.io/2015/07/01/publishing-to-the-maven-central-using-gradle/) by Damien Coraboeuf
*   Petri Kainulainen helps you [getting started with Gradle](http://www.petrikainulainen.net/getting-started-with-gradle/)
*   [Sync content on Amazon S3 with Gradle](https://twitter.com/gradleplugins/status/613070984782999553)
*   Ryan Harter on [hosting a private Maven repository on Amazon S3](http://ryanharter.com/blog/2015/06/18/hosting-a-private-maven-repo-on-amazon-s3/)
*   Anto Aravinth published a [GrooScript plugin for Karma](https://twitter.com/antoaravinth/status/612112565137571840)
*   Running [Spring MVC 4 with Gradle and Gretty](http://www.mkyong.com/spring-mvc/gradle-spring-4-mvc-hello-world-example-annotation/)
*   [WebSockets in Grails 3.0](https://objectpartners.com/2015/06/10/websockets-in-grails-3-0/) by Mike Plummer
*   [Using Gradle in your command-line Android projects](https://blog.nraboy.com/2015/04/using-gradle-in-your-command-line-android-project/) by Nic Raboy
*   Iván López about [speaking at GR8Conf](http://www.kaleidos.net/blog/1168/speaking-at-gr8conf/) Europe 2015
*   Painless Android development with Groovy and SwissKnife
    *   [part one](http://www.codebulb.ch/2015/06/painless-android-development-with-groovy-and-swissknife-part-1.html)
    *   [part two](http://www.codebulb.ch/2015/06/painless-android-development-with-groovy-and-swissknife-part-2.html)
    *   [part three](http://www.codebulb.ch/2015/06/painless-android-development-with-groovy-and-swissknife-part-3.html)

## Presentations

*   GR8Conf Europe 2015
    *   The [GR8Conf keynote](https://twitter.com/gr8conf/status/605991341676494848) by Guillaume Laforge was livestreamed on YouTube
    *   The slides of the [Groovy keynote](https://speakerdeck.com/glaforge/groovy-state-of-the-union-gr8conf-europe-2015) by Guillaume Laforge
    *   [Groovy with style](https://speakerdeck.com/glaforge/groovy-with-style-gr8conf-europe-2015) by Guillaume Laforge
    *   [Contributing to GR8 technologies](http://danhyun.github.io/gr8conf-eu-2015-contribute-to-gr8tech/#/) by Danny Hyun
    *   [Groovy Safari](http://danhyun.github.io/gr8conf-eu-2015-groovy-safari/#/) by Danny Hyun, a beginner workshop
    *   [Ratpack 101 workshop](http://fr.slideshare.net/alvarosanchezmariscal/ratpack-101-gr8conf-2015) by Álvaro Sánchez Mariscal
    *   [No-nonsense NoSQL](http://jlstrater.github.io/No-Nonsense-NoSQL/#/) by Jennifer Strater
    *   [Groovy under Macro-scope](https://speakerdeck.com/bsideup/gr8conf-groovy-under-macroscope) by Sergei Egorov
    *   [Spring Boot and Groovy](http://fr.slideshare.net/ilopmar/gr8conf-2015-spring-boot-and-groovy-what-more-do-you-need) by Iván López
    *   Göran Ehrsson on [customer relationship management plugins for Grails](http://gr8crm.github.io/)
    *   [Groovy REST](https://speakerdeck.com/glaforge/groovy-rest-gr8conf-europe-2015) by Guillaume Laforge
    *   [Groovy and legos](http://fr.slideshare.net/ryanvanderwerf/all-your-legos-are-belong-to-us-testout) by Ryan Wanderverf
    *   [Geb for testing Grails applications](http://imada.sdu.dk/~jamik/gr8conf/geb.html#/) by Jacob Aae Mikkelsen
    *   [Lessons learned teaching a Groovy / Grails course](http://imada.sdu.dk/~jamik/gr8conf/lessons-learned.html#/) by Jacob Aae Mikkelsen
    *   [Testing with Spock, the logical choice](http://fr.slideshare.net/ilopmar/gr8conf-2015-testing-with-spock-the-logical-choice), by Iván López
    *   [Groovy on the Shell](http://fr.slideshare.net/sascha_klein/groovy-ontheshell-gr8-48989676) by Alexander Klein
    *   [Android on Groovy](http://fr.slideshare.net/sascha_klein/android-on-groovygr8-48989809) by Alexander Klein
    *   [Stateless authentication for microservices](http://fr.slideshare.net/alvarosanchezmariscal/stateless-authentication-for-microservices-gr8conf-2015) by Álvaro Sánchez Mariscal
    *   [GrooScript in Action](http://es.slideshare.net/JorgeFrancoLeza/grooscript-gr8conf-2015) by Jorge Franco Leza
    *   [Rapid application development with Ratpack](http://fr.slideshare.net/aestasit/rapid-web-application-development-with-groovy-ratpack-for) by Andrey Adamovich
    *   Guillaume Laforge presented on [Groovy on Android]({{< ref "/talks/2015/06/24/groovy-on-android-for-the-paris-android-user-group" >}}) at the Paris Android User Group
    *   [Gradle hot or not](http://zeroturnaround.com/rebellabs/gradle-hot-or-not-by-andres-almiray/), by Andrés Almiray
    *   Iván López' slides and code on [metaprogramming options with Groovy](https://twitter.com/ilopmar/status/618681788307800064)
*   Greach 2015 videos
    *   Andrés Almiray presented the [Groovy Ecosystem](https://www.youtube.com/watch?v=gmDi-8k2NhQ)
    *   [Groovy options for reactive programming](http://greachconf.com/speakers/steve-pember-groovy-options-for-reactive-programming/) by Steve Pember
    *   [GPars remoting](http://greachconf.com/speakers/russel-winder-gpars-remoting/) by Russel Winder
    *   [Beyond Gradle 2](http://greachconf.com/speakers/rene-groeschke-beyond-gradle-2-0/) by René Gröschke
    *   [Idiomatic Gradle plugin writing](http://greachconf.com/speakers/schalk-w-cronje-idiomatic-gradle-plugin-writing/) by Schalk Cronjé
    *   [Advanced micro services concerns](http://greachconf.com/speakers/steve-pember-advanced-microservice-concerns/) by Steve Pember at Greach 2015
*   Gradle Summit presentations
    *   [State of the art Gradle multi-module builds](https://speakerdeck.com/bmuschko/state-of-the-art-gradle-multi-module-builds) by Benjamin Muschko at Gradle Summit
    *   [Advanced dependency management with Gradle](https://speakerdeck.com/bmuschko/advanced-dependency-management-with-gradle) by Benjamin Muschko at Gradle Summit
    *   [A centralized team in a decentralized world](http://fr.slideshare.net/jmcgarr/centralized-team-in-a-decentralized-world-engineering-tools-at-netflix) Mike McGarr at Gradle Summit

## Interviews

*   Andrés Almiray interviewed at Greach about the [Griffon ecosystem](https://www.youtube.com/watch?v=OtzQYJxHcaA) (in Spanish but subtitled in English)

## Tweets

*   Guillaume Laforge announces that [Groovy has been downloaded 4.5 million times for the first half of the year](https://twitter.com/glaforge/status/617061188199936000), as much as the whole of 2014. With 1M downloads from Bintray and 4.5M downloads from Maven Central.
*   Guillaume Laforge updated the [Groovy Web Console to the latest Groovy 2.4.3](https://twitter.com/glaforge/status/617443128988028928), developed with the latest Gaelyk 2.1.2 update
*   Graeme Rocher [reworked the reloading in Grails 3.0.3](https://twitter.com/graemerocher/status/616903346499272704)
*   Søren Berg Glasius and Guillaume Laforge are launched [the 7th edition of GR8Conf Europe 2015](https://twitter.com/glaforge/status/605992876753985536)!
*   Ixchel Ruiz says [Groovy is alive and thriving](https://twitter.com/ixchelruiz/status/606002309349416960)!
*   Schalk Cronjé drew his [summary of Guillaume Laforge's GR8Conf keynote](https://twitter.com/ysb33r/status/606009047607865344)
*   Kostis Kapelonis feels that [even after the release of Java 8, Groovy closures are still more convenient](https://twitter.com/codepipes/status/617355655352057858)
*   Seems like [developing on Android with Groovy and RxJava can blow your mind](https://twitter.com/DexafreeHTC/status/616640764173512704)!
*   Dierk König shares interesting [ranking information about Groovy in Action on Amazon](https://twitter.com/mittie/status/616613035126484992)
*   ReGinA selfies:
    *   [Sébastien Blanc](https://twitter.com/sebi2706/status/617003864068386816)
    *   [Ben Klein](https://twitter.com/fifthposition/status/615593893082603521)
    *   [Robert Fletcher](https://twitter.com/rfletcherEW/status/611990264698114048)
    *   [Guillaume Laforge](https://twitter.com/glaforge/status/611072178407219201)
*   Russell Hart says that [GroovyChainAction is back in Ratpack 0.9.18](https://twitter.com/rus_hart/status/616586423102218240)
*   Russell Hart encourages users to [seek for help on the Ratpack forum](https://twitter.com/rus_hart/status/616584233059000320)
*   [Spring Boot 1.2.5](https://twitter.com/sdkmanager/status/616505672537083905) available on GVM
*   If you're [missing Maven archetypes in Gradle, try Lazybones](https://twitter.com/RebelLabs/status/615963195006656513), says Andrés Almiray
*   The [Geb framework team has caught up with the outstanding pull requests](https://twitter.com/GebFramework/status/615487750037483520), time to submit some more!
*   Andrés Almiray claims that [migration from Maven to Gradle is a matter of "when", not of "if"](https://twitter.com/aalmiray/status/615275454497452032)
*   Tim Yates loves how [Spock makes mocking and interaction testing easy and readable](https://twitter.com/tim_yates/status/615261252328292352) (with a code sample)
*   The [book of Geb has migrated to Asciidoctor with executable code samples](https://twitter.com/GebFramework/status/614407603620327424)
*   Danny Hyun encourages folks to use the [asset pipeline Gradle plugin](https://twitter.com/Lspacewalker/status/614148984832139265)
*   Peter Ledbrook points at the [Gradle continuous build feature that responds to filesystem changes](https://twitter.com/pledbrook/status/613998420404125696) by running tests again
*   [Gradle 2.5-rc-1](https://twitter.com/sdkmanager/status/613992559900295168) available on GVM
*   Kevin Tan pointed me at [another Groovy-built Android application available in the Play store](https://twitter.com/S1lv3rd3m0n/status/613937882605027328)
*   Ratpack.io is now powered by the [Ratpack asset pipeline plugin](https://twitter.com/Lspacewalker/status/613101435270643716)
*   [Legacy versions of Groovy are restored on GVM](https://twitter.com/sdkmanager/status/612555268677836800), thanks to the Bintray team, Marco Vermeulen and Guillaume Laforge
*   [AngularJS Annotate is a Gradle Asset Pipeline module](https://twitter.com/danveloper/status/611604849508151296) that allows AngularJS code to be minified
*   Cédric Champeau announces [older versions of Groovy to be available on Bintray](https://twitter.com/CedricChampeau/status/611332345707139074)
*   Say hello to [automatic relative asset url replacement in static HTML](https://twitter.com/davydotcom/status/611212285382664193) with the Gradle asset pipeline plugin
*   [Location of ratpack.groovy is now configurable](https://twitter.com/danveloper/status/611163598774235136) via the Ratpack Gradle plugin says Dan Woods
*   An initial list of [Grails 3 plugins to be updated in priority](https://twitter.com/grailsframework/status/611107170692825088)
*   [Grails 3.0.2](https://twitter.com/sdkmanager/status/610783733642317824) available on GVM
*   Jorge Martín says [what's a hipster Android project looks like in Groovy](https://twitter.com/arasthel92/status/610209132306694144)
*   All of Ken Kousen's [Groovy videos for O'Reilly are online](https://twitter.com/kenkousen/status/610077557065691136)
*   Graeme Rocher [improved Grails 3 performance by 20%](https://twitter.com/olavgg/status/608650670279946241)
*   [OrientDB Groovy supports the Graph API](https://twitter.com/eugenekamenev/status/608124188868669441), Gremlin, and nice IntelliJ IDEA support says Eugene Kamenev
*   You can find [GORM in Copenhagen](https://twitter.com/jmiguel/status/606745439468187648)
*   Original [Groovy project founder is hacking Groovy again](https://twitter.com/jstrachan/status/606831442425999360) within IntelliJ IDEA, in the shell and in Jenkins via the Job DSL for Continuous Integration and Continuous Delivery, and he's forgotten how much Groovy coding is fun!!
*   Craig Burke is investigating [using JFairy for sample value generation with GORM](https://twitter.com/craigburke1/status/607973363105923072)
*   Small [Ratpack enhancement with sessions and Java 8](https://twitter.com/ratpackweb/status/608063775825096706) default interface methods
*   [Danny Hyun is a happy Groovy contributor](https://twitter.com/Lspacewalker/status/606561199505801216)!
*   Philipp Berner released a [Gradle plugin that reports the number of method references in Android APKs](https://github.com/KeepSafe/dexcount-gradle-plugin)
*   [Lots of Gradle goodies to be found in the Griffon build](https://twitter.com/aalmiray/status/606435403420299264), says Andrés Almiray
*   Guillaume Laforge showing a [REST example with Ratpack using the byContent method](https://twitter.com/Lspacewalker/status/606421415512948736)
*   [Groovy 2.4.3 is 2x faster than 2.2 at starting on the Lego EV3 robot](https://twitter.com/RyanVanderwerf/status/606382108156657665) says Ryan Vanderwerf
*   [Andrés Almiray is releasing Griffon 2.3 on stage with style](https://twitter.com/gr8conf/status/606126974940147712) at GR8Conf Europe 2015!
*   [Andrés Almiray pushed his first commit as a Groovy committer](https://twitter.com/aalmiray/status/606022186135109632) at Apache
*   [JBake 2.4](https://twitter.com/sdkmanager/status/605875255974838273) available on GVM
    
## News

*   The [Paris Groovy user group is going to reboot](https://groups.google.com/forum/?hl=fr#!forum/paris-groovy-user-group) and come back in September, but starts with a fresh mailing-list on Google Groups. So if you're in the Paris area, join the band!
*   [Groovy in Action 2nd edition is available in print and eBook formats](https://twitter.com/ManningBooks/status/610553583940014080)
*   [Ratpack AWS Kinesis consumer](https://github.com/aaronzirbes/kinesis-http-adapter) that forwards to an HTTP endpoint by Aaron Zirbes
*   Mario García releases [FlambdaZ, a new Groovy functional library](http://mariogarcia.github.io/fnz/)
*   Udacity offers a [free online training on Gradle for Android](http://gradle.org/udacitys-gradle-for-android-training/) app development
*   A new [practical Groovy programming video](https://twitter.com/infiniteskills/status/614547512419074048) by Ken Kousen on O'Reilly
*   [New location for the Griffon mailing-lists](https://twitter.com/theaviary/status/611622405581197312)
*   Jacob Aae Mikkelsen's [Grails Diary](https://twitter.com/JacobAae/status/610569967864532993) week 24
*   Jacob Aae Mikkelsen's [Grails Diary](http://grydeske.net/news/show/98) for weeks 22 and 23
*   The new [Apache hosted mailing-lists are now archived on Nabble](https://twitter.com/glaforge/status/609462312840335362) like the old ones
    
## Podcasts

*   [Groovy podcast episode 14](https://twitter.com/groovypodcast/status/611944311551340545)
*   [Groovy Podcast episode 15](https://twitter.com/groovypodcast/status/616287886531522560)
    
## Code snippets

*   The [source code of Groovy in Action (2nd ed) is available on Github](https://twitter.com/mittie/status/606845647459917825)
*   Dan Woods tweeted a [hello world Ratpack in less than 140 characters](https://twitter.com/danveloper/status/608298173208100864)
*   A sample [REST API interaction from the client side with Groovy trait, JQuery and GrooScript](https://gist.github.com/chiquitinxx/b661f27c647c3cfe5d38)
*   A [Vert.x app in Groovy in a tweet](https://twitter.com/timfox/status/608304503939584003) by Tim Fox
*   Based on David Gageot's http library, Guillaume Laforge shows a little snippet for [another hello world web server in a line of Groovy](https://gist.github.com/glaforge/b5c55651f523b3281fc9) code
*   Russ Hart has put online his [Ratpack hands-on](https://github.com/rhart/hands-on-ratpack)
*   A trick to [speedup Gradle builds in Android Studio](https://dineshramitc.wordpress.com/2015/07/07/speed-up-gradle-builds-in-android-studio/)
*   A [Ratpack with React](http://forum.ratpack.io/Ratpack-with-React-hot-loader-support-td1141.html) hot loader support
*   [Marco Vermeulen loves Groovy's productivity](https://twitter.com/marc0der/status/612554222920404992) and shows a code snippet to demonstrate it
*   Eugene Kamenev published a [sample app mixing Groovy, Spring Boot, OrientDB](https://twitter.com/eugenekamenev/status/613038251155152896) and Gremlin
*   Write your [ReactiveX code in Groovy with GrooScript](https://twitter.com/grooscript/status/609093126041550848) and run in a Javascript environment
*   Arnaud Esteve shows a draft of a [Groovy DSL for Vert.x 3's router](https://twitter.com/ArnaudEsteve/status/608926350028759041)
*   Tim Fox' tweetable [hello world Vert.x app in Groovy](https://twitter.com/timfox/status/608304503939584003)
*   Dan Woods' tweetable [Ratpack hello world app in Groovy](https://twitter.com/danveloper/status/608298173208100864)
*   A [GrooScript DSL to use the Google Maps API](https://twitter.com/grooscript/status/607613663978078208)
*   [Rest API from the client-side with GrooScript](https://twitter.com/grooscript/status/607678436379885568)

## Mailing-list posts

*   Discussing an [experimental @POJO AST transformation](http://www.groovy-lang.org/mailing-lists.html#nabble-td5725804) by Paul King for a Groovy-less runtime

## Jobs

*   [Netflix is hiring Gradle talents](https://twitter.com/gradle/status/615986939905351680)
*   [Gradle job trend on the rise](http://www.indeed.com/jobanalytics/jobtrends?q=gradle)
*   A [Groovy and Grails job in Munich](https://twitter.com/deigote/status/608695031046795265), Germany
    
## Books

*   Dierk König announces that [Groovy in Action is back in stock at Amazon](https://twitter.com/mittie/status/614872367106555904) since the beginning of the month
*   [Groovy in Action 2nd edition was #1 on Amazon's hot new releases](https://twitter.com/mittie/status/610779780246577152) says Dierk König
*   [Groovy 2 tutorial cookbook](http://www.groovy-lang.org/mailing-lists.html#nabble-td5725795) update by Duncan Dickinson available on LeanPub
*   [Korean and Japanese books on Gradle](https://twitter.com/gradle/status/614527377440407552) available
*   A new Manning MEAP upda[te to the Java testing with Spock book](http://manning.com/kapelonis/)
# Groovy on Android for the Paris Android User Group


Yesterday, I had the pleasure to speak about Groovy on Android at the [Paris Android User Group](http://www.meetup.com/fr/Android-Paris/events/223305279/). This is an evolution of my presentation from the DroidCon 2014 conference, with a few updates, in particular more coverage of SwissKnife.

{{< speakerdeck 6284de7ee6d24035955a19bf6173a7a5 >}}

# Groovy in Action, 2nd edition is not a myth!


It took us a while to get it finished, but I assure you it was well worth the wait, and [Groovy in Action, 2nd edition](http://www.manning.com/koenig2/), is real! I just received my copies this morning!

Congrats to my fellow co-authors, and in particular to Dierk and Paul for their patience and dedication to this project, without whom the book would have never gone through its print stage!

![](/img/misc/2015-06-17+09.22.37.jpg)
# My GR8Conf presentations slides


It's been a busy and intense week here at Copenhagen for [GR8Conf Europe 2015](http://gr8conf.eu/#/)! Great interactions and discussions with the Groovy community, and flawless organization.  

I had the chance to present three talks this year, and I'm embedding my slides below. First of all, I've given the usual Groovy keynote, with a Groovy state of the union. 

{{< speakerdeck a961bdc6faeb466199eded25f2a402a3 >}}

Later on, I gave a talk on Groovy style! With interesting tips'n tricks, programming style advice. 

{{< speakerdeck 5e39a3f0f8ae4cc58803bc70c903bd56 >}}

Lastly, with my Web API hat on, I talked about various tools for creating and testing Web APIs.

{{< speakerdeck 7ae90f9be4c54a15a2d6c723fbca623a >}}

# Groovy Weekly #72


This 72th edition is being authored live from the Hackergarten session at [GR8Conf Europe 2015](http://gr8conf.eu/#/), in Copenhagen (Denmark), where Groovy hackers are working on various contributions to the Groovy and Grails ecosystem, updating Grails 2 plugins to Grails 3, crafting a Groovy UI builder for Android, or work on some Gradle plugins. A busy evening!

It’s been a little long while coming, but [Groovy in Action 2nd edition has just been sent to the printers](https://twitter.com/mittie/status/604634440065761280)! And the ebook formats will also be available this week!

## Releases

*   [Ratpack 0.9.17](http://ratpack.io/versions/0.9.17) released with new session support
*   [SwissKnife 1.3.1](https://twitter.com/arasthel92/status/603990688481615875) released with Android Res injection and better Parcelable support

## Articles

*   Immutable [infrastructure made easy with a Gradle](https://boxfuse.com/blog/gradle-plugin.html) plugin

## Presentations

*   [Groovy, in the light of Java 8](https://www.parleys.com/tutorial/groovy-light-java-8-1), presented by Guillaume Laforge at Devoxx Belgium (registration required, but otherwise free content)
*   [Documentation brought to life with Asciidoctor and Gradle](http://greachconf.com/speakers/markus-schlichting-documentation-brought-to-life-asciidoctor-gradle/), presented by Markus Schlichting at Greach
*   Marco Vermeulen on the [Groovy enVironment Manager](http://greachconf.com/speakers/marco-vermeulen-groovy-environment-manager-2015/), 2015 edition, at Greach
*   [Groovy Transformers](http://greachconf.com/speakers/ivan-lopez-ast-groovy-transformers-more-than-meets-the-eye/): more than meets the eye by Ivan Lopez at Greach
*   [Groovy past and future](http://greachconf.com/speakers/jochen-theodorou-groovy-past-and-future/) by Jochen Theodorou at Greach
*   Claus Ibsen shares a video of [Groovy, Grails and Apache Camel](https://twitter.com/davsclaus/status/603480717390172160)

## Tweets

*   [Groovy in Action 2nd edition has been sent to the printers](https://twitter.com/mittie/status/604634440065761280)! eBook versions available this week!
*   Object Computing Inc announces [Dave Klein and Collin Harrington are joining the Grails team](https://twitter.com/ObjectComputing/status/605496734265925632)
*   Schalk Cronjé learned about [Shoogr](https://twitter.com/ysb33r/status/605693295164051456) at GR8Conf Europe and is thinking about integration with Groovy VFS
*   Dan Woods believes [Ratpack and Spring Cloud is as natural a marriage as cloud native gets](https://twitter.com/danveloper/status/605602603016310784)
*   Add [LiveReload support to your Ratpack](https://twitter.com/ratpackweb/status/604446744198266881) app development
*   CardShifter's been a happy user of [Groovy for its game design](https://twitter.com/Cardshifter/status/604423648640925696) work
*   Yann Le Moigne is looking for [feedback for two of his Ratpack modules](https://twitter.com/LeMoigneY/status/604310642737074177)
*   [GVM mentions some alternative names](https://twitter.com/sdkmanager/status/604002646530342912) getting traction
*   Jorge Martín says [you can't truly understand the power of Groovy AST transformations until you realize how limited Java APT is](https://twitter.com/arasthel92/status/603843044950020096)
*   Dierk König tells us that [Groovy in Action 2nd edition will be 912 pages](https://twitter.com/mittie/status/603286822396010496) long

## Code snippets

*   [Create a REST API fake with Groovy](https://twitter.com/grooscript/status/605058483604570112), using npm faker and JSON server
*   Eugene Kamenev shares the code of a [Spring Boot and OrientDB app in Groovy](https://twitter.com/eugenekamenev/status/604248101927391232)
*   Eugene Kamenev is working on [Groovy wrappers around OrientDB](https://github.com/eugene-kamenev/orientdb-groovy)'s APIs

## Books

*   [Groovy in Action 2nd edition comes with 10 thousand lines of code](https://twitter.com/mittie/status/605349387892604928) tested automatically, notes Dierk König

## Podcasts

*   [Groovy Podcast episode 13](https://twitter.com/groovypodcast/status/603575371255033856) published
# Groovy Weekly #71


GR8Conf Europe 2015 is literally around the corner, as the conference will start next week in Copenhagen! I’m really excited to be joining the usual flock of Groovy afictionados and talk all things Groovy.

Speaking of conferences, lots of new videos and accompanying slide decks have been released, so there are hours of binge watching ahead!

By now, I think I can stop reminding you about the move of Groovy from Codehaus to the Apache Software Foundation? (and the move of the mailing-lists, issue tracker, sources, etc.)

## Releases

*   [GrooScript 1.1.1](https://twitter.com/grooscript/status/602547059418386435) released with associated Gradle plugin with support for Require.JS for improved Groovy / JavaScript interoperability

## Articles

*   Ken Kousen recounts his [upcoming Groovy-related events and activities](https://kousenit.wordpress.com/2015/05/25/upcoming-events-and-the-streak/)

## News

*   [Awesome Groovy crosses 100 stars](https://github.com/kdabir/awesome-groovy) and counting on Github
*   [GVM is thinking about changing its name](https://twitter.com/gvmtool/status/603123176315424768), cast your vote!
*   Jacob Aae Mikkelsen's [Grails Diary](http://grydeske.net/news/show/97) week #21
    
## Presentations — special Greach 2015 coverage

*   [Grooscript in action](http://greachconf.com/speakers/jorge-franco-grooscript-in-action/) by Jorge Franco
*   Andrés Almiray presented about the [Groovy ecosystem](http://greachconf.com/speakers/andres-almiray-the-groovy-ecosystem/)
*   Sport store chain [Decathlon built its social network with Grails](http://greachconf.com/speakers/antonio-de-la-torre-alonso-torres-decathlon-sportmeeting-sports-a-new-grails-discipline/), presented by Antonio de la Torre and Alonso Torres Ortiz
*   [Advanced microservice concerns](http://greachconf.com/speakers/steve-pember-advanced-microservice-concerns/) by Steve Pember
*   [Beyond Gradle 2.0](http://greachconf.com/speakers/rene-groeschke-beyond-gradle-2-0/) by René Gröschke
*   [Idiomatic Gradle plugin writing](http://greachconf.com/speakers/schalk-w-cronje-idiomatic-gradle-plugin-writing/) by Schalk Cronjé
*   [Building Android apps with Gradle](http://greachconf.com/speakers/rene-groeschke-building-android-apps-with-gradle/) by René Gröschke
*   [Documentation brought to life with Asciidoctor and Gradle](http://greachconf.com/speakers/markus-schlichting-documentation-brought-to-life-asciidoctor-gradle/) by Markus Schlichting
*   Marco Vermeulen gives a status update on the [Groovy enVironment Manager in 2015](http://greachconf.com/speakers/marco-vermeulen-groovy-environment-manager-2015/)
*   [Securing Ratpack](http://greachconf.com/speakers/jeff-beck-securing-ratpack/) by Jeff Beck
*   Göran Ehrsson on [cutting your Grails app to pieces with feature plugins](http://greachconf.com/speakers/goran-ehrsson-cut-your-grails-application-to-pieces-build-feature-plugins/)
*   Burt Beckwith shares [interesting nuggets found during Grails development](http://greachconf.com/speakers/burt-beckwith-little-did-he-know/)

## Tweets

*   With Codehaus' EOL, [Groovy binary distributions prior to 2.2.2 are temporarily unavailable through GVM](https://twitter.com/gvmtool/status/601312032881844224)
*   Robin Bramley suggest an [ideal Groovy snack for the break](https://twitter.com/rbramley/status/601350754595639297)!

## Snippets

*   Erik Pragt shares a [script to check the health status of a Grails 3 app](https://gist.github.com/bodiam/fe3f8448e8296bc2e07d)

## Books

*   [Groovy in Action will have a total of 912 pages](https://twitter.com/mittie/status/603286822396010496)!
    
## Jobs

*   A "fintech" startup in London is looking for [developers with Groovy, Grails and mobile experience](https://twitter.com/Charliedysonrec/status/601496181106171904)

## Events

*   The [GR8Conf Android application has been updated](https://twitter.com/CedricChampeau/status/603145483914215424) to display next week's European edition!
# Groovy Weekly #70


Last week, Codehaus has gone the way of the dodo. The lights are switching off. A page is turning.

So please remember about our infrastructure changes, as we move the Groovy project through the incubation process at Apache: the [JIRA issue tracker has moved](https://issues.apache.org/jira/browse/GROOVY/), and don’t forget that the [Groovy mailing-lists are also moving](http://www.groovy-lang.org/mailing-lists.html). The [Apache Git repository](https://twitter.com/glaforge/status/588809178958925824) is now the new mainline, but you can contribute pull requests on the new [Apache Groovy Github mirror](https://twitter.com/glaforge/status/588960808094326784). Be sure to update all your bookmarks, and register on the new mailing-list!

Beside that, there’s one particular item in the news below that I’d like to highlight here, that’s the [great and thourough presentation on Spock](https://speakerdeck.com/szpak/smarter-testing-java-code-with-spock-framework). If you want to learn the latest and greatest about Spock 1.0, that’s the slide deck you must have a look at!

## Releases

*   [Gretty 1.2.3](https://twitter.com/AndreyHihlovski/status/600703585027018753) released

## Articles

*   Igor Shults shares the [list of Groovy versions for each version of Grails](https://objectpartners.com/2015/05/14/list-of-groovy-versions-for-each-version-of-grails/)
*   Jacob Severson talks about [dependable microservices via Cloud Foundry's Lattice and Grails 3](https://objectpartners.com/2015/05/19/dependable-microservices-via-lattice/)
*   Brendon Anderson shares his [feedback on his first Ratpack application](https://objectpartners.com/2015/05/12/my-first-ratpack-app-what-i-learned/)
*   The Groovy-Programming blog post features an article on [Google Analytics measurement protocol in Groovy](http://groovy-programming.com/post/118804818009)
*   David Dawson explains how to [build a Grails application based on a hexagonal architecture](http://www.infoq.com/presentations/hexagonal-arch-grails)
*   The Groovy Algorithms blog features a post on a [model implementation of frequent pattern mining](http://groovyalgorithms.altervista.org/frequent-pattern-mining-model-implementation/)
*   Algorithms in Groovy blog post on the [top 5 that makes Groovy scripting loveable](http://groovyalgorithms.altervista.org/top-5-things-that-make-me-love-scripting-in-groovy/)

## News

*   Jacob Aae Mikkelsen's [Grails Diary](http://grydeske.net/news/show/96) week 20
*   The [Gradle GVM SDK vendor plugin](https://twitter.com/gvmtool/status/598961449193459712) is now available in the Gradle plugin portal
*   The [last month in GUM](http://groovymn.tumblr.com/post/118772921517/last-month-in-gum) news
*   The curated [Groovy Dev Weekly](http://groovydevweekly.com/issues/5#start) news

## Presentations

*   Marcin Zajączkowski gave an [excellent and detailed presentation on smarter testing Java code with Spock](https://speakerdeck.com/szpak/smarter-testing-java-code-with-spock-framework), with lots of Spock 1.0 coverage. A must see to master Spock!
*   From the GeeCon conference:
    *   Iván López shares the [slides and code of his Grails presentation](https://twitter.com/ilopmar/status/599124700527087616)
    *   Álvaro Sánchez-Mariscal shares the [slides and code of his Ratpack presentation and workshop](https://twitter.com/alvaro_sanchez/status/599178631827587072)
*   From Devoxx France (but in French!):
    *   “[Plugin Gradle, prenez le contrôle du build](https://www.parleys.com/tutorial/plugin-gradle-prenez-le-controle-du-build)”, by Cédric Champeau and Eyal Lezmy
    *   "[Groovy et son process de release](https://www.parleys.com/tutorial/groovy-et-son-process-de-release-nous-lavons-rendu-grooooooovy)" by Guillaume Laforge, Cédric Champeau and Frédéric Simon
*   From Greach, [stateless authentication for microservices with Spring Security in Grails](http://greachconf.com/speakers/alvaro-sanchez-mariscal-stateless-authentication-for-microservices/), by Álvaro Sánchez-Mariscal

## Tweets

*   Ken Kousen published a [Groovy Fundamentals video course](https://twitter.com/kenkousen/status/600725847826366464) for O'Reilly Media
*   Craig Burke believes that [Grails 3 custom scripts can prove useful for generating Grails / Angular.JS CRUD apps](https://twitter.com/craigburke1/status/598883871330062336)
*   Craig Burke [upgraded his Angular.JS / Grails test app to Grails 3](https://twitter.com/craigburke1/status/598912886031912962)

## Books

*   Dierk König says that [Groovy in Action 2nd ed offers the first full description of Groovy as a static language](https://twitter.com/mittie/status/600199545335771136), covering static compilation, static type checking, and type checking extensions

## Events

*   The Gradle summit early bird ends Friday
# Groovy Weekly #69


Groovy Weekly skipped a beat as I was very busy: I was very fortunate to spend my last week in California for various meetings, plus being a keynote speaker at JFrog’s [SwampUp](http://swampup.jfrog.com/) conference in Napa Valley. I had the chance to speak again about the Groovy release process and its history (based on my recent Devoxx [talk](https://speakerdeck.com/glaforge/groovys-release-process-devoxx-2015)).

Congrats to the Gradle team for releasing [Gradle 2.4 with much faster builds](http://swampup.jfrog.com/)!

Hurry up to [register to GR8Conf Europe 2015](http://us4.campaign-archive2.com/?u=ac7af4c02d6cec67fe3198a63&id=6071c3f248), as registration closes on May 15th! Hurry up, and join the Groovy ecosystem fans gathering!

Reminder about our infrastructure changes, as we move the Groovy project through the incubation process at Apache: the [JIRA issue tracker has moved](https://issues.apache.org/jira/browse/GROOVY/), and don’t forget that the [Groovy mailing-lists are also moving](http://www.groovy-lang.org/mailing-lists.html). The [Apache Git repository](https://twitter.com/glaforge/status/588809178958925824) is now the new mainline, but you can contribute pull requests on the new [Apache Groovy Github mirror](https://twitter.com/glaforge/status/588960808094326784). Be sure to update all your bookmarks, and register on the new mailing-list!

## Releases

*   [Gradle 2.4](https://discuss.gradle.org/t/gradle-2-4-released/9471) released
*   [Ratpack 0.9.16](http://ratpack.io/versions/0.9.16/) released
*   [Groovy Document Builder v0.4](http://www.craigburke.com/document-builder/) by Craig Burke
*   [Grengine 1.0.3](http://grengine.ch/manual.html#grengine-and-grape) released
*   [Jexler 1.0.16](http://www.jexler.net) released

## Articles

*   Mirosław Gołda on [automated tests with Geb, Spock and Groovy](http://allegrotech.io/automated-tests-with-geb-spock-and-groovy.html)
*   MrHaki's Groovy Goodness: [Share data in concurrent environment with dataflow variables](http://mrhaki.blogspot.dk/2015/05/groovy-goodness-share-data-in.html)
*   [APIs with Grails 3 and OAuth 2](http://blog.agileorbit.com/2015/05/11/Grails3-OAuth2.html) by Bobby Warner
*   [Concurrent kitties using GPars](https://kousenit.wordpress.com/2015/05/08/concurrent-kitties-using-gpars/) by Ken Kousen (spoiler, no animals harmed!)
*   [GrooScript Groovy templating on the browser client-side](http://grooscript.org/gradle/templating.html)
*   Eric MacAdie writes about the [@Hidden annotation in Groovy Validators](http://www.macadie.net/2015/05/09/hidden-annotation-in-groovy-validators/)
*   [Testing plugin compatibility against Gradle versions](https://discuss.gradle.org/t/testing-plugin-compatibility-against-gradle-versions/9473) by Schalk Cronjé on the Gradle forums
*   [Deploying Grails apps to Docker](http://www.dahlgren.so/docker/2015/04/12/Deploying-Grails-Apps-To-Docker/) by Ron Dahlgren
*   [Groovy profiling with Gprof](http://groovyalgorithms.altervista.org/groovy-profiling-with-gprof/)
*   [Groovy benchmarking with GBench](http://groovyalgorithms.altervista.org/groovy-benchmarking-with-gbench/)
*   [Using Gradle and Bower to manage JavaScript and CSS dependencies](https://objectpartners.com/2015/04/29/using-gradle-and-bower-to-manage-jscss-dependencies/) by Patrick Double
*   [Compile Groovy scripts at runtime and allow caching](http://www.intelligrape.com/blog/compile-groovyscript-at-runtime-allow-caching-of-compiled-source-to-avoid-recompilation-at-runtime-using-groovyclassloader/) of compiled source to avoid recompilation using GroovyClassLoader by Tarun Pareek
*   StackOverflow Groovy superstar Tim Yates answers a question on [map vs array performance](http://stackoverflow.com/questions/29976665/why-groovys-map-scales-better-than-array)

## News

*   [Grails Diary](http://grydeske.net/news/show/95) week 19 by Jakob Aae Mikkelsen

## Presentations

*   Cédric Champeau presented at the Bordeaux JUG on Gradle's way of convention over configuration
*   More SpringOne2GX 2014 videos released:
    *   [Grails plugin testing strategies](http://www.infoq.com/presentations/grails-plugin-testing) by Baruch Sadogursky
    *   Owen Rubel talks about [API abstraction and API chaining in Grails](http://www.infoq.com/presentations/api-grails-dry)
    *   [Groovy vampires: combining Groovy, REST, NoSQL](http://www.infoq.com/presentations/groovy-rest-nosql), and more by Ken Kousen
    *   Fabrice Matrat dives into [single page applications with Grails and RaveJS](http://www.infoq.com/presentations/single-page-app-ravejs-grails)
    *   [Conquering content-enabled web and mobile applications with Spring and Groovy](http://www.infoq.com/presentations/web-mobile-apps-spring-groovy) by Russ Danner
    *   [Writing AST transformations, get practical in 90 minutes](http://www.infoq.com/presentations/ast-transformations) by Baruch Sadogursky and Fred Simon
    *   The [future of Gradle](http://www.infoq.com/presentations/future-gradle-javascript), the ultimate build system, by Hans Dockter
*   Greach videos too:
    *   Trisha Gee on [Groovy vs Java for testing](http://java.dzone.com/articles/groovy-vs-java-testing-video)
    *   [Introducing workflow architectures using Grails](http://greachconf.com/speakers/ruben-mondejar-andreu-introducing-workflow-architectures-using-grails/) by Rubén Mondéjar Andreu
    *   [Grails and Cassandra](http://greachconf.com/speakers/jeff-beck-grails-and-cassandra/) by Jeff Beck
    *   [Groovy on the shell](http://greachconf.com/speakers/alexander-sascha-klein-groovy-on-the-shell/) by Alexander Klein
    *   [Use Groovy and Grails in your Spring Boot projects](http://greachconf.com/speakers/fatima-casau-use-groovy-grails-in-your-spring-boot-projects-don-t-be-afraid/), by Fatima Casau

## Tweets

*   Cédric Champeau echoes that the [Groovy project is looking for developers to help on the Groovy Eclipse project](https://twitter.com/CedricChampeau/status/593347714244575232)
*   Dierk König says that Groovy in Action chapter 8 is the first [complete exposition of all Groovy runtime metaprogramming capabilities](https://twitter.com/mittie/status/597649018676707328)
*   The [code base of Groovy in Action 2nd ed contains over 1000 power assert statements](https://twitter.com/mittie/status/596753493270110208) counted Dierk König
*   [Griffon 2.3 will feature JavaFX specific AST transformations](https://twitter.com/theaviary/status/597053097089826817)
*   Ratpack 0.9.17 will let you use [async promises from synchronous APIs](https://twitter.com/ratpackweb/status/594753885266378752)
*   Robert Zakrzewski is a [new contributor to the Ratpack](https://twitter.com/ratpackweb/status/595515092885643264) project
*   [Gradle 2.4](https://twitter.com/gvmtool/status/595553687617036289) available on GVM
*   [SonarQube's Groovy plugin now supports code coverage](https://twitter.com/aheritier/status/595671992797388800) notes Arnaud Héritier

## Podcasts

*   [Groovy podcast](https://www.youtube.com/watch?v=E36Dw5xbhzQ) episode 12 is out

## Screencasts

*   Bertrand Goetzmann published a screencast about [creating micro services with Grails 3](https://www.youtube.com/watch?v=LI6EIfmt26I)

## Code snippets

*   Cédric Champeau shows how he integrated [deck2pdf into his Gradle build](https://github.com/melix/bdxjug2015/blob/master/gradle/pdf.gradle)
*   Code samples for [Grails 3 and Spring Security](http://asoftwareguy.com/2015/03/30/spring-security-with-grails-3/)
*   Sergio del Amo authored a [Groovy script to interact with Wordpress' JSON REST API](https://github.com/sdelamo/wp-api-groovy)

## Jobs

*   New Grails' home [Object Computing is hiring more Grails experts](https://twitter.com/grailsframework/status/596081391013466113)
    
## Events

*   [GR8Conf Europe 2015 registration is closing May 15th](http://us4.campaign-archive2.com/?u=ac7af4c02d6cec67fe3198a63&id=6071c3f248), be fast!
*   You can see all the [speakers interviews from Greach](https://twitter.com/greachconf/status/595855035117895680) on YouTube
# Groovy Weekly #68


Remember the Android support of Groovy 2.4? Well, the new [New York Times Android application, written in Groovy](https://twitter.com/mohitpandey/status/592723947311001600) and using RxJava is now live! If a hugely popular Android app is leveraging Groovy, yours can too!

With Groovy’s move to the Apache Software Foundation, [don’t forget to star the new Groovy Github repository](https://twitter.com/sbglasius/status/591322009214160896)!

Don’t miss the interesting interviews of [Jeff Brown](http://www.infoq.com/news/2015/04/grails-3) and [Guillaume Laforge](https://www.voxxed.com/blog/2015/04/pushing-groovy-to-the-speed-of-java-and-beyond/).

Reminder about our infrastructure changes, as we move the Groovy project through the incubation process at Apache: the [JIRA issue tracker has moved](https://issues.apache.org/jira/browse/GROOVY/), and don’t forget that the [Groovy mailing-lists are also moving](http://www.groovy-lang.org/mailing-lists.html). The novelty this week is that the [Apache Git repository](https://twitter.com/glaforge/status/588809178958925824) is now the new mainline, but you can contribute pull requests on the [Apache Groovy Github mirror](https://twitter.com/glaforge/status/588960808094326784).

## Releases

*   [Gradle 2.4-rc-1](http://discuss.gradle.org/t/gradle-2-4-rc-1-is-now-available-for-testing/9282) released with annotation processing with Groovy code
*   Online presentation service Prezi releases a [Haskell plugin for Gradle](https://twitter.com/dvigovszky/status/590889954655473664)

## Articles

*   MrHaki’s on the writing spree:
    *   Grails Goodness
        *   [adding health check indicators](http://mrhaki.blogspot.fr/2015/04/grails-goodness-adding-health-check.html)
        *   [log startup info](http://mrhaki.blogspot.fr/2015/04/grails-goodness-log-startup-info.html)
        *   [save application PID in file](http://mrhaki.blogspot.fr/2015/04/grails-goodness-save-application-pid-in.html)
    *   Gradle Goodness
        *   [handle copying duplicate files](http://mrhaki.blogspot.fr/2015/04/gradle-goodness-handle-copying.html)
        *   [usee Git commit id in build script](http://mrhaki.blogspot.fr/2015/04/gradle-goodness-use-git-commit-id-in.html)
*   [Groovy now runs faster on mobile](http://www.grails.info/2015/04/23/new-blog-groovy-now-runs-faster-than-java-on-mobile/) than Java says Grails Info news site
*   Iván López on [talking about Groovy](http://www.kaleidos.net/blog/1071/talking-about-groovy-in-vienna/) in Vienna

## Interviews

*   Guillaume Laforge interviewed by Voxxed during Devoxx France, talking about [Groovy's Android support, Grails 3.0, Groovy in RESTful APIs](https://www.voxxed.com/blog/2015/04/pushing-groovy-to-the-speed-of-java-and-beyond/) and more
*   Matt Raible interview [Jeff Brown on Grails 3](http://www.infoq.com/news/2015/04/grails-3), built on Spring Boot and Gradle

## News

*   The [New York Times Android application written in Groovy](https://twitter.com/mohitpandey/status/592723947311001600) and using RxJava is now live!
*   [Grails Brasil launches its new website](http://www.itexto.net/devkico/?p=2156), promising to open source its code base so other user groups can benefit from it
*   [Gradle 2.4-rc-1](https://twitter.com/gvmtool/status/592940974470537216) available on GVM
*   Gradle 2.4-rc-1 release notes covers [annotation processing of Groovy code](https://gradle.org/docs/2.4-rc-1/release-notes#support-for-%E2%80%9Cannotation-processing%E2%80%9D-of-groovy-code)

## Presentations

*   [Programmatic browser automation with Geb](http://fr.slideshare.net/nareshak/pragmatic-browser-automation-with-geb-gids-2015) by Naresha K at the Great Indian Developer Summit

## Tweets

*   Wtih Groovy moving to Apache, so did its Github repository. [Don't forget to star the new Groovy repo on Github](https://twitter.com/sbglasius/status/591322009214160896)!
*   Dagger developer Jake Wharton mentions [support for annotation in Groovy code via generated stubs with Gradle 2.4](https://twitter.com/JakeWharton/status/591242052202934273)
*   [GrooScript moved its Groovy Ecosystem demo](https://twitter.com/grooscript/status/591713872568033282) to a new location
*   Voxxed mentions [Groovy moving to the speed of Java](https://twitter.com/voxxed/status/591231196245417984)
*   Dierk König mentions that the script of [Groovy in Action, 2nd edition, has over 1600 commits](https://twitter.com/mittie/status/592937821402443776) on its private Git repository
*   [Lazybones 0.8.1](https://twitter.com/gvmtool/status/591149663782359040) available on GVM
*   Dan Woods highlights Ratpack 0.9.15's Groovy extensions [easily transform RxJava Observables into Ratpack Promises](https://twitter.com/danveloper/status/590950625254354944)

## Podcasts

*   [Groovy podcast episode 11](https://twitter.com/groovypodcast/status/590970033410547713) available

## Screencasts

*   The NetBeans team recorded a screencast about Minecraft Forge showcasing its [Gradle support](https://twitter.com/netbeans/status/592059252702851072)

## Books

*   [Groovy in Action, 2nd edition, now in proof-reading stage](https://twitter.com/mittie/status/591272887786569730)!
*   New book, in Portuguese, “[Falando de Grails](http://www.casadocodigo.com.br/products/livro-grails)”

## Code snippets

*   [Load JSON data into Neo4J with Groovy](https://gist.github.com/jexp/7c6997242c001abfb2cd) and Cypher

## Jobs

*   A [job for beer lovers and Grails experts](https://twitter.com/sbglasius/status/590575191119507459)
    
## Google+ posts

*   New improvements to Tim Roes’ [Groovy Playground](https://plus.google.com/u/0/+TimRoes/posts/f5LrmstNqTE?cfem=1)

## Events

*   GR8Conf Europe will feature [more Groovy puzzlers](https://twitter.com/gr8conf/status/592899671519027201)
*   [Grails event driven plugins](https://twitter.com/gr8conf/status/592898886848671747) at GR8Conf Europe by Göran Ehrsson
# Groovy Weekly #67


No big focus this week in the editorial, but as in the previous edition, I’d like to remind you about the following infrastructure changes, as we move the Groovy project through the incubation process at Apache: the [JIRA issue tracker has moved](https://issues.apache.org/jira/browse/GROOVY/), and don’t forget that the [Groovy mailing-lists are also moving](http://www.groovy-lang.org/mailing-lists.html). The novelty this week is that the [Apache Git repository](https://twitter.com/glaforge/status/588809178958925824) is now the new mainline, but you can contribute pull requests on the [Apache Groovy Github mirror](https://twitter.com/glaforge/status/588960808094326784).

## Releases

*   [GrooScript 1.0.2](https://twitter.com/grooscript/status/589123058318860290) released
*   [Gretty 1.2.2](https://github.com/akhikhl/gretty/blob/master/RELEASE.md#gretty-122-release-announcement) released

## Articles

*   Paul Krill of InfoWorld on [Grails finding a new home at OCI](http://www.cio.com/article/2909687/developer/grails-web-framework-finds-home-at-object-computing.html)
*   An overview of [what's new in Grails 3](http://java.dzone.com/articles/whats-new-grails-3) by Michael Scharhag
*   Geb Gems: [Running Geb Spock tests with Maven](http://blog.jdriven.com/2015/04/geb-gems-running-geb-spock-tests-maven/) by Albert van Veen
*   Jeff Beck on [impersonating user custom roles with Spring Security in Grails](http://beckje01.com/blog/2015/04/18/springsecurity-impersonate-users-custom-roles/)
*   MrHaki's Gradle Goodness: [alter start scripts from application plugin](http://mrhaki.blogspot.dk/2015/04/gradle-goodness-alter-start-scripts.html)
*   MrHaki's Grails Goodness: [set log level for Grails artifacts](http://mrhaki.blogspot.fr/2015/04/grails-goodness-set-log-level-for.html)
*   MrHaki's Grails Goodness: [add some color to our logging](http://mrhaki.blogspot.fr/2015/04/grails-goodness-add-some-color-to-our.html)
*   [Making a Grails domain class non-persistent](http://www.intelligrape.com/blog/making-a-domain-non-persistent/) by Vinay Prajapati
*   [Parsing URL mappings in Grails](http://www.intelligrape.com/blog/parsing-url-mappings-in-grails/) by Sandeep Poonia
*   [Spring events with Grails](http://www.intelligrape.com/blog/spring-events-with-grails/)
*   Ken Kousen writes [Groovy related blog posts](https://kousenit.wordpress.com/2015/04/16/groovy-posts-in-other-places/) elsewhere too
*   [Building a Java web application with Gradle](https://weblogs.java.net/blog/manningpubs/archive/2013/03/18/building-java-web-application-gradle) by Benjamin Muschko
*   Short on time? Switch to [Groovy and Spock for unit testing](http://www.javacodegeeks.com/2015/04/short-on-time-switch-to-groovy-for-unit-testing.html)

## News

*   [Gradleware is officially welcoming Cédric Champeau and Lari Hotari](https://gradle.org/welcoming-lari-hotari-and-cedric-champeau-to-gradle-team/) into the Gradle team
*   Jacob Aae Mikkelsen's [Grails Diary](http://grydeske.net/news/show/92) week 16
*   You can still [vote for Grails 3 support in IntelliJ IDEA](https://youtrack.jetbrains.com/issue/IDEA-136970)
*   A [new curated list of Groovy news](http://groovydevweekly.com/issues/1?#start) by Sergio del Amo
    
## Presentations

*   [Groovy and Grails puzzlers](http://www.infoq.com/presentations/groovy-grails-puzzler), traps, pitfalls, and end cases by Baruch Sadogursky and Frédéric Simon, recorded at SpringOne2GX 2015
*   Guillaume Laforge shares the links to his [Devoxx France presentations on Groovy]({{< ref "/talks/2015/04/17/devoxx-2015-presentations" >}})
*   [Confessions of a Java developer who fell in love with Groovy](https://www.youtube.com/watch?v=3pdFdbvaUyg) (in Hebrew)
*   Iván López on [metaprogramming with Groovy](https://twitter.com/ilopmar/status/588338534366457856) at the Confess conference with slides and sample code
*   Alexander Klein on [Groovy in the Shell](http://fr.slideshare.net/sascha_klein/groovy-on-the-shell)

## Tweets

*   The [Geb framework developers are happy with their move to Github issues](https://twitter.com/GebFramework/status/588457692651356160)
*   Guillaume Laforge shares the new [Apache Groovy mailing-list archives](https://twitter.com/glaforge/status/588673146355613696) links
*   Guillaume Laforge gives the link to the [Apache Git web interface](https://twitter.com/glaforge/status/588809178958925824)
*   You can [send pull requests to Apache's Groovy git mirror on Github](https://twitter.com/glaforge/status/588960808094326784) notes Guillaume Laforge
*   Søren Berg Glasius reminds developers they can now [star the Groovy git mirror on Github](https://twitter.com/sbglasius/status/589088682512027648) for good reputation
*   [Cédric Champeau received his JavaOne Rock Star award](https://twitter.com/CedricChampeau/status/588968404633157632)!
*   Buildship, a [Gradle plugin for Eclipse](https://twitter.com/Gradleware/status/589102675381379072) by GradleWare and Vogella
*   Craig Burke is having fun with [laying out tables in his Groovy Document Builder for v0.4](https://twitter.com/craigburke1/status/589107422754693120)

## Events

*   [Object Computing becomes GR8Conf Europe gold sponsor](https://twitter.com/gr8conf/status/588319368477458432)
*   The [GR8Conf Europe beers are ready](https://twitter.com/JacobAae/status/589112241426931713)!
# Devoxx 2015 Presentations


I had the pleasure of presenting 3 talks at Devoxx France last week (plus the Cast Codeurs podcast live recording), and I wanted to share with you the slides of those presentations. 

## The Groovy release process 

With Cédric Champeau and Frédéric Simon

{{< speakerdeck e3398ca68b9d4ef2a65309f92bb10d16 >}}

## Groovy with style

{{< speakerdeck d46bba738e3a469281caecb3a68803b9 >}}

## Machine Learning introduction

In French, with Didier Girard

{{< speakerdeck 20d59cbfef164757baf7599d5e88c141 >}}

# Groovy Weekly #66


We’re only mid April but what a year it’s been so far! From [Groovy & Grails’ loss of funding]({{< ref "/posts/2015/01/19/the-groovy-project-is-looking-for-a-new-home" >}}), leading [Grails to a new home at Object Computing Inc.](http://interact.stltoday.com/pr/business/PR040915114421060) and [Groovy at the Apache Software Foundation]({{< ref "/posts/2015/03/04/groovy-projects-intends-to-join-the-apache-software-foundation" >}}), to [Guillaume Laforge joining Restlet](http://restlet.com/blog/2015/03/02/head-of-groovy-project-joins-restlet-to-lead-api-development-tools/) and [Cédric joining GradleWare](https://twitter.com/cedricchampeau/). Against all odds, [Groovy released its 2.4 version with the Android support]({{< ref "/posts/2015/01/21/groovy-2-4-released" >}}), and the big [3.0 release of Grails](http://grails.github.io/grails-doc/3.0.x/guide/introduction.html#whatsNew) saw the light of day. And on another personal note… I’ve [finished my first marathon](https://instagram.com/p/1YIA2KANZD/)! What’s next for the rest of the year?

With the Greach conference just over, there’s a lot of great and groovy content available in the presentations section! Take your time to have a look at this impressive lineup and interesting material.

Speaking of conferences, rush to buy early bird tickets for GR8Conf Europe! You only have till tomorrow!

As in the previous edition, I’d like to remind you about the following infrastructure changes, as we move the Groovy project through the incubation process at Apache: the [JIRA issue tracker has moved](https://issues.apache.org/jira/browse/GROOVY/), and don’t forget that the [Groovy mailing-lists are also moving](http://www.groovy-lang.org/mailing-lists.html).

## Releases

*   [Spock Subjects Collaborators Extension 1.1.0](https://twitter.com/MGrzejszczak/status/583875742053879808) released by Marcin Grzejszczak
*   [Document Builder 0.3.1](https://twitter.com/craigburke1/status/585611941072211969) released by Craig Burke with spacing and positioning fixes
*   [Gretty 1.2.1](https://twitter.com/AndreyHihlovski/status/586809300678483969) released with WebSocket support

## Articles

*   Ken Kousen writes about [kicking AST and taking names](https://www.accelebrate.com/blog/kicking-ast-taking-names/)
*   MrHaki's [Greach conference report](http://mrhaki.blogspot.fr/2015/04/greach-2015-conference-report.html)
*   Jochen Theodorou on [being a paid OSS developer for Groovy](http://blackdragsview.blogspot.de/2015/04/about-being-paid-oss-developer-for.html)
*   [Grails has a new home at OCI](http://interact.stltoday.com/pr/business/PR040915114421060)
    
## Interviews

*   Cédric Champeau interviewed by Voxxed during the Devoxx France conference: "[Groovy is everybody's language to evolve](https://www.voxxed.com/blog/2015/04/cedric-champeau-groovy-is-everybodys-language-to-evolve/)"
    
## News

*   The [Groovy podcast now has a pretty nice logo](https://twitter.com/groovypodcast/status/585446151601704960)!
*   [Geb's issue tracker moved to Github](https://twitter.com/GebFramework/status/587525108882866177)

## Mailing-list posts

*   If you or [your company is interested in helping or taking over the development of the Groovy Eclipse plugin](https://twitter.com/CedricChampeau/status/587353266457018368), please tell us!

## Presentations

*   Devoxx France 2015
    *   Guillaume Laforge presented [Groovy with Style](https://speakerdeck.com/glaforge/groovy-with-style-devoxx-2015)
    *   Cédric Champeau, Guillaume Laforge and Frédéric Simon from JFrog presented the [Groovy release process](https://speakerdeck.com/glaforge/groovys-release-process-devoxx-2015)
    *   [Take control of your build with Gradle plugins](https://docs.google.com/presentation/d/1llWSoa8KepAnYGFDE0HA4FtNmSdnVVHp7HPkQ5Ah94k/edit), presented at Devoxx France 2015 by Cédric Champeau and Eyal Lezmy
*   Greach Conference
    *   [GrooScript in action](http://fr.slideshare.net/JorgeFrancoLeza/grooscript-greach-2015) at Greach by Jorge Franco Leza
    *   Overview of the [Groovy AST Transformers](http://fr.slideshare.net/ilopmar/greach-2015-ast-groovy-transformers-more-than-meets-the-eye): More than meets the eye! by Iván López at Greach 2015
    *   Markus Schlichting brought [documentation to life with Asciidoctor and Gradle](http://fr.slideshare.net/madmas/documentation-brought-to-life-asciidoctor-gradle-greach-2015)
    *   Burt Beckwith [hacks the Grails Spring Security 2.0 plugin](http://fr.slideshare.net/burtbeckwith/hacking-the-grails-spring-security-20-plugin)
    *   Russel Winder talked about [GPars remoting](https://twitter.com/russel_winder/status/586550273855922176) and shares his slides and associated code, at Greach Conference
    *   Alonso Torres talked about [Decathlon Sport Meeting application based on Grails](http://fr.slideshare.net/alotor/greach-2015-decathlon-sport-meeting)
    *   [Use Groovy and Grails in your Spring Boot projects](http://fr.slideshare.net/fatimacasau/use-groovy-grails-in-your-spring-boot-projects) by Fátima Casaú at Greach 2015
    *   MrHaki shares the code of his Greach conference [Grails Goodness](https://github.com/mrhaki/greach2015-grails-goodness) talk
    *   Jeff Beck on [Cassandra and Grails](http://beckje01.com/talks/greach-2015-cassandra-grails.html#/)
    *   [Securing Ratpack](http://beckje01.com/talks/greach-2015-sec-ratpack.html#/) by Jeff Beck
    *   Jenn Strater on [no nonsense NoSQL](https://github.com/jlstrater/No-Nonsense-NoSQL)
    *   Jenn Strater guided a discussion about [teaching and diversity in the Groovy community](https://twitter.com/JennStrater/status/587627413825318912)
    *   Marco Vermeulen on [GVM](http://marcovermeulen.github.io/gvm-talk/#/)
    *   [DSL'ing your Groovy](http://fr.slideshare.net/alotor/greach-2015-dsling-your-groovy) by Alonso Torres
    *   [Infrastructure automation with Gradle and Puppet](http://fr.slideshare.net/aestasit/infrastructure-automation-with-gradle-and-puppet-at-greach-2015) by Andrey Adamovich
    *   Steve Pember covers [Groovy options for reactive applications](http://fr.slideshare.net/StevePember/groovy-options-for-reactive-applications-greach-2015)
    *   [Idiomatic Gradle plugin writing](http://fr.slideshare.net/ysb33r/idiomatic-gradle-plugin-writing) by Schalk Cronjé at Greach 2015
    *   Henrique Lobo presented about [how to obtain high productivity and quality with Groovy and Grails](http://www.infoq.com/br/presentations/grails-alta-produtividade-em-java) (in Portuguese)
    *   [Behaviour Driven Development with Cucumber, Groovy and Grails](http://www.infoq.com/presentations/tdd-cucumber-groovy-grails) by Marco Vermeulen, recorded at SpringOne2GX 2014

## Tweets

*   The [Grails Framework is announcing having found a new home](https://twitter.com/grailsframework/status/586263420195975169) at OCI
*   A [cool Groovy T-Shirt](https://twitter.com/greachconf/status/586806872134549504) at Greach conference
*   Schalk Cronjé draws [GrooScript in a nutshell](https://twitter.com/ysb33r/status/586818696737386496)
*   Schalk Cronjé draws [GVM in a nutshell](https://twitter.com/ysb33r/status/586843897793552384) from Marco Vermeulen Greach presentation
*   Iván López says that [only the "real" developers create AST transformations using emacs](https://twitter.com/ilopmar/status/586827597469745153)
*   A [new GVM logo in the works](https://twitter.com/gvmtool/status/586892208860704768) by Alexander Klein?
*   Andrey Hihlovskiy on the [pain of Java's parentheses and semicolons](https://twitter.com/AndreyHihlovski/status/587199044591714304) as the opposite of syntax sugar
*   Jonas Havers is impressed with [Groovy's Markup Template Engine in combination with Spring Boot](https://twitter.com/JonasHavers/status/587245765736718336)
*   The [Groovy boys and JFrog are making the show](https://twitter.com/aheritier/status/587883820654944256) on stage at Devoxx France 2015

## Podcasts

*   [Groovy podcast episode 10](https://twitter.com/groovypodcast/status/586556048305213440) is available

## Code snippets

*   John Engelman shares a Gradle tip on how to [apply a custom plugin on its own project](https://gist.github.com/johnrengelman/9a20697b2246a9bfaca2)
*   Tim Yates mixes the [Document Builder and his ASCII image generator](https://gist.github.com/timyates/99725e049fa9413f7e09)
*   Fernando Redondo shares the code of his Greach [Spock workshop](https://twitter.com/pronoide_fer/status/586825551907794944)
*   Bruno Borges uses Ratp[ack in JavaScript with the Nashorn Maven executor](https://github.com/brunoborges/nashorn/blob/master/maven/samples/ratpack/ratpack.js)

## Jobs

*   Object Computing is [looking for Groovy developers in Saint-Louis](https://twitter.com/NathanTippy/status/586887533398601728), USA

## Events

*   [GR8Conf Europe early bird tickets ending on Wednesday](https://twitter.com/gr8conf/status/587841371266015232), be fast!
*   A new [Grails event in Azerbaijan](https://twitter.com/glaforge/status/587572281511141376)
*   Tomas Lin collected the links to the [slides and code of all the Greach 2015 conference presentations](https://fbflex.wordpress.com/2015/04/12/collection-of-links-for-greach-2015-from-twitter/)
*   Browse the [Greach 2015 conference pictures](https://twitter.com/greachconf/status/587251262615334913)
# Groovy Weekly #65


I hope you all had a Groovy Easter, with baskets full of eggs and chocolate!

Little update on the Groovy infrastructure, as the project moves into incubation at Apache, the [JIRA issue tracker has moved](https://issues.apache.org/jira/browse/GROOVY/), and don’t forget that the [Groovy mailing-lists are also moving](http://www.groovy-lang.org/mailing-lists.html).

## Releases

*   [SwissKnife 1.2.3](https://twitter.com/arasthel92/status/584746749245423617) released, the Swiss knife for for Android development with Groovy
*   [Ratpack 0.9.15](http://ratpack.io/versions/0.9.15) released
*   [Spock Subjects Collaborators Extension 1.0.3](https://twitter.com/MGrzejszczak/status/583390682938798080) released by Marcin Grzejszczak
*   [Grails 3.0.1](https://twitter.com/grailsframework/status/583557647623913472) released
*   [ElasticSearch Groovy client v1.5.0](https://twitter.com/pickypg/status/585108230373830656) released
    
## Articles

*   [Grails 3.0 built upon Spring Boot and Gradle](http://jaxenter.com/grails-3-0-built-upon-spring-boot-and-gradle-116071.html) on JaxEnter
*   Using [Android product flavors to build full and demo version of an application](http://www.objectpartners.com/2015/03/31/using-android-product-flavors-to-build-full-and-demo-version-of-the-app/), by Manij Shrestha

## News

*   The [Groovy JIRA has now moved to Apache](https://issues.apache.org/jira/browse/GROOVY/?selectedTab=com.atlassian.jira.jira-projects-plugin:summary-panel)
*   [Gradle has a brand new forum](https://twitter.com/Gradleware/status/583310059108712448) powered by Discourse
*   Tim Fox shares a glimpse of the [upcoming new Vert.x website](http://vert-x3.github.io/)
*   Jacob Aae Mikkelsen [Grails Diary](http://grydeske.net/news/show/90) week 14
    
## Presentations

*   SpringOne2GX 2014
    *   [Ratpack and Grails 3](http://www.infoq.com/presentations/ratpack-grails-3) by Lari Hotari
    *   [Building awesome APIs with Grails](http://www.infoq.com/presentations/grails-api-2014) by Chris Latimer
    *   [Gradle for Android](http://www.infoq.com/presentations/gradle-android) by Ken Kousen
    *   [Introduction to Grails 3.0](https://www.youtube.com/watch?v=CKkovWazbJM) by Dan Vega
    *   [Creating and running a Grails 3 application](https://www.youtube.com/watch?v=PlMyRGIJNa0) by Dan Vega

## Tweets

*   [Creating iOS applications with Groovy](https://twitter.com/grooscript/status/582180967164563456) and GrooScript, using ReactJS native
*   April Fools from Apache Groovy mentor says [Groovy could graduate on April 1st](https://twitter.com/bdelacretaz/status/583192854757007360) already
*   [Spring Boot 1.1.12](https://twitter.com/gvmtool/status/583384389201080321) available on GVM
*   [Spring Boot 1.2.3](https://twitter.com/gvmtool/status/583384477612797953) available on GVM
*   [Grails 3.0.1](https://twitter.com/gvmtool/status/583555987854008320) available on GVM

## Mailing-list posts

*   [Groovy's JIRA moved to Apache](http://groovy.329449.n5.nabble.com/ANN-JIRA-moved-to-Apache-td5723366.html)

## Books

*   Peter Ledbrook shares early [draft chapters of his Practical Groovy](https://twitter.com/pledbrook/status/583291238067077120) self-published book

## Events

*   [GR8Conf US 2015 registration is open](https://twitter.com/gr8confus/status/585089220848517121)
# Groovy Weekly #64


Today marks the [end of the sponsorship of the Groovy and Grails projects by Pivotal]({{< ref "/posts/2015/01/19/the-groovy-project-is-looking-for-a-new-home" >}}). The projects are now turning a new page in their lives. For Groovy, the project is going to wear some feathers, with [joining the Apache Software Foundation](http://www.programmableweb.com/news/groovy-project-joins-apache-software-foundation/2015/03/27). And Grails is [releasing its major 3.0 version](http://grails.io/post/115110650393/grails-3-0-released-and-the-road-ahead).

With Groovy’s move to Apache, it’s important to notice that the Groovy mailing-lists are moving. You [must subscribe to the new mailing-lists at Apache](http://groovy.329449.n5.nabble.com/IMPORTANT-New-mailing-lists-and-JIRA-migration-td5723329.html), as we won’t force-subscribe people, so you’ll have to opt-in to these new lists.

Last but not least, Groovy has been submitted for nomination for the JAX 2015 innovation award, so we encourage you to [vote for Groovy for the JAX innovation award](http://jaxenter.com/jax-awards-2015/submit-your-vote)!

## Releases

*   [Grails 3.0](https://github.com/grails/grails-core/releases/tag/v3.0.0) released
*   [Grails 2.4.5 and 2.5.0](https://twitter.com/grailsframework/status/580610565808197632) are released
*   [Grails 3.0 RC-3](https://twitter.com/grailsframework/status/581094391521132546) released, the last RC before the final release
*   Al Baker releases [Stardog Groovy 3.0](https://twitter.com/AlBaker_Dev/status/581168099614937088)
*   [Gradle Nebula-test plugin releases v2.2.1](https://twitter.com/NebulaPlugins/status/581203594021584897) with an updated Spock 1.0
*   [Document Builder 0.3.0](https://twitter.com/craigburke1/status/582575048764055552) released by Craig Burke with header / footer support

## Articles

*   [Grails 3.0 released and the road ahead](http://grails.io/post/115110650393/grails-3-0-released-and-the-road-ahead) by Graeme Rocher
*   ProgrammableWeb covers [Groovy project joining the Apache Software Foundation](http://www.programmableweb.com/news/groovy-project-joins-apache-software-foundation/2015/03/27)
*   Cédric Champeau dives into the details of an [improved sandboxing approach for Groovy scripts](http://melix.github.io/blog/2015/03/sandboxing.html)
*   Write your [games in Groovy with libGDX](https://impetus-games.com/blog/libGDX-the-Groovy-Way)
*   Marco Vermeulen details the [GVM vendor API](http://www.wiredforcode.com/blog/2015/03/26/the-gvm-vendor-api/)
*   Pavel Dudka's first Gradle [tip on Gradle tasks](http://trickyandroid.com/gradle-tip-1-tasks/)
*   [Gradle 2.4, the fastest yet](https://gradle.org/gradle-2-4-the-fastest-yet/), says Luke Daley
*   Hans Dockter gives the [Gradle team's perspective on Google's Bazel](https://gradle.org/gradle-team-perspective-on-bazel) build solution
*   [How to pitch Gradle to your boss](https://gradle.org/why/return-on-investment/)? Here's a recipe on Gradle's website
*   MrHaki's Groovy Goodness: [New methods to sort and remove duplicates from collection](http://mrhaki.blogspot.fr/2015/03/groovy-goodness-new-methods-to-sort-and.html)
*   Peter Ledbrook covers the infamous [Gradle halting problem](http://blog.cacoethes.co.uk/gradle/comments-on-recent-gradle-criticisms)
*   Ratpack 0.9.15 will feature [non blocking health checks](https://twitter.com/ratpackweb/status/582642475388444672)
*   Integration vs functional testing: how to [test REST APIs in Grails using Spock](http://aruizca.com/integrated-vs-functional-testing-how-to-test-rest-apis-in-grails-using-spock/), by Angel Ruiz
*   [Writing AngularJS applications in Groovy](http://devsoap.com/#!/Writing-AngularJS-applications-in-Groovy) by John Ahlroos

## News

*   [Grails is moving away from JIRA to Github issues](https://twitter.com/grailsframework/status/582466373894438912)
*   The [Groovy Podcast now has a Twitter feed](https://twitter.com/kenkousen/status/580745262148280320), announces Ken Kousen
*   Jacob Aae Mikkelsen [Grails Diary](http://grydeske.net/news/show/89) week 13
    
## Presentations

*   SpringOne2GX 2014
    *   [Advanced GORM, beyond relational](http://www.infoq.com/presentations/advanced-gorm), by Graeme Rocher
    *   [Performance tuning Grails applications](http://www.infoq.com/presentations/grails-perf-tuning) by Lari Hotari
    *   [Runtime meta-programming with Groovy](http://www.infoq.com/presentations/groovy-metaprogramming) by Jeff Brown
    *   [Groovy mobile automation](http://www.infoq.com/presentations/groovy-spock-gradle) by Bobby Warner

## Tweets

*   Cédric Champeau tweets about the [new mailing-lists for the Groovy project at Apache](https://twitter.com/CedricChampeau/status/582656729600622592), encouraging all users to move to the new lists
*   The [new Groovy documentation is already 630 pages long in PDF](https://twitter.com/cedricchampeau/status/582908247692181504) form, with all code snippets automatically tested, notes Cédric Champeau
*   Rob Winch and Sam Brannen are experiencing important [decreased build times thanks to Gradle 2.4](https://twitter.com/sam_brannen/status/581884182156197888) build time improvements
*   Eugene Kamenev announces the use of Gitter for [chatting about SwissKnife and Groovy Android](https://twitter.com/eugenekamenev/status/582548963661729792) support
*   Cédric Champeau's [Bytecode AST transformation supports debugging](https://twitter.com/CedricChampeau/status/581129087126609920)
*   Dan Woods notices the [NIO support from Groovy 2.3](https://twitter.com/danveloper/status/581553702525214720)
*   Dan Woods is sad to learn that the [Groovy Grails Tool Suite is discontinued](https://twitter.com/danveloper/status/581765073258987520), following up Pivotal's end of funding of the Groovy and Grails projects
*   Dierk König notes that [Groovy's safe navigation operator is like the Maybe monad](https://twitter.com/mittie/status/581768305771450368), and GPath is like a list monad
*   [Grails 2.4.5](https://twitter.com/gvmtool/status/580608623719686144) is available on GVM
*   [Grails 2.5.0](https://twitter.com/gvmtool/status/580608731085447168) is available on GVM
*   [Grails 3.0 RC-3](https://twitter.com/gvmtool/status/581097862899113986) available on GVM
*   [Grails 3.0](https://twitter.com/gvmtool/status/582850247929532416) is available on GVM
*   Craig Burke is moving his [document builder to OOXML](https://twitter.com/craigburke1/status/580732939371171840)
*   Craig Burke managed to get [headers working for his document builder](https://twitter.com/craigburke1/status/580788527341924352)
*   Al Baker says [Stardog Groovy 3.0 includes simplified reasoning configuration](https://twitter.com/AlBaker_Dev/status/581169267619602433)

## Mailing-list posts

*   With its move to the Apache foundation, Groovy is moving its mailing-lists, and [subscribers of the old lists should subscribe to the new ones](http://groovy.329449.n5.nabble.com/IMPORTANT-New-mailing-lists-and-JIRA-migration-td5723329.html)

## Podcasts

*   [Groovy podcast episode 9](https://twitter.com/groovypodcast/status/581107353459658752) is available

## Code snippets

*   Tim Yates has fun with some [ASCII based image generation](https://gist.github.com/timyates/7234c83d9e7df39e5a09) script

## Events

*   The latest [newsletter about GR8Conf Europe](https://twitter.com/gr8conf/status/580603331707559936) 2015
*   If you're wondering about [GR8Conf Europe, check its YouTube channel](https://twitter.com/gr8conf/status/580769221023399936) to figure out!
# Groovy Weekly #63


The big news today is that Groovy has now [passed the vote for entering the Apache Software Foundation incubator]({{< ref "/posts/2015/03/23/groovy-2-4-3-out-and-entering-apache-s-incubator" >}})! Thus, in the coming weeks and months, while going through the incubation process, you can expect some changes in terms of infrastructure (moving sources, issue tracker, mailng-lists, etc) to be taking place, but don’t worry, we’ll keep you informed along the way.

This past week, we’ve had some new releases of Groovy, as well as the second release candidate for Grails 3! Grails 3 is really really close now, get ready, it’s gonna rock the house!

Alongside the Groovy releases, [big efforts have been made with the new Groovy documentation]({{< ref "/posts/2015/03/19/groovy-2-4-2-and-2-3-11-released" >}}). Be sure to check it out, and to help us further improve that documentation

Last but not least, Groovy has been submitted for nomination for the JAX 2015 innovation award, so we encourage you to [vote for Groovy for the JAX innovation award](http://jaxenter.com/jax-awards-2015/submit-your-vote)!

## Releases

*   [Grails 3.0 rc-2](https://twitter.com/grailsframework/status/578127217198174208) released
*   [Groovy 2.4.2 and 2.3.11]({{< ref "/posts/2015/03/19/groovy-2-4-2-and-2-3-11-released" >}}) released along with tons of new documentation
*   [Groovy 2.4.3](http://groovy-lang.org/changelogs/changelog-2.4.3.html) released
*   [Gradle Android plugin for Groovy 0.3.6](https://twitter.com/CedricChampeau/status/580017871620874241) released, working with the 1.1.0 version of the Android plugin
*   [japicmp plugin for Gradle 0.1.1](https://twitter.com/CedricChampeau/status/579727386452819969) released
*   [SonarQube Groovy 1.1](https://twitter.com/SonarSource/status/579950945263620096) released with JaCoCo coverage and latest CodeNarc 0.23
*   [IntelliJ IDEA 14.1](https://www.jetbrains.com/idea/whatsnew/) released with improved Groovy and Gradle support

## Articles

*   Guillaume Laforge announces the [release of Groovy 2.4.3 and that the vote for accepting Groovy in the Apache incubator passed]({{< ref "/posts/2015/03/23/groovy-2-4-3-out-and-entering-apache-s-incubator" >}})
*   Schalk Cronjé shares his thoughts on [Gradle's halting problem](http://delivervalue.blogspot.co.uk/2015/03/so-what-about-this-halting-problem-in.html)
*   MrHaki's Groovy Goodness
    *   [Use constructor as method pointer](http://mrhaki.blogspot.fr/2015/03/groovy-goodness-use-constructor-as.html)
    *   [Combine elements iterable with index](http://mrhaki.blogspot.fr/2015/03/groovy-goodness-combine-elements.html)
    *   [Swapping elements in a collection](http://mrhaki.blogspot.fr/2015/03/groovy-goodness-swapping-elements-in.html)
*   [Automatic release / promotion of artifacts to Maven Central from Gradle](https://solidsoft.wordpress.com/2015/03/24/automatic-promotion-of-artifacts-to-maven-central-from-gradle/) (with Gradle Nexus Staging Plugin)
*   Set up easy [cross-language benchmarking using Gradle](http://blog.comsysto.com/2015/02/20/cross-language-benchmarking-made-easy/) by Ben Steinert
*   [Archive addition Android artifacts with Gradle](http://wiebe-elsinga.com/blog/archive-addition-android-artifacts-with-gradle/) by W.Elsinga
*   [Basic Groovy and Grails code review guidelines](https://tedvinke.wordpress.com/2015/03/15/basic-groovy-and-grails-code-review-guidelines/) by Ted Vinke
*   Using delegation for [audit columns in Groovy on Grails](http://helpingtoomuch.blogspot.fr/2015/03/using-delegation-for-audit-columns-in.html)
*   Dustin Marx on [Groovy joining the Apache foundation](http://java.dzone.com/articles/excellent-groovy-intends-join)
*   [Control a presentation remotely with a Vert.x module written in Groovy](https://twitter.com/bgoetzmann/status/577958849551822848) by Bertrand Goetzman
*   Why [developing in Groovy and Grails is faster than in Java and Spring](http://www.techgig.com/readnews.php?category=Technology%2F+Skill+News&tgnews_link=http%3A%2F%2Ffeeds.dzone.com%2F~r%2Fdzone%2Ffrontpage%2F~3%2FYLKvHSdp1X0%2Fwhy_developing_in_groovygrails_is_faster_than_in.html&tg_type=rss&tgnews_id=54456) asks Luigi Candita
*   Jorina Freya Gerken introduces a new series on [Spock by example](http://eclipsesource.com/blogs/2015/03/20/spock-by-example-introducing-the-series/)

## News

*   You can [vote for Groovy for the JAX 2015 innovation award](http://jaxenter.com/jax-awards-2015/submit-your-vote)
*   The [Gradle website has been redesigned](http://www.gradle.org/)
*   Jacob Aae Mikkelsen [Grails Diary](https://twitter.com/JacobAae/status/580150710886645760) week 12
    
## Presentations

*   Iván López published his code and slides on [Grails and the realtime world](https://twitter.com/ilopmar/status/578121164632936450)
*   Video of the [Getting Groovy on Android](https://twitter.com/andrewreitz_/status/580337018493775873) presentation by Andrew Reitz
*   Peter Ledbrook gave a tutorial on [Groovy for Java developers](https://www.parleys.com/talk/groovy-java-developers) at Devoxx UK 2014
*   SpringOne2GX 2014
    *   [Groovy AST transformations](http://www.infoq.com/presentations/groovy-ast) by Paul King
    
    *   [Distributed Platform Development with Groovy](http://www.infoq.com/presentations/groovy-distributed-enterprise) by Dan Woods
    *   [Advanced Groovy Tips and Tricks](http://www.infoq.com/presentations/groovy-tips-tricks) by Ken Kousen
    *   [GORM Inside and out](http://www.infoq.com/presentations/groovy-gorm) by Jeff Scott Brown

## Tweets

*   Bertrand Delacretaz, mentor of the Groovy project, announces the [vote passed to accept Groovy in the Apache Software Foundation incubator](https://twitter.com/bdelacretaz/status/580057703202086912)
*   Cédric Champeau updated his [@Bytecode AST transformation](https://twitter.com/CedricChampeau/status/580479826563362817), but he warns about using it for educational purpose only
*   Baruch Sadogursky claims that [Maven's biggest problem is not XML so polyglotism won't help it](https://twitter.com/jbaruch/status/580269909520752640)
*   [Groovy 2.4.3](https://twitter.com/gvmtool/status/580071538805862400) available on GVM
*   [Groovy 2.4.2](https://twitter.com/gvmtool/status/579688895304085504) available on GVM
*   [Groovy 2.3.11](https://twitter.com/gvmtool/status/579688160973713408) available on GVM
*   Creating [CUDA code with Groovy scripts](https://twitter.com/PSJedox/status/578671464074752003/photo/1)
*   Bavo Bruylandt says that the [@ClosureParams and @DelegatesTo annotations greatly help IDE integration for Groovy DSLs](https://twitter.com/bavobbr/status/578807970886209537)
*   Ben McGuire noted that most NFJS attendees were using Groovy in some capacity, showing an [ongoing growth of the Groovy community](https://twitter.com/ben_t_mcguire/status/579399082029944832)
*   Oliver Gierke likes the [Groovy based poms with Maven 3.3.1](https://twitter.com/olivergierke/status/577903566070902785)
*   Oliver Gierke ported the Spring HATEOAS [pom.xml to Groovy with Maven's polyglot](https://twitter.com/olivergierke/status/578521532349157376) support
*   [Third party plugins compatible with Grails 3](https://twitter.com/grailsframework/status/577843537284325378) are becoming available
*   A [Flyway Gradle plugin](https://twitter.com/FlywayDb/status/577872090998575108) appears into the Gradle plugin portal
*   [Grails 3.0 rc-2](https://twitter.com/gvmtool/status/578129119361306624) available on GVM
    
## Books

*   [Groovy in Action, 2nd edition](https://twitter.com/ManningMEAP/status/580416001814204417), in the finish line!

## Events

*   [Tickets for GR8Conf Europe](https://twitter.com/gr8conf/status/580435505852071936) now on sale!
*   [GR8Conf Europe 2015 is available on Lanyrd](https://twitter.com/gr8conf/status/577996465248718848), you can mark you're attending
*   [Two Java Champions will be speaking at the Greach](https://twitter.com/greachconf/status/579609854320381952) conference, with Andrés Almiray and Trisha Gee
# Groovy 2.4.3 out and entering Apache's incubator


The Groovy team is happy to announce another 2.4 release, with Groovy 2.4.3.

We noticed some regressions that needed our attention, and we decided to release rapidly after our recent 2.4.2 release of last week. Please upgrade to 2.4.3 if you're on the 2.4.x line.

You can read about the tickets resolved in our changelog: [http://groovy-lang.org/changelogs/changelog-2.4.3.html](http://groovy-lang.org/changelogs/changelog-2.4.3.html)

And you can download the [Groovy distribution](http://www.groovy-lang.org/download.html) as usual on the new Groovy website.

I'd also like to announce that Groovy [passed the vote to enter the Apache Software Foundation Incubator](http://markmail.org/message/uaickpdsffd4gnzu)! In the coming weeks, we'll be through the incubation process, likely for a few months, where we'll be moving things around (sources, JIRA, mailing-lists, etc), so you can expect a bit of change, but we'll keep you posted on how we progress along.
# Groovy 2.4.2 and 2.3.11 released


The Groovy development team is happy to announce the bug fix releases of Groovy 2.4.2 and Groovy 2.3.11.

For the 2.4.2 release, some **key performance improvements have found their way in static compilation mode**, so you might be happy to see your programs snappier!

Along with those two releases, you'll notice **lots more documentation has been written** on the new Groovy website, as well as important updates to existing topics. You might want to have a look at the following new or improved sections:

*   [Domain-Specific Languages](http://docs.groovy-lang.org/latest/html/documentation/core-domain-specific-languages.html)
*   core language
    *   [scripts vs classes](http://docs.groovy-lang.org/docs/latest/html/documentation/#_scripts_versus_classes)
    *   [fields and properties](http://docs.groovy-lang.org/docs/latest/html/documentation/#_fields_and_properties)
    *   [interfaces](http://docs.groovy-lang.org/docs/latest/html/documentation/#_interfaces)
    *   [labeled statements](http://docs.groovy-lang.org/docs/latest/html/documentation/#_labeled_statements)
    *   [traits](http://docs.groovy-lang.org/latest/html/documentation/core-traits.html)
*   annotations
    *   [meta-annotations](http://docs.groovy-lang.org/docs/latest/html/documentation/#_meta_annotations)
    *   [closure annotation parameters](http://docs.groovy-lang.org/docs/latest/html/documentation/#_closure_annotation_parameters)
*   AST
    *   [testing AST transformations](http://docs.groovy-lang.org/docs/latest/html/documentation/#_testing_ast_transformations)
    *   [AST API guide](http://docs.groovy-lang.org/docs/latest/html/documentation/#_ast_api_guide)
    *   [global AST transformations](http://docs.groovy-lang.org/docs/latest/html/documentation/#transforms-global)
    *   [local AST transformations](http://docs.groovy-lang.org/docs/latest/html/documentation/#transforms-local)

*   [power assertions](http://docs.groovy-lang.org/docs/latest/html/documentation/#_power_assertions)
*   [base script classes](http://docs.groovy-lang.org/docs/latest/html/documentation/#_script_base_classes)
*   [type checking extensions](http://docs.groovy-lang.org/latest/html/documentation/type-checking-extensions.html)
*   [template engines](http://docs.groovy-lang.org/latest/html/documentation/template-engines.html)

*   [markup template engine](http://docs.groovy-lang.org/latest/html/documentation/markup-template-engine.html)
*   builders
    *   [Ant builder](http://docs.groovy-lang.org/docs/latest/html/documentation/#_antbuilder)
    *   [object graph builder](http://docs.groovy-lang.org/docs/latest/html/documentation/#_objectgraphbuilder)
*   guides
    *   [servlet user guide](http://docs.groovy-lang.org/latest/html/documentation/servlet-userguide.html)
    *   [working with collections](http://docs.groovy-lang.org/latest/html/documentation/working-with-collections.html)
    *   [working with I/O](http://docs.groovy-lang.org/latest/html/documentation/working-with-io.html)
    *   [testing guide](http://docs.groovy-lang.org/latest/html/documentation/core-testing-guide.html)

Note that it might be the last releases under the Codehaus era, as Groovy is **currently being voted for incubation at the Apache Software Foundation**. The vote is ongoing right now, as I write those lines, so we should know pretty soon what's the outcome, and if Groovy is accepted or not! So far... only positive votes!

You can:

*   **download** those latest Groovy releases in our [download area](http://www.groovy-lang.org/download.html)
*   read the **release notes** for
*   [Groovy 2.4.2](http://www.groovy-lang.org/changelogs/changelog-2.4.2.html)
*   [Groovy 2.3.11](http://www.groovy-lang.org/changelogs/changelog-2.3.11.html)

Thanks a lot to all who contributed to those releases, and thanks for your support of Groovy and your positive feedback on our move to Apache!

Keep on groovy'ing!
# Groovy Weekly #62


Following-up last week’s [decision of the Groovy team to join the Apache Software Foundation]({{< ref "/posts/2015/03/04/groovy-projects-intends-to-join-the-apache-software-foundation" >}}), this week, a [proposal](https://wiki.apache.org/incubator/GroovyProposal) has been made and submitted, and Apache has [announced it on its blog](https://blogs.apache.org/foundation/entry/groovy_submitted_to_become_a). So the process is now really officially started and on its track!

## Releases

*   [Grails 3.0 RC-1](https://twitter.com/grailsframework/status/575995370376949760) released
*   [GVM 2.4.0](https://twitter.com/gvmtool/status/575689514317975552) released with broadcast and offline checks optimizations
*   [Groovy Grails Toolsuite 3.6.4](https://spring.io/blog/2015/03/11/spring-tool-suite-and-groovy-grails-tool-suite-3-6-4-released) released with Groovy 2.4 support

## Articles

*   The Groovy team and Apache members collaborated on a [proposal to join the Apache Software Foundation](https://wiki.apache.org/incubator/GroovyProposal)
*   Matt Raible [interviewed Guillaume Laforge about Groovy moving to Apache](http://www.infoq.com/news/2015/03/groovy-moving-to-apache)
*   Darryl Taft from [eWeek is covering the proposal of Groovy to join the Apache](http://www.eweek.com/developer/groovy-language-proposed-as-apache-incubator-project.html) incubator
*   Paul Krill writes on CIO "[dumped by Pivotal, Groovy moves to Apache](http://www.cio.com.au/article/570225/dumped-by-pivotal-groovy-moves-apache/)"
*   Kay Ewbank on [Groovy joining the Apache Software Foundation](http://www.i-programmer.info/news/136-open-source/8378-groovy-joins-apache.html)
*   [Groovy hands-on](https://twitter.com/Shmoolki/status/576818810587611136), in French
*   A new [Griffon / JavaFX tutorial](http://new.griffon-framework.org/tutorials/4_javafx_views.html) is available
*   A [flamewar against Gradle](http://wiki.apidesign.org/wiki/Gradle) which is said to suffer from the halting problem
*   Allegro Tech is sharing its [success story adopting Gradle](http://allegrotech.io/Adopting-Gradle-at-allegro-pl-a-success-story.html)

## News

*   The Apache Software Foundation announces [Groovy's submission to become an official Apache project](https://blogs.apache.org/foundation/entry/groovy_submitted_to_become_a)
*   At the Adobe Summit, [Time Warner Cable announced some of its Gradle plugins](https://github.com/TWCable/cq-gradle-plugin) to work with Adobe tools
*   A very interesting contribution from JetBrain's Peter Gromov has been merged into Groovy's master to [speedup compilation](https://github.com/groovy/groovy-core/pull/552)
*   [OpenCSVIterator](https://github.com/andyjduncan/opencsv-iterator): a useful library for processing flat text files in Groovy and Java
*   GR8CRM, a suite of [Grails plugins for Customer Relationship Management](http://gr8crm.github.io/) by Göran Ehrsson
*   A nice online [Groovy playground](https://groovy-playground.appspot.com/) by Tim Roes
    
## Presentations

*   [Great introduction to Groovy](http://groovy-the-superb-homeless.mally.pl/#/) by Michał Mally at the Groovy user group in Poland
*   [Groovy for Java developers](http://www.infoq.com/presentations/groovy-for-java), by Peter Ledbrook, recorded during SpringOne2GX 2014
*   [Groovy browser automation with Geb](http://www.infoq.com/presentations/geb), by Colin Harrington, recorded at SpringOne2GX 2014
*   A video introduction to [Gradle for Android Studio](https://www.youtube.com/watch?v=cD7NPxuuXYY)
    
## Tweets

*   Cédric Champeau is annoyed when [people reduce Groovy to just a "dynamic" language when it's much more](https://twitter.com/CedricChampeau/status/576062386085433345) than that
*   Ken Kousen tasting a [Groovy Smoothie](https://twitter.com/kenkousen/status/576904271163232257)
*   Matthew McCullough [Groovy JMeter plugin is moving to Github](https://twitter.com/matthewmccull/status/576062271924891649), like the many Google Code projects following Google's closing
*   [GrooScript plugin working for Grails 3 RC-1](https://twitter.com/grooscript/status/576858409678540800)

## Mailing-list posts

*   The [Groovy incubation proposal is being discussed on the Apache](http://mail-archives.apache.org/mod_mbox/incubator-general/201503.mbox/%3CCA+ULb+tHEc5N9vDvu526Jmb=te4F3yCwCWWJxxMC07EAz_35wQ@mail.gmail.com%3E) mailing-lists

## Podcasts

*   Ken Kousen published [Groovy Podcast episode 8](https://twitter.com/kenkousen/status/576067688931454977)

## Code snippets

*   Using [RxJs from GrooScript with Groovy's @BaseScript](https://gist.github.com/chiquitinxx/ef2d33ce9d1a810ba216) transformation
    
## Books

*   You can find Ken Kousen's [Making Java Groovy book code samples](https://twitter.com/manningbooks/status/577487522990714881) on Manning's website

## Events

*   [Registration for SpringOne2GX](https://twitter.com/springone2gx/status/576765439348318208) 2015 is open
*   Guillaume Laforge will be speaking about [Groovy's continuous delivery at the SwampUp conference](https://twitter.com/jfrog/status/576052612144885762)
*   At the Gradle Summit, [Netflix' build team will share lessons learned about Gradle plugins](https://twitter.com/gradleware/status/577527498281472000)
# Groovy Weekly #61


Big news for this week with the intention of the [Groovy project to join the Apache Software Foundation]({{< ref "/posts/2015/03/04/groovy-projects-intends-to-join-the-apache-software-foundation" >}})! And if you wnat to know more about who actually [contributed to Groovy over the years](http://melix.github.io/blog/2015/02/who-is-groovy.html), Cédric detailed that on his blog.

## Releases

*   [GMavenPlus 1.5](http://gmavenplus.56682.x6.nabble.com/gmavenplus-announce-GMavenPlus-1-5-Released-td222.html) released
*   [GrooScript 1.0.1](http://grooscript.org/changes.html) released
*   [GrooScript Gradle plugin 1.0.1](https://twitter.com/grooscript/status/572876188902813697) released
*   [Android-Spock 1.2](https://twitter.com/andrewreitz_/status/575138522077659136) released working with Spock 1.0
*   [GVM 2.3.0](https://twitter.com/gvmtool/status/574982347768119296) released with new “outdated” command to know if newer candidates are available

## Articles

*   Guillaume Laforge announces the intention of the [Groovy project to join the Apache Software Foundation]({{< ref "/posts/2015/03/04/groovy-projects-intends-to-join-the-apache-software-foundation" >}})
*   Cédric Champeau wrote a very interesting and insightful [analysis on who contributed to Groovy](http://melix.github.io/blog/2015/02/who-is-groovy.html) over the years
*   John K. Waters from ADTMag on [Groovy to join Apache Software Foundation](http://adtmag.com/articles/2015/03/04/groovy-joins-apache-foundation.aspx) following up an interview with Guillaume Laforge
*   Jochen Theodorou brainstorms on the path [towards a revamped MOP for Groovy](http://blackdragsview.blogspot.fr/2015/03/thoughts-about-new-meta-class-system.html)
*   MrHaki's Awesome Asciidoctor: [Use inline extension DSL with Gradle](http://mrhaki.blogspot.fr/2015/03/awesome-asciidoctor-use-inline.html)
*   MrHaki's Gradle Goodness: [Define system properties in gradle.properties](http://mrhaki.blogspot.fr/2015/03/gradle-goodness-define-system.html)
*   [New features for Gradle Coming in IntelliJ IDEA 14.1](http://blog.jetbrains.com/idea/2015/03/new-features-for-gradle-coming-in-intellij-idea-14-1/) by Andrey Cheptsov
*   [Groovy, GrooScript with React.JS](http://grooscript.org/react_example.html)
*   Marcin Zajączkowski on [Spock 1.0 with Groovy 2.4 configuration comparison in Maven and Gradle](https://solidsoft.wordpress.com/2015/03/09/spock-1-0-with-groovy-2-4-configuration-comparison-in-maven-and-gradle/)
*   Benoît Hédiard writes about how to [publish your Grails 3 plugin to Bintray](https://medium.com/@benorama/how-to-publish-your-grails-3-plugin-to-bintray-c341b24f567d)
*   The Ratpack team published more information on [how the Ratpack documentation is working](http://www.ratpack.io/manual/0.9.15/intro.html#about_this_documentation) and how code samples are tested
*   Ken Kousen in "[If a method arg is a closure, for crying out loud pass it a closure](https://kousenit.wordpress.com/2015/03/10/if-a-method-arg-is-a-closure-for-crying-out-loud-pass-it-a-closure/)"
*   [Faster Groovy Compilation in IntelliJ IDEA](http://blog.jetbrains.com/idea/2015/03/faster-groovy-compilation-in-intellij-idea-14-1/) 14.1 by Peter Gromov
*   Grails tip: [Rendering errors of multiple beans](http://blog.jdriven.com/2015/03/grails-tip-rendering-errors-of-multiple-beans/) by Albert van Veen
*   Get Groovy with [JRebel and Grails](http://zeroturnaround.com/blog/get-groovy-with-jrebel-and-grails/) by Adam Koblentz
*   Working with [SASS scripts in Grails 2.3](http://www.intelligrape.com/blog/working-with-sass-scripts-in-grails-2-3-x/) by Mansi Arora
*   [Customize your Grails test reports](http://www.objectpartners.com/2015/03/03/customize-your-grails-test-reports/) by Igor Shults
*   [Another method for admin screens with Grails](http://www.objectpartners.com/2015/03/06/another-method-for-admin-screens-with-grails/) by Mike Hostetler

## News

*   The [GVM project just reached 400 stars on Github](https://twitter.com/marc0der/status/573405378744098817), keep star'ing!
*   New [documentation on Groovy meta-annotations](http://docs.groovy-lang.org/next/html/documentation/core-object-orientation.html#_meta_annotations) authored by Cédric Champeau
*   Kunal Dabir created a simple [DSL to create directory trees and files](https://github.com/kdabir/directree)
*   An updated [roadmap for GrooScript](http://grooscript.org/roadmap.html), including support for require.js
*   Jacob Aae Mikkelsen's [Grails Diary](http://grydeske.net/news/show/86) week 10 of 2015
    
## Tweets

*   Thanks to Luke Daley and Will Erickson, [Dagger 2 will work out of the box with Groovy sources and Gradle 2.4](https://twitter.com/CedricChampeau/status/573763143593295872)
*   Cédric Champeau documented how you can [use closures as annotation parameters](https://twitter.com/CedricChampeau/status/573583638127845376)
*   Cédric Champeau is so much into AST transformations that he wrongly coined the [Apache Software Foundation with the AST acronym](https://twitter.com/CedricChampeau/status/573522774758662144) instead of the ASF
*   Using [Reactor with Groovy is a nice experience in data processing](https://twitter.com/davidthecoder/status/574223398945091584) says David Dawson
*   Dan Woods reminds us that [Ratpack has a forum](https://twitter.com/danveloper/status/574298666623614976) in case you need help getting started
*   Tim Yates found some [Groovy biscuits](https://twitter.com/tim_yates/status/574270524139945984) for the discerning Groovy developer

## Code snippets

*   Using [RxJs with GrooScript](https://gist.github.com/chiquitinxx/b01d0696cfabcc34527b)
*   Iván López authored a handy Groovy [script to generate the HTML of the Greach conference speakers pages](https://gist.github.com/lmivan/a752644419fb8d2f2221)

## Events

*   GR8Conf Europe 2015 announces a [first batch of speakers](http://gr8conf.eu/#/)
# Groovy Projects intends to join the Apache Software Foundation


The Groovy team is happy to announce its intention to join the Apache Software Foundation (ASF).

  

Following up the recent announcement from Pivotal to end funding of full time developers for the Groovy programming language project, the team thought it would be appropriate to demonstrate to the Groovy community that the project is here for the long term, regardless of any funding from particular sponsoring organizations and regardless of any changes to the team of committers over time.

  

We had several discussions both online and offline with representatives of various foundations, in particular with the Eclipse Foundation, the Software Conservancy foundation and the ASF.

  

We’ve been very grateful for the time and advice given by everybody, our users, committers to projects of those foundations, board members, etc. Those discussions have been very fruitful and enlightening. Those foundations are all very interesting and could be a great fit for the project, even if all have their pros and cons, of course. But overall, the Apache Software Foundation is the one that appears to be the best candidate considering our constraints and our philosophy.

  

We will soon start the process of submitting a proposal for incubation. If the proposal is accepted, the discussions we had on the mailing list highlighted some grey areas that we are going to deal with during that incubation process and we will be very happy to work with our mentors to make sure Groovy remains a major OSS project in the JVM ecosystem.
# Groovy Weekly #60


This round number edition is pretty busy!

Last week ended with a pretty sad note, with the news of Leonard Nimoy’s passing, the famous vulcan extraterrestrial from Star Trek. This certainly resonates with the Groovy community (and geeks & fans out large) because of our very own Spock testing framework. So let’s all gather and have a thought for this great actor and for his family.

But as a tribute to this great actor and character, the long awaited news is that the [Spock testing framework releases its 1.0 version](http://spockframework.github.io/spock/docs/1.0/release_notes.html)!

Still about releases, [Griffon 2.2](http://new.griffon-framework.org/news/griffon_2.2.0.html) is out! As well as the last milestone of Grails 3 before it reaches release candidate status.

Following up the loss of funding for the Groovy and Grails projects, [Guillaume Laforge, lead of Groovy, joins Restlet, a startup dedicated to API software](http://restlet.com/blog/2015/03/02/head-of-groovy-project-joins-restlet-to-lead-api-development-tools/).

Another important news for the Groovy community is the [closing of Codehaus](http://www.codehaus.org/), which was the birth place of many projects from the ecosystem, including Groovy, Grails, Griffon, GPars, Geb, and others. All projects with some assets remaining there will have to migrate them before mid-May.

I’d like to congratulate Tim Yates for being so awesome and helpful on Stack Overflow, as he’s accounted that he replied to 14% of all questions tagged Groovy!

## Releases

*   [Spock 1.0](http://spockframework.github.io/spock/docs/1.0/release_notes.html) released!
*   [Griffon 2.2](http://new.griffon-framework.org/news/griffon_2.2.0.html) released
*   [Grails 3.0 milestone 2](https://twitter.com/grailsframework/status/570976462439878656) released
*   [Ratpack 0.9.14](http://www.ratpack.io/versions/0.9.14) released
*   [CodeNarc 0.23](http://groovy.329449.n5.nabble.com/ANN-Announcing-CodeNarc-0-23-td5722800.html) released
*   [GVM 2.2.1](https://twitter.com/gvmtool/status/572008212712587264) released
*   [Spring Boot 1.1.11](https://spring.io/blog/2015/02/27/spring-boot-1-1-11-released) released
*   [Spring Boot 1.2.2](https://spring.io/blog/2015/02/27/spring-boot-1-2-2-released) released
*   [JMH Gradle plugin 0.2.0](https://twitter.com/CedricChampeau/status/570995951835312128) released4financeIT [Gradle UpToDate plugin 1.2.0](https://twitter.com/MGrzejszczak/status/570600241604509696) release with proxy supportA Gradle plugin to [upload Android APKs and app details to the Google Play Store](http://android-arsenal.com/details/1/1609)
*   [Gretty Gradle plugin 1.1.9](https://twitter.com/AndreyHihlovski/status/572799840754782208) for running webapps on Tomcat & Jetty from Gradle

## Articles

*   Head of Groovy project, [Guillaume Laforge, joins Restlet](http://restlet.com/blog/2015/03/02/head-of-groovy-project-joins-restlet-to-lead-api-development-tools/) to lead API development tools
*   Guillaume Laforge's first post at his new gig about [making APIs groovy-er](http://restlet.com/blog/2015/03/02/lets-make-apis-groovy-er/)
*   The Register writes about "[Groovy Java guy off for Restlet](http://www.theregister.co.uk/2015/03/02/groovy_java_guy_off_for_restlet/)"
*   Schalk Cronjé remarks that the [increasing number of Twitter congrats pouring out for Guillaume Laforge is a sign of the respect the Groovy community has for the man](https://twitter.com/ysb33r/status/572420138185715712)
*   Bertrand Delacretaz says that with half a million user, the project lead not fulltime anymore, [it's time that Groovy finds a neutral home](https://twitter.com/bdelacretaz/status/572426911491756032)
*   Graeme Rocher gives an [update on the Grails project infrastructure](http://grails.io/post/112130778738/grails-project-infrastructure-update)
*   A user guide was published explaining how to [migrate from Grails 2 to Grails 3](http://grails.github.io/grails-doc/3.0.x/guide/upgrading.html)
*   Kohsuke Kawaguchi suggests the Groovy team to [start agreeing on a choice of a foundation](http://kohsuke.org/2015/02/27/groovy-folks-time-to-start-agreeing/)
*   Danny Hyun describes how to use [Gradle and Asciidoctor for HTML, PDF, ePUB, Deck.JS, Reveal.JS](http://danhyun.github.io/asciidoctor-gradle-examples/) outputs
*   How to [configure Geb and Spock with Gradle](http://planet.jboss.org/post/how_to_configure_geb_spock_with_gradle)
*   [Groovy oddities](http://www.eclecticlogic.com/2015/02/17/groovy-oddities/) by Karthik Abram
*   The Griffon team published the [Griffon 2.2 release notes](http://new.griffon-framework.org/releasenotes/griffon_2.2.0.html)
*   First [Griffon 2.2 tutorials](http://new.griffon-framework.org/tutorials/) available
*   Marcin Grzejszczak on how he [reduced his Gradle build from 90 to 8 minutes](http://toomuchcoding.blogspot.com/2015/02/how-to-speed-up-your-gradle-build-from.html)
*   Craig Burke updates his [Groovy Document Builder](http://www.craigburke.com/2015/03/02/groovy-document-builder-mpl-edition.html) with a friendly OSS license
*   Kyle Boon has up'ed his Spock dependency to 1.0
*   After Spock 1.0, Iván López wonders [which framework will get to 1.0: Geb or Ratpack](https://twitter.com/ilopmar/status/572424545426116608)?
*   Arthur Tsang blogs about the [changes required for moving from Ratpack 0.9.12 to 0.9.13](http://arthur-notes.youramaryllis.com/2015/02/moving-from-ratpack-0912-to-0913.html) with the new configuration changes
*   [Geb is now using Spock 1.0](https://twitter.com/GebFramework/status/572689714760835072) just released
*   Dan Woods announces slick [Groovy extensions for RxJava and 'ReactiveStreams in Ratpack's next version](https://twitter.com/danveloper/status/572764621007814656)

## Interviews

*   Victor Grazi of [InfoQ interviewed Guillaume Laforge](http://www.infoq.com/news/2015/03/Groovys-Laforge-Joins-Restlet) on the fact he's joining the Restlet startup
*   Voxxed [interviews Guillaume Laforge with the imminent move of Groovy to a foundation and with joining Restlet](https://www.voxxed.com/blog/2015/03/with-foundation-decision-imminent-groovy-creator-moves-to-restlet/)
    
## Presentations

*   Cédric Champeau presented [Groovy and Android, a winning pair](https://twitter.com/CedricChampeau/status/572428885708697601), at MCE 2015

## News

*   [Codehaus is shutting its doors](http://www.codehaus.org/)
*   Andy Clément announces that [Groovy Eclipse 2.9.2 builds for Eclipse 4.4 and includes Groovy 2.3.10 and 2.4.1](https://twitter.com/andy_clement/status/570989272406233089)
*   Søren Berg Glasius and Guillaume Laforge [collaborated on the GR8Conf Europe 2015 agenda](https://twitter.com/glaforge/status/571044985463803904)
*   [GroovyLab now works on Raspberry Pi 2](http://groovy.329449.n5.nabble.com/GroovyLab-on-Raspberry-Pi-2-td5722839.html) by Stergios Papadimitriou
*   [React support in Grails Asset Pipeline](https://grails.org/plugin/react-asset-pipeline) plugin
*   With Codehaus closing, [Geb has moved its mailing-lists to Google Groups](https://twitter.com/GebFramework/status/572305358913331201)
*   [Ratpack 0.9.14 adds support for Slf4j's Mapped Diagnostic Context](http://www.ratpack.io/manual/0.9.15/api/ratpack/logging/MDCInterceptor.html)

## Tweets

*   Congrats to [Tim Yates who posted 14% of all answers to Stack Overflow questions on Groovy](https://twitter.com/tim_yates/status/571231496004108288)
*   The [Spock Framework has its own twitter account](https://twitter.com/spockframework/status/572378381146300418)
*   In memory of Leonard Nimoy's passing last week, Guillaume Laforge [wishes the Spock framework to "live long and prosper"](https://twitter.com/glaforge/status/571393595825111041)
*   Cédric Champeau outlines the fact that [Guillaume Laforge will continue to work on Groovy](https://twitter.com/CedricChampeau/status/572412160304934912)
*   With Codehaus closing, [Geb is going to move its mailing-list and issue tracker](https://twitter.com/GebFramework/status/571234105313988609) soon
*   Marco Vermeulen continues working on [GVM's Vendor API](https://twitter.com/marc0der/status/571765090342596609)
*   Billy Yarosh [enjoys Groovy's documentation](https://twitter.com/keaplogik/status/570385013042225152)
*   [Grails 3 milestone 2](https://twitter.com/gvmtool/status/570979574768652288) available on GVM
*   [Spring Boot 1.2.2](https://twitter.com/gvmtool/status/571217914944221185) is available on GVM
*   [Spring Boot 1.1.11](https://twitter.com/gvmtool/status/571218056095137792) is available on GVM
*   Peter Niederwieser choses [TravisCI for Spock's continuous integration](https://twitter.com/pniederw/status/572107004510126082) solution

## Code snippets

*   The [GrooScript project reached 150 followers on twitter](https://twitter.com/grooscript/status/571730552564420608), let's add more followers!
*   [Mixing Angular.JS and GrooScript](https://gist.github.com/chiquitinxx/a38ba0b54a405c11ece4) using closures for controllers
*   Cédric Champeau created a [file / directory structure builder](https://twitter.com/CedricChampeau/status/571257801630220288)
*   Russell Hart shows how to [externalize Ratpack's metrics collection configuration](https://github.com/ratpack/example-books/blob/latest/src/ratpack/ratpack.groovy#L44)
*   Benoit Hediard on using [Grails on Amazon Beanstalk with TravisCI](https://gist.github.com/benorama/b26e7a94fe80e8c54daf)
*   A [trait approach for GrooScript with Angular.JS](https://gist.github.com/chiquitinxx/e0c561547e0e1b690767) controllers

## Screencasts

*   A screencast introducing [JRebel's improved Grails support](https://vimeo.com/zeroturnaround/review/120679908/75a58f2e13)
    
## Books

*   Dierk König notes that even the [small code listings in Groovy in Action 2nd edition makes for a 3MB archive](https://twitter.com/mittie/status/572497775872630784)

## Events

*   Most [speakers for GR8Conf Europe 2015](https://twitter.com/sbglasius/status/571045481666605056) have been picked up
*   [Álvaro Sánchez will be speaking at GR8Conf Europe](https://twitter.com/alvaro_sanchez/status/571248810309095424) 2015
# Groovy Weekly #59


Groovy keeps rocking with a [joint release of Groovy 2.4.1 and also a 2.3.10]({{< ref "/posts/2015/02/18/joint-releases-of-groovy-2-4-1-and-2-3-10" >}})!

And did you notice the nice new design of the [new Grails website](https://grails.org/), based on [Groovy’s website](http://www.groovy-lang.org/)? That’s a family look!
  
Also, I’d like to end this short editorial with a big congrats to the [GVM team who’s reached the 100,000 unique installs](https://twitter.com/gvmtool/status/570138706973224960)! That’s a big milestone!

## Releases

*   Joint releases of [Groovy 2.4.1 and Groovy 2.3.10]({{< ref "/posts/2015/02/18/joint-releases-of-groovy-2-4-1-and-2-3-10" >}})
*   [GMavenPlus 1.4](http://groovy.329449.n5.nabble.com/GMavenPlus-1-4-Released-td5722753.html) released
    
## Articles

*   Voxxed covers the [latest double Groovy release drops and the deliberations on the choice of a foundation](https://www.voxxed.com/blog/2015/02/groovy-latest-double-release-drop-foundation-deliberations/) for the project
*   Shane Curcuru reflected on the fact of [Groovy joining a foundation](https://medium.com/@shanecurcuru/its-groovy-to-join-a-foundation-4145732b4ec1)
*   MrHaki's Groovy Goodness: [Access XML-RPC API](http://mrhaki.blogspot.fr/2015/02/groovy-goodness-access-xml-rpc-api.html)
*   Kyle Boon on [using Groovy and Go's GVMs together](http://kyleboon.org/blog/2015/02/23/groovy-gvm-and-go-gvm/)
*   Installing [SonarQube for managing the quality of your Grails](http://www.intelligrape.com/blog/sonarqube-all-in-one-code-quality-manager/) project
*   Miguel de la Cruz teaches a [Geb 101 course](http://www.kaleidos.net/blog/993/geb-101-simple-scripts/) in this article
*   Laurent Napias wrote an article in French on [Groovy on Android with the SwissKnife](http://www.laurent-napias.com/post/2015/02/22/plus-de-groovy-avec-android-et-un-peu-de-swissknife-dedans) library
*   Andy Wilkinson wrote about [better dependency management for Gradle](https://spring.io/blog/2015/02/23/better-dependency-management-for-gradle)
*   Dustin Marx on [writing Groovy's XmlParser's Node content as XML](http://java.dzone.com/articles/writing-groovys-groovyutilnode)
*   [Integrating PubNub with Grails](http://www.intelligrape.com/blog/integrating-pubnub-with-grails/) by Sumant Thakur
*   Ted Vinke on starting a [video blog on Grails](https://tedvinke.wordpress.com/2015/02/19/starting-a-video-blog-grails-in-the-first8friday-series/)

## News

*   Guillaume Laforge submitted [Groovy to the Google Summer of Code](https://twitter.com/glaforge/status/567675689575669760) program
*   [Ken Kousen is co-hosting the Groovy podcast](https://kousenit.wordpress.com/2015/02/22/now-co-hosting-the-groovy-podcast/) with Peter Ledbrook
*   The [Grails team launches its new website](https://twitter.com/grailsframework/status/568471340686180352), based on Groovy’s new site design
*   Jacob Aae Mikkelsen's [Grails Diary](http://grydeske.net/news/show/84) week 8 of 2015
    
## Tweets

*   [GVM crossed the 100k unique installs](https://twitter.com/gvmtool/status/570138706973224960) mark!
*   Cédric Champeau is happy having [released two versions of Groovy in only two hours](https://twitter.com/CedricChampeau/status/568009999122894848)
*   Dean Macaulay finds that [mixing Grails and Intellij IDEA makes a world of productivity](https://twitter.com/dean_macaulay/status/567622801943564289)
*   Tim Yates [Groovy-logic library is listed on the MiniKanren website](https://twitter.com/tim_yates/status/567764313252896768)
*   Russel Winder wonders [how Groovy release can be "hot" as Groovy is "cool"](https://twitter.com/russel_winder/status/568008750340173824)!
*   [Groovy 2.3.10](https://twitter.com/gvmtool/status/568008971828768768) is available on GVM
*   [Groovy 2.4.1](https://twitter.com/gvmtool/status/568009006440194048) is available on GVM
*   [GrooScript encourages speakers to use its vintage logo](https://twitter.com/grooscript/status/568529775150510080)
*   Russel Winder is [looking for some CSS guru for redesigning the GPars website](https://twitter.com/russel_winder/status/568139020879974402)
*   Dierk König notes that [Groovy is 4 times in JavaOne 2014's rock stars](https://twitter.com/mittie/status/568709714105765890)
*   Cédric Champeau notes the [progress on the new Groovy documentation but highlights lots of sections looking for help for completion](https://twitter.com/CedricChampeau/status/568769788102619136)
*   Cédric Champeau highlights this [commit of the Groovy executable documentation on type checking extensions](https://twitter.com/CedricChampeau/status/568767762417364993)
*   Answering Peter Ledbrook and Ken Kousen on the Groovy podcast, Cédric mentions that [Grails' new site is a static site on Github, forked from the Groovy website](https://twitter.com/CedricChampeau/status/569189775707652097)
*   Kostis Kapelonis teases about [Groovy giving a 75% reduction of code lines against Java](https://twitter.com/codepipes/status/569067464853749760), as an excerpt of his Spock book
*   Kostis Kapelonis thinks the ["Making Java Groovy" book from Ken Kousen is one of the best Groovy for Java developers book](https://twitter.com/codepipes/status/569775343806091264) he's ever read
*   Versions 1.4.3 and 1.4.4 of the [ElasticSearch Groovy client released with special support for Grails 2.x](https://twitter.com/pickypg/status/569885478775861248)
*   Schalk Cronjé is astonished that [some Java developers still don't know about Spock, Gradle, Bintray and Artifactory](https://twitter.com/ysb33r/status/570168038848405504)
*   Erik Pragt is working on an [IntelliJ IDEA plugin in Groovy to support Ionic framework](https://twitter.com/epragt/status/570014405515186176)
*   Dan Woods and Iván López discuss about [LogBack's Groovy DSL configuration](https://twitter.com/ilopmar/status/570113950391664641) and the tool to convert XML configurations into Groovy
    
## Code snippets

*   Andrés Almiray shares his configuration for [combining Asciidoctor, Ditaa based diagrams, PDF rendering, in your Gradle build](https://gist.github.com/aalmiray/7369b977a68baca32e13)
*   Vladimír Oraný is trying to [achieve better test isolation in Grails](https://gist.github.com/musketyr/164bf82d4a07b3355a08)
*   [Groovy making 3D figures dance in the browser thanks to GrooScript](https://twitter.com/grooscript/status/568475830072041472) and Three.js
*   Danny Hun shares how to use [Asciidoctor, Gradle and Reveal.JS](https://github.com/danhyun/asciidoctor-gradle-examples/tree/master/asciidoc-to-revealjs-example)
    
## Podcasts

*   Peter Ledbrook and Ken Kousen recorded [Groovy podcast episode 7](https://twitter.com/pledbrook/status/568896651055771648)

## Books

*   Konstantinos Kapelonis is authoring [Java testing with Spock for Manning](https://twitter.com/mittie/status/567803572570828801)

## Events

*   The [SpringOne2GX 2015 call for paper is open](https://twitter.com/springcentral/status/568948321047293953)
*   You can [submit a talk to the Gradle Summit](http://gradlesummit.com/conference/santa_clara/2015/06/home)
*   The [Greach conference has announced its final agenda](https://twitter.com/greachconf/status/568699197307920384)
*   Andrew Reitz will be speaking about Groovy on Android at GR8Conf US
# Joint releases of Groovy 2.4.1 and 2.3.10


The Groovy development team is happy to announce the joint releases of the Groovy 2.4.1 and Groovy 2.3.10 of the Groovy programming language for the Java platform.

  

Both releases are bug fix releases, and while Groovy 2.4.1 is the latest official stable branch, we thought it might be helpful to some projects who are still on the 2.3.x line to get a final release for that branch. But going forward, the 2.3.x branch won’t see any upcoming release.

  

You can learn more about all the tickets closed by reading:

*   the [Groovy 2.4.1 changelog](http://groovy-lang.org/changelogs/changelog-2.4.1.html)
    
*   the [Groovy 2.3.10 changelog](http://groovy-lang.org/changelogs/changelog-2.3.10.html)
    

  
For reference, you can also read the [release notes of Groovy 2.4](http://groovy-lang.org/releasenotes/groovy-2.4.html) if you haven't had a chance to since the announcement.  

Head over to the [download section of the new Groovy website](http://www.groovy-lang.org/download.html) to download the binary distribution, or update your dependencies accordingly with those new version numbers.

  

Thanks a lot for all those who contributed to this release!
# Groovy Weekly #58


The past week’s been pretty calm, in terms of news, but a few of them really stood out.

[Netflix again leverages Groovy for scripting its user experience API](http://www.forbes.com/sites/danwoods/2015/02/11/how-a-netflix-tech-innovation-can-unleash-creativity-in-your-business/print/) (additional coverage following last week’s announcement).

The Gradleware team delivered [Gradle 2.3](http://forums.gradle.org/gradle/topics/gradle-2-3-released)! Congrats guys!

And closer to home, a very important discussion about [moving Groovy into a foundation](http://groovy.329449.n5.nabble.com/Moving-Groovy-to-a-Foundation-td5722483.html) has started, inviting members and representatives of different foundations to join and offer their views and experience on the matter.

## Releases

*   [Gradle 2.3](http://forums.gradle.org/gradle/topics/gradle-2-3-released) released
*   [Gradle 2.3-rc-3](http://forums.gradle.org/gradle/topics/gradle-2-3-rc-3-is-now-available-for-testing) is ready for testing
*   [Spock-reports 1.2.4](https://groups.google.com/forum/#!topic/spockframework/008xHyM5DEI) released
*   [gServ 0.9.6](https://www.linkedin.com/groupItem?view=&item=5972153940031131649&type=member&gid=76751&trk=eml-b2_anet_digest_weekly-hero-12-grouppost-0&midToken=AQES0rgmUQCbHg&fromEmail=fromEmail&ut=3j0nkf-NtM9CE1) released, a Groovy-based container-less REST framework
*   [GBench 0.4.3](https://twitter.com/nagai_masato/status/566531438795698180) released
    
## Articles

*   A Forbes article explains how a [Netflix innovation unleash the creativity in their business, thanks to Nicobar, their Groovy based scripting solution](http://www.forbes.com/sites/danwoods/2015/02/11/how-a-netflix-tech-innovation-can-unleash-creativity-in-your-business/print/)
*   Jaxenter on the ongoing discussion about [moving the Groovy project to a foundation](http://jaxenter.com/will-groovy-soon-eclipse-apache-project-114536.html)
*   Masato Nagai [benchmarks Groovy's as operator](http://nagaimasato.blogspot.fr/2015/02/gbench-043-released-lets-benchmark-as.html?spref=tw) between Groovy 2.3 and 2.4, using GBench
*   Jeff Beck writes about [Grails integration testing of complex transactions](http://beckje01.com/blog/2015/02/14/grails-integration-testing-of-complex-transactions/)
*   [Getting started with Android development using Groovy 2.4](http://hosain.net/2015/02/07/getting-started-with-android-development-using-groovy-2.4-and-android-studio.html) and Android Studio
*   [Releasing a project to Maven Central with Gradle](http://www.jroller.com/ie/entry/releasing_a_project_to_maven) by John McClean
*   [Geb and Gradle rules](http://davesmith.me//blog/2015/geb-gradle-rules.html) by Dave Smith
*   [Gradle rules](http://davesmith.me//blog/2015/gradle-devops-rules.html) by Dave Smith

## Mailing-lists

*   An important discussion on [moving Groovy to a foundation](http://groovy.329449.n5.nabble.com/Moving-Groovy-to-a-Foundation-td5722483.html)

## News

*   [Cédric Champeau becomes a JavaOne rock star](http://steveonjava.com/congratulations-to-the-2014-javaone-rock-stars/) thanks to his excellent presentation on rethinking APIs with traits during JavaOne 2014
*   Duncan Dickinson launches his [Groovy 2 tutorial series](http://www.groovy-tutorial.org/), with 4 tutorials on getting started, variables, operators, and control flow statements
*   You can vote for an [improvement to let Gradle-built IntelliJ IDEA projects support clickable source code files](https://youtrack.jetbrains.com/issue/IDEA-136587) from the output window
*   [Grails Diary](http://grydeske.net/news/show/83) Week 7 of 2015 by Jacob Aae Mikkelsen
    
## Tweets

*   Cédric Champeau calls for feedback and [seeks advice on the idea of moving Groovy to a foundation](https://twitter.com/CedricChampeau/status/565548766946926592)
*   Andrés Almiray publishes the first Griffon tutorial for the next iteration of the Griffon website
*   The [GVM vendor API](https://twitter.com/marc0der/status/566758590472794112) is now in a dev environment
*   GrooScript updated its [groovy ecosystem frameworks](https://twitter.com/grooscript/status/565282808307150848) page
*   The JFrog crew earned a [JavaOne Rock Star title thanks to their Groovy puzzlers talk](https://twitter.com/jfrog/status/565589535862841346)
*   [Gradle 2.3](https://twitter.com/gvmtool/status/567274822141763584) available through GVM
*   The Groovy puzzlers guys are [looking for new Groovy puzzlers for their second season](https://twitter.com/groovypuzzlers/status/567316156411691009)!

## Code snippets

*   Tim Yates and Cédric Champeau are playing [Groovy code golf on Fibonacci](https://twitter.com/tim_yates/status/565490899963375616)
*   Tim Yates shares some [snippets combining Groovy and GroovyFX](https://gist.github.com/timyates/d97d613e4379434ff7a8)

## Podcasts

*   Episode 48 of the JavaPubHouse is about using [Groovy and Gradle for Java projects](https://twitter.com/fguime/status/566098122901041152)
    
## Events

*   Iván López will be speaking about being a [full-stack Groovy developer](https://twitter.com/ilopmar/status/565806105042120704) at the Spring.IO conference
*   Marco Vermeulen notes that [SpringOne2GX keeps its 2GX suffix and that the CFP is open](https://twitter.com/marc0der/status/566136563214876672)
*   Craig Burke will be talking about [Angular.JS in a Groovy world](https://twitter.com/craigburke1/status/566637455982731264) at GR8Conf US
# Groovy Weekly #57


So what’s Groovy this week? The Groovy community is still celebrating the 4.5+ million downloads of Groovy last year, is drive testing the upcoming Gradle 2.3, while Greach is announcing its impressive roster of speakers.

But there’s an item of news dear to my heart this week, with the “go to production” message from Dierk about Groovy in Action, second edition! Many times the book has been revised to catch up with the latest and greatest of Groovy, and this new edition will bring you up-to-date with Groovy 2.4, so you can expect the official print and e-book final versions imminently!

## Releases

*   [Gradle 2.3-rc-2](https://twitter.com/gradleware/status/562992965724172288) is available
*   [GrailsFlow 1.5](https://twitter.com/grailsflow/status/563301303464755201) released with Bootstrap 3
*   Joachim Baumann published the [Windows installer for Groovy 2.4](https://bintray.com/groovy/Distributions/Windows-Installer/groovy-2.4.0-installer/view)
*   [Spock-Android 1.1](https://twitter.com/andrewreitz_/status/564908080593244160) released
    
## Articles

*   [Netflix open sources a new Groovy-based scripting library](http://techblog.netflix.com/2015/02/nicobar-dynamic-scripting-library-for.html) for customizing their API UIs
*   [Accelerate your Gradle build time](https://www.voxxed.com/blog/2015/02/speed-gradle-build-90-8-minutes/) from 90 to 8 minutes
*   MrHaki's Spocklight: [Capture and assert system output](http://mrhaki.blogspot.fr/2015/02/spocklight-capture-and-assert-system.html)
*   Jochen Theodorou on [getting rid of compareTo in favor of ==](http://blackdragsview.blogspot.fr/2015/02/getting-rid-of-compareto-for.html)
*   [New features for the venerable AEM](http://www.citytechinc.com/us/en/blog/2015/02/aem-groovy-console-new-features.html) (Adobe CQ) Groovy Console
*   [Developing a web automation framework using Geb](http://blog.varunin.com/2015/01/developing-web-automation-framework.html) and Groovy by Varun Menon
*   The [new EAP of IntelliJ IDEA features enhanced Gradle support](http://blog.jetbrains.com/idea/2015/02/intellij-idea-14-1-eap-is-available/) and allows you to use the Groovy-Eclipse compiler
*   [Groovy Closures create tidy, flexible services](http://www.objectpartners.com/2015/02/03/groovy-closures-create-tidy-flexible-services/) by Ben Brunk
*   [Significance of “mappedBy” in Grails domain classes](http://www.intelligrape.com/blog/significance-of-mappedby-in-grails-domain/) by Naman Gautam
*   [Creating Android apps with Groovy 2.4](http://www.mscharhag.com/2015/02/creating-android-apps-with-groovy.html) by Michael Scharhag

## Presentations

*   [Reactive Oriented Architecture with Grails](http://www.infoq.com/presentations/reactive-arch-grails) by Steve Pember recorded at SpringOne2GX 2014
*   Cédric Champeau posted his slides from the MCE Conference in Poland about [Groovy & Android, a winning pair](https://speakerdeck.com/melix/groovy-and-android-a-winning-pair-2)
*   [Groovy in the light of Java 8](https://www.parleys.com/talk/groovy-light-java-8) by Cédric Champeau at JavaOne 2014

## Books

*   Dierk König announces that [all the content of the second edition of Groovy in Action is committed to production](https://twitter.com/mittie/status/563825962606149632)
*   Dierk König tells that the [second edition of Groovy in Action contains 20 chapters and 9 appendices](https://twitter.com/mittie/status/564461905281294336)

## Podcasts

*   Peter Ledbrook posted [Episode 6 of the Groovy podcast](https://twitter.com/pledbrook/status/563371370974035968)

## News

*   A [Groovy based rules engine](https://github.com/jdereg/n-cube), decision table & tree, templating engine
*   A [Groovy package installer](https://github.com/tkruse/gpi), "gpi", from Thibault Kruse
*   Jacob Aae Mikkelsen publishes [Grails Diary](http://grydeske.net/news/show/82) week 6
*   The list of [Grails plugins ready for Grails 3](https://github.com/grails3-plugins/)

## Tweets

*   Cédric Champeau summarizes the nice upward trend for [Groovy's yearly download numbers, reaching 4.5 millions in 2014](https://twitter.com/CedricChampeau/status/562887140271726593)
*   Craig Burke found a parallel with iOS' "there's an app for that", with "[in Groovy, there's an AST transformation for that](https://twitter.com/craigburke1/status/562630876883083265)"
*   Craig Burke is working on a [PdfBox based document builder](https://twitter.com/craigburke1/status/563413112238649345) with a friendly open source license
*   The [book of Geb is being migrated to Asciidoctor](https://twitter.com/gebframework/status/563270465452376064) with automatically tested code snippets
*   The new [Geb twitter account](https://twitter.com/gebframework/status/563041355816239104) reached hundred followers
*   [Gradle 2.3-rc-3](https://twitter.com/gvmtool/status/564691564665266177) available through GVM
*   You can [fill a survey to help make Gradle tutorials better](https://twitter.com/nisafla/status/562303038912614400)
*   Luke Daley announces a new [Gradle plugin for running tests within Docker containers](https://twitter.com/ldaley/status/563113387169562624)
*   Peter Ledbrook learned that [Groovy's type checker can infer the component type of list literals](https://twitter.com/pledbrook/status/563434449191579648)
*   Clint Liddick says [IntelliJ IDEA's Groovy console is way nicer than an hypothetic Java REPL](https://twitter.com/ClintLiddick/status/563817158720118784)
*   You can watch [GrooScript in action](https://twitter.com/grooscript/status/565265212761464832) at the Greach conference
*   A last final MEAP of Groovy in Action second edition will be out soon, says Dierk König
*   Sean Gilligan works on a [Groovy support for JSR-354 / Money](https://twitter.com/jsr354/status/564420791224508416)

## Events

*   [Greach tweets about its roster of speakers](https://twitter.com/greachconf/status/563296040539811840)
*   [More speakers for the Greach](https://twitter.com/greachconf/status/563294745183539201) conference
*   The [Greach conference agenda](https://twitter.com/greachconf/status/565084022733160448) is online
# Groovy Weekly #56


Congrats to the GrooScript team with the [GrooScript 1.0](http://grooscript.org/announcement.html) release! With GrooScript, if you will, you can have a full Groovy experience, from the build (Gradle), backend (Groovy, Grails, Ratpack), mobile (Groovy on Android), up to the front-end web layer with Groovy translated into JavaScript!

Another impressive and widely acclaimed release is the [first milestone of Grails 3](https://github.com/grails/grails-core/releases/tag/v3.0.0.M1)! You can have a look at the [novelties in Grails 3](http://grails.github.io/grails-doc/3.0.x/guide/introduction.html#whatsNew), and watch a [screencast](https://www.youtube.com/watch?v=aro3_RZqgtU) about it.

The Ratpack team has also been pretty busy with [Ratpack 0.9.13](http://www.ratpack.io/versions/0.9.13), with over 17k lines of code changed in this release!

Guillaume Laforge also announced that [Groovy was downloaded over 4 million times from Maven Central](https://twitter.com/glaforge/status/562590782084112384), without even counting the downloads of the binary distributions from Codehaus or Bintray. In total, Groovy will likely be beyond 5 million times in total, compared with 3 millions the past year.

## Releases

*   The [first milestone release of Grails 3](https://github.com/grails/grails-core/releases/tag/v3.0.0.M1) is out!
*   [GrooScript 1.0](http://grooscript.org/announcement.html) released, the Groovy to JavaScript transpiler
*   [Ratpack 0.9.13](http://www.ratpack.io/versions/0.9.13) released, a "big one"!
*   [Grails asset-pipeline plugin v2.1.1](https://twitter.com/davydotcom/status/560503261137231872)
    
## Articles

*   InfoQ covers the [Groovy 2.4 release and highlights the Android support](http://www.infoq.com/news/2015/01/groovy14-android)
*   MrHaki's Groovy Goodness:
    *   [getting all but the last element in a collection with the init method](http://mrhaki.blogspot.fr/2015/01/groovy-goodness-getting-all-but-last.html)
    *   [getting the indices of a collection](http://mrhaki.blogspot.fr/2015/01/groovy-goodness-getting-indices-of.html)
    *   [pop and push items in a list](http://mrhaki.blogspot.fr/2015/01/groovy-goodness-pop-and-push-items-in.html)
*   Mariano Gonzalez wrote about [polyglot programming in Mule](http://blogs.mulesoft.org/mule-3-6-polyglot-programming/), with the scripting pack now part of the distribution, and showing an example with Groovy
*   [Grails 3.0.0.M1 Asset-Pipeline tips and tricks](http://davydotcom.com/blog/2015-01-29-grails-3-0-0-m1-asset-pipeline-tips-tricks) by David Estes
*   Grails Clean Code: [Configure Codenarc plugin](http://www.intelligrape.com/blog/grails-clean-code-configure-codenarc-plugin/) by Uday Pratap Singh
*   Building a [geolocation web application with Groovy and Grails](https://www.accelebrate.com/blog/building-geolocation-web-application-groovy-grails/) by Ken Kousen

## Presentations

*   The [PayPal API platform is using Groovy as its orchestration language](http://www.infoq.com/presentations/paypal-api-evolution), as mentioned in this presentation given at QCon San Francisco 2014
*   SpringOne2GX 2014 Replay
    *   [Groovy for system administrators](https://spring.io/blog/2015/01/26/springone2gx-2014-replay-groovy-for-system-administrators) by Dan Woods
    *   [The Ratpack web framework](http://www.infoq.com/presentations/ratpack-2014) by Dan Woods
    *   [Web clustering, integration with Terracotta, BigMemory, Quartz & Grails](http://www.infoq.com/presentations/clustering-terracota-quartz-grails) by Ryan Vanderwerf
    *   [Testing Grails](http://www.infoq.com/presentations/grails-testing-2014) by Ken Kousen
    *   [Building a Continuous Delivery pipeline with Gradle and Jenkins](http://www.infoq.com/presentations/cd-gradle-jenkins-2014) by Peter Niederwieser
*   Building a [geolocation web application with Groovy and Grails](https://www.accelebrate.com/blog/building-geolocation-web-application-groovy-grails/) by Ken Kousen
    
## Screencasts

*   A [screencast preview of Grails 3](https://twitter.com/grailsframework/status/560752646093832192) by Graeme Rocher for the M1 release

## News

*   Jacob Aae Mikkelsen's [Grails Diary](http://grydeske.net/news/show/81)

## Tweets

*   Guillaume Laforge announced [Groovy being downloaded over 4 million times in 2014 from Maven Central](https://twitter.com/glaforge/status/562590782084112384). With the Codehaus distribution figures, it might mean beyond 5 million total downloads!
*   Cédric Champeau realizes [how huge Groovy is when one has to write its documentation](https://twitter.com/cedricchampeau/status/560837091764887552)! Or when you notice that Groovy in Action (second edition) is over 1000 pages!
*   [Testing Android apps with Espresso is very expressive in Groovy](https://twitter.com/mg6maciej/status/560865008830382081) remarks Maciej Górski
*   Victor Trakhtenberg needs some [votes for his Groovy talk](https://twitter.com/victortr75/status/560393895658283009) on confessions of a Java developer that fell in love with Groovy
*   Dierk König says that [Groovy in Action, second edition, contains over 600 code listings](https://twitter.com/mittie/status/562570994918100993)
*   John Engelman counted [17k code line changes in Ratpack 0.9.13](https://twitter.com/johnrengelman/status/562081630677127168)
*   At FOSDEM, the [Oracle team mentioned Groovy's contributions to debugging JDK 8](https://twitter.com/thetaph1/status/561891670082732032), thanks to Cédric Champeau's bug reports
*   You can get grooscript.js from from NPM and Bower
*   Marco Vermeulen is [impressed with Grails 3](https://twitter.com/marc0der/status/561993267819323393) and how the Grails team outdid themselves!
*   [Grails 3.0 milestone 1](https://twitter.com/gvmtool/status/560920057916948480) is available on GVM
    
## Code snippets

*   Philippe Charrière implemented his first [http server framework with Groovy](https://github.com/k33g/kiss-groovy/blob/master/app/main.groovy#L16)

## Events

*   [Marco Vermeulen will be speaking at Greach](https://twitter.com/marc0der/status/562142093267959808)
# Groovy Weekly #55


This week is a bit more positive than the previous with the announcement of the [release of Groovy 2.4]({{< ref "/posts/2015/01/21/groovy-2-4-released" >}})!

But some interesting and thoughtful pieces have also been written about last week’s sad news about Pivotal divesting in Groovy and Grails.

In spite of this, [SpringOne2GX 2015 has been announced with 4 Groovy and Grails tracks](https://twitter.com/springone2gx/status/559903903756861440), in Washington DC, mid-September.

Last but not least, the [second edition of Groovy in Action is going into production](https://twitter.com/mittie/status/558011051313491969)!
  
## Releases

*   [Groovy 2.4]({{< ref "/posts/2015/01/21/groovy-2-4-released" >}}) released
*   [GMaven Plus 1.3](http://groovy.329449.n5.nabble.com/GMaven-1-3-Released-td5722239.html) released
*   [SwissKnife 1.2.2](https://twitter.com/arasthel92/status/559659062309449728) released
*   [Second release candidate for GrooScript 1.0](https://twitter.com/grooscript/status/557999421691269120)
*   [GrooScript Gradle plugin 0.10](https://twitter.com/grooscript/status/558000095070015488) released
*   [Gradle 2.3-rc-1](https://twitter.com/gradleware/status/560099446508519426) available for testing

## Articles

*   Voxxed notes that [Groovy is back to business with its 2.4 release](https://www.voxxed.com/blog/2015/01/groovy-verse-back-business-2-4-release/)
*   Object Partners writes [Keep Calm and Groovy on](http://www.objectpartners.com/2015/01/23/keep-calm-groovy-on/)!
*   Henrique Lobo Weissmann compares [Groovy and Grails to "bridges" technology](http://www.itexto.com.br/devkico/en/?p=69)
*   Dan Vega shares his [thoughtful views on the Groovy & Grails loss of funding](http://therealdanvega.com/blog/2015/01/20/pivotal-drops-groovy-grails-sponsorship) from Pivotal
*   Peter Ledbrook shares his [thoughts on the future of Groovy](http://blog.cacoethes.co.uk/groovyandgrails/the-future-of-groovy)
*   TheRegister covers the [loss of sponsorship from Pivotal of the Groovy and Grails projects](http://www.theregister.co.uk/2015/01/22/open_source_java_grails_and_groovy_as_pivotal_pulls_out/)
*   Dustin Marx writes about the [total bummer that Pivotal drops Groovy](http://java.dzone.com/articles/total-bummer-pivotal-drops)
*   Koshuke Kawaguchi shares his view that the [Groovy project should have a clear governance structure](http://kohsuke.org/2015/01/20/groovy-project-should-have-a-clear-governance-structure/)
*   Mike Miller detects a [disturbance in the (Groovy & Grails) force](http://programmingitch.blogspot.dk/2015/01/i-detect-disturbance-in-groovy-grails.html)
*   Groovy and Grails, [GR8 without Pivotal](http://www.intelligrape.com/blog/groovy-and-grails-gr8-without-pivotal/) writes IntelliGrape's Himanshu Seth
*   Craig Burke worked on a [document builder to create Word and PDF documents in Groovy](http://www.craigburke.com/2015/01/22/groovy-document-builder.html)
*   The [Groovy 2.4 release notes](http://beta.groovy-lang.org/releasenotes/groovy-2.4.html)
*   The [Groovy 2.4 changelog](http://beta.groovy-lang.org/changelog-2.4.0.html) now up on the new Groovy website
*   A Quora question: "[I've started a Grails project, what should I do?](https://www.quora.com/Pivotal-is-no-longer-sponsoring-Grails-I-have-a-Grails-project-in-the-works-What-should-I-do)"
*   Another Quora question: [why is Pivotal ending sponsorship of Groovy and Grails](https://www.quora.com/Why-is-Pivotal-ending-the-sponsorship-of-Groovy-and-Grails)?
*   MrHaki's Groovy goodness: [take or drop last items of a collection](http://mrhaki.blogspot.fr/2015/01/groovy-goodness-take-or-drop-last-items.html)
*   On [building multiple editions of an Android application with Gradle](http://blog.robustastudio.com/mobile-development/android/building-multiple-editions-of-android-app-gradle/) by Hassan Ibraheem
*   [JVM metrics + Grails = awesomeness](https://www.voxxed.com/blog/2015/01/jvm-metrics-grails-awesomeness/), by Erwan Arzur
*   Yamila Moreno comes back on her Groovy 101 series with a post on [Groovy, GVM, Gradle, Travis and Jenkins](http://moduslaborandi.net/groovy-101-gradle-travis-and-jenkins/)
*   Using the [CIA world fact book with Groovy](http://www.perfectlearn.com/2015/01/how-i-used-the-cia-world-factbook-to-test-my-product/)
*   Let’s talk commitment: [Gradle and version control](http://blog.ship.io/2015/01/23/lets-talk-commitment-gradle-and-version-control/), by Tim Rosenblatt

## Podcast

*   The Groovy podcast [interviewed Graeme Rocher and Guillaume Laforge](https://twitter.com/dailygrailstip/status/557943849251643393)

## Interviews

*   Project lead [Graeme Rocher on the future of Grails](http://jaxenter.com/grails-future-113958.html) on JaxEnter

## Presentations

*   A [Grails 3.0 preview](http://www.infoq.com/presentations/grails-3-preview) by Graeme Rocher, recorded at SpringOne2GX 2014
*   The [quest for the holy Grails](http://www.infoq.com/presentations/grails-introduction) by Ken Kousen, recorded at SpringOne2GX 2014
*   [Securing your Grails application, beyond authentication and authorization](http://www.infoq.com/presentations/grails-security-auth), by Colin Harrington, recorded at SpringOne2GX 2014
*   David Carr's latest [Ratpack introduction presentation](http://www.slideshare.net/davidmc24/intro-to-ratpack-cdjdn-2015)

## News

*   You can [upvote this DZone news item about the release of Groovy 2.4](http://www.dzone.com/links/groovy_24_released_with_android_support.html)
*   A fun little [demo of Groovy in the browser with GrooScript](http://grooscript.org/demo/stars.html)
*   Alcatel-Lucent's [PaaS solution leverages Groovy as its orchestration language](http://ecosystem.cloud-band.com/wp-content/uploads/2013/09/CloudBand-cPaas-Technical-Overview-1.6.pdf)
*   Andy Clement announces [Groovy Eclipse snapshots for Eclipse 4.4 have moved to Groovy 2.4](https://twitter.com/andy_clement/status/559061751736455169)
*   [Graxxia, a mathematics library for Groovy](https://github.com/ssadedin/graxxia), wrapping commons-math, OpenCSV, GroovyCSV
*   Jacob Aae Mikkelsen [Grails Diary](http://grydeske.net/news/show/80)

## Books

*   Dierk König is announcing that [Groovy in Action eventually goes to production](https://twitter.com/mittie/status/559841646654029824)!

## Code snippets

*   In [24 lines of Groovy code to develop a JAX-RS service with OpenEJB](https://gist.github.com/rmannibucau/e14324cdfc278ad388f1)

## Tweets

*   A Twitter [poll considers Google, Red Hat, Netflix and Gradleware as best sponsors](https://twitter.com/alvaro_sanchez/status/559635311329026048) for the Groovy and Grails projects
*   Gradleware initiated a [twitter hashtag on "why Gradle"](https://twitter.com/hashtag/WhyGradle?src=hash), to which many contributed. Why do you use Gradle?
*   Dierk remarks that [Groovy 2.4 is as a compelling Android alternative to Java](https://twitter.com/mittie/status/558011051313491969)
*   Sergey Tselovalnikof noticed a [funny little banner in Groovy's build](https://twitter.com/SerCeMan/status/557960043380109312)!
*   [Groovy 2.4.0](https://twitter.com/gvmtool/status/557941663319203841) available through GVM
*   [Gradle 2.3-rc-1](https://twitter.com/gvmtool/status/560101012623880192) available through GVM
*   Peter Ledbrook is looking forward to seeing the impact of Gradle's new configuration model
*   Cédric Champeau remarks that [positive comments outnumber FUD by an order of magniture](https://twitter.com/cedricchampeau/status/557822571543273473)
*   Cédric Champeau announces the [changes in versions in the Github branches](https://twitter.com/CedricChampeau/status/558197359197560832) following up the release of Groovy 2.4
*   [Performance improvements against Groovy 2.4](https://twitter.com/mittie/status/558252300775731200) when Dierk König is running the self testing listings of Groovy in Action
*   Iván López thinks [Google should sponsor the Groovy and Grails projects](https://twitter.com/ilopmar/status/558274612287778816), especially now that Groovy 2.4 supports the Android platform
*   Florent Biville thinks [since Groovy supports Android, Google should hire the Groovy and Grails teams](https://twitter.com/fbiville/status/558977065710800896)
*   GradleWare offers two [free O'Reilly e-books on Gradle](https://twitter.com/tomaslin/status/558806680599670784)
*   Erik Pragt shares a glimpse into the [new Asciidoctor-based Geb documentation](https://twitter.com/epragt/status/558983812655640576)
*   The [Groovy Light Table client is not dead](http://rundis.github.io/blog/2015/gr_lt_status_jan2015.html) says Magnus Rundberget
*   Marco Vermeulen is making progress on the [GVM security access for vendors](https://twitter.com/marc0der/status/559130196855771136)
*   Antonio Goncalves tweets that a Maven [pom.xml with the GMaven plugin and hundreds lines of Groovy code is probably by someone who wanted to use Gradle](https://twitter.com/agoncal/status/560001785654685696) but couldn't
    
## Events

*   The [Greach organizers have received lots of great talk proposals](https://twitter.com/greachconf/status/559035001225101313)
*   [SpringOne2GX 2015 has been announced](https://twitter.com/springone2gx/status/559903903756861440), with 4 Groovy and Grails tracks, in Washington DC on Sept 14th-17th
# Groovy 2.4 released


The Groovy team is happy to announce the release of Groovy 2.4.0!  

The big highlight of this release is the Android support, which allows developers to write Android applications fully using Groovy, with much less boilerplate code than raw Java.  

The team also focused on various improvements in terms of performance, smaller bytecode generation, or memory consumption.  

Other interesting aspects worth noticing in this release are:

*   traits can use the `@SelfType` annotation with static type checking enabled to restrict to what classes traits can be applied
*   GDK methods improvements
*   some refinements to existing AST transformations
*   further Groovysh improvements as well.

Please have a look at the [full release notes for Groovy 2.4](http://docs.codehaus.org/display/GROOVY/Groovy+2.4+release+notes) to know more about the new features and all the interesting tickets closed.  

You can have a look at the [2.4 changelog](http://beta.groovy-lang.org/changelog-2.4.0.html) on the new Groovy website too.  

And then, just go [grab this release](http://beta.groovy-lang.org/download.html) while it's hot!  

Thanks a lot to all those who contributed to this release, whether through bug reports, but also with documentation or code contributions through pull requests. All your help is warmly welcome!  

Your support of Groovy and its ecosystem is what makes Groovy so strong, and what will allow it to continue making us all more productive for the next decade!  

Keep on groovy'ing!
# Groovy Weekly #54


This week’s edition of Groovy Weekly is a bit peculiar, as the big news of the week is [Pivotal’s announcement that it will stop funding the Groovy and Grails](http://blog.pivotal.io/pivotal/news-2/groovy-2-4-and-grails-3-0-to-be-last-major-releases-under-pivotal-sponsorship) projects.

As a result those popular Open Source projects are now seeking a new home!

You can read [Guillaume Laforge’s]({{< ref "/posts/2015/01/19/the-groovy-project-is-looking-for-a-new-home" >}}) and [Graeme Rocher’s](http://grails.io/post/108534902333/the-future-of-groovy-grails-sponsorship) announcements to hear a bit more about the story. And if your company is interested in further funding the projects, please don’t hesitate to [get in touch](mailto:sponsorship@groovy-lang.org)!

## Releases

*   [Gradle Groovy Android plugin 0.3.5](https://twitter.com/cedricchampeau/status/555014971814576129) updated with new coordinates
*   The axion-release-plugin hits 1.0, a ["release" plugin for Gradle](http://allegrotech.io/axion-release-plugin.html)
*   [Groovy-Macro-Methods 0.3.0](https://twitter.com/bsideup/status/556820732576272385) with huge optimizations
*   [Groovy Grails Tool Suite 3.6.3 SR1](https://twitter.com/springcentral/status/557245887051603969) released fixing a security vulnerability
*   [Grain 0.6.3](https://twitter.com/grainframework/status/557452579819360257) released with updated Asciidoctor

## Articles

*   [Pivotal announces the end of the funding of the Groovy and Grails](http://blog.pivotal.io/pivotal/news-2/groovy-2-4-and-grails-3-0-to-be-last-major-releases-under-pivotal-sponsorship) projects
*   [Guillaume Laforge’s announcement]({{< ref "/posts/2015/01/19/the-groovy-project-is-looking-for-a-new-home" >}}) about Pivotal’s end of sponsorship of the Groovy and Grails projects
*   [Graeme Rocher’s announcement](http://grails.io/post/108534902333/the-future-of-groovy-grails-sponsorship) regarding the end of the funding of the Groovy and Grails projects by Pivotal
*   [Pivotal's FAQ on the end of sponsorship](https://docs.google.com/a/pivotal.io/document/d/1R_bQv_8JSLOEzVzPdqOISF0guGtcUPE6vFBeAuxtcG4/edit) of the Groovy and Grails projects
*   Cédric Champeau wrote a guest blog post on TeamCity's blog about [how Groovy uses TeamCity](http://blog.jetbrains.com/teamcity/2015/01/how-groovy-uses-teamcity/)
*   [Cédric Champeau of Groovy fame would love to continue to work on Groovy full time, but he's soon gonna be for hire otherwise](http://melix.github.io/blog/2015/01/for-hire.html), catch him if you get a chance!
*   Ken Kousen’s lovely post on [why Groovy and Grails community matters](https://kousenit.wordpress.com/2015/01/19/groovygrails-pivotal-opportunity/), opportunities ahead!
*   Peter Ledbrook details [why you should use Gradle](http://blog.cacoethes.co.uk/software/why-gradle)
*   [Groovy listed in the top 20 of RedMonk's programming language rankings](http://redmonk.com/sogrady/2015/01/14/language-rankings-1-15/) of January 2015
*   [Reset your H2 database for a clean state between functional tests](http://www.objectpartners.com/2015/01/13/reset-your-h2-database-for-a-clean-state-between-functional-tests/) with the help of Spock and Groovy traits
*   A lively imaginary [discussion on interfaces, abstract classes, multiple inheritance](http://blog.cleancoder.com/uncle-bob/2015/01/08/InterfaceConsideredHarmful.html) by Uncle Bob, which may make you think Groovy traits might be the answer
*   The [ins and outs of Gradle](http://code.tutsplus.com/tutorials/the-ins-and-outs-of-gradle--cms-22978), by Jessica Thornsby, from an Android perspective
*   Voxxed published a master-post to [guide Java developers choosing a new JVM language](https://www.voxxed.com/blog/2015/01/thinking-about-picking-up-a-new-jvm-language-a-masterpost-to-guide-java-devs/), including Groovy in the list
*   [Publishing Gradle Android library to JCenter repository](https://www.virag.si/2015/01/publishing-gradle-android-library-to-jcenter/) by Jernej Virag
*   Anton Arhipov thinks what’s happening could be a [new beginning for Groovy and Grails](http://arhipov.blogspot.fr/2015/01/g.html)

## Interviews

*   Victor Grazi [interviewed Guillaume Laforge on Pivotal's decision](http://www.infoq.com/news/2015/01/Pivotal-Pulls-Groovy-Grails-Fund) with regards to Groovy and Grails
*   Guillaume Laforge interviewed by Voxxed on the “[sad and odd decision by Pivotal to set Groovy adrift](https://www.voxxed.com/blog/2015/01/sad-odd-decision-pivotal-set-groovy-adrift/)”

## Presentations

*   InfoQ SpringOne2GX coverage:
    *   [Rethinking API design with traits](http://www.infoq.com/presentations/groovy-2-3-api-design), by Cédric Champeau
    *   [Testing Java, Groovy, Spring and web applications with Spock](http://www.infoq.com/presentations/groovy-test-java-spock), by Peter Niederwieser
    *   [Scalable Big Data stream processing with Storm and Groovy](http://www.infoq.com/presentations/bigdata-storm-groovy), by Eugene Dvorkin
*   SpringOne2GX 2014 replay from the Spring.IO blog
    *   [How to get Groovy with Java 8](https://spring.io/blog/2015/01/09/springone2gx-2014-replay-how-to-get-groovy-with-java-8) by Peter Ledbrook
    *   [Android and Groovy, a winning pair?](https://spring.io/blog/2015/01/08/springone2gx-2014-replay-android-and-groovy-a-winning-pair) by Cédric Champeau
    *   [Experiences using Grails in a microservice architecture](https://spring.io/blog/2015/01/08/springone2gx-2014-replay-experiences-using-grails-in-a-microservice-architecture) by Jeff Beck
    *   Dan Woods [introduction to Ratpack](http://fr.slideshare.net/danveloper/ratpack-web-framework-from-oreilly-webcast-20150113) in this O'Reilly webcast
*   Slides of the Grails Centro meetup on the [Grails API toolkit](https://www.slideshare.net/fullscreen/bobdobbes/silicon-valley-grails/1) by Owen Rubel

## News

*   All the [Grails release notes are now available on Github](https://github.com/grails/grails-core/releases)
*   [Pedal-Loader is a Groovy DSL for data loading](http://www.eclecticlogic.com/pedal-loader/) and an attractive substitute to db-unit
*   A work-in-progress of the [future Grails static web site](http://grails.github.io/grails-static-website/), forked from Groovy's new website
*   The [GrooScript's documentation](http://grooscript.org/doc.html) is almost finished, any feedback?
*   Jacob Aae Mikkelsen’s [Grails Diary](http://grydeske.net/news/show/79)

## Code snippets

*   A [single page interface with Groovy traits, templates, builders and GrooScript](https://gist.github.com/chiquitinxx/6ef000456732aa9bd7fb)

## Tweets

*   Stephan Janssen, founder of Devoxx predicts that [2015 will be the year Red Hat hires the Groovy and Grails teams](https://twitter.com/Stephan007/status/557459062221455364) and embraces their communities
*   Latest [Gradle Groovy Android plugin available on Bintray and the Gradle plugin portal](https://twitter.com/cedricchampeau/status/555015335313932289)
*   Guillaume Laforge's [duck typing joke in the age of quantum computing](https://twitter.com/glaforge/status/556027163494084608)
*   Rohit Kelapure answers yes to the question of [pushing Ratpack apps on Cloud Foundry out of the box](https://twitter.com/rkela/status/555079299074916353)
*   [GrooScript is aiming a 1.0 release](https://twitter.com/grooscript/status/556466614259154944) by the end of January
*   Arnaud Héritier is supporting Groovy saying "[Je Suis Groovy](https://twitter.com/aheritier/status/557138343914655744)", in echo to recent tragic terrorists attacks in France
*   Jeff Brown reminds us that the [main focus for the Groovy and Grails teams are to secure the technologies' future](https://twitter.com/jeffscottbrown/status/557196649916022784)
*   Burt Beckwith suggesting [being fast to get a chance to snap the talented Groovy and Grails teams](https://twitter.com/burtbeckwith/status/557220977437081600)!
*   Andy Wilkinson reminds us [some developers believe that software costs nothing to produce](https://twitter.com/ankinson/status/557457888160280576)
*   Dean Iverson notes that the [Pivotal's divesting doesn't make Groovy any less useful](https://twitter.com/deanriverson/status/557302834815700992)

## Events

*   Jochen Theodorou will be the Groovy keynote speaker of Greach 2015
*   [Salenda is a new gold sponsor of the Greach](https://twitter.com/greachconf/status/556021832747192321) conference
*   [Burt Beckwith will be speaking at the Greach](https://twitter.com/greachconf/status/556031871260192768) conference
*   GR8Ladies founder [Jane Stratter will be speaking at Greach](https://twitter.com/greachconf/status/554964855027818497)
*   Still [curious about the GR8Conf conference](https://twitter.com/gr8conf/status/556244984177766400)? Check the videos!
# The Groovy project is looking for a new home


Pivotal just announced it’s decision [to stop sponsoring and funding the development of the popular Groovy and Grails Open Source projects](http://blog.pivotal.io/pivotal/news-2/groovy-2-4-and-grails-3-0-to-be-last-major-releases-under-pivotal-sponsorship). As a result, both Groovy and Grails are looking for new sponsors willing to further help develop the projects full steam!

The [Groovy programming language](http://groovy-lang.org) has been around for a while for more than 11 years. During that time, it has nicely evolved from a side hobby project to the very mature and successful alternative language it is today, used by Fortune 500 companies throughout the world, in various projects and contexts.

With 1.7 million downloads in 2012, 3 million in 2013, and well over 4 million in 2014 (definitive numbers still need to be calculated), Groovy is leading the pack of the JVM language ecosystem, and continues seeing positive growth.

There are many ideas the Groovy team wants to develop further, features we want to bring to life, improvements we want to make, to keep Groovy always ahead of the curve, to help you developers be productive on the JVM platform. For that, we’ve been thankful for having had a handful of us able to work full time on the project, and we’re looking forward continuing to do so under a new umbrella.

The Groovy community has always been a key driver for the language, providing feedback, bug reports, contributions big and small, and we hope that you will help us find a solution to make Groovy shine as bright as ever.

Of course, we’re going to continue to develop Groovy, open it to new horizons like we did for the Android platform, implement new features, fix bugs, increase performance, complete the new documentation, launch the new website, and more. Your contributions will obviously be more than welcome to sustain the project’s pace. We’re looking forward to working with you all to push Groovy forward!

If your company is interested in discussing funding of the project, and employing members of the Groovy team, please don’t hesitate to contact us directly ([sponsorship@groovy-lang.org](mailto:sponsorship@groovy-lang.org)). Thanks in advance for your help, and keep on groovy’ing!


*Update:* [Graeme's blog post](http://grails.io/post/108534902333/the-future-of-groovy-grails-sponsorship) about the announcement
# Groovy Weekly #53


The Groovy development team released the second release candidate of Groovy 2.4, please be sure to check your applications with this version and report any issue you may be finding, so that we can all ensure 2.4 is a rock-solid release.

Note the publication of MrHaki’s [Gradle Goodness Notebook](http://mrhaki.blogspot.fr/2015/01/gradle-goodness-notebook-is-published.html)! If you’re using Gradle, this is worth the investment to have that resource handy for mastering your build automation.

## Releases

*   [Groovy 2.4 second release candidate](http://groovy.329449.n5.nabble.com/ANN-Second-release-candidate-for-Groovy-2-4-td5722110.html), please help testing it!
*   [Spring Boot 1.2.1](https://spring.io/blog/2015/01/08/spring-boot-1-2-1-released) released
*   The [Windows installer for Groovy 2.3.9](http://beta.groovy-lang.org/download.html) is available
*   [Grooscript Gradle plugin 0.9](https://twitter.com/grooscript/status/553626428772995072) released
*   Groovy Android library [SwissKnife 1.2](https://github.com/Arasthel/SwissKnife/blob/master/CHANGELOG.md) released with @Parcelable transformation

## Articles

*   Jochen "Blackdrag" Theodorou behind the scenes of [bytecode optimizations for improving array access performance](http://blackdragsview.blogspot.fr/2015/01/indy-and-compilestatic-as-tag-team-to.html)
*   Doug Borg describes what [makes a good build.gradle](http://dougborg.org/what-makes-a-good-build-dot-gradle)
*   Reinout Korbee writes about [running your Antlr DSL as a Groovy script](http://java.dzone.com/articles/run-your-antlr-dsl-groovy)
*   [Some Groovy magic](http://arzur.net/octopress/blog/2015/01/07/groovy-magic/) by Erwan Arzur
*   [Preventing naming collisions in Grails](http://blog.jdriven.com/2015/01/grails-preventing-naming-collisions/) by Albert van Veen
*   Bertrand Goetzman shows how to display data coming from [REST with DataFX / JavaFX and Ratpack](http://www.odelia-technologies.com/content/afficher-des-donnees-provenant-dune-source-de-donnees-rest-dans-une-application-javafx-avec) (article in French)
*   Robert McIntosh on [Grails with a billion record Mongo collection](http://robertmcintosh.me/blog/2015/grails_with_billion_record_mongo_collection.html)
*   Peter Ledbrook on [Groovy in the light of Java 8](http://blog.cacoethes.co.uk/groovyandgrails/groovy-in-light-of-java-8)
*   [Feedback from GrailsConf in India](http://www.intelligrape.com/blog/the-biggest-grails-conference-in-india-grailsconf-2015/) by Amit Jain

## Presentations

*   Dan Woods will be speaking about [Ratpack online during an O'Reilly webinar](https://twitter.com/ratpackweb/status/552796932049883137)
*   [Groovy in 2014 and beyond](http://www.infoq.com/presentations/groovy-2-3) by Guillaume Laforge at SpringOne2GX 2014
*   [Making Spring Boot even groovier](http://www.infoq.com/presentations/groovy-grails-spring-boot) by Graeme Rocher at SpringOne2GX 2014
*   Slides form "[Demystifying Gradle DSL](https://speakerdeck.com/kdabir/demystifying-gradle-dsl)" presented at GrailsConf 2015, New Delhi

## Interviews

*   Guillaume Laforge interviewed at Devoxx 2014 about what makes [Groovy the Swift of the Android world](https://www.voxxed.com/blog/2015/01/groovy-swift-android-world/)

## Books

*   MrHaki publishes the [Gradle Goodness Notebook](http://mrhaki.blogspot.fr/2015/01/gradle-goodness-notebook-is-published.html)
*   Marco Vermeulen enjoys the [terrific section on writing nested Gradle plugin extension DSLs](https://twitter.com/marc0der/status/554254484013330432) in Tim Berglund's [Gradle beyond the basics](http://shop.oreilly.com/product/0636920019923.do) book

## News

*   Jacob Aae Mikkelsen [Grails Diary](http://grydeske.net/news/show/78)
*   Testatoo, a web [user interface testing tool with a Groovy DSL](https://github.com/Ovea/testatoo/blob/2.0.b3/src/doc/testatoo.adoc)

## Mailing-list

*   A debate about [JVM application installers with Gradle](http://groovy.329449.n5.nabble.com/JVM-application-installer-via-maven-gradle-repo-td5722094.html) and more
    
## Code snippets

*   Iván Lopez participates in the Spring Boot book contest with a [full Groovy solution](http://lmivan.github.io/contest/#_technological_stack)! Star the project to make it win!
*   Dan Woods shares some [examples of standalone Ratpack](https://twitter.com/danveloper/status/554008783077134336) 0.9.13

## Tweets

*   Guillaume Laforge celebrated the [1000th star on Github for Groovy](https://twitter.com/glaforge/status/552492079386198020), keep on spreading the word and double that number!
*   [Groovy Weekly released its 2000th news item](https://twitter.com/glaforge/status/552492370768723968) last week!
*   [Ratpack is teasing that the next release](https://twitter.com/ratpackweb/status/552796345749082112) is going to be a big "one"
*   [Groovy 2.4.0-rc-2](https://twitter.com/gvmtool/status/552825902514847744) available through GVM
*   Cédric Champeau asks the twittosphere what they'd like to [see him speak about at GR8Conf](https://twitter.com/cedricchampeau/status/553107314182717440)
*   Andrew Reitz managed to get [Spock tests running on Android](https://twitter.com/andrewreitz_/status/553301907322576896)
*   Vishal Savajiani claims [Groovy is a powerful language](https://twitter.com/vishalgreat/status/553296725025120258)! For the Internet of Things, for the Cloud, and more.
*   The Groovy Android library [SwissKnife is ready for Groovy 2.4](https://twitter.com/eugenekamenev/status/554716837720915969), reports Eugene Kamenev
*   Mike Milinkovich is excited to see [Gradleware bringing first-class Gradle support to Eclipse](https://twitter.com/mmilinkov/status/553556027913031680)
*   Iván López demonstrates you can be a [full stack developer using only Groovy](https://twitter.com/ilopmar/status/554219468843270144) with a concrete example
*   [Spring Boot is ready for Groovy 2.4](https://twitter.com/ankinson/status/554609893395927040) announces Andy Wilkinson
*   Dan Woods compares the [performance of Ratpack with Vert.x](https://twitter.com/danveloper/status/554576240833986560)

## Events

*   [Groovy at DevNexus](http://devnexus.com/s/presentations?tags=groovy), with an epic keynote with the Groovy puzzlers and a Groovy workshop, by the JFrog team
*   The [Greach Call for Paper is closing in 10 days](https://twitter.com/greachconf/status/553125994114994176), get ready!
*   [Last week for the GR8Conf Call for Paper](https://twitter.com/gr8conf/status/552507512323600386), hurry up!
*   Cédric Champeau will speak about [Groovy at Niort for the Poitou-Charentes JUG](https://twitter.com/poitoujug/status/552767245357944832) on January 20th
*   Greach announces its first accepted speakers: [Russel Winder](https://twitter.com/greachconf/status/554937171027574784)
*   Only [2 days left for the early bird tickets for Greach](https://twitter.com/greachconf/status/554952362042097665)
*   [Dan Woods will be speaking at Greach](https://twitter.com/greachconf/status/554582324973539332) about Ratpack
*   Another speaker announced for [Greach with MrHaki](https://twitter.com/greachconf/status/554597468977901569)
*   [GR8Conf US announces multiple tracks for the workshop day](https://twitter.com/GR8ConfUS/status/552672571754569728)
# Groovy Weekly #52


First of all, let me wish you a very Groovy year! May 2015 fulfill all its promises, keep you healthy, bring joy and hapiness around! And of course, may it be filled with tons of bits of Groovy code!

Following up my plea for [more stars on Github](https://github.com/groovy/groovy-core), we went from below 600 stars to beyond 1000! But we don’t need to stop there, so let’s keep starring and spreading the word!

Another thousand milestone reached with the 2000th news item delivered in Groovy Weekly this week!

Remember that you can [subscribe](http://bit.ly/groovy-weekly-subscribe) to this Groovy Weekly series to get those news directly in your inbox, and that you can also [contribute news](http://bit.ly/groovyweekly) yourself by filling a form if there’s something you want to tell the world!

## Releases

*   [Grooscript 1.0-rc-1](https://twitter.com/grooscript/status/552051531399577600), be sure to test it before the final release!
*   [Ratpack 0.9.12](http://www.ratpack.io/versions/0.9.12) released
    
## Articles

*   All in Together: [Android Studio, Gradle and Robolectric](http://www.bignerdranch.com/blog/all-in-together-android-studio-gradle-and-robolectric/) by Jason Atwood
*   [Grails + Angular + PhantomJS = PDF Reports](http://groovymn.tumblr.com/post/106798263197/grails-angular-phantomjs-pdf-reports)
*   [Grails Demo PDF app](http://groovymn.tumblr.com/post/107130385197/grails-demo-pdf-app)
*   Second part on [Grails unique constraint optimization](http://www.intelligrape.com/blog/grails-unique-constraint-optimization-part-2/) by Deepak Kumar Mittal

## Presentations

*   [Groovy for system administrators](http://www.infoq.com/presentations/Groovy-ea-ops), by Dan Woods, recorded at SpringOne2GX 2014

## News

*   GPars 1.3 will feature a new Asciidoctor-based [GPars user guide](http://gpars.org/SNAPSHOT/aguide/html5/index.html)
*   Jacob Aae Mikkelsen's [Grails Diary](http://grydeske.net/news/show/77) week 51
*   This [month in GUM](http://groovymn.tumblr.com/post/106705639062/this-month-in-gum)
    
## Mailing-list

*   Interesting dicussion on using [Groovy for data science, as a killer application for Groovy](http://groovy.329449.n5.nabble.com/Groovy-for-data-science-a-killer-application-for-Groovy-td5722061.html)
    
## Code snippets

*   Cédric Champeau is musing with ideas of how to [improve Groovy command-line interactions](https://gist.github.com/melix/e27dce2c23467d47e7f4#file-cli-friendly-groovy-L10)
    
## Tweets

*   You can contribute to Grooscript by going through the [Grooscript documentation](https://twitter.com/grooscript/status/552052096183590912)
*   Andrew Reitz finds using [unit testing Android more bearable with Groovy](https://twitter.com/andrewreitz_/status/552147730550644737)
*   The Groovy team builds [Groovy on Continuous Integration with JDK 9 Jigsaw](https://twitter.com/CedricChampeau/status/550982802272178178) too
*   Russell Hart explains how to [make authenticated user details available to Ratpack view model](https://twitter.com/rus_hart/status/551019292805070849)
*   Guillaume Laforge got a [groovy electric guitar](https://twitter.com/glaforge/status/552159421292630016) for Christmas... or was it for his daughter?

## Events

*   [10 languages in 10 minutes (including Groovy)](https://plus.google.com/u/0/events/ceh2qfaalqv3vgnhq8tjoihjnic) at the Coder Consortium in Sacramento on February 5th
*   [GR8Conf Europe is looking for sponsors](https://twitter.com/tbsalling/status/551979427924807680)
# Groovy Weekly #51


Here’s the end of a pretty Groovy year coming, giving room for an even groovier one!

I hope you all enjoyed the holidays, and that you’re ready to pour in some more drops of Groovy into your software mixes!

Don’t forget to continue [starring the Groovy project on Github](https://github.com/groovy/groovy-core), if you haven’t done so, so we try to reach 1000 in the new year!

What are going to be your new year’s resolutions? Perhaps some contributions to Groovy’s documentation, some bug fixes or new features?

In the meantime, happy reading, here are a few news bits for your consumption!

And let me wish you a very Groovy year!

## Articles

*   [Metrics + Grails = Awesomeness](http://arzur.net/octopress/blog/2014/12/28/metrics-plus-grails-equals-awesomeness/) by Erwan Arzur
*   Experiments (in French) with [Grails and transactions](http://arzur.net/octopress/blog/2014/12/28/amusons-nous-avec-les-transactions-et-grails-dot-dot-dot/) by Erwan Arzur
*   A [Groovy 101](http://moduslaborandi.net/groovy-101-groovycalc-with-tests-and-travis-ci-integration/) article also explaining how to use Groovy integration with Travis-CI
*   [Spring Boot with the Gradle Asset Pipeline](http://davydotcom.com/blog/2014-12-21-spring-boot-with-the-asset-pipeline) by David Estes
*   The [Grails stats command gives useful insight](http://www.intelligrape.com/blog/grails-stats/) in the structure of your Grails projects
*   Abhinav Anand covers [Groovy's tokenize() and split() methods](http://www.oodlestechnologies.com/blogs/tokenize%28%29-and-split%28%29-in-groovy)
*   [Nesting custom tags in Grails](http://www.oodlestechnologies.com/blogs/Nesting-custom-tags-in-grails) by Abhinav Anand

## News

*   [Groovy Weekly in Italian](http://www.bmeweb.it/category/groovy-weekly/)
*   GR8Conf US launched its [new website](http://gr8conf.us/#/)
*   Jacob Aae Mikkelsen's [Grails Diary](http://grydeske.net/news/show/76) week 52

## Code snippets

*   [Type classes in Groovy](https://github.com/uehaj/groovyz)
*   Paul King shares an example of a simple [fluent English-like DSL using Groovy command chains](http://groovyconsole.appspot.com/script/5646392177459200/)

## Tweets

*   Cédric Champeau is trying to solve a long standing feature request about [enforcing 'final'](https://twitter.com/CedricChampeau/status/548477288627847168)
*   Cédric Champeau coins a catchy movie title: [Groovy Wars ep1: The Phantom MetaClass](https://twitter.com/cedricchampeau/status/549629946889777152)
*   A [tribute to Groovy](https://twitter.com/agoncal/status/548805556992241664) by the Mike Flowers Pops celebrated by Antonio Goncalves
*   Craig Burke is looking forward to release his [document builder](https://twitter.com/craigburke1/status/548546842892713984) by the end of this year
*   Dierk König highlights [Groovy's ability to take on the challenge to support many programming language concepts](https://twitter.com/mittie/status/548508666358669312)
*   Dean Del Ponte notices that [Grails 3 apps can be run like any Gradle app within IntelliJ IDEA Community edition](https://twitter.com/ddelponte/status/547841332224339969)
*   [AsciidoctorJ is now available on GVM](https://twitter.com/gvmtool/status/549330992197304320)
*   Dierk König is [leveraging Groovy categories for an elegant integration with Frege](https://twitter.com/mittie/status/549587163151872000)'s data structures
*   [What makes the Groovy community shine](https://twitter.com/marc0der/status/549619315683889153), according to Marco Vermeulen? Its people are kind and helpful.
*   Marco Vermeulen wishes the [Gradle task API had dependency injection to ease testing](https://twitter.com/marc0der/status/549613033031729152)
*   Marco Vermeulen is finding [Groovy productive for authoring Gradle plugins](https://twitter.com/marc0der/status/549539981069656064)
    
## Events

*   Venkat Subramaniam to demonstrate how to [apply Groovy closures for fun and productivity](https://twitter.com/GrailsConf/status/548396817033879552) at GraisConf India
*   Cédric Champeau is going to [speak about why using Groovy at the Poitou JUG](https://twitter.com/cedricchampeau/status/549478535216496640)
*   Cédric Champeau will be speaking about [Groovy on Android at the MCE 2015](https://twitter.com/CedricChampeau/status/549871190245126144) conference for mobile developers
*   The [Greach conference launched its Lanyrd](https://twitter.com/greachconf/status/549507636719128579) page
# First release candidate of Groovy 2.4


Hot on the heels of our 2.3.9 update, the Groovy team is happy to release the first release candidate of Groovy 2.4 as another Xmas present!  

This release candidate is our upcoming new major version of Groovy, including:

*   official support for the Android development platform: you can now develop full Android applications in Groovy, dramatically reducing boilerplate code while keeping performance and memory consumption at the same level as Java apps
*   performance optimizations: lots of improvements have been implemented in both statically compiled Groovy code and dynamic code. (example report of an illustrative [micro-benchmark](https://gist.github.com/melix/ea819c77c4b568660877))
*   optimized memory use: reworked some compiler internals to reduce memory consumption
*   traits refinements: like the ability to tell that a trait can only be applied to a specific type hierarchy
*   and as usual, lots of bugfixes

We’re planning on releasing the final Groovy 2.4 version in January, once we’re happy with the stability and feedback from the community.  

You can read the [Groovy 2.4-rc-1 release notes](https://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=20785) to learn more about the tickets closed, and head over to the [download](http://beta.groovy-lang.org/download.html) section of the beta Groovy website to get the latest and latest bits on your computer! The documentation for this version can be found [here](http://docs.groovy-lang.org/2.4.0-rc-1/html/documentation/).

We need your help to test drive this release candidate! We would greatly appreciate if you check this version against your projects and report back any regression or blocker that you come across.  

Thanks a lot for all your contributions and support!  

Keep on groovy-ing, and groovy holidays!
# Groovy Weekly #50


Lots among us are celebrating Christmas this week, and Groovy Weekly is happy to wish you all a Merry Christmas! And there’s also an anniversary, as it’s been one year that Groovy Weekly was launched, with the first edition on December 24th (hence my excuse to publish this column on Wednesday 24th instead of on Tuesday as usual)!

For Christmas, the Groovy team decided to release a [first release candidate for Groovy 2.4]({{< ref "/posts/2014/12/24/first-release-candidate-of-groovy-2-4" >}}), as well as a Groovy 2.3.9 update.

Did you see this little guerrilla marketing campaign by Guillaume Laforge to encourage you all to make Groovy trendy by [starring Groovy on Github](https://twitter.com/glaforge/status/545504762456969216)?

Thanks for helping us spread the word!

And last news item of the week, [Groovy Weekly is being translated in Italian](http://www.bmeweb.it/settimanale-groovy-2014-49/)!

## Releases

*   [Groovy 2.4-rc-1]({{< ref "/posts/2014/12/24/first-release-candidate-of-groovy-2-4" >}}) released!
*   [Groovy 2.3.9](http://groovy.329449.n5.nabble.com/ANN-Groovy-2-3-9-td5721985.html) released
*   [gServ](https://github.com/javaConductor/gserv/wiki/gServ-Home), a new micro-service inspired, container-less tool to deploy Groovy REST services
*   [Lazybones Gradle plugin v1.2.3](https://twitter.com/pledbrook/status/545178973651894272)
*   [Groovy VFS 1.0 Beta 2](http://groovy.329449.n5.nabble.com/ANN-Groovy-VFS-1-0-Beta-2-td5721979.html)
*   [Groovy-Stream v0.9](https://twitter.com/tim_yates/status/547510301634338816) with new repeat methods

## Articles

*   [Grails domain classes and special presentation requirements](https://www.voxxed.com/blog/2014/12/grails-domain-classes-special-presentation-requirements/) by Ted Vinke
*   A [lightweight release process to Maven Central with Gradle](http://mnmlst-dvlpr.blogspot.de/2014/12/my-lightweight-release-process.html), TravisCI, Bintray
*   An [introduction to Spock](http://blog.soat.fr/2014/12/spock-tester-autrement/) in French
*   MrHaki's Gradle Goodness: [rename Ant task names when importing Ant build files](http://mrhaki.blogspot.fr/2014/12/gradle-goodness-rename-ant-task-names.html)
*   Iván López' [impressions of the Groovy Grails eXchange conference](http://www.kaleidos.net/blog/759/ggx-my-talk-and-general-impressions/)
*   [Groovy annotations for logging](http://www.intelligrape.com/blog/groovy-annotations-for-logging/) by Neetesh Bhardwaj
*   [Grails performance optimization with the unique constraint](http://www.intelligrape.com/blog/grails-performance-optimization-unique-constraint/) by Deepak Kumar Mittal

## Presentations

*   [Groovy in the light of Java 8](https://parleys.com/play/5471dd16e4b0e15e672384e7/chapter0/about) by Guillaume Laforge at Devoxx 2014 (Parleys subscription required)

## Screencasts

*   A [Gradle for Android webcast](http://www.oreilly.com/pub/e/3286) by Ken Kousen on O'Reilly

## News

*   Julien Viet announces a [preview of Vert.x 3](https://groups.google.com/forum/#!msg/vertx/Pr8QejfMIj0/YGQ_QRQyK2cJ) (Groovy language support included)
*   The [Groovy Weekly now in Italian](http://www.bmeweb.it/settimanale-groovy-2014-49/), thanks to Giuliano Lo Iacono!
*   [Grails Diary week 51](http://grydeske.net/news/show/75) by Jacob Aae Mikkelsen
    
## Code snippets

*   The new repeat method in Groovy-stream helps generate the [fizz-buzz sequence without the need of conditionals](https://twitter.com/tim_yates/status/547517168708222976)

## Tweets

*   [Star the Groovy project on Github](https://twitter.com/glaforge/status/545504762456969216) asks Guillaume Laforge!
*   Jeff Brown calls for [help to test drive the Groovy 2.4 release candidate](https://twitter.com/jeffscottbrown/status/547516371412975617)!
*   Jörg Prante finds Groovy so much fun that he [embeds Ratpack in an ElasticSearch plugin](https://twitter.com/xbib/status/546425480657010690)
*   New documentation on [how to use Jackson in Ratpack](https://twitter.com/ratpackweb/status/541908183212490752)
*   The Grain static site generator releases a [company website theme with a blog](https://twitter.com/grainframework/status/545167185669545984) included
*   Chris Earle reminds us that [ElasticSearch's Groovy client](https://twitter.com/pickypg/status/545664315026845698) has been updated with full compatibility for ElasticSearch 1.4.2
*   Eugene Kamenev enjoys the [greater Groovy support in Android Studio](https://twitter.com/eugenekamenev/status/545657795404525568)
*   Greg Williams believes [Groovy will become the Swift for Android](https://twitter.com/greg2020/status/545611812087943168)
*   Peter Ledbrook added [documentation on the config command of Lazybones](https://twitter.com/pledbrook/status/545881211047268352)
*   [Lazybones 0.8](https://twitter.com/gvmtool/status/545978461509394432) available on GVM
*   [Groovy 2.3.9](https://twitter.com/gvmtool/status/545960385237778432) available on GVM
*   Iván López is having [fun with Groovy on Android](https://twitter.com/ilopmar/status/545238870485639169)
*   [GrooScript added Continous Integration](https://twitter.com/grooscript/status/546274756484673536) thanks to SnapCI
*   Cédric Champeau found a comic strip with a [hand G sign for top geekery](https://twitter.com/CedricChampeau/status/547513924157853697)... and with a Groovy t-shirt!
*   The [JFrog Bintray team's been helping the Groovy team with deployment and release issues](https://twitter.com/CedricChampeau/status/547503135011643394), thanks guys!
*   [Groovy 2.4-rc-1](https://twitter.com/gvmtool/status/547502562791161860) available on GVM
*   [JITWatch now has Groovy support](https://twitter.com/chriswhocodes/status/547403796754993153?cn=ZmF2b3JpdGVfbWVudGlvbmVkX3VzZXI%3D&refsrc=email) announced Chris Newland

## Events

*   The [Greach call for papers has been extended to January 18th](https://twitter.com/greachconf/status/546968408009371649)
# Groovy Weekly #49


This has been a super busy week, in particular with the 7th edition of the Groovy Grails eXchange conference in London. You’ll find lots of slides and videos already published online, so you won’t miss a beat! For instance don’t miss this talk from Shuichisan how [Groovy is used by Japan’s Rakuten mobile backend as a service platform at scale](https://www.skillsmatter.com/skillscasts/6107-developing-api-platform-in-groovy-at-ratuken)!

A special highlight in the articles section to Cédric’s article on [10 things your static language can’t do](http://melix.github.io/blog/2014/12/10-things-static-cant-do.html).

## Releases

*   A new version of the [Grooid template for Groovy on Android development](https://twitter.com/marioggar/status/544814985776734208)
*   [Spring Boot 1.2](https://spring.io/blog/2014/12/11/spring-boot-1-2-0-released) released
    
## Articles

*   Cédric Champeau lists [10 things your static language can't do](http://melix.github.io/blog/2014/12/10-things-static-cant-do.html)
*   [Using Groovy extension modules with the Gradle Shadow plugin](http://matthurne.com/blog/2014/using-groovy-extension-modules-with-gradle-shadow.html) by Matt Hurne
*   [Copying multiple directories in a single Gradle task with up-to-date checking](http://www.objectpartners.com/2014/12/11/copying-multiple-directories-in-a-single-gradle-task-with-up-to-date-checking/) by Craig Atkinson
    
## Groovy Grails eXchange Interviews

*   [Graeme Rocher interviewed about Grails](http://blog.skillsmatter.com/2014/12/15/while-its-compiling-skills-matter-interviews-graeme-rocher/)
*   [Guillaume Laforge interviewed about Groovy](http://blog.skillsmatter.com/2014/12/12/while-its-compiling-skills-matter-interviews-guillaume-laforge/)

## Presentations

*   Paul King discusses the [good parts of Groovy](http://fr.slideshare.net/paulk_asert/awesome-groovy) at YOW! 2014
*   All the [presentations of the Groovy Grails eXchange 2014](https://www.skillsmatter.com/conferences/1957-groovy-grails-exchange-2014#skillscasts) conference are being put online on the conference website (you need to be logged-in to view the videos)
*   Day one
    *   Guillaume Laforge's [Groovy update keynote](https://skillsmatter.com/skillscasts/6047-what-s-up-in-the-groovy-world)
    *   Vladimír Oraný presented ["Feed you Grails karma"](https://www.skillsmatter.com/skillscasts/6075-feed-your-grails-karma)
    *   Peter Ledbrook presented [“Groovy for Java developers”](https://www.skillsmatter.com/skillscasts/5485-groovy-for-java-developers)
    *   Shuichi Suzuki spoke about "[Developing API Platform in Groovy at Ratuken](https://www.skillsmatter.com/skillscasts/6107-developing-api-platform-in-groovy-at-ratuken)"
    *   Alvaro Sanchez-Mariscal on "[Stateless authentication for microservices](https://www.skillsmatter.com/skillscasts/6058-stateless-authentication-for-microservices)"
    *   Russel Winder on "[Spocktacular testing](https://www.skillsmatter.com/skillscasts/6081-spocktacular-testing)"
    *   Jeff Brown on "[Groovy AST Transformations And Type Checking Extensions](https://www.skillsmatter.com/skillscasts/6062-groovy-ast-transformations-and-type-checking-extensions)"
    *   Schalk Cronjé on “[Groovy VFS](https://www.skillsmatter.com/skillscasts/6049-groovy-vfs)”
    *   Guillaume Laforge on "[Behind the scenes of the new Groovy website and documentation](https://www.skillsmatter.com/skillscasts/6072-behind-the-scenes-the-new-groovy-website)"
    *   Markus Schlichting on "[Gradle: harder, better, stronger, faster](https://www.skillsmatter.com/skillscasts/6084-gradle-harder-better-stronger-faster)"
*   Day two
    *   Graeme Rocher's [Grails 3](https://www.skillsmatter.com/skillscasts/4958-keynote-grails-three-point-zero-preview) keynote
    *   Guillaume Laforge on “[Groovy on Android](https://skillsmatter.com/skillscasts/6073-groovy-and-android-a-winning-pair)” presentation
    *   Iván López on “[Grails and the real-time world](https://skillsmatter.com/skillscasts/6074-grails-and-the-real-time-world#video)”
    *   Marcin Erdmann on “[Running an Open Source project](https://skillsmatter.com/skillscasts/6064-running-an-open-source-project)”
    *   Jeff Brown on “[Restful Grails 2](https://www.skillsmatter.com/skillscasts/6063-restful-grails-2)”
    *   Marco Vermeulen on "[Micro Service Architecture with Spring Boot and Groovy](https://www.skillsmatter.com/skillscasts/6050-micro-service-architecture-with-spring-boot-and-groovy)"
    *   David Dawson on “[Forces on Groovy architecture](https://www.skillsmatter.com/skillscasts/6044-forces-on-groovy-architecture)”
    *   Guillaume Laforge on “[Groovy with Style](https://www.skillsmatter.com/skillscasts/4957-groovy-with-style)”
*   Slides from the Groovy Grails eXchange 2014 conference:
    *   Guillaume Laforge published his slides from the “[Groovy update](https://speakerdeck.com/glaforge/groovy-in-2014-and-beyond-groovy-grails-exchange-2014)” talk
    *   Guillaume Laforge published the slides of the "[Behind the Groovy website and documentation](https://speakerdeck.com/glaforge/behind-the-scenes-of-the-new-groovy-website-and-documentation)" presentation
    *   Guillaume Laforge's “[Groovy on Android](https://speakerdeck.com/glaforge/groovy-on-android-groovy-grails-exchange-2014)” slides
    *   Guillaume Laforge’s “[Groovy with style](https://speakerdeck.com/glaforge/groovy-with-style-groovy-grails-exchange-2014)” presentation
    *   Russel Winder published the slides of his ["Spocktacular testing"](https://twitter.com/russel_winder/status/543038550631915520) talk
    *   Vladimír Oraný published the slides of his "[Feed your Grails karma](http://fr.slideshare.net/vladimirorany/feed-your-grails-karma-ggx-2014)" talk
    *   Slides of "[Micro-service architecture with Spring Boot and Groovy](http://marcovermeulen.github.io/spring-boot-groovy-talk/#/)" by Marco Vermeulen

## News

*   The [new GR8Conf Europe website](http://gr8conf.eu/#/) is launched!
*   You can [vote for solving this regression on the support of IntelliJ IDEA for standard Groovy extension methods](https://youtrack.jetbrains.com/issue/IDEA-130198)
*   Jacob Aae Mikkelsen’s [Grails Diary](http://grydeske.net/news/show/74) week 50
*   This [month in the Groovy Users of Minnesota](http://groovymn.tumblr.com/post/104760987832/this-month-in-gum)

## Mailing-lists

*   An ongoing mailing-list thread is wondering [what is the unique selling point of Groovy](http://groovy.329449.n5.nabble.com/The-single-USP-for-Groovy-td5721782.html). What's yours?
*   Another ongoing thread on the Groovy lists is a discussion on [what is Groovy's value proposition compared with Java 8](http://groovy.329449.n5.nabble.com/Groovy-Value-Proposition-Compared-with-Java-8-td5721855.html). What's your take on that?
*   Alain Stalder shares a [case story with Groovy and his Grengine Groovy-powered scripting solution](http://groovy.329449.n5.nabble.com/quot-Grey-quot-Sets-of-Groovy-Scripts-A-Case-Story-with-Groovy-and-Grengine-td5721936.html)

## Code snippets

*   An example of a [Beaker data scientist notebook using Groovy](http://sharing.beakernotebook.com/gist/anonymous/3fcbb2e8c0d67079d313)
*   Vladimír Oraný pushed online his [demo application of his "Feed Your Grails Karma"](https://github.com/musketyr/earls-list) Groovy Grails eXchange talk
    
## Tweets

*   Cédric Champeau thinks [Groovy's uniqueness is its runtime and compile-time capabilities](https://twitter.com/cedricchampeau/status/542996207854190593)
*   Craig Burke is making progress on his [Groovy document builder DSL](https://twitter.com/craigburke1/status/543064329533521921)
*   Luis Arias congratulates [Guillaume Laforge for his 11+ years on the Groovy](https://twitter.com/realkaaloo/status/543332004050530305) project! How time flies…
*   Mario García published a [Lazybones template for getting started with Groovy on Android development](https://twitter.com/marioggar/status/543358372477960192)
*   During Graeme Rocher's keynote at Groovy Grails eXchange, Marcin Erdmann notes that [Grails 3 will use Geb for functional tests by default](https://twitter.com/marcinerdmann/status/543343346081890304)
*   Schalk Cronjé draws the [main points of Guillaume Laforge's Groovy update](https://twitter.com/ysb33r/status/542988039606521856) presentation
*   [Spring Boot 1.1.10](https://twitter.com/gvmtool/status/542985840545529856) available on GVM
*   [Spring Boot 1.2](https://twitter.com/gvmtool/status/542971505278459904) available on GVM
*   Russel Winder notes [Groovy Macros will be re-scheduled to Groovy 2.5](https://twitter.com/russel_winder/status/542984966058311680) to gather further feedback and real use-cases
*   Danny Hyun did a quick photoshop montage of [Guillaume Laforge as the Fresh Prince of Bel-Air](https://twitter.com/lspacewalker/status/542340712134868992), as Guillaume's transliteration name in English would be Will Smith!
*   Tomas Lin also reinterprets the [Fresh Prince of Bel Air family as the Groovy family](https://twitter.com/tomaslin/status/542348040552448000)
*   Sean Gilligan shows off a [screenshot of Groovy running on iOS](https://twitter.com/msgilligan/status/542606254405713920)
*   A nice list of useful and [interesting Gradle plugins to investigate](https://twitter.com/macg33zr/status/543046348153847808) and play with
*   Brian Johnsen believes the [Groovy core team have taken executable documentation to a new level](https://twitter.com/brianjohnsendk/status/543061487741595649)
*   Angel Ruiz believes [Groovy's executable documentation is how tech documentation should be done](https://twitter.com/aruizca/status/543188269605732352) these days
*   In [Ratpack 0.9.12, a type can implement Renderable](https://twitter.com/ratpackweb/status/543187563947651072) to make it renderable
*   Robert Fletcher notes that [Groovy method closures can be coerced to Guava functions](https://twitter.com/rfletcherEW/status/543108794150944768), or actually any functional interface where Java 8 lambdas would be expected
*   Russel Winder remarks that [Grails 3 will be able to both be a serious full stack web application framework and a lightweight microframework](https://twitter.com/russel_winder/status/543347767096410113)
*   Phil Webb counted 194 people who [voted for a Gradle "provided" scope](https://twitter.com/phillip_webb/status/543271226542522368)
*   "[The Java used on Android is out of the stone age](https://twitter.com/russel_winder/status/543356824947556353)", said Guillaume Laforge during his Groovy on Android talk, and Russel Winder thinks it's worse than that!
*   Russel Winder believes [Android needs Java 8, or developers can just use Groovy, and that's what the New York Times decided to do](https://twitter.com/russel_winder/status/543357338816888832) for its Android application
*   Another great feature of [Grails 3 is that it's coming integrated with tools that projects usually need: Gradle, Spock, Geb](https://twitter.com/mgdelacroix/status/543344032475533312)
*   Mario García is working on a new [Lazybone template for authoring AST transformations for Groovy on Android](https://twitter.com/marioggar/status/543394656726556672)
*   A [picture of the Grails team and the Groovy lead](https://twitter.com/lhotari/status/543488286229286912) at Groovy Grails eXchange 2014

## Events

*   [Venkat Subramaniam will be speaking at GrailsConf India](https://twitter.com/naresha_k/status/542982488658677760) on pleasure and perils of dynamic ecosystem
*   Read about the [sessions of GrailsConf India](http://grailsconf.in/sessions)
*   The [GR8Ladies have created a Meetup page](http://www.meetup.com/Gr8Ladies/) to get the latest news, upcoming event announcements, etc
*   You can watch the [pictures of Groovy Grails eXchange](https://skillsmatter.com/conferences/1957-groovy-grails-exchange-2014#photos) online
*   [GR8Conf US 2015](https://twitter.com/gr8confus/status/544522716897083392) will take place July 29th-31st
# Groovy Weekly #48


Almost a year since I started the Groovy Weekly newsletter. And perhaps for the first anniversary, in a handful of weeks, we’ll have reached 2000 news items shared with you all in this column!

This week is a London-ian one, as lots of the Groovy ecosystem inhabitants are migrating to the UK to celebrate the Groovy Grails eXchange conference. I’m looking forward to seeing some of you this week there. It also means that next week, you’ll likely see many links to slides and videos of the conference.

And congrats to the Griffon team for a nice Griffon 2.1 release!

## Releases

*   [Griffon 2.1.0](http://groovy.329449.n5.nabble.com/ANN-Griffon-2-1-0-released-td5721850.html) released
*   [GrooScript 0.6.3](https://twitter.com/grooscript/status/540115721611927552) released, equivalent of the first release candidate for 1.0
*   Spring Tool Suite and [Groovy/Grails Tool Suite 3.6.3](https://spring.io/blog/2014/12/02/spring-tool-suite-and-groovy-grails-tool-suite-3-6-3-released) released
*   New versions of Craig Burke's [Grails and Angular.JS Gradle asset pipeline plugins](https://twitter.com/craigburke1/status/539876227382005760)
*   Groovy-based [Jenkins Workflow plugin reaches 1.0](http://jenkins-ci.org/content/workflow-plugin-10)
*   [GrooScript Gradle plugin v0.8](https://twitter.com/grooscript/status/540597302704865280) is out
*   [Asciidoctor Gradle plugin v1.5.2](https://twitter.com/gradleplugins/status/541981425181155329) released
*   [Groovy VFS 1.0 beta 1](http://groovy.329449.n5.nabble.com/ANN-Groovy-VFS-1-0-Beta-1-td5721839.html) released
*   The [Groovy Windows installer for Groovy 2.3.8](http://groovy.329449.n5.nabble.com/Windows-Installer-for-Groovy-2-3-8-td5721841.html) is available
*   [Gretty 1.1.8](https://twitter.com/andreyhihlovski/status/542045672623861760) released
    
## Articles

*   The [Groovy style guide](http://beta.groovy-lang.org/style-guide.html) document migrates to the new documentation and website
*   Kyle Boon mixes [Ratpack, Docker and Gradle](http://kyleboon.org/blog/2014/08/14/ratpack-plus-docker-plus-gradle/)
*   Four steps to a [Docker-based build environment with CodeEnvye, showcasing Grails](http://blog.codenvy.com/cooking-custom-build-environments/)
*   MrHaki's Gradle Goodness: [skip building project dependencies](http://mrhaki.blogspot.fr/2014/12/gradle-goodness-skip-building-project.html)
*   Jochen Theodorou gives a deeper look at [interface default methods conflicts and proxies](http://blackdragsview.blogspot.de/2014/12/a-deeper-look-at-default-methods.html)
*   MrHaki's Gradle Goodness: [continue build even with failed tasks](http://mrhaki.blogspot.fr/2014/12/gradle-goodness-continue-build-even.html)
*   [Setting up SonarQube for Grails projects](http://hussain.io/2014/12/setting-up-sonarqube-for-grails-project/) by Hussain Fakhruddin
*   Parampreet Singh on [Groovy's @WithReadLock and @WithWriteLock transformations](http://www.intelligrape.com/blog/groovy-goodness-readwritelocks/)
*   [Restricting concurrent sessions for a single user using Grails and Spring Security](http://www.intelligrape.com/blog/restricting-concurrent-sessions-for-a-single-user-using-grails-and-spring-security/)
*   More about the [Asset-Pipeline Gradle plugin v2.0](http://davydotcom.com/blog/2014-12-03-asset-pipeline-2-0) by David Estes
*   [Case-insensitive criteria ordering on child properties](http://www.objectpartners.com/2014/12/03/case-insensitive-criteria-ordering-on-child-properties/) by Igor Shults
*   [Effective Grails plugin development with in-place plugins](http://www.groovy-code.com/2014/12/effective-grails-plugin-development.html)

## Presentations

*   Guillaume Laforge presented about [What makes Groovy groovy at the Virtual JUG](https://twitter.com/virtualjug/status/539848790732472320)
*   SpringOne2GX 2014 presentations on InfoQ
    *   [Groovy on Android, a winning pair](http://www.infoq.com/presentations/android-groovy-jvm), by Cédric Champeau
    *   [Experiences using Grails in a microservice architecture](http://www.infoq.com/presentations/grails-microservices-arch), by Jeff Beck
    *   [How to get Groovy with Java 8](http://www.infoq.com/presentations/groovy-java8-streams-api), by Peter Ledbrook
*   Craig Atkinson delivered a GR8Ladies [workshop about TDD with Groovy and Spock](https://twitter.com/craigatk1/status/542041878276096000)

## News

*   [Android Studio 1.0](http://android-developers.blogspot.fr/2014/12/android-studio-10.html) out with its Gradle built-in support for building Android applications
*   Hans Dockter delivers the [November Gradleware newsletter](http://www.gradleware.com/newsletter/gradleware-newsletter-november-2014/)
*   Jacob Aae Mikkelsen's [Grails Diary](http://grydeske.net/news/show/73) week 49
    
## Screencasts

*   Bertrand Goetzmann released a screencast showing how to [build a beautiful timeline with Linked Data, Spring Boot, Groovy, GroovySparql, and TimelineJS](https://www.youtube.com/watch?v=yktftRpoeg4&feature=youtu.be&a)

## Code snippets

*   Following up a [conversation](https://twitter.com/cedricchampeau/status/539802492000026624) on Twitter with Peter Ledbrook, Guillaume Laforge shares a gist showing [Groovy's List and Map coercion to types on assignments](https://gist.github.com/glaforge/1f481e0f0d043260aa9a)

## Tweets

*   The GrooScript project encourages you to [try out GrooScript, to make a solid 1.0 release](https://twitter.com/grooscript/status/540169463271018496)
*   Cédric Champeau shares the results of the Fibonacci [micro-benchmark comparing various dynamic languages](https://gist.github.com/melix/ea819c77c4b568660877)
*   Cédric Champeau and Jochen Theodorou continue looking into [optimizations for Groovy](https://twitter.com/cedricchampeau/status/540117338784530433)
*   The Warsaw Groovy user groups has some [cool Groovy stickers](https://twitter.com/szimano/status/540070403268673536)!
*   The [GrooScript project celebrates a first pull request](https://twitter.com/grooscript/status/539898692237795328)!
*   You can [try online the GrooScript conversions of Groovy into JavaScript](https://twitter.com/grooscript/status/540492118721298433)
*   New [documentation on using Ratpack with the Jackson](https://twitter.com/ratpackweb/status/541908183212490752) library
*   Dan Allen believes [Groovy succeeds in making us happy and efficient programmers](https://twitter.com/mojavelinux/status/541554762575929344)
*   Sean Gilligan made [Groovy hello world work natively on Mac OS X](https://twitter.com/msgilligan/status/539295258962436097) from Cédric Champeau's experiments with RoboVM

## Jobs

*   BloomHealth is [hiring Groovy + Angular.JS + Docker fans](https://twitter.com/shoemaker/status/540187482013573120)

## Events

*   Schalk Cronjé [reminds us the Call for Papers for Greach and GR8Conf are still open](https://twitter.com/ysb33r/status/540415402246172672)
*   You can [buy your ticket for the Greach conference at an early bird price](http://groovy.329449.n5.nabble.com/Ann-Greach-You-can-buy-your-tickets-td5721819.html) till January 15th
# Groovy Weekly #47


Today I highly recommend you read about the nice [Groovy dedicated support for ElasticSearch](http://www.elasticsearch.org/blog/making-elasticsearch-groovy-er/)! We also have a few interesting dot releases this week. And there’s the scoop that there’s a Ratpack book in the works!

Don’t forget that the Call for Papers for GR8Conf Europe / US and Greach are still open, if you want to speak about your favorite Groovy technologies and experiments!

## Releases

*   [Groovy 2.4.0-beta-4]({{< ref "/posts/2014/11/26/groovy-2-4-0-beta-4" >}}) released
*   [Groovy 2.3.8]({{< ref "/posts/2014/11/28/groovy-2-3-8-released-too" >}}) released
*   [Ratpack 0.9.11](http://www.ratpack.io/versions/0.9.11) released
*   [Gradle Bintray plugin 1.0](https://twitter.com/_yoav_/status/539551753742471168) released with Maven Central sync
*   A much faster [Asset Pipeline Gradle plugin with v2.0.4](https://twitter.com/davydotcom/status/539478433445994496)
*   First public version of an [HTML sanity checker Gradle plugin](https://twitter.com/gernotstarke/status/539441261531660289)
*   [GroovySparql 0.9](https://plus.google.com/b/113675159854671799959/+AlBakerDev/posts/9tMes6wcaTX?cfem=1) released

## Articles

*   "[Making ElasticSearch Groovy-er](http://www.elasticsearch.org/blog/making-elasticsearch-groovy-er/)" with a dedicated Groovy client to interact with ElasticSearch
*   Jochen "blackdrag" Theodorou experiments with Java's processing API for a [stub-less Groovy joint compiler](http://blackdragsview.blogspot.fr/2014/11/a-joint-compiler-for-groovy-and-java.html)
*   MrHaki's Grails goodness: [create new application without wrapper](http://mrhaki.blogspot.fr/2014/11/grails-goodness-create-new-application.html)
*   [Testing JVM server-side JavaScript with Jasmine, Spock and Nashorn](http://eshepelyuk.github.io/2014/11/26/-testing-jvm-javascript-jasmine-spock-nashorn.html), by Evgeny Shepelyuk
*   Series of articles on [getting started with Gradle](http://www.petrikainulainen.net/getting-started-with-gradle/)
*   In this interview, JetBrains developer Maxim Medvedev mentions that [Groovy and Apple Swift are similar in terms of IDE support](http://blog.jetbrains.com/objc/2014/11/cooking-swift-an-interview-with-maxim-medvedev/), as both languages have type inference, closures, and higher order functions
*   On [recursive observables with RxJava, and showing how Groovy can cut verbosity](https://jkschneider.github.io/blog/2014/recursive-observables-with-rxjava.html) down

## Presentations

*   [Android development with Groovy](https://twitter.com/madridgug/status/537944334008872960), by Mario García, at CodeMotion Spain 2014

## News

*   [Grails Diary week 48](http://grydeske.net/news/show/72) by Jacob Aae Mikkelsen

## Code snippets

*   Cédric Champeau created a [Docker container with GVM and Groovy](https://gist.github.com/melix/e4b63fd684e63713c162) installed
*   A new [GrooScript demo with snap.svg](http://grooscript.org/demo/snapsvg.html)
*   Using [Firebase from your web pages with Groovy with GrooScript](https://gist.github.com/chiquitinxx/5192ff81d3b3351e3f1d)
    
## Tweets

*   Cédric Champeau teases for his Groovy Grails eXchange talk where he'll explain how [Groovy leverages Gradle, Asciidoctor, TeamCity for the new website](https://twitter.com/cedricchampeau/status/538261967488974848)
*   [Groovy 2.4 beta-4](https://twitter.com/gvmtool/status/537882370066874369) available through GVM
*   The [GVM announcement of the availability of Groovy 2.4 beta-4 was done from Groovy's CI server](https://twitter.com/cedricchampeau/status/537883662633959424) through GVM's API
*   [Gradle 2.2.1](https://twitter.com/gvmtool/status/537874472888705024) available on GVM
*   Bertrand Goetzman spotted a [Yeoman generator for Angular.JS + Ratpack](https://twitter.com/bgoetzmann/status/537363461832196097) applications
*   Tomas Lin suggests a [Ratatouille inspired book cover for Dan Woods' upcoming Ratpack book](https://twitter.com/tomaslin/status/537436124189175809)
*   Eugene Kamenev is showing a screenshot of an [Android Wear application written in Groovy](https://twitter.com/eugenekamenev/status/537664752621989889)
*   Roberto Guerra is having fun with [Ratpack and Gulp.JS](https://twitter.com/robertoguerra19/status/538048345529663489)
*   [Groovy 2.3.8](https://twitter.com/gvmtool/status/538269325959106561) has been released on GVM
*   Dierk König is looking forward to using Tim Yates' [groovy-stream library](https://twitter.com/mittie/status/539056498073407488) more
*   Jacob Aae Mikkelsen will be [teaching web development with Groovy and Grails at the University of Southern Denmark](https://twitter.com/JacobAae/status/538115269034774528)
*   Rob Fletcher points at [Gdub a tool that transparently uses gradle or gradlew when available](https://twitter.com/rfletcherEW/status/538283579978317825)
*   The Grain framework now features some [stylish bootstrap based templates](https://twitter.com/grainframework/status/539409491197173760)

## Book

*   Dan Woods will write a [book on Ratpack](https://twitter.com/danveloper/status/537277382571610112) for O'Reilly

## Events

*   [Autentia becomes gold sponsor for the Greach](https://twitter.com/greachconf/status/537548869429522433) conference
*   [Pronoid becomes gold sponsor of Greach](https://twitter.com/greachconf/status/538273658494406656)
*   Remember that the [Call for Paper of the Greach conference is still open](https://twitter.com/greachconf/status/538271091085418496)!
*   You can [buy tickets for the Greach](https://twitter.com/greachconf/status/539356504244367360) conference now!
*   The [GR8Conf Europe and GR8Conf US Call for Paper](https://twitter.com/gr8conf/status/539577626185052160) is still open
# Groovy 2.3.8 released too


Hot on the heels of our [new beta for 2.4]({{< ref "/posts/2014/11/26/groovy-2-4-0-beta-4" >}}), here's a bug fix release with Groovy 2.3.8.  

You can have a look at the [JIRA release](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=20648) and you can [download Groovy 2.3.8](http://beta.groovy-lang.org/download.html) right away!  

Thanks all for your contributions!  

Keep on groovy'ing!
# Groovy 2.4.0-beta-4


This is with great pleasure that we are announcing the release of Groovy 2.4.0-beta-4.

The highlights for this release are:

*   a rewritten JsonBuilder for improved performance in JSON generation
*   a [`@SelfType`](http://docs.groovy-lang.org/2.4.0-beta-4/html/documentation/core-traits.html#_self_types) annotation for traits
*   a new [variant of `GStringTemplateEngine`](http://docs.groovy-lang.org/2.4.0-beta-4/html/gapi/groovy/text/StreamingTemplateEngine.html) capable of handling strings larger than 64k
*   improved support for overloaded setters
*   lots of bugfixes (some of which are backported in the upcoming 2.3.8 release)
*   a new naming convention for closures

The last point is important if your project somehow relies on the name of the closure classes as it is a potential breaking change. The reason for the new scheme is detailed [here](https://jira.codehaus.org/browse/GROOVY-5351).

You can download Groovy in our download area:
[http://beta.groovy-lang.org/download.html](http://beta.groovy-lang.org/download.html)


You can consult the JIRA change log:
[http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=20612](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=20612)

Thanks for your feedback and contributions!

Note that we are likely to change the scope of the 2.4 to exclude macros. There’s still a lot of work and discussion to be done on that topic, making it incompatible with our target for a 2.4 release. This feature is likely to be delayed to Groovy 2.5.
# Groovy Weekly #46


My favorite read of the week is definitely Ken Kousen’s tale about Groovy’s [Plain Old Groovy Object](http://www.accelebrate.com/blog/call-pogo-name/)! Note the releases of the new Groovy Eclipse support and the Eclipse Maven batch compiler. Last but not least, for those of you heading to the [Groovy & Grails eXchange conference in London](https://skillsmatter.com/conferences/1957-groovy-grails-exchange-2014), notice the [program](https://skillsmatter.com/conferences/1957-groovy-grails-exchange-2014#program) of the conference unfolding before your eyes!

Let me also mention the [Beaker notebook project](http://beakernotebook.com/index), which offers Groovy support for data scientists who want to explore their data sets. And the [Spoon.net](https://twitter.com/virtualkenji/status/535280638580887553) team which features Groovy support for its Windows containers.

Final word, don’t miss Graeme’s tweets pointing at the Grails 3 scaffolding plugin and code generation APIs!

## Releases

*   [Groovy Eclipse 2.9.1](https://github.com/groovy/groovy-eclipse/wiki/Groovy-Eclipse-2.9.1-Release-Notes) released
*   [Groovy Eclipse Maven Batch comiler 2.3.7](http://groovy.329449.n5.nabble.com/Groovy-Eclipse-Maven-Batch-comiler-2-3-7-release-candidate-available-for-testing-td5721719.html) release candidate available for testing
*   [Gradle 2.2.1](http://forums.gradle.org/gradle/topics/gradle-2-2-1-released) released

## Articles

*   An awesome tale about POGOs by Ken Kousen: "[That Which We Call A POGO, By Any Other Name](http://www.accelebrate.com/blog/call-pogo-name/)"
*   [How to use Groovy traits](http://www.oodlestechnologies.com/blogs/How-to-use-Groovy-Traits) by Rohan Jain
*   [Tracking down not expected transitive dependencies in multi-project Gradle build](https://solidsoft.wordpress.com/2014/11/19/gradle-tricks-tracking-down-not-expected-transitive-dependencies/) by Marcin Zajączkowski
*   Craig Burke publishes the second part on [advanced customization of the Angular.JS Grails template](http://www.craigburke.com/2014/11/24/angular-grails-template-2.html)
*   MrHaki's Gradle goodness: [Using and working with Gradle version](http://mrhaki.blogspot.fr/2014/11/gradle-goodness-using-and-working-with.html)
*   MrHaki's Gradle goodness: [Using CopySpeck with Tasks](http://mrhaki.blogspot.fr/2014/11/gradle-goodness-using-copyspec-with.html)
*   How to use [custom tags in Grails controllers and services](http://www.oodlestechnologies.com/blogs/How-to-use-custom-tags-in-grails-controller%2C-services-groovy-file) by Ankush Kocher
*   How to [render JSON properly inside a GSP script tag](http://aruizca.com/how-to-render-json-properly-without-escaping-quotes-inside-a-gsp-script-tag/) by Angel Ruiz
*   [Object based security using Spring Security ACL in Grails](http://www.intelligrape.com/blog/2014/11/19/object-based-security-using-spring-security-acl-in-grails/) by Anil Agrawal
*   Ames Lorenzen shares an [example using Grails promises](http://java.dzone.com/articles/example-using-grails-promises)

## Presentations

*   Cédric Champeau presented in French a quick [introduction to Groovy and its powers](https://speakerdeck.com/melix/human-talks-nayez-pas-peur-de-faire-du-groovy), and the slides are quite self-explanatory even if you don't speak French!
*   A quick [intro and comparison between Groovy and Apple Swift](http://fr.slideshare.net/Ciklum_Kyiv/groovy-on-android) in the context of mobile development with Android, by Olexandr Leuschenko
*   [Scalable Big Data stream processing with Apache Storm and Groovy](https://twitter.com/alsargent/status/536019492204068864) by Eugene Dvorkin, at SpringOne2GX 2014

## Screencasts

*   Dan Woods is preparing a [webcast about Ratpack](http://www.oreilly.com/pub/e/3275) for O'Reilly

## News

*   Jacob Aae Mikkelsen's [Grails Diary](http://grydeske.net/news/show/71) week 47
*   The [data scientist's laboratory, Beaker, offers support for Groovy](http://beakernotebook.com/index) for working with large and complex datasets

## Tweets

*   Guillaume Laforge mentions on twitter a [telescope project using Groovy](https://twitter.com/glaforge/status/535518780185903104)
*   Graeme Rocher worked on the [first cut of the new Grails 3 scaffolding plugin](https://twitter.com/graemerocher/status/537184433489866753) with the new code generation APIs
*   Graeme Rocher shows [how to implement a codegen script for Grails 3](https://twitter.com/graemerocher/status/537185286456115200)
*   Craig Burke is working on a [Word and PDF Groovy builder](https://twitter.com/craigburke1/status/535452259363356673)
*   Luke Daley launches a rumor about [Dan Woods working on a Ratpack book](https://twitter.com/ldaley/status/535499624682119170) for O'Reilly
*   Rob Fletcher [appreciates Groovy even more when forced to write Java](https://twitter.com/rfletcherew/status/535426936974368768) code
*   Andrés Almiray releases v0.1 of the [Clirr Gradle plugin for checking binary compatibility between different API versions](https://twitter.com/gradleplugins/status/536270638898774017)
*   Dan Woods tells anyone [excited by the idea of a Java REPL that there's already one available, Groovy's one!](https://twitter.com/danveloper/status/534857082965880832)
*   Peter Ledbrook says [Groovy Grails eXchange will feature a beginner track](https://twitter.com/pledbrook/status/535094362645233665) on the first day and a full day hacking session on the second
*   Jacek Laskowski notes that the [Gremlin terminal is a Groovy shell](https://twitter.com/jaceklaskowski/status/536889293307146240)
*   Etienne Studer releases a [Gradle plugin to help plugin authors with bundling and publishing of Gradle plugins](https://twitter.com/etiennestuder/status/536696709112283136)
*   [Spring Boot 1.2-rc-2](https://twitter.com/gvmtool/status/536066336850735104) is available on GVM
*   Ryan Vanderwerf is looking forward [programming in Groovy on his Xmas Android smartwatch](https://twitter.com/RyanVanderwerf/status/535911468424638464)
*   Bruno Borges announces Groo[vy support for scripted Java FX on webservers](https://twitter.com/brunoborges/status/535999133254184960)
*   Erik Pragt is working on the [IntelliJ IDEA support for Asciidoctor and shows a screenshot of the Groovy documentation](https://twitter.com/epragt/status/536091467153162240) as an example
*   Iván López spoke about [Groovy on Android to a packed room at the CodeMotion](https://twitter.com/ilopmar/status/536115353815105536) conference
*   Burt Beckwith shares a tip for those who can't use Spock: [add a static import on GroovyAssert#shouldFail to JUnit 4 tests](https://twitter.com/burtbeckwith/status/536716841737916416) to follow the same pattern as in JUnit 3
*   Spoon.net releases a [Groovy image for its Windows container engine](https://twitter.com/virtualkenji/status/535280638580887553)
*   Craig Burke says that [reading on functional programming in Java 8 makes him appreciate Groovy closures](https://twitter.com/craigburke1/status/535112280703516673) even more

## Book

*   Schalk Cronjé is looking for [feedback on smart techniques used within your Gradle plugins for contributions for a Gradle book](https://twitter.com/ysb33r/status/535574251114598400)

## Events

*   [Guillaume Laforge will be speaking at the Virtual JUG](http://www.meetup.com/virtualJUG/events/218827084/?gj=rcs.a&a=co2.a_grp&rv=rcs.a)
*   The [December GR8 Ladies meetup](https://twitter.com/Gr8Ladies/status/534886675424755712) is sponsored by BloomHealth and AgileOrbit
*   [Object Partners becomes platinum sponsor of the GR8 Ladies](https://twitter.com/gr8ladiesmsp/status/535499595175182336) December GR8 workshop
*   The [Groovy & Grails eXchange conference agenda](https://skillsmatter.com/conferences/1957-groovy-grails-exchange-2014#program) is uncovering
# Groovy Weekly #45


This week, coming back from the Devoxx conference in Belgium, I’ve gathered a bag of Groovy news for your consumption, for our usual Tuesday Groovy Weekly release!
  
No particular big highlight today, but perhaps just a happy birthday to GrooScript, the Groovy to JavaScript transpiler, and also notice the opening of the Call for Paper for the GR8Conf conferences in Europe and in the United States.

## Releases

*   [Gradle 2.2.1-rc-1](http://forums.gradle.org/gradle/topics/gradle-2-2-1-rc-1-is-now-available-for-testing) released

## Articles

*   Luke Daley explains [Ratpack's execution model in practice](http://ldaley.com/post/102495950257/ratpacks-execution-model-in-practice)
*   [Custom collections in Groovy](http://grysz.com/2014/11/14/custom-collections-in-groovy/) by Marcin Gryszko
*   MrHaki's Gradle Goodness: [Check task dependencies with a dry run](http://mrhaki.blogspot.fr/2014/11/gradle-goodness-check-task-dependencies.html)
*   Dan Tanner wrote about the [differences between Groovy's collect and spread-dot operator](http://otherthanthink.blogspot.fr/2014/11/groovy-collect-vs-spread-dot-operator.html)
*   Displaying [all dependencies for all subprojects in a multi-project Gradle build](https://solidsoft.wordpress.com/2014/11/13/gradle-tricks-display-dependencies-for-all-subprojects-in-multi-project-build/)
*   [String templates in Groovy](http://www.objectpartners.com/2014/11/11/stringtemplates-in-groovy/) by Mike Hostetler
*   Craig Burke writes the first article of a series about the [Angular.JS Grails template](http://www.craigburke.com/2014/11/17/angular-grails-template-1.html)

## Presentations

*   Devoxx special
    *   Guillaume Laforge presented "[Groovy in the light of Java 8](https://speakerdeck.com/glaforge/groovy-in-the-light-of-java-8-devoxx-2014)"
    *   Guillaume Laforge presented "[Groovy in 2014 and beyond](https://speakerdeck.com/glaforge/groovy-in-2014-and-beyond-devoxx-2014)"
    *   Cédric Champeau presented "[Groovy and Android, the winning pair](https://speakerdeck.com/melix/groovy-and-android-a-winning-pair-1)"
*   Jérôme Louvel from the Restlet and APISpark projects mentions a [PayPal API platform presentation showing Groovy being used for API composition](https://twitter.com/jlouvel/status/532699896600477696)

## Mailing-lists

*   [New versions of the Groovy Eclipse compiler](http://groovy.329449.n5.nabble.com/New-version-of-groovy-eclipse-compiler-td5721689.html) are coming along

## News

*   An update of [GroovyBlogs with infinite loading of recent and popular blog posts](https://twitter.com/groovyblogs/status/533146828275859456)
*   Andrés Almiray found this old gem in honor of Dick Wall from the Javaposse fame as the podcast comes to its end, showing [Dick loving the Groovy](http://blog.cliffano.com/2009/03/02/lovin-the-groovy/)
*   Jacob Aae Mikkelsen's [Grails Diary week 46](http://grydeske.net/news/show/70)
    
## Tweets

*   [GrooScript celebrates 2 years since the 0.1 release](https://twitter.com/grooscript/status/533687966951297026)!
*   Lari Hotari is working on [Grails 3 / Spring Boot startup time optimisations](https://twitter.com/lhotari/status/534082054527672320)
*   Patrick Double published a [Grails plugin to improve Grails / SauceLabs Geb integration](https://twitter.com/DoubleCreekNE/status/532295990586658816)
*   [GrooScript chat application deployed on Heroku](https://twitter.com/grooscript/status/532619382703521792) with Node.JS and Socket.IO
*   Ratpack features a [URL builder](https://twitter.com/ratpackweb/status/532631677411917826) utility
*   Hans Dockter showed [declarative dependency replacement with Gradle](https://twitter.com/CedricChampeau/status/532841402733178880) at Devoxx 2014
*   Hans Dockter showed how to [tell Gradle that you don't want to depend on beta dependencies](https://twitter.com/CedricChampeau/status/532842212581978112)
*   [Gradle 2.2.1-rc-1](https://twitter.com/gvmtool/status/534458011893633025) available on GVM
*   Álvaro Sánchez sparks a discussion about [Spock labels indentation](https://twitter.com/alvaro_sanchez/status/532477553576271872) on twitter

## Code snippets

*   Cédric Champeau is working on [AST tree matching](https://gist.github.com/melix/6875e12077908129f400)
*   Vladimir Orany shares a snippet showing how to [enable DSL support in IntelliJ IDEA](https://gist.github.com/musketyr/611cacb57639dcaa6b94)

## Events

*   The [Call for Paper for GR8Conf Europe and GR8Conf US is open](http://us4.campaign-archive2.com/?u=ac7af4c02d6cec67fe3198a63&id=60cfa3d0b4&e=88c97e251c)
# Groovy Weekly #44


Today is the celebration of the veteran day / remembrance day in various countries throughout the world. So I’ll start with a big thank you to our ancestors who fought for our freedom!

This week is also a busy week as a part of the Groovy core team is moving to Antwerpen in Belgium to speak about Groovy at the Devoxx conference.

My picks of the week, among the news below are: the release of Gradle 2.2, the release of ElasticSearch 1.4 which now standardizes on Groovy for its default scripting language, and the announcement of the dates of the Greach conference in Spain and its call for paper which is open.

## Releases

*   [ElasticSearch 1.4.0](http://www.elasticsearch.org/blog/elasticsearch-1-4-0-released/) released with Groovy as the default scripting language
*   [Gradle 2.2](http://forums.gradle.org/gradle/topics/gradle-2-2-released) released
*   [GORM for Cassandra](https://twitter.com/grailsframework/status/530268377080946689) released by Paras Lakhani

## Articles

*   Roberto Guerra is showing how to [test the Guava EventBus with Spock](http://blog.stumblingoncode.com/posts/2014-11-06-ratpack-guava-eventbus.html)
*   Ted Naleid on [debugging Grails forked mode](http://naleid.com/blog/2014/11/10/debugging-grails-forked-mode/)
*   Søren Berg Glasius details the [resurrection of GroovyBlogs](http://sbglasius.tumblr.com/post/101934935847/groovyblogs), sponsored by the GR8Conf Europe team
*   [Deploy a Caelyf Groovy app on Anynine's Cloud Foundry](http://blog.anynines.com/groovy/) platform
    
## Screencasts

*   A screencast of the [Gradle asset pipeline](http://bertram.d.pr/1fiob) in action

## News

*   Jacob Aae Mikkelsen’s [Grails Diary week 45](http://grydeske.net/news/show/69)

## Tweets

*   Cédric Champeau highlights the fact that both [Groovy traits and Markup template engine use custom type checking extensions](https://twitter.com/CedricChampeau/status/530032446415597569)
*   A new [Ratpack application online for beer fans](https://twitter.com/ratpackweb/status/530163157004587010)
*   [Gradle 2.2](https://twitter.com/gvmtool/status/531833062699839488) available on GVM
*   [GroovyServ is now available on Homebrew](https://twitter.com/groovyserv/status/529967998065340418)
*   [GroovyServ will also be available in the form of an RPM](https://twitter.com/groovyserv/status/531786080404516866)

## Code snippets

*   This Spring Boot class shows how to [create your own template resolver for Groovy's markup template engine](https://github.com/melix/spring-boot/blob/master/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/groovy/template/GroovyTemplateResolver.java#L40-40)

## Events

*   The [Greach conference will take place in Madrid on April 10th-11th](https://twitter.com/greachconf/status/530662229998186496), and its Call for Paper is open
*   Paul King will be speaking at Yow 2014 on the [awesome parts of Groovy](https://twitter.com/paulk_asert/status/530483395457843200)
*   [Kaleidos is gold sponsor of the Greach conference](https://twitter.com/greachconf/status/530323772092710912) (whose CfP is open)
# Groovy Weekly #43


This week, an InfoWorld article lists [Groovy among the 9 cutting-edge programming language worth learning today](http://www.infoworld.com/article/2840235/application-development/9-cutting-edge-programming-languages-worth-learning-next.html), although it reduces Groovy to a mere Java dynamic scripting language. Are you happy with the investment you made into learning Groovy a while ago?

We also have some nice releases, like the monthly Ratpack release, or the 1.0 versions of GroovyServ (for starting up your Groovy scripts at light speed), and Gaiden for making nice documentation with Markdown.

Jorge Franco keeps on writing some cool demos with GrooScript, to write your JavaScript apps in your favorite programming language. He also unveiled the new [GrooScript](http://grooscript.org/) website!

In the news section, I’ve also listed a couple refinements coming up in Groovy 2.4, with @DelegatesTo / @ClosureParams annotations alignments and the new @SelfType annotation for traits to restrict trait application.

## Releases

*   [GroovyServ 1.0](http://kobo.github.io/groovyserv/changelog.html) released
*   [Ratpack 0.9.10](http://www.ratpack.io/versions/0.9.10) released
*   [Gradle 2.2-rc-2](http://forums.gradle.org/gradle/topics/gradle-2-2-rc-2-is-now-available-for-testing?rfm=1) released fixing a couple of regressions from the previous release candidate
*   [GrooScript 0.6.2](https://twitter.com/grooscript/status/529365793642131457) released
*   [Groovy android plugin for Gradle 0.3.4](https://twitter.com/cedricchampeau/status/528184277306183681) released with support for product flavors
*   [Spock Reports Extension 1.2.1](https://github.com/renatoathaydes/spock-reports) released
*   [Gaiden 1.0](http://groovy.329449.n5.nabble.com/ANN-Gaiden-1-0-released-td5721608.html) is out, with theme, numbering, wrapper, and others
*   An updated [optimized Grails Docker container](https://registry.hub.docker.com/u/mozart/grails/)
    
## Articles

*   InfoWorld reports about [9 cutting-edge programming language worth learning now, including Groovy](http://www.infoworld.com/article/2840235/application-development/9-cutting-edge-programming-languages-worth-learning-next.html)
*   Roberto Guerra dives into [Ratpack Guice-based modularisation and dependency injection](http://blog.stumblingoncode.com/posts/2014-10-31-ratpack-guice.html)
*   Another great demo of [Grooscript writing a Node.JS chat application with Groovy and Socket.IO](http://grooscript.org/chat_example.html)
*   Julien Viet details the [Rx extension for Vert.x and shows the RxGroovy integration](https://github.com/vert-x3/ext/blob/master/ext-rx/README.md) too
*   Patrick Double shares his [experience with publishing a Grails plugin](http://www.objectpartners.com/2014/10/29/experiences-with-publishing-a-grails-plugin/)
*   Albert van Veen on [Grails' generation of asynchronous controllers](http://blog.jdriven.com/2014/10/grails-generate-async-controller/)
*   Iván López shares his tales from the GeeCON conference
    
## Presentations

*   [Groovy introduction](https://speakerdeck.com/jlstrater/groovy-at-gr8ladies-iowa-code-camp) by the GR8 Ladies at the Iowa code camp 2014

## Screencasts

*   Bertrand Goetzmann recorded a screencast on [monitoring an Apache Camel route started from a Groovy script, with the Hawtio web console](https://www.youtube.com/watch?v=wSlCWJL0Q5I&feature=youtu.be&a)
    
## News

*   A [new look for the GrooScript website](https://twitter.com/grooscript/status/527253669264502784)
*   Jacob Aae Mikkelsen [Grails Diary](http://grydeske.net/news/show/68) week 44
*   Groovy's [@DelegatesTo and @ClosureParams will be more aligned in Groovy 2.4](https://jira.codehaus.org/browse/GROOVY-6956), the latter gaining the same parameters as the former, for more closure type checking goodness
*   Groovy 2.4 adds a [@SelfType annotation to traits](https://jira.codehaus.org/browse/GROOVY-7134) allowing you to restrict to what types a trait can be applied

## Tweets

*   [Groovy works well on the new Android runtime ART](https://twitter.com/cedricchampeau/status/529191824796430336) as well tells Cédric Champeau
*   Schalk Cronjé tweets that [Groovy isn't magical, but is an elixir to better programmer health](https://twitter.com/ysb33r/status/528184841951780864)
*   Robert Fletcher updated the [Gradle Compass plugin](https://twitter.com/rfletcherew/status/527498052752265217)
*   Dan Woods [loves the new Groovy documentation](https://twitter.com/danveloper/status/527155055917412352)
*   [Gradle 2.2-rc-2](https://twitter.com/gvmtool/status/529403342095925248) available on GVM
*   [GroovyServ 1.0](https://twitter.com/gvmtool/status/529625692028538880) is available on GVM
*   Dierk König [compares GPars dataflow variables to references in pure functional languages](https://twitter.com/mittie/status/528961665292054529)

## Jobs

*   André Steingreß is looking for a [Grails developer](http://findgrailsjobs.com/job/673-software-developer-fm-java-groovy-grails-remote) in this job posting
*   Ben McGuire is [looking for Grails developers](https://twitter.com/ben_t_mcguire/status/527812020607787008) for a major project in San Diego
    
## Events

*   GrailsConf India has opened its [Call for Paper](http://grailsconf.in/call-for-paper)
*   Cédric Champeau will be speaking about [Groovy for Android at Mobile Central Europe](https://twitter.com/cedricchampeau/status/527443577388142592), Warsaw, in February
*   Iván López is speaking about the [Grails framework at jDays 2015](https://twitter.com/ilopmar/status/527832608835923968) in Gothenburg next March
*   The [next GR8 Ladies meetup will be November 17th](https://twitter.com/gr8ladiesmsp/status/529316231459778560) if you're in the Minneapolis area
# Groovy Weekly #42


Isn’t it a mythical number? The 42nd edition of Groovy Weekly! Will we get the answer to life the universe and everything?

At least, we have a nice list of releases, this week, in particular with Grails 2.4.4, Geb 0.10 and the first milestone of Reactor 2.0!

And if there’s one thing I’d like to highlight in addition, that would be MrHaki’s release of his new book, the Spock Notebook, with all those nice recipes about our preferred testing framework.

## Releases

*   [Grails 2.4.4](https://twitter.com/grailsframework/status/527119729631461376) released with bug fixes and improvements
*   [Geb 0.10](https://twitter.com/tomaslin/status/524798100041261058) released
*   [Reactor 2.0.0.M1](https://spring.io/blog/2014/10/21/reactor-2-0-0-m1-released-with-reactive-streams-integration) released
*   [Groovy Android Gradle plugin 0.3.2](https://twitter.com/cedricchampeau/status/526687506323238912) released fixing joint compilation issues
*   [JMH Gradle plugin 0.1.3](https://twitter.com/cedricchampeau/status/527031406124609536) released
*   [Gretty 1.1.5](https://groups.google.com/forum/#!topic/gradle-dev/dpQkogqx_bw) is out
    
## Articles

*   Roberto Guerra writes about [Ratpack handlers and Groovy chains](http://blog.stumblingoncode.com/posts/2014-10-20-ratpack-groovy-chain.html)

## Presentations

*   Hans Dockter on [Gradle and the road ahead](https://thenewcircle.com/s/post/1673/gradle_and_the_road_ahead_hans_dockter_video), recorded at SF Java in June 2014
*   Cédric Champeau presented [Groovy on Android](https://twitter.com/cedricchampeau/status/525608597863268353), with a sample application using Google Wear, at SoftShake 2014
*   Danny Hyun [presented Ratpack](https://twitter.com/Lspacewalker/status/524763500674310144) (slides and code included)
*   Guillaume Laforge gave his "[What makes Groovy groovy](https://www.youtube.com/watch?v=8E3TdP_KIJo)" through Google Hangout at the Barcelona JUG
*   Iván López presented "[Metaprogramming with Groovy](https://twitter.com/ilopmar/status/525549799638966273)" at GeeCON and offers links to his slides and code samples
*   More recordings of Trisha Gee's [AngularJS / HTML5 / Groovy / Java / MongoDB](http://trishagee.github.io/presentation/angularjs_html5_groovy_java_mongodb_wcpgw/) talk

## Screencasts

*   Cédric Champeau recorded this video showing a [Google Wear application built with Groovy](https://vine.co/v/Ob2Z1dZrAFt), that he demonstrated at the Soft Shake 2014 conference

## News

*   Andrés Almiray repackages the huge [Google Material Design icon as JARs that you can reuse](https://github.com/aalmiray/google-materialdesignicons) in your web / desktop / mobile projects
*   Jacob Aae Mikkelsen published the [Grails Diary week 43](http://grydeske.net/news/show/67)

## Google+

*   A new [CodinGame contest supporting Groovy](https://plus.google.com/u/0/105332504458974739532/posts/L6edmMmQ6JR?cfem=1) is happening soon

## Tweets

*   Meet [Gradle expert Peter Niederwieser in Stockholm](https://twitter.com/gradleware/status/524843728511320064)
*   Use [Grails' --non-interactive flag for easier Continuous Integration](https://twitter.com/dailygrailstip/status/524964020478939136)
*   A week into Groovy and Grails, and Yosi Pramajaya [celebrates Groovy and Grails' awesomeness](https://twitter.com/yosipramajaya/status/525469302594347008)!
*   Jorge Martín is looking into [adding some Groovy-ness to some Android APIs](https://twitter.com/arasthel92/status/525914957599088640)
*   Cédric Champeau wishes there were as many [contributions to the Groovy documentation](https://twitter.com/CedricChampeau/status/525010686951579648) as there are edits on the Groovy entry on Wikipedia
*   Dierk König remarks a [programming language popularity tanking where Groovy ranks 8th](https://twitter.com/mittie/status/526137634671034368)
*   [GPars makes concurrency on Groovy not suck](https://twitter.com/Bl_nK_/status/525081570424532992)
*   Burt Beckwith shares the link to a [tracker analyzing changes between Grails versions](https://twitter.com/burtbeckwith/status/526440858217111553)
*   [Grails 2.4.4](https://twitter.com/gvmtool/status/527126880714252288) available on GVM
*   Dierk König's been [programming in Groovy for 10 years](https://twitter.com/mittie/status/527115100654956544) and is still amazed
*   After 10 years of Groovy, Dierk König notes that [Java finally has high-order functions](https://twitter.com/mittie/status/527129202588680193)

## Code snippets

*   Cédric Champeau published the code of his [Google Wear Android application written in Groovy](https://twitter.com/cedricchampeau/status/525608882253877248)
*   Dierk König presents a [null-safe monad in Groovy](https://gist.github.com/Dierk/358a2bf24cdcd10044e8) with Java 8 function
*   Stéphane Maldini shared a snippet showing a [send & receive RabbitMQ flow with Reactor's AMQP](https://gist.github.com/smaldini/d6858b08773e028f5383) support
    
## Books

*   MrHaki published the [Spock Notebook](http://mrhaki.blogspot.fr/2014/10/spocklight-notebook-is-published.html)

## Events

*   The [Greach conference is looking for sponsors](https://twitter.com/greachconf/status/525582247387480064)! If you or your company is willing to help, don't hesitate to get in touch with the Greach crew!
# Groovy Weekly #41


Along with some valuable releases like the first release candidate of Gradle 2.2, there are interesting links on the topic of the Groovy Android story, as well as new glimpse on AST macros and AST pattern matching coming up. Worth a look!

In terms of events, the Greach conference in Spain has opened its Call for Paper, and the GR8Conf Europe crew reminds us that all the great content from the last edition is freely available on their YouTube channel.

## Releases

*   [Groovy Android Gradle plugin 0.3.1](https://twitter.com/cedricchampeau/status/524123611766878209) released
*   [Gradle 2.2.rc-1](http://forums.gradle.org/gradle/topics/gradle-2-2-rc-1-is-now-available-for-testing) is available
*   [CodeNarc 0.22](http://groovy.329449.n5.nabble.com/ANN-Announcing-CodeNarc-0-22-td5721472.html) released with new rules
*   [Groovy-macro-methods 0.2.0](https://twitter.com/bsideup/status/522682180204376065) released
    
## Articles

*   [Spaceships, Elvis, and Groovy inject](http://kousenit.wordpress.com/2014/10/14/spaceships-elvis-and-groovy-inject/) by Ken Kousen
*   An article about [@SaveInstance: a new AST transformation in SwissKnife](http://www.dexa-dev.com/groovy-saveinstance-on-swissknife/), the project that adds nice shortcuts for Android development with Groovy
*   MrHaki's Gradle Goodness: [show standard out or error output from tests](http://mrhaki.blogspot.fr/2014/10/gradle-goodness-show-standard-out-or.html)
*   MrHaki's Gradle Goodness: [changing the name of the default build file](http://mrhaki.blogspot.fr/2014/10/gradle-goodness-changing-name-of.html)
*   [Groovier Groovy DSL](http://www.eclecticlogic.com/2014/09/26/groovy-dsl-executor/) by Karthik Abram
*   [Publishing arbitrary artifacts with Gradle and Artifactory](http://devops.judes.co.il/post/100396130279/artifactory-gradle-publishing-arbitrary-artifact)

## Presentations

*   The GR8Conf crew has published all the [videos of GR8Conf Europe 2014](https://www.youtube.com/playlist?list=PLwxhnQ2Qv3xuE4JEKBpyE2AbbM_7G0EN1)
*   Russel Winder presented [Spock-tacular testing](https://speakerdeck.com/russelwinder/spocktacular-testing) at JAX London
*   Andrés Almiray and Ixchel Ruiz posted the slides of there JavaOne 2014 presentation titled [Gradle: harder, better, stronger, faster](http://fr.slideshare.net/aalmiray/javaone-gradle)
*   [Reactive services on Vert.x with Groovy](http://fr.slideshare.net/gfrison/lean-reactiveserviceswithvertx)
    
## News

*   [Grails Diary week 42](http://grydeske.net/news/show/66) by Jacob Aae Mikkelsen
*   Caelyf, the lightweight toolkit for Cloud Foundry, is moving to a [new domain](http://caelyf.net/)

## Mailing-lists

*   Cédric Champeau gives an update on the ongoing work around Groovy AST macros, with some work around [AST pattern matching](http://groovy.329449.n5.nabble.com/State-of-the-macros-td5721429.html#a5721475)

## Tweets

*   Kamil Szymański remarks that the release of [JDK 8 update 25 solves the VerifyError affecting Groovy](https://twitter.com/kszdev/status/522662104344854529)
*   Cédric Champeau shows a [Groovy demo application running on an Android smartwatch](https://twitter.com/cedricchampeau/status/523934124898521090)
*   Eugene Kamenev is working on [Grails-like domain classes for Groovy Android](https://twitter.com/eugenekamenev/status/523486523472109569) development
*   Marcin Grzejszczak did an implementation of [Consumer Driven Contracts in Groovy](https://twitter.com/MGrzejszczak/status/523420864612925441) at 4finance
*   The [Groovy Puzzlers team wants to become at JavaOne rockstar](https://twitter.com/groovypuzzlers/status/524533757857267712) by collecting good survey results

## Code snippets

*   Cédric Champeau is teasing his work around [AST macros and AST tree matching](https://twitter.com/cedricchampeau/status/523116956275064833)
*   Cédric Champeau shows another example of [AST tree matching](https://gist.github.com/melix/c02227081dd60f5cedaa)
*   Guillaume Laforge shows a quick example of using the newly released CoffeeScript javax.script engine to [execute some CoffeeScript code from Groovy](https://gist.github.com/glaforge/f7ddece9d4e0ff2afe82)
*   Another [demo of GrooScript with the sigma.js](https://twitter.com/grooscript/status/523856523492335617) API
    
## Events

*   The [Call for Paper of the Greach](https://twitter.com/greachconf/status/524122916871368705) conference is open
*   Guillaume Laforge will speak at the [Barcelona JUG about What makes Groovy groovy](https://twitter.com/BarcelonaJUG/status/523919077036015617) next Thursday
# Groovy Weekly #40


No big highlight this week, but still plenty to learn from!

We have some minor releases, interesting articles on Spock, on how to leverage traits with Geb, some thoughts on reactive programming, new demos and tutorials for GrooScript.

And we can wish a happy birthday to the GR8 Ladies!

## Releases

*   Spring Tool Suite & [Groovy Grails Tool Suite 3.6.2](http://docs.spring.io/sts/nan/v362/NewAndNoteworthy.html) released
*   [GrooScript 0.6.1](https://twitter.com/grooscript/status/521314194319507458) released
*   [GridGain 0.6.2](https://twitter.com/grainframework/status/520515098289651712) with better support of themes that use plain CSS and better handling of large files
*   [Spring Boot 1.1.8](https://spring.io/blog/2014/10/11/spring-boot-1-1-8-released) released
*   [Spring Boot 1.2.0.M2](https://spring.io/blog/2014/10/11/spring-boot-1-2-0-m2-available-now) released
*   [Gretty 1.1.4](https://github.com/akhikhl/gretty/blob/master/changes.md) released
*   Alain Stalder released an [extensive manual for his Grengine](http://groovy.329449.n5.nabble.com/ANN-Grengine-User-Manual-td5721453.html), his alternative approach to integrating Groovy in your applications

## Articles

*   MrHaki's Spocklight: [indicate class under test with @Subject annotation](http://mrhaki.blogspot.fr/2014/10/spocklight-indicate-class-under-test.html)
*   MrHaki's Groovy Goodness: [Closure as a Class](http://mrhaki.blogspot.fr/2014/10/groovy-goodness-closure-as-class.html)
*   Kyle Boon is leveraging [Groovy traits with Geb](http://kyleboon.org/blog/2014/10/11/traitsandgeb/)
*   Luke Daley explains [executional flexibility through reactive programming](http://ldaley.com/post/99527932537/executional-flexibility-through-reactive-programming)
*   A follow-up post from Andrés Almiray on the [new desktop application framework JSR](http://www.jroller.com/aalmiray/entry/new_desktop_application_framework_jsr)
*   Savant, a [new Groovy-powered build tool](http://www.inversoft.com/blog/2014/10/08/introducing-savant-inversoft/)?

## Presentations

*   [Groovy introduction](https://speakerdeck.com/jlstrater/2014-ghc-groovy-gr8ladies-workshop-v16) slides by the GR8 Ladies
*   Colin Harrington on [web security](http://slides.com/colinharrington/web-application-security#/)
    
## News

*   Jacob Aae Mikkelsen's [Grails Diary](http://grydeske.net/news/show/65) week 41

## Interview

*   [Interview of Hans Dockter](https://twitter.com/droidconuk/status/520861514396606464) on Gradle and continuous delivery

## Tweets

*   [Groovy makes Android code much more concise](https://twitter.com/eugenekamenev/status/521007874529447937)
*   The [GR8 Ladies celebrate their first birthday](https://twitter.com/Gr8Ladies/status/520401087694917632)!
*   Joe Wolf notes that [Groovy reached 10,000 questions on Stack Overflow](https://twitter.com/bdkosher/status/520295206219173888)
*   Eugene Kamenev is investigating bring [GORM-like features for Groovy on Android](https://twitter.com/eugenekamenev/status/521562112146276352)<, to deal with building UI, handling validation, and more
*   Youri Ackx liked Guillaume Laforge's funny slide from his JavaOne presentation about how to represent [map / reduce, sandwich-style](https://twitter.com/youriackx/status/519744695497273345)
*   Ratpack adds [more Promise operations](https://twitter.com/ratpackweb/status/519830913106968577) and improved the documentation
*   Dierk König says the [builder pattern in Groovy is a great example of the state monad](https://twitter.com/mittie/status/520191158467960832)
*   Graeme Rocher waves [goodbye to the old Grails build system](https://twitter.com/graemerocher/status/520234393940787200)
*   Gradle features a handful of [plugins for JavaScript / front-end build automation](https://twitter.com/DailyGrailsTip/status/520618252888584192)
*   One could wish all [front end development be done with Groovy and GrooScript](https://twitter.com/groovylang/status/521424091447066624)?
*   [Spring Boot 1.1.8](https://twitter.com/gvmtool/status/520927004351549440) available through GVM
*   [Spring Boot 1.2.0.M2](https://twitter.com/gvmtool/status/520927209415249921) available through GVM
    
## Code snippets

*   [GrooScript for client-side templating](https://twitter.com/grooscript/status/521760399398805504) with the HTML builder or with Groovy templates

## Events

*   Baruch Sadogursky will be speaking about AST transformations at [JavaDay Kiev](http://javaday.org.ua/#nav-speakers) and will wow the crowds with Groovy Puzzlers at JavaDay Kiev and [Jokerconf](http://jokerconf.com/)!
*   Iván López will be talking about ["Metaprogramming with Groovy" at GeeCON Prague](http://geecon.cz/speakers/) next 23rd October
*   The [Greach conference](https://twitter.com/greachconf/status/521564797444190208) is being prepared and is taking shape, and the organizers are looking for sponsors
*   [GR8Conf Europe 2015](https://twitter.com/jacobaae/status/520910335570894848) is in the works, as the team reunites
# Back from JavaOne


After some trouble getting to San Francisco because of strikes, transportation issues, burnt control tower, and more... I managed to land to JavaOne! I missed my own first talk and I was glad and grateful that Cédric could present it for me.

At JavaOne, the Groovy project received the award from ZeroTurnaround / RebelLabs, for the "Best Tech - Geek Choice Award" :

> Youpi mon projet a reçu un prix de l'innovation ! Très fier de ce que mon équipe a accompli !
> 
> [Instagram](https://instagram.com/p/tuU20HgNf7/)

And at the famous "Script Bowl" competition, I managed to get on the first place of the podium, along with the Clojure representative, showing Groovy traits, Groovy on Android, and GrooScript transpiling Groovy into JavaScript.

> [#groovylang](https://twitter.com/hashtag/groovylang?src=hash) still first on the podium of the [#JavaOne](https://twitter.com/hashtag/JavaOne?src=hash) script bowl, along with [#clojure](https://twitter.com/hashtag/clojure?src=hash) too :-) Thanks to all the attendees!
> 
> — Guillaume Laforge (@glaforge) [October 2, 2014](https://twitter.com/glaforge/status/517485161496051712)

And last but not least, my presentation slides...

{{< speakerdeck 69e2f5e02c6a013279dd1ea472fb96ba >}}

{{< speakerdeck 937906e02c6a0132389e4274f6195918 >}}

# Groovy on Android at DroidCon Paris 2014


I was very honored to be able to speak about Groovy at DroidCon Paris 2014 a couple of weeks ago. It was really great to spend time with the Android community and learn more about their needs, pain points, and more.

The video of the presentation is available below:

{{< youtube kOVxiob9ZgQ >}}

And you can find the slides here too:

{{< speakerdeck 4a2f75502495013299fd7e85eb08a929 >}}

# Groovy Weekly #39


Back from JavaOne, where the Groovy project received its "Best Tech - Geek Choice Awards" from ZeroTurnaround, and where it win the Script Bowl competion this year again!

## Releases

- [Griffon 2.0.0](http://new.griffon-framework.org/news/griffon_2.0.0.html) final released!
- [Ratpack 0.9.9](http://www.ratpack.io/versions/0.9.9) is out moving to Java 8 as a base requirement
- Alain Stalder releases [Grengine](http://groovy.329449.n5.nabble.com/ANN-Grengine-td5721425.html), another approach to running and embedding Groovy
- [RxGroovy 1.0.0-RC-1](https://twitter.com/RxJava/status/517187762307350528) was released with a new artifact ID

## Articles

- Marcin Zajączkowski comes back with Part 2 of [what's coming up in Spock 1.0](http://solidsoft.wordpress.com/2014/10/03/whats-new-in-upcoming-spock-1-0-part-2-cleaning-up/)
- Andrés Almiray explains it's [time for a desktop application framework JSR](http://www.jroller.com/aalmiray/entry/it_s_time_for_a)
- Trisha Gee is using [Groovy to insert XML into MongoDB](http://trishagee.github.io/post/groovy_import_to_mongodb/)
- Hans Dockter published the [Gradleware July-September newsletter](http://www.gradleware.com/newsletter/gradleware-newsletter-july-aug-sep/)
- André Steingreß writes about [principals tracking in Grails](http://blog.andresteingress.com/2014/10/04/grails-principal-stamp/)
- [Part 8](http://rpeszek.blogspot.fr/2014/10/i-dont-like-hibernategrails-part-8-but.html) of the series “I don’t like Hibernate / Grails”
- A [Spock quick tip for Grails integration tests](http://blog.andresteingress.com/2014/10/05/grails-integration-tests/) from André Steingreß
- Quick Gradle tip: [setting Bintray attributes for Gradle plugins](https://andrew-oberstar.squarespace.com/blog/2014/9/28/quick-gradle-tip-setting-bintray-attributes-for-gradle-plugins)
- Tomás Lin on [Spring Boot and Webjars](http://fbflex.wordpress.com/2014/09/22/spring-boot-and-webjars-overwriting-configuration-during-runtime/): overwriting configuration during runtime
- Burt Beckwith answers a Stack Overflow question on [overriding Grails' default create-app files](http://stackoverflow.com/questions/26127364/override-default-grails-create-app-files/26131261#26131261)

## Presentations

- Ixchel Ruiz and Andrés Almiray demonstrated the [funky-ness of Groovy](http://fr.slideshare.net/aalmiray/javaone-getting-funky-with-groovy) at JavaOne 2014
- Cédric Champeau presented “[rethinking API design with traits in Groovy](https://speakerdeck.com/melix/rethinking-api-design-with-traits-in-groovy)” at JavaOne 2014
- Guillaume Laforge posted his JavaOne 2014 slides about “[Groovy in the light of Java 8](https://speakerdeck.com/glaforge/groovy-in-the-light-of-java-8-javaone-2014)”
- Guillaume Laforge published his slides about “[Groovy in 2014 and beyond](https://speakerdeck.com/glaforge/groovy-in-2014-and-beyond-javaone-2014)” from JavaOne 2014
- Guillaume Laforge presented [Groovy on Android](https://www.youtube.com/watch?v=kOVxiob9ZgQ) at DroidCon Paris 2014

## News

- Jacob Aae Mikkelsen’s [Grails Diary week 39](http://grydeske.net/news/show/63)
- Jacob Aae Mikkelsen’s [Grails Diary week 40](http://grydeske.net/news/show/64)

## Tweets

- [Groovy reaches first place on the podium](https://twitter.com/glaforge/status/517485161496051712), along with Clojure, beating JRuby and Scala at JavaOne 2014's Script Bowl competition
- [Groovy received its Best Tech Geek Choice Award](https://twitter.com/glaforge/status/518307473766514688) from ZeroTurnaround at JavaOne 2014
- Cédric Champeau is looking into [integrating Sergei Egorov’s Groovy macros](https://twitter.com/cedricchampeau/status/519102857812144128) into Groovy 2.4
- Dierk König says the [finish line is in sight for Groovy in Action](https://twitter.com/mittie/status/517456134018318336), second edition
- If you use dependency classifiers (like Groovy’s “indy”) in Gradle builds with IntelliJ IDEA, you might want to [vote for this issue as it’s broken in Intellij IDEA](https://twitter.com/SolidSoftBlog/status/515043592511844353)
- If you like [SASS and Gradle](https://twitter.com/Lspacewalker/status/516711346801373184), Danny Hyun notes there's a plugin for that
- Russel Hart notes that as of Ratpack 0.9.9 you can [stream your Hystrix metrics out to the Hystrix dashboard or Turbine](https://twitter.com/rus_hart/status/517275624197865472)
- Russel Hart remarks that [Ratpack's GroovyChainAction is replaced](https://twitter.com/rus_hart/status/517273884845170688) with Action\<Chain\> and the Groovy.chain() call in Ratpack 0.9.9
- Craig Burke is readying his [Angular.JS Grails Lazybones template](https://twitter.com/craigburke1/status/519201978694778880)

## Code snippets

- Ken Sipe’s code samples from his JavaOne 2014 [Spock presentation](https://github.com/kensipe/spock-javaone2014)
- More [GrooScript demos](https://twitter.com/grooscript/status/517449135897993216) available
- [Ratpack promises, a comparison between Java 7 and 8](https://github.com/ratpack/ratpack/commit/cc41092f7cc6?diff=split)

## Events

- Mac Liaw will be speaking about [Ratpack at 1 Dev Day Detroit](http://1devday.net/sessions/ratpack-fun-profit/)
- Andrés Almiray is presenting [Gradle, harder, better, stronger, faster](http://jazoon.com/talk/Talk122/), at Jazoon

## Books

- Jon Kerridge publishes [two ebooks on concurrency and parallelism](http://gpars-user-mailing-list.19372.n3.nabble.com/Using-Concurrency-and-Parallelism-Effectively-td4025035.html) and makes good use of Groovy

# Groovy Weekly #38


Here’s a short column this week, a bit in advance, as I’m flying to JavaOne tomorrow to spread the Groovy truth!

## Releases

*   Cédric Champeau announced the release of [Groovy 2.3.7](http://groovy.329449.n5.nabble.com/ANN-Groovy-2-3-5-released-and-upward-compatibility-td5720556.html#a5721353)
*   [Spring Boot 1.1.7](https://spring.io/blog/2014/09/26/spring-boot-1-1-7-released) released
    
## Articles

*   MrHaki's Gradle Goodness: [running Groovy scripts as application](http://mrhaki.blogspot.fr/2014/09/gradle-goodness-running-groovy-scripts.html)
*   [The reason the internet was invented or cat pictures for the win](http://kousenit.wordpress.com/2014/09/17/the-reason-the-internet-was-invented-or-cat-pictures-ftw/), by Ken Kousen, sprinkled with bits of Groovy JSON and Swing code
*   [Exporting Grails' i18n messages into Javascript](http://razum.si/blog/grails-javascript-i18n-messages)
*   Andrés Almiray’s [Gradle Glam on features that would benefit the Gradle community](http://www.jroller.com/aalmiray/entry/gradle_glam_future_features)
*   Jorge Martin on the [inception and the Groovy Swiss Knife library for Android and the problems encountered with Android Studio's Groovy support](http://blog.arasthel.com/so-i-made-this-thing-english/)

## Presentations

*   Guillaume Laforge presented on [Groovy on Android](https://speakerdeck.com/glaforge/groovy-on-android-droidcon-paris-2014) at DroidCon Paris 2014

## Tweets

*   Robert Fletcher noticed [IntelliJ IDEA's clever capability of properly renaming closures it parameter](https://twitter.com/rfletcherew/status/516585075077832705)
*   Java's [Duke is looking pretty Groovy](https://twitter.com/aalmiray/status/516400403487809536) at JavaOne!
*   [Groovy 2.3.7](https://twitter.com/gvmtool/status/515216180333002752) is available on GVM
*   A [pretty Groovy book](https://twitter.com/gregturn/status/514759918633881600)!
*   Jon DeJong [makes Groovy strongly typed by hitting the keys harder](https://twitter.com/jondejong/status/515233596731559936) when coding!
*   [New component selection and replacement rules](https://twitter.com/Gradleware/status/515021179640246272) for upcoming Gradle 2.2
*   Robert Guerra shows a screenshot of [deployment of Ratpack with Java 8 on Heroku](https://twitter.com/robertoguerra19/status/514990054880866304)

## Code snippets

*   Cédric Champeau shows a fun snippet of code using [metaprogramming to let Groovy be pretty tolerant to typos in method names](https://gist.github.com/melix/5bc7c5db7ab986924181)
# Groovy Weekly #37


SpringOne2GX 2014 in Dallas is over. And next week starts JavaOne. It’s conference season! Speaking of which… the fine GR8Conf US crew released many more presentations this week! There’s a lot of content to go through!

## Releases

*   [GrooScript 0.6](https://twitter.com/grooscript/status/512724108941881344) is out, on the road to 1.0, and Jorge Franco is looking for your feedback
*   [Gradle Android plugin 0.13](https://twitter.com/droidxav/status/512731018097209344) works with Gradle 2.1
*   [JBake 2.3.2](https://twitter.com/javabake/status/513793973857828864) with Asciidoctor 1.5
    
## News

*   [Incremental Java compilation landed in Gradle](http://www.gradle.org/docs/2.1/release-notes#incremental-java-compilation) 2.1
*   [Grails Diary week 38](http://grydeske.net/news/show/62) by Jacob Aae Mikkelsen
    
## Articles

*   [What's new in Spock 1.0](http://solidsoft.wordpress.com/2014/09/17/whats-new-in-upcoming-spock-1-0-simpler-conditional-test-execution-with-requires-and-ignoreif/), by Marcin Zajączkowski
*   [GPars remote dataflows and actors](http://mariogarcia.github.io/gpars-workshop/#_remoting) by Mario García
*   [Writing React.JS components in Groovy with GrooScript](http://grooscript.org/react_example.html)
*   The "[Grails revolution](http://grailsrevolution.wordpress.com/2014/09/18/grails-revolution-the-force/)" movement is looking forward to spreading the word on how great Grails is
*   What's new with [Gradle Vaadin Plugin 0.9](http://devsoap.com/#!/What-is-new-with-Gradle-Vaadin-Plugin-09)? Groovy support!
*   MrHaki's Gradle Goodness: [Adding dependencies only for packaging to war](http://mrhaki.blogspot.fr/2014/09/gradle-goodness-adding-dependencies.html)
*   [Multi-project code coverage using Gradle and JaCoCo](http://csiebler.github.io/blog/2014/02/09/multi-project-code-coverage-using-gradle-and-jacoco/) by Clemens Siebler
*   After his Hibernate/Grails series, Robert Peszek comes to functional programming: "My dream: software without any bugs ... and [is Groovy functional? How about Grails](http://rpeszek.blogspot.fr/2014/09/my-dream-software-without-any-bugs-and.html)?"
*   How to [speed up Gradle builds? Use the daemon](https://www.timroes.de/2013/09/12/speed-up-gradle/)!

## Presentations

*   Guillaume Laforge presented about [Groovy's Android support](https://speakerdeck.com/glaforge/groovy-on-android-droidcon-paris-2014) at DroidCon Paris 2014
*   [Idiomatic Spock](https://www.youtube.com/watch?v=RuTupC0I59M&feature=youtu.be) with Robert Fletcher recorded at Netflix
*   Trisha Gee gave her [Groovy / Angular.JS / HTML 5 / MongoDB](http://virtualjug.com/html5-angularjs-groovy-java-and-mongodb-all-together-what-could-go-wrong/) talk to the Virtual JUG
*   [Micro-services with Groovy and Spring Boot](https://www.youtube.com/watch?v=f_fGwa2-rMk) by Marcin Grzejszczak
*   GR8Conf US 2014 presentations
    *   [Groovy at SmartThings](https://www.youtube.com/watch?v=0aYcLMJkv5c) presented by Scott Vlaminck and Ryan Applegate
    *   The [Groovy Ecosystem revisited](https://www.youtube.com/watch?v=O0vt57XeF5E&feature=youtu.be) by Andrés Almiray
    *   [Getting started with Ratpack](https://www.youtube.com/watch?v=g0fX5yA-Xzg&feature=youtu.be) presented by Jeff Beck
    *   [Realtime Ratpack](https://www.youtube.com/watch?v=Ap16ueXSJig) by Robert Fletcher
    *   [Introduction to Gradle](https://www.youtube.com/watch?v=G4EAd514jdE) by John Engelman
    *   [Grails Goodness](https://www.youtube.com/watch?v=qyj7A-8n49w) presented by Hubert Klein Ikkink
    *   [Gradle Goodness](https://www.youtube.com/watch?v=erg5Ng8yuKQ) presented by Hubert Klein Ikkink
    *   [Distributed platform development with Groovy](https://www.youtube.com/watch?v=u3KpiLZ1-64&feature=youtu.be) by Robert Fletcher
    *   [Introduction to multithreaded programing with GPars](https://www.youtube.com/watch?v=unUJwAAtLcM) by Jon DeJong
    *   [Tour de plugin](https://www.youtube.com/watch?v=ZYISj1RmQA0&feature=youtu.be), by Søren Berg Glasius
    *   [Grails Worst Practices](https://www.youtube.com/watch?v=tSbx2MSsD5A) by Burt Beckwith
    *   [Griffon, what's new and what's coming](https://www.youtube.com/watch?v=QhVCYLgHak4&feature=youtu.be), by Andrés Almiray
    *   [How to test your Grails application](https://www.youtube.com/watch?v=u8Ib2JFcyX8) presented by Colin Harrington
    *   [Hybrid view rendering with Grails](https://www.youtube.com/watch?v=UlJByqywIkE&feature=youtu.be) by Robert Fletcher
    *   [Testing BitCoin and MasterCoin with Spock](https://www.youtube.com/watch?v=lL_wQF5AjH8) by Sean Gilligan
    *   [Performance tuning Grails applications](https://www.youtube.com/watch?v=EnyKt7NQTEY) by Lari Hotari
    *   [What's new in the Grails Spring security plugin](https://www.youtube.com/watch?v=1umis5WS8_w) by Burt Beckwith
    *   [Application architectures in Grails](https://www.youtube.com/watch?v=Rid_hOnJTrk) by Peter Ledbrook
    *   [Idiomatic Spock](https://www.youtube.com/watch?v=dV-a21JQ21k) by Robert Fletcher
    *   [Getting Grails into the Enterprise](https://www.youtube.com/watch?v=hHMaTZarRjY) by Ryan Vanderwerf
    *   [Metaprogramming with the Groovy Runtime](https://www.youtube.com/watch?v=YG1hWfLDuBo) by Jeff Brown
    *   [Getting Groovy with Graphs](https://www.youtube.com/watch?v=OFFjqeqt8Ds) by Stefan Armbruster
    *   [Serving Websockets to iOS, Android and the Web using Groovy, Spring, Angular.js, SockJs and STOMP](https://www.youtube.com/watch?v=LyJ4fORkHfA) presented by Sean Gilligan

## Screencasts

*   Bertrand Goetzmann publishes a screen cast of [Grails with the Ionic framework](https://www.youtube.com/watch?v=QHGqxMpxqMU&feature=youtu.be) demonstrating a REST API example

## Tweets

*   Peter Niederwieser is [lobbying for fixing those issues in the IntelliJ IDEA Groovy support](https://twitter.com/pniederw/status/513084438582800385). Please vote for them!
*   [Ratpack 0.9.9 onward will require Java 8](https://twitter.com/ratpackweb/status/514200501890457600)
*   [Ratpack ships new releases every first day of the month](https://twitter.com/ratpackweb/status/514243729192779778)
*   [Ratpack’s RxJava support in Java 7 vs Java 8](https://twitter.com/ratpackweb/status/514066358959501313)
*   You can decorate your garden with [Groovy flowers](https://twitter.com/finistseb/status/511984302809444352)!
*   Proper [overloaded setter support](https://twitter.com/cedricchampeau/status/512941179395399681) is coming to Groovy
*   [Groovy as a gateway drug into the JVM](https://twitter.com/_ericlobdell/status/513299775538864129)
*   With OpenJDK 8 out, [Ratpack's next release will require Java 8](https://twitter.com/ratpackweb/status/512365480070221824)
*   Benoît Hédiart mentions CodingGame.com: a [coding game where you can program games in Groovy](https://twitter.com/benorama/status/512541644269584384)
*   Guillaume Laforge is having fun coding an [Android application in Groovy for helping her daughter to learn how to read](https://twitter.com/glaforge/status/513782559919341568)
*   Guillaume Laforge on stage at [DroidCon Paris 2014 evangelizing Groovy on Android](https://twitter.com/droidconfr/status/514073374742818816)
*   [GroovyBlogs now displays latest blog entries and most popular](https://twitter.com/sbglasius/status/513834602746478592) ones

## Code snippets

*   How to create [multiple Android dex files with a Gradle trick](http://stackoverflow.com/questions/23614095/using-gradle-to-split-external-libraries-in-separated-dex-files-to-solve-android/25975702#25975702)
# Groovy Weekly #36


The SpringOne2GX 2014 conference is over, but you can see below more tweets and presentations from the second part of the conference, and the videos will be available later on on InfoQ.

Apart from the excitement around Grails 3, Spring Boot, Groovy, and more, I’d like to highlight the very interesting feedback from Scott Hickey who comes back on 6 years of production usage of Groovy at Mutual of Omaha, saying “Groovy is a phenomenal language for businnes applications”, and that there’s nothing “better” on the JVM! See the first couple of tweets in the Twitter section.

## News

*   With Gradle 2.1, you can [type check or statically compiled all your Groovy code by default](http://www.gradle.org/docs/2.1/release-notes#groovy-compiler-configuration-script-support)
*   Oracle mentions briefly the [collaboration between Oracle and the Groovy development team to test JDK 8](https://blogs.oracle.com/henrik/entry/java_8_not_just_for)
*   [Grails Diary](http://grydeske.net/news/show/61) week 37 by Jacob Aae Mikkelsen
    
## Articles

*   Luke Daley explains the [Ratpack execution model](http://ldaley.com/post/97376696242/ratpack-execution-model-part-1)
*   Jeff Beck details [Ratpack promises](http://beckje01.com/blog/2014/09/10/ratpack-promise/)
*   Roberto Guerra dives into how to replicate an [asset-pipeline for Ratpack](http://blog.stumblingoncode.com/posts/2014-09-11-ratpack-asset-processing.html)
*   Mark Perry writes on [Groovy Monad Combinators](http://mperry.github.io/2014/09/10/groovy-monad-combinators.html)
*   [I don't like Grails / Hibernate](http://rpeszek.blogspot.fr/2014/09/i-dont-like-hibernategrails-part-7.html), part 7, working on more complex projects
*   [Integrate Groovy and Java](http://www.itexto.net/devkico/?p=1957) by Henrique Lobo Weissmann in Portuguese
*   SpringOne2GX 2014 recap by Uday Pratap Singh
    *   [Day #1](http://www.intelligrape.com/blog/2014/09/09/day-1-at-springone2gx-2014-opening-night-keynotes/)
    *   [Day #2](http://www.intelligrape.com/blog/2014/09/10/day-2-at-springone-2gx-2014/)
    *   [Day #3](http://www.intelligrape.com/blog/2014/09/11/day-3-at-springone-2gx-2014/)
    *   [Day #4](http://www.intelligrape.com/blog/2014/09/12/day-4-at-springone-2gx-2014-the-finale/)
    
## Presentations

*   Andrew Reitz posts his [Groovy on Android](https://twitter.com/andrewreitz_/status/509543532181610496) lightning talk slides
*   Andrés Almiray presented [Functional Groovy](http://2014.javazone.no/presentation.html?id=afbc91ce) at the JavaZone conference
*   GR8Conf US 2014 videos
    *   Kyle Boon on [growing up with Grails](https://www.youtube.com/watch?v=nVT8Gw-7x_c&feature=youtu.be)
    *   Ryan Applegate and Adam Lanners explain how to [get Groovy with Vert.x](https://www.youtube.com/watch?v=x2-yF-L4gdQ)
*   SpringOne2GX 2014 presentations
    *   Cédric Champeau posted the [slides and code of his Groovy on Android](https://twitter.com/cedricchampeau/status/510166855994990593) presentation
    *   [Making Spring Boot groovier](https://speakerdeck.com/graemerocher/making-spring-boot-groovier) by Graeme Rocher
    *   [Advanced Grails GORM beyond relational](https://speakerdeck.com/graemerocher/advanced-gorm-beyond-relational) by Graeme Rocher
    *   Graeme Rocher reveals a [preview of Grails 3.0](https://speakerdeck.com/graemerocher/grails-3-preview)
    *   Marco Vermeulen presented [Behavior-Driven-Development with Cucumber and Groovy](http://marcovermeulen.github.io/cuke-groovy-talk/#/)
    *   Marco Vermeulen posted the code and slides of his [Spring Boot + Groovy + Cucumber](https://twitter.com/marcovermeulen/status/510089484545687552) talk
    *   Stéphane Maldini posted the slides of his presentation on [Reactor and Reactive Streams](http://fr.slideshare.net/StphaneMaldini/spring-one2gx-2014reactivestreams)
    *   Lari Hotari's [performance tuning talk](https://twitter.com/lhotari/status/510569280606199808): on unnecessary block operations
    *   Lari Hotari's [performance tuning presentation](https://twitter.com/lhotari/status/510568222190354432): on CPU-hogging regular expressions
    *   Fabrice Matrat shares his presentation on [RaveJS and Grails](http://fabricematrat.github.io/grails-rave/)

## Tweets

*   SpringOne2GX 2014 Groovy BOF started with the case study of Groovy production usage at Mutual of Omaha
*   Testimonial from the [6 years of Groovy in production at Mutual of Omaha](https://twitter.com/glaforge/status/509533986897399808): "We learned Groovy is better, period."
*   "[Groovy is a phenomenal language for complicated business applications](https://twitter.com/glaforge/status/509535048341520384)" says Mutual of Omaha
*   [Netflix is contributing heavily to the Gradle plugin ecosystem](https://twitter.com/sbglasius/status/510075936964763648)
*   Jack Frosch finds Groovy is getting better and better, especially with [traits as a "game changer"](https://twitter.com/jackfrosch/status/509540543278235648)
*   Stéphane Maldini mentions the ongoing [collaboration between the Groovy development team and the Reactor team to make Reactor play nice with Groovy on Android](https://twitter.com/smaldini/status/511171875649880065)
*   You can [send Groovy puzzlers](https://twitter.com/sbglasius/status/509839267711840256) by email and through twitter
*   Szymon Stepniak shares a [recipe for having a good time: Groovy + GPars + Spring Boot](https://twitter.com/wololock/status/509605494869463040)
*   Andrés Almiray notes [issues with JDK 8 update 11 with Groovy and Cobertura](https://twitter.com/aalmiray/status/510010512726585344) and decides to move to JaCoCo instead
*   [Ratpack is making promises transformable](https://twitter.com/ratpackweb/status/510037090344501248) making async easier
*   [GVM asks your feedback in a survey](https://twitter.com/gvmtool/status/510041384569409536) asking you if you prefer lite or full distributions when downloading candidates
*   Dierk König remarks that [Intellij IDEA shows Java constructor calls like Groovy named-parameter constructor calls](https://twitter.com/mittie/status/510099003779055616)
*   Dierk König teases with a [GroovyFX demo](https://twitter.com/mittie/status/511289143243337728) for his upcoming JavaOne presentation
*   Cédric Champeau will be speaking about [Groovy on Android at SoftShake](https://twitter.com/cedricchampeau/status/511909801811398656)

## Code snippets

*   SpringOne2GX 2014 [demo application combining Ratpack, Spring Boot, Reactor and its reactive streams on Java 8](https://github.com/SpringOne2GX-2014/reactive-geocoder)
*   Václav Pech illustrates a [safe thread starter with a Groovy trait](https://gist.github.com/vaclav/c93225b2f93263bb8c55)

## Events

*   The 3rd [Gradle Summit](https://twitter.com/gradleware/status/511641094442860544) will be held June 11-12th in Santa Clara, California
*   [SpringOne2GX 2015 will talk place in Washington DC](https://twitter.com/colinharrington/status/509754307009581056) on September 14th-17th
*   The [GR8Ladies now have a monthly meetup](https://twitter.com/jennstrater/status/509758555142889472). Next talk on October 6th with an introduction to Groovy
*   The Austin Groovy Grails user group wraps up its [coverage of the SpringOne2GX 2014 conference](http://www.meetup.com/Austin-Groovy-and-Grails-Users/events/206899722/) on September 24th

## Jobs

*   [Work with RxJava, Groovy on Android for the New York Times](http://careers.stackoverflow.com/jobs/67807/160k-android-developer-work-with-android-l-averity)
# Groovy Weekly #35


Direct live from [SpringOne2GX](http://springone2gx.com/), in Dallas! So you can expect some news and presentations from the show this week and the next, and certainly tons of tweets!

Speaking of tweets from SpringOne2GX, you’ll notice the flurry of very positive and excited reactions regarding the upcoming Grails 3 release.

In the release section, don’t miss the release of Gradle 2.1.

## Releases

*   [Gradle 2.1](http://forums.gradle.org/gradle/topics/gradle-2-1-released) released with community plugins, and incremental java compilation
*   [GVM 2.1](https://twitter.com/gvmtool/status/506086805759066112) released with improved self-updates
*   [Swiss Army](https://github.com/Arasthel/SwissKnife), a handy library for Groovy on Android, covering view injection, threading and more, by Jorge Martín
*   [Gradle 2.1 rc-4](http://forums.gradle.org/gradle/topics/gradle-2-1-rc-4-is-now-available-for-testing) is ready for testing
*   [Spring Boot 1.1.6](https://spring.io/blog/2014/09/05/spring-boot-1-1-6-released) released
*   A [Groovy DSL that allows for easy definition of Asciidoctor extensions](https://github.com/robertpanzer/asciidoctorj-groovy-dsl) by Robert Panzer
*   [Asciidoctor Gradle Template 1.0.0](https://twitter.com/aalmiray/status/507818302496702465) announced by Andrés Almiray

## News

*   [GroovyBlogs](http://www.groovyblogs.org/) is coming back to life thanks to Søren Berg Glasius
*   Jacob Aae Mikkelsen [Grails Diary week 36](http://grydeske.net/news/show/60)

## Articles

*   [Remoting comes to GPars](http://docs.codehaus.org/display/GPARS/2014/09/06/Remoting+for+GPars), thanks to Google Summer of Code Rafał Sławik's great work
*   [Ratpack + Docker + Gradle](http://kyleboon.org/blog/2014/08/14/ratpack-plus-docker-plus-gradle/) by Kyle Boon
*   Benjamin Muschko speaks about [Gradle's support of Maven POM profiles](http://www.gradleware.com/tutorials/feature-spotlight-gradles-support-maven-pom-profiles/)
*   "I don't like Grails / Hibernate" goes on, covering [how to save objects using refresh()](http://rpeszek.blogspot.fr/2014/09/i-dont-like-hibernategrails-part-6-how.html)

## Presentations

*   [Gradle in the enterprise at LinkedIn](http://www.gradleware.com/conferences/gradle-summit-2014-video-gradle-enterprise-linkedin/) at Gradle Summit 2014
*   [Benefit from Groovy, when, why, and how](http://www.parleys.com/play/530b52fbe4b085f68c6b653f/chapter0/about), presented by Guillaume Laforge at JFokus 2014
*   The [Groovy way to write Jenkins CI plugins](https://twitter.com/ShlomiBenHaim/status/508772445852278784) by Shiran Rubin
*   [Functional programming in Groovy](http://www.infoq.com/fr/presentations/programmation-fonctionnelle-groovy), by Guillaume Laforge, recorded at BreizhCamp 2014 (in French)
*   [How to get fully functional in Groovy](http://jaxenter.de/videos/funktionen-monaden-groovy-jaxtv-175429), by Dierk König (in German)
*   Video tutorial how [Gradle is integrated in Java IDEs](http://www.gradleware.com/conferences/gradle-summit-2014-video-gradle-ides/)
*   A [Groovy introduction presentation](http://www.java-tv.com/2014/08/28/groovy-introduction/) by Joachim Baumann
*   First slide decks published from SpringOne2GX 2014 in Dallas, Texas:
    *   Cédric Champeau dived into [rethinking API design with Groovy traits](https://speakerdeck.com/melix/rethinking-api-design-with-traits)
    *   Guillaume Laforge presented the [latest state of the Groovy nation](https://speakerdeck.com/glaforge/groovy-in-2014-and-beyond-at-springone2gx-2014) at SpringOne2GX 2014
    *   Guillaume Laforge answers the question wheter [Groovy is still relevant now that we have Java 8](https://speakerdeck.com/glaforge/groovy-in-the-light-of-java-8-springone2gx-2014)
    *   Paul King speaks about [working with databases in Groovy](http://fr.slideshare.net/paulk_asert/groovy-databases)
    *   Paul King covers [Groovy AST transformations](http://fr.slideshare.net/paulk_asert/groovy-transforms)

## Tweets

*   Cédric Champeau will present "[Rethinking API design with traits](https://twitter.com/cedricchampeau/status/507130051909808130)" at JavaOne
*   Andrés Almiray will [evangelize Gradle at the Jazoon](https://twitter.com/aalmiray/status/507263810932310016) conference
*   [Groovy 2.4 beta 3](https://twitter.com/gvmtool/status/507862222585200640) available on GVM
*   Søren Berg Glasius tells us that [GroovyBlogs is coming back to life](https://twitter.com/sbglasius/status/507726726697218048)
*   [Gradle 2.1-rc-4](https://twitter.com/gvmtool/status/507663212918349824) is available on GVM
*   [Groovy had Peter Ledbrook at "properties"](https://twitter.com/msgilligan/status/503365901052149760)
*   Dan Woods believes [Ratpack's handler chain and Groovy DSL is the best combo for building restful APIs](https://twitter.com/danveloper/status/502900825161601024)
*   You can [customize the GVM self-update prompt](https://twitter.com/gvmtool/status/502358588539826176)
*   Ted Naleid notes that the [@DirtiesRuntime test-level annotation can mark tests with metaclass changes in Grails](https://twitter.com/tednaleid/status/501881682178220033) 2.4.4
*   Even during the SpringOne2GX keynote, [GVM makes the show](https://twitter.com/ryanvanderwerf/status/509130411125919744)!
*   [All the new Groovy documentation is tested](https://twitter.com/cedricchampeau/status/509350223521406976): all snippets are included from test cases.
*   Lots of Grails 3 related tweets following up Graeme Rochere’s Grails 3 preview at SpringOne2GX 2014
    *   The [Grails 3 preview gets developers excited](https://twitter.com/rfletcherew/status/509374166555176960)
    *   [Spring Boot 1.2.0.M1](https://twitter.com/gvmtool/status/509342714249220096) is available on GVM
    *   [Grails 3 is abandoning Gant in favor of Gradle](https://twitter.com/danveloper/status/509371622143184896)
    *   [Goals for Grails 3](https://twitter.com/danveloper/status/509139062561599489): support a plugin model, better eventing, better micro-services, based off Spring Boot, and more
    *   [Grails 3 will make a clean delineation between plugins](https://twitter.com/danveloper/status/509139609997950976), distinguishing code generation, build-time, runtime
    *   [Grails 3 apps can be packaged as runnable JARs](https://twitter.com/danveloper/status/509373452277805056)
    *   [Grails 3 will be independent of the Servlet API](https://twitter.com/danveloper/status/509382811376041986)
    *   You can [create micro-Grails applications that as simple Groovy scripts](https://twitter.com/danveloper/status/509375965743431680)
    *   Grails 3 is going to feature [application profiles](https://twitter.com/danveloper/status/509380846319456257)
    *   Grails 3 will allow you to [debug your controllers](https://twitter.com/pledbrook/status/509380623312502784) more easily as they are now Groovy traits
    *   The [roadmap for Grails 3 is to have a first milestone before the end of the year](https://twitter.com/danveloper/status/509383407516647424) and the GA before next year's SpringOne2GX, a year from now.

## Code snippets

*   [Painting like Jackson Pollock](http://grooscript.org/demo/bezier.html), in Groovy, in the browser, thanks to GrooScript with this demo from Jorge Franco Leza
*   Graeme Rocher wowed the crowds at SpringOne2GX's keynote with a [tweetable full data-driven rest application with Grails 3](https://twitter.com/danveloper/status/509141002838220800)
*   Cédric Champeau shares a Gradle tip to [bypass odd VerifyErrors when you're developing Android applications in Groovy](https://gist.github.com/melix/60d9f94a2ab961c1a0da)
*   Lari Hotari contributed [Spring Boot support for Ratpack](https://github.com/ratpack/ratpack/pull/433)
*   Schalk Cronjé shares a tip on [how control logging running tests in Gradle](https://gist.github.com/ysb33r/68ba7ad1279d0492086a)
*   Stéphane Nicoll shows a neat [Spring Boot rabbit support from Groovy](https://twitter.com/snicoll/status/507924858823786496)
*   [Grails 3 and Spring Boot integration](https://twitter.com/danveloper/status/509374137622482946)
    
## Events

*   [Devoxx 2014 will feature Groovy](http://cfp.devoxx.be/2014) with Cédric Champeau speaking of Groovy on Android, and Guillaume Laforge on Groovy in the light of Java 8
*   Phil Webb will be talking about [Spring Boot at the Groovy Grails Centro meetup on September 23rd](http://www.meetup.com/San-Francisco-Grails-Centro/events/205421502/)
*   Guillaume Laforge is going to speak about [Groovy in the light of Java 8 at JavaOne](https://twitter.com/vfabric/status/509324343982424065) 2014

## Books

*   Interested in beta-testing an [introductory Groovy and Grails book](https://twitter.com/ErinWith2Ls/status/506826876266889216)?
*   [44% off of Manning’s Groovy, Grails, Spring books](https://twitter.com/manningbooks/status/509359104692084736)
# Beta 3 for Groovy 2.4


The Groovy development team is happy to announce the release of a third beta for Groovy 2.4.  

This release contains various bug fixes and minor improvements.  

I'll highlight the fact that you can now use multiple labels on your statements (instead of just one).  

With beta-3 now, many of the unneeded synthetic methods generated by Groovy are not generated anymore, reducing the number of methods nicely yielding smaller bytecode. This is of particular interest for Android developers limited in the overall number of methods used in Android applications.

You can read the [JIRA release notes](https://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=20544) and go straight to the [download area](http://beta.groovy-lang.org/download.html)!
# Groovy Weekly #34 back from vacations!


After a long summer break, it’s high time we resume Groovy Weekly, and come back to our every-Tuesday agenda! Get ready for lots of content!

If there were one particular item of news I’d like to highlight in this edition, that’s the news about the [New York Times that is going to use Groovy and its Android support](http://open.blogs.nytimes.com/2014/08/18/getting-groovy-with-reactive-android/?_php=true&_type=blogs&_r=0) (in the upcoming Groovy 2.4), as well as RxJava, to revamp its Android application to make more “reactive”.

Speaking of Groovy 2.4, it’s interesting to note that the new beta released today reduces the bytecode size, by not generating unneeded methods anymore. This should make Android developers happy, since they are overal limited in the number of methods in Android applications.

Next week will be pretty Groovy in Dallas, as the SpringOne2GX conference will be on. Perhaps we won’t have yet much news and presentations to share next Tuesday, but the following week will list all the great content and news happening at the conference. If you’re around, don’t hesitate to tell hi!

## Releases

*   [Groovy 2.4-beta-3]({{< ref "/posts/2014/09/02/beta-3-for-groovy-2-4" >}}) released with reduced synthetic methods (particularly handy for Android developers) to reduce the bytecode size
*   [Ratpack 0.9.8](http://www.ratpack.io/versions/0.9.8) released with Ratpack's HttpClient testing support, dangling request detection, and reactive stream support
*   [Griffon 2.0 RC-2](http://docs.codehaus.org/display/GRIFFON/2014/08/11/Griffon+2.0.0.RC2+Released) released
*   [Gradle 2.1 RC-3](http://forums.gradle.org/gradle/topics/gradle-2-1-rc-3-is-now-available-for-testing) is available for testing
*   [Grooscript Gradle plugin 0.5.1](https://bintray.com/chiquitinxx/grooscript/org.grooscript%3Agrooscript-gradle-plugin/0.5.1) is out
*   [Grails Petclinic sample](https://github.com/grails-samples/grails-petclinic) app has been updated to 2.4.3 and now uses the asset-pipeline plugin and has new tests for the Domain classes.
*   [Gdub, an enhanced Gradle wrapper](http://www.gdub.rocks/)
*   [JavaFX charting support for GroovyLab](https://code.google.com/p/jlabgroovy/wiki/JavaFXChartsInGroovyLab)
*   Fabiano Taioli created a [micro Groovy, thread-safe, dependency injection container](http://fbn.github.io/gimple/), called Gimple

## News

*   The [New York Times is going Groovy with Reactive Android](http://open.blogs.nytimes.com/2014/08/18/getting-groovy-with-reactive-android/?_php=true&_type=blogs&_r=0) by Mohit Panday
*   The Groovy project on Github has just crossed the [500th pull requests](https://github.com/groovy/groovy-core/pulls) mark. Still some work to close the 25 still open though! Keep'em coming, it's a wonderful way to contribute to the project!
*   The Grails Diary by Jacob Aae Mikkelsen
    *   [Week 32](http://grydeske.net/news/show/56)
    *   [Week 33](http://grydeske.net/news/show/57)
    *   [Week 34](http://grydeske.net/news/show/58)
    *   [Week 35](http://grydeske.net/news/show/59)
    
## Articles

*   [Why your company should be using Groovy](http://www.objectpartners.com/2014/08/25/gr8conf-us-recap-why-your-company-should-adopt-groovy/)? Scott Hickey comes back on the Mutual of Omaha Groovy case study
*   Mark Perry on [Groovy Monads](http://mperry.github.io/2014/08/19/groovy-monads.html)
*   [Using the GrooScript Node.js support](http://grooscript.org/nodejs_example.html)
*   Robert Fletcher uses [Hamcrest with Spock](http://blog.freeside.co/2014/08/07/spock-and-hamcrest/)
*   [Multiple interface mocks with Spock](http://blog.freeside.co/2014/08/11/multiple-interface-mocks-with-spock/) by Rob Fletcher
*   [Ratpack: First Impressions](http://swalsh.org/blog/2014/08/26/ratpack-first-impressions/), by Sean Walsh
*   Andrés Almiray's Gradle glam: [custom Asciidoctor extensions](http://www.jroller.com/aalmiray/entry/gradle_glam_custom_asciidoctor_extensions) in Groovy
*   MrHaki’s Asciidoctor goodness: [writing extensions in Groovy](http://mrhaki.blogspot.fr/2014/08/awesome-asciidoc-write-extensions-using.html)
*   MrHaki's Groovy goodness
    *   use [custom template class with MarkupTemplateEngine](http://mrhaki.blogspot.fr/2014/08/groovy-goodness-use-custom-template.html)
    *   [nested templates with MarkupTemplateEngine](http://mrhaki.blogspot.fr/2014/08/groovy-goodness-nested-templates-with.html)
    *   [using layouts with MarkupTemplateEngine](http://mrhaki.blogspot.fr/2014/08/groovy-goodness-using-layouts-with.html)
*   MrHaki's Gradle goodness
    *   [getting more dependency insight](http://mrhaki.blogspot.fr/2014/08/gradle-goodness-getting-more-dependency.html)
    *   [suppress progress logging](http://mrhaki.blogspot.fr/2014/08/gradle-goodness-suppress-progress.html)
    *   [Eliminating development redeploys](http://www.cholick.com/entry/show/280) using Gradle
*   Romin Irani’s Gradle tutorial series
    *   Part 4: [Java web applications](http://rominirani.com/2014/08/12/gradle-tutorial-part-4-java-web-applications/)
    *   Part 5: [Google AppEngine plugin](http://rominirani.com/2014/08/15/gradle-tutorial-part-5-gradle-app-engine-plugin/)
    *   Part 6: [Android Studio and Gradle](http://rominirani.com/2014/08/19/gradle-tutorial-part-6-android-studio-gradle/)
    *   Part 7: [Android Studio, Gradle and Google AppEngine](http://rominirani.com/2014/08/20/gradle-tutorial-part-7-android-studio-app-engine-gradle/)
    *   Part 8: [Gradle, Google AppEngine, Endpoints and Android Studio](http://rominirani.com/2014/08/25/gradle-tutorial-part-8-gradle-app-engine-endpoints-android-studio/)
    *   Part 9: [Cloud Endpoints, persistence and Android Studio](http://rominirani.com/2014/08/26/gradle-tutorial-part-9-cloud-endpoints-persistence-android-studio/)
    *   Part 10: [Consuming Cloud Endpoints in Android Studio](http://rominirani.com/2014/08/27/gradle-tutorial-part-10-consuming-endpoints-in-android-code/)
*   Robert Peszek's Grails/Hibernate series:
    *   Part 3: [DuplicateKeyException, catch it if you can](http://rpeszek.blogspot.fr/2014/08/i-dont-like-grailshibernate-part-3.html)
    *   Part 4: [Hibernate proxy objects](http://rpeszek.blogspot.fr/2014/08/i-dont-like-grailshibernat-part-4.html)
    *   Part 5: [auto-saving and auto-flushing](http://rpeszek.blogspot.fr/2014/08/i-dont-like-hibernategrails-part-5-auto.html)
*   [Add Javascript unit tests and run them with “grails test-app”](http://www.objectpartners.com/2014/08/19/add-javascript-unit-tests-and-run-them-with-grails-test-app/) by Igor Shults
*   Dmitriy Drenkalyuk covers [advanced GORM features](http://sysgears.com/articles/advanced-gorm-features-inheritance-embedded-data-maps-and-lists-storing/): inheritance, embedded data, maps and lists storing

## Presentations

*   Venkat Subramaniam reveals [how Groovy named parameter constructor works](https://twitter.com/agilelearner/status/496970094946562048)
*   GR8Conf US 2014 videos
    *   [DevOps, Chef and Grails](https://www.youtube.com/watch?v=KvBjO4WXL24&feature=youtu.be), presented by Ken Liu
    *   [Groovy Puzzlers](https://www.youtube.com/watch?v=k6vXQwxk7N8&feature=youtu.be) presentation by Baruch Sadogursky and Andrés Almiray
    *   [Why your build matters](https://www.youtube.com/watch?v=oF-gK-x8RGw&feature=youtu.be), by Peter Ledbrook
    *   [One build to rule them all](https://www.youtube.com/watch?v=ROYQlc-wVEg), by John Engelman
    *   [REPL driven development with the Grails console](https://www.youtube.com/watch?v=bTRUC78X87g) plugin, by David Kuster
*   A paid video on [effective Gradle implementation](https://www.packtpub.com/effective-gradle-implementation/video) by Lee Fox and Ryan Vanderwerf for Packt Publishing

## Google+ posts

*   Richard Vowles releases a [new version of his Maven Groovydoc plugin](https://plus.google.com/u/0/+RichardVowles/posts/fQzj2Zfn8Ux)
*   Al Baker reports about [Groovy's presence the next semantic web conference](https://plus.google.com/b/113675159854671799959/+AlBakerDev/posts/11DxyvNoKi7?cfem=1) with GroovySparql and Stardog-Groovy

## Tweets

*   GVM 2.0 is rolling out a [new broadcast API](https://twitter.com/gvmtool/status/497521264094093313)
*   [Spring Boot 1.1.5](https://twitter.com/gvmtool/status/497490734980005889) is available through GVM
*   [Gradle 2.1 RC-2](https://twitter.com/gvmtool/status/505331657508134912) is available on GVM
*   The [Lazybones Gradle plugin](https://twitter.com/pledbrook/status/503823613536251904) is now in the Gradle plugin portal
*   [Lazybones 0.7.1](https://twitter.com/gvmtool/status/503591205071233024) is on GVM
*   Cédric Champeau is [gathering feedback about Groovy traits in production](https://twitter.com/cedricchampeau/status/503834637203173378) for his SpringOne2GX presentation
*   Cédric Champeau will be speaking about [Groovy and Android at Devoxx](https://twitter.com/cedricchampeau/status/504599269379436545)
*   The Asciidoctor Java integration [(Asciidoctorj) is on the road to Gradle](https://twitter.com/ysb33r/status/504665335476539392)
*   [Marcin Erdmann recently joined the GradleWare](https://twitter.com/cedricchampeau/status/506465145825267712) team. Congrats to him!
*   Peter Ledbrook reminds us we can [submit talks for the Groovy / Grails eXchange](https://twitter.com/pledbrook/status/505744842568531968) conference in London, next December

## Mailing-lists posts

*   The debate around advocating Groovy vs Java resumes speaking about [how to manage adoption](http://groovy.329449.n5.nabble.com/Advocating-Groovy-vs-Java-Phase-II-How-to-Manage-Groovy-Adoption-td5720932.html)
*   A discussion on [using Groovy in a Java EE project](http://groovy.329449.n5.nabble.com/Using-groovy-in-a-JEE-project-td5720948.html)
*   Søren Berg Glasius is planning on taking over and [updating the GroovyBlogs website](http://groovy.329449.n5.nabble.com/GroovyBlogs-td5721104.html)
*   [Groovy as a gateway drug into the enterprise](http://groovy.329449.n5.nabble.com/The-potential-of-Groovy-for-unit-testing-Java-code-The-quot-ticket-to-Groovy-quot-for-millions-of-Ja-td5720984.html)
*   Sergei Egorov plays with [pattern matching in Groovy](http://groovy.329449.n5.nabble.com/Basic-Scala-like-pattern-matching-implementation-td5721078.html) thanks to his Groovy Macro project
*   Sergei Egorov created an [online Groovy AST console](http://groovy.329449.n5.nabble.com/Online-Groovy-AST-Console-td5720986.html)
*   Recent [Oracle's Java 8 updates have been breaking Groovy](http://groovy.329449.n5.nabble.com/Oracle-breaking-Groovy-is-a-problem-td5720928.html) but the Groovy team works with Oracle to resolve those problems
*   Ways to get an [executable Groovy program to run without Groovy installed](http://groovy.329449.n5.nabble.com/groovy-in-jar-td5720858.html)

## Code snippets

*   Following up a question on the Groovy mailing-list about [how to disable @Grab](https://github.com/glaforge/disable-grab-sample/blob/master/src/main/groovy/disablegrab/DisableGrabTransformation.groovy), Guillaume Laforge created a small sample project showing a global AST transformation that generates compilation errors when the @Grab or @Grapes annotations are used in a Groovy script
*   A [Groovy puzzler in the "daily WTF"](http://thedailywtf.com/Articles/Securing-Input.aspx) about input validation

## Events

*   [First San Diego Groovy user group meeting](https://twitter.com/ben_t_mcguire/status/503631937701830658) on September 3rd
*   The [Groovy & Grails eXchange Call for Paper is already open](https://twitter.com/skillsmatter/status/496936164809793536)!
*   A [Groovy and Grails training](https://skillsmatter.com/courses/265-groovy-and-grails-workshop) by Peter Ledbrook in London, end of September

## Books

*   [Grails in Action 2nd edition](http://www.amazon.com/gp/product/1617290963) is now available on Amazon
*   MrHaki's [Grails Goodness notebook has been updated](http://mrhaki.blogspot.fr/2014/08/grails-goodness-notebook-updated.html) with new recipes
# Disable @Grab with a global AST transformation


On the Groovy mailing-list, we had an interesting question about [how to disable annotations like @Grab](http://groovy.329449.n5.nabble.com/Disabling-Grape-td5720694.html), to prevent users from downloading third-party dependencies. There are a few possibilities for that, but my favorite was to create a global AST transformation that would generate a compilation error if the @Grab annotation is found on an import.  

I created a first [small prototype within a script](http://groovyconsole.appspot.com/script/5686306919153664), but I used an injected local transformation to get everything working with a simple script. So I decided afterwards to do it for real this time, using a real [project on Github](https://github.com/glaforge/disable-grab-sample/) with a proper global AST transformation this time.  

If you checkout the project from Github, with:

```bash
git clone git@github.com:glaforge/disable-grab-sample.git
```

You then 'cd' in the disable-grab-sample directory, and you can run the following command to launch the Spock test showing the transformation in action:

```bash
./gradlew test
```

So what's inside that project? First of all, we need to create our AST transformation (I'll skip the imports for brevity):

```groovy
@GroovyASTTransformation(phase = CompilePhase.CANONICALIZATION)
class DisableGrabTransformation implements ASTTransformation {
    void visit(ASTNode[] nodes, SourceUnit source) {
        def imports = source.AST.imports
        
        if (imports) {
            imports.each { anImport ->
                anImport.annotations.each { anno ->
                    if (anno.classNode.name in ['groovy.lang.Grab', 'groovy.lang.Grapes']) {
                        source.errorCollector.addError(
                            new SyntaxErrorMessage(
                                new SyntaxException('@Grab and @Grapes are forbidden',
                                anImport.lineNumber, anImport.columnNumber), 
                            source))
                    }
                }
            }
        }
    }
}
```

We create a class implementing the ASTTransformation class with its visit() method. In that method, we access the "module" imports, and if there are any import, we iterate over each of them, checking if there are annotations put on them. If those imports are annotated with @Grab or @Grapes (ie. if the annotation class node's fully qualified class name are the FQN of the Grab and Grapes annotations), we then use the error collector to add a new syntax error, so that a compilation error is thrown by the Groovy compiler if ever someone uses @Grab in a Groovy script or class.  

We need to wire in that [global transformation](http://groovy.codehaus.org/Global+AST+Transformations). As they are not triggered by annotations like local transformations, we need do declare the transformation in a specific META-INF / services / org.codehaus.groovy.transform.ASTTransformation file, that will just contain one line: the fully qualified class name of the AST transformation that needs to be applied to each script and classes that will be compiled when this transformation is on the classpath. So our services file will just contain:

```
disablegrab.DisableGrabTransformation
```

Now we need to see if our transformation is applied, and works as expected. For that purpose, we'll create a [Spock](http://spock-framework.readthedocs.org/en/latest/) test:

```groovy
class DisableGrabSpec extends Specification {
    def "test"() {
        given:
        def shell = new GroovyShell()
        when:
        shell.evaluate '''
            @Grab('org.apache.commons:commons-lang3:3.3.2')
            import org.apache.commons.lang3.StringUtils
            println "hi"        
        '''
        then:
        def e = thrown(MultipleCompilationErrorsException)
        e.message.contains('@Grab and @Grapes are forbidden')
    }
}
```

We are using the GroovyShell class to evaluate (and thus compile) a script that contains a @Grab instruction. When evaluating that script, a compilation error should be thrown, and we indeed assert that it's the case, and that our compilation error contains the message we've crafted.  

Done!  

Let's step back a little with a couple words about our build file:

```groovy
apply plugin: 'groovy'

repositories {
    jcenter()
}

dependencies {
    compile 'org.codehaus.groovy:groovy-all:2.3.6'
    testCompile 'org.spockframework:spock-core:0.7-groovy-2.0'
    testCompile 'org.apache.ivy:ivy:2.4.0-rc1'
}
```

Not much to see here actually! We're just applying the groovy plugin, use the [jcenter](https://bintray.com/bintray/jcenter) repository from Bintray. We're using Groovy-all, the Spock library for our test scope, as well as the Ivy library that's needed by the grape infrastructure for fully functioning, for retrieving artifacts.  

With our Gradle build file, we can call the jar task to create a JAR that will contain the META-INF/services file, and as soon as you'll have that JAR on your classpath with that AST transformation, any script or class compiled with it will get compilation errors if @Grab is used.
# Groovy Weekly #33


You probably remember Groovy and Gradle being selected in RebelLabs’ report as part of the 10 “kick-ass” technologies developers love? But I’m also happy to report that [Groovy won the Geek Choice Award]({{< ref "/posts/2014/08/01/groovy-receives-geek-choice-award" >}}), showing how groovy Groovy is!

GR8Conf US 2014 last week is delivering tons of [great videos and materials](https://www.youtube.com/channel/UC7wUp2KIa1hoMNn0r7JUVEg) from all the speakers that came to the conference, and I hope you’ll find time to watch a few. My personal highlight was the great Q&A talk by Scott Hickey and Jim McGill on looking back into [9 years of using Groovy at a big US insurance company](https://www.youtube.com/watch?v=CvpxRoLEq7M). Don’t miss it!

Also, if you missed GR8Conf US 2014, remember there’s [SpringOne2GX](http://springone2gx.com/) fast approaching, and the [early bird price for registering to the conference ends August 9th](https://2014.event.springone2gx.com/register), so be quick!

Last but not least, the Groovy Weekly schedule will slow down a little this month, as I’ll take some vacations! So I might be skipping a beat or two in the agenda, but fear not, Groovy Weekly will come back in full force in September!

## Releases

*   [Grails 2.4.3](https://grails.org/2.4.3+Release+Notes) is out
*   [Ratpack 0.9.7](http://www.ratpack.io/versions/0.9.7) released, with the new Groovy markup template engine, continued work on Reactive Streams, usage of the Gradle Shadow plugin
*   Renato Athaydes is releasing [v1.2 of the Spock reports](https://groups.google.com/forum/#!msg/spockframework/RzXOqfw4OD0/ZoJsL8VTnmgJ) project

## News

*   [Groovy wins Geek Choice Award]({{< ref "/posts/2014/08/01/groovy-receives-geek-choice-award" >}}), following up RebelLabs study of the 10 kick-ass technologies developers love
*   Jacob Aae Mikkelsen published [week 31 of the Grails Diary](http://grydeske.net/news/show/55)

## Articles

*   A tutorial for a [REST / grid-driven application with Ratpack, Angular.JS and CoffeeScript](http://wordpress.transentia.com.au/wordpress/2014/07/04/livin-on-the-grid/), as well as a comparison with Grails
*   A [demo using Groovy, Ratpack, the Gradle plugin, and GrooScript](http://grooscript.org/ratpack-demo.html)
*   Robert Peszek writes that [he doesn't like Hibernate and Grails](http://rpeszek.blogspot.fr/2014/08/i-dont-like-hibernate-and-grails-part-1.html) in part one
*   Robert Peszek continues in part two with the [problems he encounters with Hibernate and Grails](http://rpeszek.blogspot.fr/2014/08/i-dont-like-hibernategrails-part-2.html)
*   Getting started guide with [Grails on App42 platform as a service](http://app42paas.shephertz.com/dev-center/grails-platform-as-a-service/)
*   Andrés Almiray comes back on [Jacoco and Coveralls in his Gradle Glam series](http://www.jroller.com/aalmiray/entry/gradle_glam_jacoco_coveralls_take)
*   MrHaki's Groovy goodness: [Relax... Groovy Will Parse Your Wicked JSON](http://mrhaki.blogspot.fr/2014/08/groovy-goodness-relax-groovy-will-parse.html)
*   MrHaki’s Grails goodness:
    *   [use Spring Java configuration](http://mrhaki.blogspot.fr/2014/08/grails-goodness-use-spring-java.html)
    *   [using Bintray JCenter as repository](http://mrhaki.blogspot.fr/2014/08/grails-goodness-using-bintray-jcenter.html)
    *   [load beans in Java configuration based on Grails environment](http://mrhaki.blogspot.fr/2014/08/grails-goodness-conditionally-load.html)
*   JaxEnter comes back on the [Gradle 2 release and the interview they made with Guillaume Laforge](http://jaxenter.com/gradle-2-0-is-here-sleek-speedy-and-supporting-java-8-50707.html) at the JAX conference
*   [Static site generation with Grain](http://www.objectpartners.com/2014/07/29/static-website-generation-in-groovy/) by Mike Hostetler
*   [Meta-Object Protocol and interceptors In Grails](http://www.oodlestechnologies.com/blogs/Metaobject-Protocol-%26-Interceptors-In-Grails) by Jasgeet Singh
*   [Grails unit test filters with the injected service](http://www.intelligrape.com/blog/2014/08/04/grails-unit-test-filters-with-the-injected-service/)

## Presentations

*   Julien Viet on [CRaSH](http://www.youtube.com/watch?v=ZRQwZfP2uIc&feature=youtu.be&a), the shell for the Java Virtual Machine, recorded at GR8Conf Europe 2014
*   GR8Conf US 2014 specials
    *   The [GR8Conf US 2014 videos](https://twitter.com/gr8confus/status/494856150261567489) will appear progressively on YouTube and the slides on Github
    *   A look back at the [9 years of Groovy at the Mutual of Omaha insurance company](https://www.youtube.com/watch?v=CvpxRoLEq7M) by Scott Hickey and Jim McGill
    *   The now famous [Groovy Puzzlers](http://fr.slideshare.net/GroovyPuzzlers/the-groovy-puzzlers-gr8-conf-us-2014) talk by Baruch Sadogursky and Andrés Almiray
    *   Guillaume Laforge published his slide deck about "[Groovy in 2014 and beyond](https://speakerdeck.com/glaforge/groovy-in-2014-and-beyond-at-gr8conf-us-2014)"
    *   The [Grails asset pipeline](https://www.youtube.com/watch?v=A17geQa5WQc) by Ted Naleid
    *   [Groovy Vampires: Groovy, REST, NoSQL](https://www.youtube.com/watch?v=fhGRLFLamN8) and Bad Marketing by Ken Kousen
    *   [Experiences using Grails in a micro-service architecture](https://www.youtube.com/watch?v=wF8gjfh0Kyw) by Jeff Beck
    *   [Hibernate metrics: paying attention to the ORM behind the curtain](https://www.youtube.com/watch?v=_cdb7zYNEFg&feature=youtu.be) by David Kuster
    *   [Spock, a logical framework for enterprise testing](https://www.youtube.com/watch?v=i28F13zZwlg&feature=youtu.be) by Ken Kousen
    *   [Functional testing your Grails app with Geb](https://www.youtube.com/watch?v=VvTxOwYsj88) by Collin Harrington
    *   [Vagrant](https://www.youtube.com/watch?v=-WQGIZ90H2w&list=UU7wUp2KIa1hoMNn0r7JUVEg) by Kyle Boon at GR8Conf US 2014
    *   [Introduction to graph databases and Neo4J](https://www.youtube.com/watch?v=8W8F9zVmwDs) by Stefan Armbruster
    *   [Polyglot web programming with Grails](https://www.youtube.com/watch?v=KFz0n7NLXJA) by Jeff Brown
    *   [Angular.JS for the Grails enthusiast](https://www.youtube.com/watch?v=ObbQw6_VbWs) by Will Buck
    *   [Fine-grained security in Grails](https://www.youtube.com/watch?v=IGgsARk8BGE&feature=youtu.be) presented by Andrew Miller

## Google+ posts

*   The Groovy [markup template engine used as an alternative Magnolia CMS renderer](https://plus.google.com/u/0/100991326727521012956/posts/BzRTzUjRinF?cfem=1)

## Tweets

*   [GVM has passed 60,000 unique installs](https://twitter.com/gvmtool/status/494515638669705216)!
*   Backward and binary compatibility is an important concern for the Groovy project, and Cédric Champeau just developed a [Gradle plugin integrated in the Groovy build to create reports of binary compatibility](https://twitter.com/cedricchampeau/status/494457760986456064) between Groovy versions
*   [Grails 2.4.3](https://twitter.com/gvmtool/status/494482701567528960) available through GVM
*   [Groovy 2.4.0-beta-2](https://twitter.com/gvmtool/status/494827442641833984) available through GVM
*   The [Ratpack project publishes its test coverage](https://twitter.com/ratpackweb/status/494957092474605570) and ask for help for improving it
*   David Norton asks the question: [how many actuaries in the world can put Groovy on their résumés](https://twitter.com/davidnortonjr/status/494197093524054017)?
*   [Ratpack reminds us its got a forum](https://twitter.com/ratpackweb/status/494985575863050240) for user support
*   Senthil Gopal really [enjoyed the Groovy puzzlers](https://twitter.com/sengopal/status/495593355032555521) by Baruch Sadogursky and Andrés Almiray at GR8Conf US 2014
*   The [JavaFX FXPlayground has added support for Groovy](https://twitter.com/javafxpert/status/495921622730018816)
*   Andrés Almiray remarks the [ongoing growth of Griffon plugins](https://twitter.com/aalmiray/status/496391849356300289)
*   Robert Guerra is [having fun with Ratpack and ElasticSearch](https://twitter.com/robertoguerra19/status/496309476933517312)
*   Discussing with Robert Fletcher reminded us of [Groovy Koans](https://twitter.com/rfletcherew/status/496636379485728768), for getting acquainted with Groovy
*   The [Ratpack.io website is powered by the Groovy markup template engine](https://twitter.com/lspacewalker/status/496640143097626624)
*   Andrés Almiray is using the [Gradle Git plugin](https://twitter.com/aalmiray/status/496759565309186048) to easily push content to Github's pages

## Code snippets

*   Laurent Huet shows how to get the [list of twitter followers with Groovy and the Twitter4J](https://gist.github.com/lhuet/9cc05bab4417c0f1026f) library
*   Jack Holt created a [Spring MVC 4 demo using Groovy](https://bitbucket.org/jackcholt/spring4hw)

## Events

*   [Early bird for SpringOne2GX 2014 ends August 9th](https://2014.event.springone2gx.com/register), be quick!
*   [Bagalore Groovy meetup](http://www.meetup.com/Bangalore-Groovy-Grails-Meetup/) next saturday
# Groovy receives Geek Choice Award


![](/img/misc/Geek-Choice-Awards-JVM-Language-300x300-black.png)

[RebelLabs](http://zeroturnaround.com/rebellabs/) launched an annual study and awards to select 10 "kick-ass" technologies that developers love, and both Gradle and Groovy were among the winners!

You can learn more about this ["kick-ass" technology study](http://pages.zeroturnaround.com/Kickass-Technologies.html) in the PDF report they crafted and which can be downloaded there (form filing required to download the PDF).

Details are available for:

*   [Groovy](http://zeroturnaround.com/rebellabs/10-kick-ass-technologies-modern-developers-love/4/)
*   [Gradle](http://zeroturnaround.com/rebellabs/10-kick-ass-technologies-modern-developers-love/3/)

It's always nice to see such reports and awards recognizing the great work and energy the Groovy and Gradle teams have been put into developing those technologies, and making developers around the world delighted to work with them.
# Groovy Weekly #32


Live from GR8Conf US 2014, in Minneapolis, MN, USA! The code samples and slides of presentations are already flowing and are listed below in the presentations section. Lots of great content and talks to learn from.

## Releases

*   Andrés Almiray [released Griffon 2.0.0-rc-1](http://griffon-user.3225736.n2.nabble.com/ANN-Griffon-2-0-0-RC1-released-td7578844.html) live on stage at GR8Conf US 2014, along with the announcement of the [new Griffon website](http://new.griffon-framework.org/)
*   Cédric Champeau announces the [releases of Groovy 2.3.6 and Groovy 2.4.0-beta-2](http://groovy.329449.n5.nabble.com/ANN-Groovy-2-3-5-released-and-upward-compatibility-td5720557.html#a5720571)
*   Guillaume Laforge announced [Groovy 2.3.5 with upward compatibility]({{< ref "/posts/2014/07/25/groovy-2-3-5-out-with-upward-compatibility" >}})
*   Cédric Champeau released [v0.3.0 of the Gradle Groovy Android plugin](https://twitter.com/cedricchampeau/status/492594605003902976), allowing you to support Android libraries
*   Cédric Champeau announces [v0.1.2 of the JMH Gradle plugin](https://twitter.com/cedricchampeau/status/493493646940184576)
*   Kunal Dabir released [Glide 0.3.3](http://glide-gae.appspot.com), with upgraded dependencies, and more goodness for Windows
*   Cédric Champeau releases a [Japicmp Gradle plugin](https://github.com/melix/japicmp-gradle-plugin) to compare binary compatibility between JAR binaries
*   [Gradle Shadow plugin 1.0.3](https://twitter.com/johnrengelman/status/494228881155424256) released
    
## News

*   [ElasticSearch using Groovy scripting by default](http://www.elasticsearch.org/blog/elasticsearch-1-3-0-released/)
*   The [new Griffon website](http://new.griffon-framework.org/index.html) is online!
*   Dan Woods is contributing an [Apache Camel module for Ratpack](https://github.com/ratpack/ratpack/pull/395)
*   Jacob Aae Mikkelsen published [Grails Diary](http://grydeske.net/news/show/54), week 30

## Articles

*   Ryan Vanderwerf on [getting started with programming with Groovy on Lego Mindstorms](http://rvanderwerf.blogspot.com/2014/07/lego-mindstorms-ev3-lejos-and-groovy.html) EV3
*   Andrés Almiray's [Gradle Glam: JaCoCo + CoverAlls](http://www.jroller.com/aalmiray/entry/gradle_glam_jacoco_coveralls)
*   [NullObject pattern implementation](http://solidsoft.wordpress.com/2014/06/05/null-object-pattern-implementation-in-groovy-a-map-with-default-behavior/) in Groovy, a map with default behavior, by Marcin Zajączkowski
*   John Ferguson Smart wrote about data-driven testing with JUnit and highlighting [Spock's data-driven approach](https://weblogs.java.net/blog/johnsmart/archive/2014/07/23/data-driven-unit-testing-java)
*   Guide showing how to use [Grails' REST support from GSPs using GrooScript](http://grooscript.org/grails-plugin/rest-demo.html)
*   Craig Burke writes about [Grails, Angular.JS and the Asset pipeline](http://www.craigburke.com/2014/07/24/angular-grails-asset-pipeline.html)
*   Andrés Almiray shows how to [test JavaFX services, the Griffon way](http://www.jroller.com/aalmiray/entry/how_to_test_javafx_services1)
*   Juan Vazquez wrote about adding map / filter / reduce [method aliases with a Groovy extension module](http://javazquez.com/juan/2013/02/05/add-map-reduce-and-filter-to-groovy-with-groovy-extension-modules/)
*   André Steingreß explained how to create your own [Groovy type checking extensions](http://blog.andresteingress.com/2013/01/25/groovy-2-1-type-checking-extensions/)
*   [WebSocket support with GrooScript within Grails](http://grooscript.org/grails-plugin/websocket-support.html) applications
*   [Email tracking with MailGun in a Grails](http://www.intelligrape.com/blog/2014/07/24/email-tracking-using-mailgun-with-grails-application/) application
*   [Jsoup for the Grails soul](http://www.intelligrape.com/blog/2014/07/24/jsoup-for-the-grails-soul/)
*   A [Gradle tutorial series](http://rominirani.com/2014/07/28/gradle-tutorial-series-an-overview/)
*   Gradle Tutorial: Part 1 — [Installation + Setup](http://rominirani.com/2014/07/28/gradle-tutorial-part-1-installation-setup/)
*   Gradle Tutorial: Part 2 — [Java Projects](http://rominirani.com/2014/07/28/gradle-tutorial-part-2-java-projects/)
*   Gradle Tutorial: Part 3 — [Multiple Java Projects](http://rominirani.com/2014/07/29/gradle-tutorial-part-3-multiple-java-projects/)
*   [InfoQ on ElasticSearch using Groovy for scripting](http://www.infoq.com/news/2014/07/elasticsearch-1-3-0)

## Presentations

*   Cédric Champeau demonstrates the [Groovy support for developing Android applications](http://www.youtube.com/watch?v=AebkFsfcuDg&feature=youtu.be&a)
*   Jeff Beck published his GR8Conf US 2014 [Ratpack intro presentation and code](https://github.com/beckje01/ratpack-subscription-api)
*   Colin Harrington published his GR8Conf US 2014 presentation slides on [how to test your Grails application](http://slides.com/colinharrington/how-to-test-your-grails-application#/)
*   Colin Harrington on [functional testing your Grails apps with Geb](http://slides.com/colinharrington/functional-testing-your-grails-app-with-geb--2#/), at GR8Conf US 2014
*   Ryan Vanderwerf on [getting Grails / Groovy into the enterprise](https://twitter.com/ryanvanderwerf/status/493895466480717825), at GR8Conf US 2014
*   Ted Naleid on us[ing the Grails Asset pipeline](https://speakerdeck.com/tednaleid/using-grails-asset-pipeline-plugin), presented at GR8Conf US 2014
*   [Performance tuning Grails applications](http://www.slideshare.net/lhotari/performance-tuning-grails-applications-applications-gr8-confus) by Lari Hotari at GR8Conf US 2014
*   [Fine-grained security](https://github.com/onetribeyoyo/fine-grained-security) by Andy Miller at GR8Conf US 2014
*   [Grails 3 and Ratpack, Micro-services](http://fr.slideshare.net/lhotari/ratpack-and-grails-3-gr8confus), and more, by Lari Hotari, at GR8Conf US 2014
*   [GR8Conf US 2014 slides and samples](https://twitter.com/gr8confus/status/494255220654764032) are being collected on Github

## Mailing-list posts

*   Interesting thread on the Groovy user list about [Groovy performance, advocating Groovy vs Java](http://groovy.329449.n5.nabble.com/Advocating-Groovy-vs-Java-td5720573.html), and more

## Tweets

*   How [Target is embracing Groovy](https://twitter.com/targetcareers/status/494156672420831232)
*   [Highlight.js now supports Groovy syntax highlighting](https://twitter.com/highlightjs/status/492421799410282496)
*   Guillaume Laforge contributed a [Groovy logo for the devicons font](https://twitter.com/glaforge/status/492206420017049600)
*   [Vert.x 2.1.2](https://twitter.com/gvmtool/status/492244790101426176) is available through GVM
*   Angel Ruiz likes Java 8 streams but [loves Tim Yates' Groovy streams](https://twitter.com/aruizca/status/492551332218159104) even more
*   [Glide 0.3.3](https://twitter.com/gvmtool/status/493004971810762752) available through GVM
*   [Groovy 2.3.5](https://twitter.com/gvmtool/status/493042458318864384) available through GVM
*   Jeff Beck suggests to [use GVM and Lazybones for getting started with Ratpack](https://twitter.com/sheetsj/status/493841650217545728)
*   A new Groovy-related account to follow on Twitter with [Groovy puzzlers](https://twitter.com/groovypuzzlers/status/493821368157220865)
*   Ken Kousen showed the nice [Grails url-mapping-reports command](https://twitter.com/rfletcherew/status/494138116043997184) on stage
*   Rob Fletcher claims [Ratpack is your gateway drug to non-blocking](https://twitter.com/elanorriley/status/494205248500555778)
*   Thanks to the GR8Ladies work, we're seeing [more women participating to GR8Conf](https://twitter.com/wmacgyver/status/494234801348812801)
*   Scott Hickey is still [impressed, amazed and appreciative of the Groovy community](https://twitter.com/jshickey/status/494263654166982657) after 9 years of using Groovy in various enterprise projects

## Code snippets

*   Andrés Almiray shows how to [aggregate JaCoCo reports in a multi-project Gradle build](https://gist.github.com/aalmiray/e6f54aa4b3803be0bcac)
*   Luke Daley adds [test support for async support in Ratpack](https://github.com/ratpack/ratpack/blob/master/ratpack-test/src/test/groovy/ratpack/test/exec/ExecHarnessSpec.groovy#L27)
*   Andrey Hihlovskiy shows a snippet [removing parts of a string with regular expressions](https://twitter.com/andreyhihlovski/status/492930646252457984)
*   Cédric Champeau shows an example [usage of the Groovy Android Gradle plugin with an Android library](https://twitter.com/cedricchampeau/status/492611846953005056)
*   MrHaki’s GR8Conf US 2014 G\* Goodness talks’ samples:
    *   [code samples of his Gradle Goodness presentation](https://github.com/mrhaki/gr8conf2014us-gradle-goodness)
    *   [code samples of his Grails Goodness presentation](https://github.com/mrhaki/gr8conf2014us-grails-goodness)
    *   [code samples of his Groovy Goodness presentation](https://github.com/mrhaki/gr8conf2014us-groovy-goodness)
*   Erik Pragt shares a snippet of code showing [exceptions implementing a no-stacktrace trait to make exceptions fast and cheap](https://gist.github.com/bodiam/2ab1b98a1abb33f5ba1b)

## Books

*   [Grails in Action, 2nd edition, is available in epub and kindle formats](https://twitter.com/ManningBooks/status/492749460603432960)

## Events

*   [Early bird for SpringOne2GX is ending on August 9th](https://2014.event.springone2gx.com/register)

## Jobs

*   [Target is hiring Groovy developers](https://twitter.com/danveloper/status/494214232343203840)
# Groovy 2.3.5 out with upward compatibility


The Groovy team is pleased to announce the release of Groovy 2.3.5.

Groovy 2.3.5 is a bug fix release of our Groovy 2.3 branch.

You’ll find fixes for static compilation and type-checking, JSON serialization issues, markup template engine errors, and performance improvements.

We care a lot about backward and binary compatibility, but in this release, we also thought about upward compatibility, so that code compiled with a newer version can even run on an older runtime.

So we leveraged this version to add a new artifact, named groovy-backports-compat23. This artifact shouldn’t be necessary for most of you, but if you face an error like:

```
Caused by: java.lang.ClassNotFoundException: org.codehaus.groovy.runtime.typehandling.ShortTypeHandling
  at java.net.URLClassLoader$1.run(URLClassLoader.java:372)
```

in your project, then it means that a class has been compiled with Groovy 2.3+ but that you are trying to use it with an older version of Groovy. By adding this jar on classpath, you give a chance to your program to run. This may be particularily interesting for Gradle users that want to use a plugin built on Gradle 2+ on older versions of Gradle and face this error. Adding the following line to their build files should help:

```groovy
buildscript {  
    // ...  
    dependencies {  
        classpath 'some plugin build on gradle 2'  
        classpath 'org.codehaus.groovy:groovy-backports-compat23:2.3.5'  
    } 
}
```


Note that for now, this jar only contains the ShortTypeHandlingClass. Future versions may include more.


You can download Groovy 2.3.5 here:
[http://beta.groovy-lang.org/download.html](http://beta.groovy-lang.org/download.html)


The detailed JIRA release notes can be found here:
[https://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=20491](https://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=20491)
# Groovy Weekly #31


The news keep flowing even in the summer!

It’s probably not new to you, my readers, but Groovy and Grails are kick-ass technologies, as reported by the RebelLabs report.
  
And did you know that Groovy is now the default scripting technology in the popular ElasticSearch? Or used by Jenkins in its Job DSL?

We even have rumors, with the potential acquisition of Groovy-powered SmartThings IoT platform by Samsung!

We also have more videos available of presentations from GR8Conf Europe, to prepare yourself for those who are attending GR8Conf US next week! See you there!

## Releases

*   [Groovy Eclipse 2.9.0](https://github.com/groovy/groovy-eclipse/wiki/Groovy-Eclipse-2.9.0-Release-Notes) released
*   [Spring Framework 4.1 RC](https://spring.io/blog/2014/07/21/spring-framework-4-1-release-candidate-available) is out with Spring Web MVC support for Groovy markup templates
*   Andrés Almiray created a [Gradle Stats plugin](https://github.com/aalmiray/stats-gradle-plugin) to gather some metrics on your project
*   Andy Wilkinson released a plugin to [add Maven-like dependency management to Gradle](https://github.com/spring-gradle-plugins/dependency-management-plugin)
*   New version of the [GrooScript Grails 2.4 plugin](https://twitter.com/grooscript/status/491538345265491969)

## News

*   Rebel Labs selects [Groovy and Gradle in their 10 kick-ass technologies](http://zeroturnaround.com/rebellabs/10-kick-ass-technologies-modern-developers-love/) developers love
*   [ElasticSearch's default scripting engine is now Groovy](https://twitter.com/robertoguerra19/status/491246418137714688)
*   Guillaume Laforge worked on making the [future Groovy website fully responsive](http://beta.groovy-lang.org/)
*   Rumor has it that Internet of Things startup [SmartThings using Groovy for orchestrating "things" in talks to be acquired by Samsung](http://gigaom.com/2014/07/15/if-samsung-buys-smartthings-its-a-win-for-both/) for $200 million
*   A Gradle plugin to [bundle MacOS X applications of your Groovy / Java project](https://code.google.com/p/gradle-macappbundle/)
*   [Grails just crossed the 1000 stars on Github](https://github.com/grails/grails-core), still time to star it!
*   Jacob Aae Mikkelsen is back with the [Grails Diary](http://grydeske.net/news/show/53)!
    
## Articles

*   Cédric Champeau describes the [technical details of the new Groovy website](http://melix.github.io/blog/2014/07/new-groovy-website.html)
*   DrDobbs features an article by Benjamin Muschko on [writing build scripts with Gradle](http://www.drdobbs.com/open-source/writing-build-scripts-with-gradle/240168648)
*   Andrés Almiray inaugurates a series of blog posts on cool Gradle plugins, starting with the [versions Gradle plugin](http://www.jroller.com/aalmiray/entry/gradle_glam_versions)
*   André Steingreß on [JUnit rules with Spock](http://blog.andresteingress.com/2014/07/22/spock-junit-rules/)
*   The [Java magazine mentions Groovy](http://www.oraclejavamagazine-digital.com/javamagazine/july_august_2014/?sub_id=BUXrE7pqvqBhE&folio=67#pg68) in two articles, one on JavaFX showing how neat GroovyFX is, and the other on cool aspects of various alternative languages
*   Peter Ledbrook explains how to [add Spring Security users in bulk in your Grails](http://blog.cacoethes.co.uk/groovyandgrails/adding-spring-security-users-in-bulk-in-grails) application
*   Rob Fletcher looks into [Groovy closures and field visibility](http://blog.freeside.co/2014/07/21/closures-and-field-visibility/)
*   The Gretty project can now [generate runnable products](http://akhikhl.github.io/gretty-doc/Product-generation.html)
*   Using [Spring events in Grails](http://www.intelligrape.com/blog/2014/07/17/using-spring-events-in-grails/) by Madhave Khanna
*   Craig Atkinson blogs about [Grails API functional testing](http://www.objectpartners.com/2014/07/15/grails-api-functional-testing/)
*   Marco Pas details an issue when [migrating from Grails 2.3.8 to 2.4.2](http://mpas.github.io/post/2014/07/upgrade-grails-2.4.2/)
*   Igor Shults illustrates [Groovy’s with() and multiple assignments](http://www.objectpartners.com/2014/07/09/groovys-with-and-multiple-assignment/)
*   Ravi Kumar on the [importance of the Grails asset pipeline](http://www.oodlestechnologies.com/blogs/Importance-of-Grails-asset-pipeline-plugin)
*   Archna Dhingra writes about [ways to access grailsApplication in Grails](http://www.oodlestechnologies.com/blogs/Ways-to-access-grailsApplication-in-Grails-Project)
*   [Create default data and test data the easy way using fixture and build test data plugins](http://www.oodlestechnologies.com/blogs/Create-Default-Data-and-Test-Data-the-Easy-Way-Using-Fixture-and-Build-Test-Data-plugins) by Ankit Nigam
*   Shiv kumar explains how to [use handlebars in Grails](http://www.oodlestechnologies.com/blogs/How-to-use-handlebars-in-grails)
*   Using the [Drools Planner from Grails](http://www.oodlestechnologies.com/blogs/Drools-Planner-Example-using-Grails) by Alok Kumar Swain

## Presentations — GR8Conf Europe 2014

*   [Cut your Grails application to pieces, build feature plugins](https://www.youtube.com/watch?v=LZQ-1f9RGqg&feature=youtu.be&a), by Göran Ehrsson
*   [Micro-service architecture with Spring Boot, Groovy](https://www.youtube.com/watch?v=4LLQeMcFUpY&feature=youtu.be&a) and friends, by Marco Vermeulen
*   [Functional testing your Grails apps with Geb](https://www.youtube.com/watch?v=McFoNTKD8Q0&feature=youtu.be&a), by Collin Harrington
*   [Performance tuning Grails applications](https://www.youtube.com/watch?v=d_w7v-Cy8q4&feature=youtu.be&a), by Lari Hotari, at GR8Conf Europe 2014

## Tweets

*   Cédric Champeau claims that [if Netflix can use Groovy, you can too](https://twitter.com/cedricchampeau/status/489316376696598528)!
*   Kohsuke Kawaguchi invites us to play in the playground of the [Groovy-based Jenkins job DSL plugin](https://twitter.com/kohsukekawa/status/489333038573039617)
*   Cédric Champeau reminds us about the creation of a [HipChat public channel for Groovy](https://twitter.com/cedricchampeau/status/489310387272421376) if you want to chat with Groovy users and developers
*   Marco Vermeulen realizes that [Spring Boot supports Spock for testing](https://twitter.com/marcovermeulen/status/491232279008911361) out of the box
    
## Code snippets

*   Michael van Niekerk created a [proof of concept running a Groovy application on iOS](https://github.com/mvniekerk/GradleGroovyRobot)
*   The [2048 web game developed with GrooScript](https://twitter.com/grooscript/status/489190810282643456)
*   Cédric Champeau shares a snippet to [dump the AST transformations being used](https://gist.github.com/melix/628b2f04f83f7f9721b8)
*   Guillaume Laforge is contributing [Groovy syntax highlighting support to the Highlight.js](https://github.com/isagalaev/highlight.js/pull/512/files) JavaScript syntax highlighting library
*   Danny Hyun created a ["pixel service" with Ratpack](https://github.com/danhyun/ratpack-pixel-service) for user tracking

## Events

*   [JFrog is a sponsor of GR8Conf US](https://twitter.com/gr8confus/status/491629430700535809) next week
# Groovy Weekly #30


The [new Groovy website](http://beta.groovy-lang.org/) announced last week keeps on improving, thanks to your feedback and already many contributions through pull requests on Github!

To wet your appetite for GR8Conf US 2014 at the end of the month, we also have more GR8Conf Europe 2014 videos published last week!

## Releases

*   [Groovy Grails ToolSuite 3.6.0 out with Groovy 2.3 and Grails 2.4](https://twitter.com/martinlippert/status/487631673836965888) support on Eclipse 4.4
*   [GrooScript 0.5.2](https://twitter.com/grooscript/status/488453854032560128) is out
*   The [Windows installer for Groovy 2.3.4](http://beta.groovy-lang.org/download.html) is available thanks to Joachim Baumann
*   Andrés Almiray released the [Asciidoctor Gradle plugin v0.7.3](https://twitter.com/aalmiray/status/487255344234905600) which is compatible with JDK 6+

## News

*   Kunal Dabir created an “[awesome-groovy](https://github.com/kdabir/awesome-groovy)” Github project providing a curated list of interesting Groovy-based projects

## Articles

*   Benjamin Muschko explains [why build your Java projects with Gradle](http://www.drdobbs.com/jvm/why-build-your-java-projects-with-gradle/240168608) rather than Ant or Maven
*   Guillaume Laforge gathered the [feedback the team received about the new Groovy website]({{< ref "/posts/2014/07/13/feedback-and-actions-for-the-new-groovy-website" >}})
*   Roberto Guerra writes about [Ratpack's templates](http://blog.stumblingoncode.com/posts/2014-07-11-ratpack-templates.html)
*   [Use Gradle to switch a dependency from binary to source](http://www.sven-ehrke.de/asciidocblog/switch_dependencies_binary_source.html) mode and back, by Sven Ehrke
*   Grails Goodness by MrHaki
    *   [change response formats in RestfulController](http://mrhaki.blogspot.fr/2014/07/grails-goodness-change-response-formats.html)
    *   [custom controller class with resource Annotation](http://mrhaki.blogspot.fr/2014/07/grails-goodness-custom-controller-class.html)
    *   [using converter named configurations with default renderers](http://mrhaki.blogspot.fr/2014/07/grails-goodness-using-converter-named.html)
*   Pawel Oczadly reveals a Gradle tip: [set a different name for wrapper and the default build script](http://paweloczadly.github.io/dev/2014/07/09/gradle-set-different-name-for-wrapper-and-default-build-script/)

## Presentations — GR8Conf Europe 2014

*   Noam Tenne delivered a [fantastic Groovy puzzler talk](https://www.youtube.com/watch?v=GfIhxi7L6R0&feature=youtu.be&a)
*   Graeme Rocher talks about [Grails 3 and beyond](https://www.youtube.com/watch?v=NZH9n3s8Ai0&feature=youtu.be&a)
*   Andrés Almiray on [what's new and coming in Griffon](https://www.youtube.com/watch?v=hrM_AtD5eCw&feature=youtu.be&a)
*   Lari Hotari on [Grails 3 and Ratpack](https://www.youtube.com/watch?v=_JVeuC8R5BM&feature=youtu.be&a)
*   Peter Ledbrook guides you through [bootstrapping your projects with Lazybones](https://www.youtube.com/watch?v=pzZARB7SxdA&feature=youtu.be&a)
*   Jeff Brown shows you how you can do [polyglot web development with Grails 2](https://www.youtube.com/watch?v=L-sH9Bn9y_c&feature=youtu.be&a)

## Mailing-list posts

*   Dylan Bijnagte announces Spock-Genesis: [data generators for data-driven / property based testing with Spock](http://groovy.329449.n5.nabble.com/ANN-spock-genesis-initial-release-0-1-0-td5720402.html)

## Google+ posts

*   LinYuan Zheng launched an effort to [translate the Groovy documentation in Chinese](https://plus.google.com/b/113675159854671799959/106541219437002995923/posts/hcKBXa3tSkW?cfem=1)

## Tweets

*   Marco Vermeulen is looking for a [PaaS sponsor to host GVM](https://twitter.com/marcoVermeulen/status/488436820456525824)
*   Dan Woods measured [Ratpack's great stable performance at 52K requests/second](https://twitter.com/danveloper/status/488138482280189952) on a large Amazon EC2 instance
*   Cédric Champeau notices that in a matter of hours, the new [Groovy website project on Github received 3 pull requests](https://twitter.com/cedricchampeau/status/486627877656752128)
*   As noted by Vladimír Oraný, the ["improve the doc" button on the new Groovy web site makes it easy to contribute](https://twitter.com/musketyr/status/486739565265555456) improvements to the site
*   Andrés Almiray choses [JBake and Asciidoctor for the upcoming Griffon 2.0 website](https://twitter.com/aalmiray/status/486951644874432512)
*   Guillaume Laforge mentions a [dozen pull requests](https://twitter.com/glaforge/status/487323336876515329) in a day following the announcement of the beta version of the new Groovy website
*   Cédric Champeau published an updated [Android GR8Conf agenda application built with Groovy](https://twitter.com/CedricChampeau/status/488708268181954560) for GR8Conf US 2014
*   Cédric Champeau and Robert Fletcher [contrast Groovy traits and Java 8 default methods](https://twitter.com/CedricChampeau/status/488708437493420034)
*   The [Gr8Ladies website received a nice facelift](https://twitter.com/JennStrater/status/488511425548013568)
*   [Ratpack 0.9.7 will integrate with the Gradle Shadow plugin](https://twitter.com/ratpackweb/status/488650602230980608) for fat-jar-ing Ratpack apps
*   Eric MacAdie is using [Groovy Validator on immutable objects](http://www.macadie.net/2014/07/10/using-groovy-validator-on-immutable-objects/)

## Code snippets

*   Alexander Klein is exploring [Groovy builders for Android](https://github.com/karfunkel/grooid-playground)
*   Roberto Guerra shows to [authenticate with via Google OAuth for your Ratpack](https://github.com/uris77/ratpack-oauth-example) applications
    
## Books

*   Glen Smith is proud to have the [Grails in Action 2nd edition book](https://twitter.com/glen_a_smith/status/488602309123772419) in his hands for real
*   [Grails in Action 2nd edition is now available in print](https://twitter.com/manningbooks/status/487923316318277632)
# Feedback and actions for the new Groovy website


In this post, I'll sum up the feedback we've gathered through the mailing-lists, Twitter, Google+, blog comments, Github issues, regarding the release of the beta of the [new Groovy website](http://beta.groovy-lang.org/).

Overall, so far, the feedback has been very positive, and people are very excited about the fresher and more modern look of the website, as well as happy to find relevant information more easily in a couple of clicks.

But like anything, there are various aspects we can improve! Some ideas exposed below were already elements we already had on our roadmap, or on the back-burner as nice-to-have’s, but it’s worth sharing them here and comment on them.  

Also worth noting that in less than 12 hours after the announcement of the beta of the new website, we received several contributions on Github for fixing some typos or broken sentences, as well as some new content like a new book in the learn section.

## Responsive design

Although some elements of the design are responsive (with CSS media queries), various aspects of the site are clearly not responsive and don’t degrade well and display nicely on mobile devices like phones and tablets.

For example, the menu doesn’t shrink down into a menu widget like is pretty common nowadays, and it’s probably the reason why the width of text content containers also doesn’t shrink accordingly, letting the text become very small and unreadable on smaller screens.

## Concrete feedback mentioned:

*   scrolling lagging on mobile safari 
*   from the US the site appeared slow (our hoster is in Germany)
*   text too small on mobile devices
*   not fully responsive
    
Help needed from frontend-savy persons to help us:

*   improve the responsiveness of the screen for mobile devices
*   optimize the size so it loads and renders faster

Actions:

*   we can cache the fonts coming from Google Fonts and serve them from the website
*   decrease the size of pictures
*   use sprites for the logos (“they use Groovy”)
    
## Content improvements

Here are some suggestions for content that users would like to see.

### Getting started guide

We’re missing a “getting started guide” that would take users through the steps to download and install Groovy, and then showing them the basics of the language.

We could perhaps integrate a guide like the [getting started guide](http://gr8labs.org/getting-groovy/) from MrHaki.

Additionally, it would be nice if the samples in such a guide could be edited live, or played with by the readers. See next section on this topic.

Actions:

*   write a getting started guide distinct from the reference documentation for a fast-track learning approach

Possible improvements:

*   The website could also provide some introductions to the 6 key areas listed, that we could link directly from the front page:
    *   “flat learning curve” — mention how it’s familiar to Groovy developers
    *   “smooth Java integration” — mention how you can mix Groovy and Java together
    *   “vibrant and rich ecosystem” — perhaps just link to the “ecosystem” section
    *   “powerful feature” — perhaps lead to the “getting started guide” that would give a quick intro to those powerful features
    *   “domain-specific languages” — perhaps a link to the DSL user guide from the reference documentation or a simpler getting started page on the topic
    *   “scripting & test glue” — show some samples of how to use Groovy for command-line scripting / automation, and samples of readable tests (likely Spock)
    
### Interactive code samples

We received several related comments regarding the fact we’re missing code samples (apart from inside the documentation of course):

*   show code samples from the front page to show readers what Groovy looks like 
*   some kind of built-in terminal or shell where we could play with Groovy code in a sandbox in the browser
*   being able to run the code samples we display

Actions:

*   add code sample on the front page
*   add a built-in shell
    
## Missing blog

Currently, we don’t yet have a news or blog section in the website, as we haven’t yet decided how we would integrate that in the website. It’s important to be able to announce new releases, interesting articles, etc, to our community, beyond the mailing-lists or the social networks through which we usually communicate.

Actions:

*   decide what technical approach to take to offer news and posts in the website
*   implement / integrate the desired blogging approach
    
Possible future improvements:

*   also integrate the Groovy Weekly news as blog posts
    

## User groups

The Groovy user groups are clearly an important part of the success of Groovy and its community. The website currently doesn’t have a user group section as initially planned.

Actions:

*   add a new section in the community about user groups (2014-07-10)


Possible future improvements:

*   show an interactive map of the location of the various groups    
*   let user groups contribute calendar events that could be displayed in the events page

## Sponsors not listed

In the old website, we had some places where we could mention our sponsors, but the new website currently doesn’t mention them.

Existing sponsors of the project:

*   Pivotal — hire several Groovy core team members  
    The Pivotal logo is already present in the design, in the footer of the page.
*   JetBrains — provide us with free TeamCity and IntelliJ IDEA Ultimate licenses, and cover the cost of our server (hosting the CI server, the website, and the documentation)
*   JFrog — provide the Bintray and Artifactory OSS infrastructure for deploying our releases and snapshots
    
Actions:

*   see how we can integrate our sponsors, in the footer or in a dedicated section (2014-07-13)
    
## Videos

Interesting videos related to the Groovy project have been recorded at conferences like GR8Conf, Greach, SpringOne2GX and other Java-related conferences. Such videos could also be a key asset in the learning experience of Groovy users.

Actions:

*   add a video section in the learning area of the website
    
## Other ecosystem projects

The “ecosystem” page currently lists just a handful of well-known Groovy ecosystem projects. Other module / projects authors would be interested in appearing in that section as well. But the problem (in the old website for instance) is that often several small projects are not really alive anymore, and it gives a bad feeling about the state of the community overall.
  
Actions:

*   see how we can get additional / lesser-known projects up in the community section, perhaps with another page for contributed projects

Possible improvements:

*   see if we can integrate with an API like Ohloh’s which provide an indicator of project “health”, which could allow us to automatically list / remove projects which are not deemed healthy or need some more love
    
There are various indicators that we can take into account for evaluating the liveliness of a project:

*   its Ohloh health status mentioned above
*   the date of the latest commits
*   the date of the latest release
*   recent successful Travis / Jenkins / other CI build status
    
## Translations

Several persons mentioned their desire to have the documentation translated in other languages, and some even proposed their help.

On the technical side, we haven’t put anything in place neither for the website nor for the documentation to be able to provide translated website and documentation.

On the human side, I know it’s already difficult to even just finish the documentation, that I’m a bit doubtful that we will ever get to a point where all the documentation is also translated, and in “sync” with the English base documentation. Some efforts have been made historically on the Groovy website or Grails documentation, but none ever got to completion.

Possible future actions:

*   investigate how we can provide the technical infrastructure for authoring translations and publish them
    
## Usability

Apart from the important responsiveness aspect we’ve outlined already, there are other areas where we can improve the usability of the website.

## Subdomain usage

Currently, the website is in beta mode under the “beta” subdomain, and the documentation is also available through that subdomain as well as under “docs”.

Actions:

*   once the website exits the beta status, we’ll be able to have dedicated “www” and “docs” subdomains to clearly demarcate website and documentation (which is important for search, see below)

## Search

The search is powered by Google Custom Search and is even faceted so that users can search only mailing-list posts, JIRA issues, documentation, etc.

The faceted aspect can be improved a bit when we properly separate and finalize the subdomains, with “www” for the website and “docs” for the reference documentation.

Beside that, the main gripe is the fact that when a user clicks on a search result, the browser moves to that result page, but when the user tracks back to the previous page, the results are gone, showing blank search field and results — ie. the search results are lost.

Actions:

*   use target \_blank to open a new tab in the browser for the search results (2014-07-13)
    
## UI inconsistencies

The website and the reference documentation share a similar look’n feel, with the same fonts and colors, but there are still differences like the color of the links, the font size, the spacing between elements, etc.

Action:

*   futher work to homogenized both the website and the reference documentation

## Miscellaneous

Other feedback we’ve received and other ideas but not listed in the previous sections:  

*   The “definition” of what Groovy is might perhaps be a bit too long or complicated, as Groovy is by nature a “multi-faceted” language with different flavors (static / dynamic / optional typing, and OO / imperative / functional language)  
*   In the “they use Groovy” section
*   EADS is now actually the Airbus Group, so the logo could be changed (2014-07-10)
*   Best Buy are heavy users of Groovy and their logo could be added (2014-07-10)
*   Suggestion to use a different domain name, with .io, without dashes, etc.  
*   Add a sitemap.xml file to help with search engine indexing
# Groovy Weekly #29


Keywords for today: beta Groovy website, Gradle roadmap, GR8Conf presentations!

It’s a launch day! The launch of the beta of the Groovy website, mentioned in the news section (and also a bug fix release with Groovy 2.3.4).

In the article section, you’ll find the link to Hans Dockter’s latest post on the Gradle forums which details what you can expect from future Gradle versions, and it’s very promising: think performance, parallelization, caching, sharing and tooling!

In the presentation section, the GR8Conf Europe crew has been editing and publishing the videos of presentations given at last month conference in Denmark. So you have a few hours worth of Groovy content to watch! Also for those in the US, don’t forget that GR8Conf US is fast approaching, at the end of the month!

## Releases

*   Guillaume Laforge announces the [release of Groovy 2.3.4]({{< ref "/posts/2014/07/08/groovy-2-3-4-is-out" >}}), with further bug fixes in the anonymous inner class support and also compatibility between AST transformations and static compilation
*   The [third beta of Griffon 2.0](http://docs.codehaus.org/display/GRIFFON/2014/07/03/Griffon+2.0.0.BETA3+Released) is out
*   [Spring Boot 1.1.4](https://spring.io/blog/2014/07/08/spring-boot-1-1-4-released) released

## News

*   Guillaume Laforge announces the [beta of the new Groovy website]({{< ref "/posts/2014/07/08/a-new-groovy-website-in-beta" >}}), a project hosted on Github people can contribute to, built with Groovy and Gradle

## Articles

*   Hans Dockter reveals the upcoming plans for the [revolutionary features on the Gradle roadmap](http://forums.gradle.org/gradle/topics/revolutionary_new_gradle_features_on_the_2014_roadmap)
*   Robert Fletcher explains one of the [subtle differences in behavior between "dynamic Groovy" and statically compiled Groovy](http://blog.freeside.co/post/91127019156/compilestatic-and-polymorphic-method-dispatch) code in the case of multi-methods
*   Mark Perry's ongoing functional explorations with [Groovy applicatives](http://mperry.github.io/2014/07/02/groovy-applicatives.html)
*   Andrés Almiray explains how to [get started with Griffon and JavaFX](http://www.jroller.com/aalmiray/entry/getting_started_with_griffon_and)
*   Andrés Almiray delivers the second part of [Griffon and JavaFX](http://www.jroller.com/aalmiray/entry/getting_started_with_griffon_and1) article
*   Pawel Oczadly details how to [use variables and methods from another Gradle build](http://paweloczadly.github.io/dev/2014/07/03/gradle-how-to-use-variables-and-methods-from-another-gradle-file/) file
*   MrHaki's Grails Goodness: [enable accept header for user agent requests](http://mrhaki.blogspot.fr/2014/07/grails-goodness-enable-accept-header.html)

## Presentations — GR8Conf Europe 2014 videos

*   Alexander Klein on [Vert.x using Groovy](https://twitter.com/gr8conf/status/486086506608459780)
*   Andrés Almiray gives an [overview of the Groovy Ecosystem](https://twitter.com/gr8conf/status/485050696236929024)
*   Peter Ledbrook talking about [application architectures with Grails](https://twitter.com/gr8conf/status/485044283917885440)
*   Jeff Brown talks about [metaprogramming with the Groovy runtime](https://twitter.com/gr8conf/status/486085532137426944) (part 1 of 2)
*   Jeff Brown's second part on [metaprogramming with the Groovy runtime](https://twitter.com/gr8conf/status/486085531193708544) (part 2 of 2)
*   Marco Vermeulen on [BDD using Groovy and Cucumber](https://twitter.com/gr8conf/status/486425245717233664)
*   Grails and Devops, [continuous integration and delivery in the cloud](https://twitter.com/gr8conf/status/486424949058322432) by Benoît Hédiard
*   Guillaume Laforge on [Groovy in 2014 and beyond](https://twitter.com/gr8conf/status/485475403864104960)
*   Robert Fletcher demonstrates [hybrid client/server view rendering with Grails](https://twitter.com/gr8conf/status/485335393315717120)
*   Claus Ibsen on [integration with Apache Camel and Groovy](https://twitter.com/gr8conf/status/485166038510620672)
*   Jorge Franco Leza delves into [GrooScript, the Groovy to JavaScript transpiler](https://twitter.com/gr8conf/status/485160698205327360)

## Google+ post

*   Guillaume Barthe announces a [Google+ page dedicated to French-speaking Groovy and Grails users](https://plus.google.com/u/0/b/100737441520485064384/100737441520485064384/posts)
    
## Tweets

*   Cédric Champeau reveals that the [new Groovy website is making use of Groovy's new markup template engine](https://twitter.com/cedricchampeau/status/486583986979090432)
*   [Ratpack 0.9.7 will support Groovy 2.3's markup template engine](https://twitter.com/ratpackweb/status/484289839500513280)
*   In its latest update, Apple updated the range operator of the [Swift language to borrow again from Groovy with the ..< notation](https://twitter.com/practicalswift/status/486479638760140800) for ranges with excluded upper bound
*   Eric MacAdie works on a [Groovy validator project](http://www.macadie.net/2014/07/02/more-on-groovy-validation/)
*   Cédric Champeau [updated the GR8Conf Agenda Groovy / Android application](https://twitter.com/cedricchampeau/status/485360654266945536) to work with GR8Conf US 2014
*   The new Groovy documentation is built with Asciidoctor, and Dan Allen shows how this [Groovy documentation can be rendered in ePub format](https://twitter.com/mojavelinux/status/485197497594171392)
*   Yoav Landman mentions [enhancements in the Gradle Bintray plugin](https://twitter.com/_yoav_/status/485185270283657216) that will help auto-inclusion of Gradle plugins in the Gradle plugin portal
*   [Spring Boot 1.1.4](https://twitter.com/gvmtool/status/486585262580195328) available in GVM
*   [Groovy 2.3.4](https://twitter.com/gvmtool/status/486584287689719810) is available through GVM

## Code snippets

*   Paul Osborne shows a nice usage of [multiple assignment to split a date string](https://twitter.com/posbornet/status/484294950772023296) and fetch its mont and year elegantly
*   Andrés Almiray [contrasts a Griffon / JavaFX application written in Groovy and in Java](https://twitter.com/aalmiray/status/484778706339381248)
*   A new example [Ratpack application using GStorm for persistence](https://github.com/dbirtwell/trackmystuff_ratpack_with_db) by David Birtwell

## Events

*   More teasers for the [upcoming presentations at GR8Conf US 2014](https://storify.com/glaforge/more-gr8conf-us-teasers), with new talks announced
# Groovy 2.3.4 is out


We're happy to announce the bug-fix release of Groovy 2.3.4.  

In store, we continued on our hunt of bugs related to anonymous inner classes, and we have a big work on the compatibility of our AST transformations with static compilation.  
[Download Groovy 2.3.4](http://beta.groovy-lang.org/download.html) from our [new website](http://beta.groovy-lang.org/):  

You can read the [JIRA release notes](https://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=20432).  

Thanks to all those who contributed to this release!  

Keep on Groovy-ing!
# A new Groovy website in beta


The past few weeks, the Groovy team has been working on a new website for the project.  

Without further ado, let me introduce you to its beta: [http://beta.groovy-lang.org](http://beta.groovy-lang.org).  

The website is actually a [Groovy and Gradle application that you can fork](https://github.com/groovy/groovy-website) and help us improve! So don't hesitate to contribute fixes for things like typos or broken English, or suggest new relevant sections, etc. Your help will be welcome. Notice the "improve this doc" buttons on all pages which lead you to the relevant Github page that you can edit live, inline, on Github (if you've got an account already).  

This initial design prototype was created by [Damien Vitrac](https://twitter.com/oodamien), who also designed the [Grails](https://grails.org/) website. Big thanks to Damien for this great work!  

The site is currently in beta, awaiting your feedback, and some further minor improvements. You will notice also some links in the documentation leading to 404s as we still have Asciidoctor documentation to write. This is also an area where authors are welcome to give a hand; if there are particular topics you'd like to work on, please raise your hand.  

Once we're happy with the state of this website, and also with the related documentation that still needs to be written and linked to, we'll be switching from beta to official mode, and www.groovy-lang.org will become the new home for the Groovy project. The old wiki documentation from Confluence will be frozen and available in PDF form should you need it.  

We're looking forward to your feedback, your suggestions, and more!
# Groovy Weekly #28


A big week for the Gradle team as they’ve just announced the final release of Gradle 2.0! It’s of course a very important milestone for the project, and it’s nice to see that the migration to Groovy 2.3 as a baseline.

There are also some updates to Grails, Ratpack, and also the launch of the Spring IO platform that you might be interested in.

You’ll see also a list of job postings for Netflix, where Groovy is deployed at a very large scale and who are always seeking Groovy talents.

## Releases

*   [Gradle 2.0](http://forums.gradle.org/gradle/topics/gradle_2_0_released) released (with Groovy 2.3 included!)
*   [Ratpack 0.9.6](http://www.ratpack.io/versions/0.9.6) released
*   [Grails 2.4.2 and 2.3.11](https://grails.org/news/1290721) are released
*   The GrooScript Gradle pluging v0.4 is out, with Gradle 2.0 and Groovy 2.3.3
*   The [Spring IO platform 1.0](https://spring.io/blog/2014/06/26/spring-io-platform-1-0-0-released) has just been released, aligned with the recent Groovy & Grails releases
*   [Lazybones 0.7](https://twitter.com/pledbrook/status/481773978206601217) is released
*   [Spring Boot 1.1.2](https://twitter.com/springboot/status/481569291754434560) is out
*   [Spring Boot 1.1.3](https://spring.io/blog/2014/06/27/spring-boot-1-1-3-available-now) out as well!

## Articles

*   June [newsletter from GradleWare](http://www.gradleware.com/newsletter/gradleware-newsletter-june-2014/) about all things Gradle
*   [Functors in Groovy](http://mperry.github.io/2014/07/01/groovy-functors.html) by Mark Perry
*   MrHaki's Spocklight: [assign multiple data variables from provider](http://mrhaki.blogspot.fr/2014/06/spocklight-assign-multiple-data.html)
*   MrHaki shows how to [write your own data providers for Spock](http://mrhaki.blogspot.fr/2014/06/spocklight-write-our-own-data-provider.html)
*   Infographic article from Cygnet Infotech on [moving from legacy technologies towards Grails](http://www.cygnet-infotech.com/infographics/legacy-system-to-grails)

## Presentations

*   Dan Woods presented [Ratpack](https://github.com/danveloper/uberconf2014-ratpack) at UberConf 2014, with slides and demos
*   Slides and demos from Dan Woods on [introducing Groovy developers to the Java 8](https://github.com/danveloper/uberconf2014-from-groovy-to-java8) new features, presented at UberConf 2014
*   [Groovy as a scripting language](https://speakerdeck.com/jlstrater/groovy-as-a-scripting-language), by Jen Strater, at the GR8Ladies GR8Workshop

## News

*   The [GroovyFX project migrated its documentation to Asciidoctor](http://groovyfx.org/docs/index.html)
*   [Intellij IDEA's new Early Access Program](https://twitter.com/rfletcherew/status/482479225253810176) has started, for version 14, which includes the Groovy traits support, as well as better interactions between Grails and Gradle

## Mailing-lists

*   Cédric Champeau announced that [older versions of the Groovy documentation](http://groovy.329449.n5.nabble.com/Docs-available-for-older-versions-of-Groovy-td5720254.html) were now also available online

## Jobs

*   [Netflix is still looking for Groovy talents](https://twitter.com/tmbradley73/status/481824337343684608)
*   Daniel Jacobson from Netflix lists some of the [job postings from Netflix where Groovy skills are needed](https://gist.github.com/glaforge/e1d88601c053611678ae)

## Podcasts

*   Peter Ledbrook recoreded [Episode 4 of the Groovy podcast](http://groovypodcast.podbean.com/e/groovy-podcast-ep-2-1403795851/), including an interview with Baruch Sadogursky of JFrog, to discuss Groovy, Gradle, Bintray and more

## Tweets

*   Cédric Champeau points at the [Groovy support for Android](https://twitter.com/cedricchampeau/status/482045140547428352), for those who are disappointed that Google didn't announce a new language for Android
*   [Grails 2.4.2 and 2.3.11](https://twitter.com/gvmtool/status/482131395419308032) are available on GVM
*   Rob Fletcher shares a screenshot of the nice [T icon for traits in IntelliJ IDEA 14](https://twitter.com/rfletcherew/status/482498222074912769) EAP
*   [Lazybones 0.7](https://twitter.com/gvmtool/status/481767669361045504) is available on GVM
*   [Spring Boot 1.1.2](https://twitter.com/gvmtool/status/481767515564281856) available through GVM
*   Alexander Klein explains the [inception of the GVM logo](https://storify.com/glaforge/alexander-klein-explains-the-inception-of-the-gvm)
*   A [Ratpack tip](https://twitter.com/ratpackweb/status/482242234029318145) to enable static compilation of Ratpack scripts
*   More [happy users of Groovy on Android](https://twitter.com/joanzap/status/483635064224624641)!
*   [Gradle 2.0](https://twitter.com/gvmtool/status/483941783811129344) is available through GVM

## Code snippets

*   Jon Brisbin is brainstorming some a [Basho WebMachine Groovy](https://twitter.com/j_brisbin/status/482942386843041793) approach

## Events

*   [GR8Conf US programme, sponsors, and teasing the great talks](https://storify.com/glaforge/gr8conf-us-programme-and-last-day-for-the-early-bi) you'll be able to attend
# Groovy Weekly #27


This week, I’d like to highlight how you can contribute to the Groovy project!

The Groovy core team is a very small team, compared to the huge team a company like Oracle puts behind Java and the JVM, or Microsoft behind its languages and the .Net platform. So all contributions, in any form, count, and are important to the success and evolution of the Groovy language.

If you want to contribute to the code of Groovy, Cédric Champeau recorded a [screencast showing how you can set up IntelliJ IDEA to be able to work on the Groovy codebase](http://melix.github.io/blog/2014/06/contribute-groovy-ide.html).

But another key area we’ve been working on for a while is the new Groovy documentation. Peter Ledbrook [detailed how you can help us author some sections of the documentation](http://www.cacoethes.co.uk/blog/groovyandgrails/contributing-to-the-groovy-documentation). Like Peter, you can dedicate a bit of your time on a topic of your choice, to further deepen your understanding of a particular area of Groovy and share your knowledge with your peers.

We’re really looking forward for your contributions!

## Releases

*   Szczepan Faber announces [Gradle 2.0 rc-2](http://forums.gradle.org/gradle/topics/we_need_your_help_trying_out_gradle_2_0_rc_2?rfm=1)
*   [Griffon 2.0.0 beta-2](http://docs.codehaus.org/display/GRIFFON/2014/06/20/Griffon+2.0.0.BETA2+Released) released
*   An update release of all the [Griffon 2.0.0 beta-3 lazybones templates](https://twitter.com/theaviary/status/480697869767569408)
*   [Vert.x 2.1.1](https://groups.google.com/forum/?fromgroups#!topic/vertx/BFOjtqKeIjI) released
*   [Bug fix release of the Light Table Groovy](https://twitter.com/mrundberget/status/479693228015644672) client with v0.0.7
*   Peter Ledbrook released [v1.1 of the Lazybones Gradle plugin](https://twitter.com/pledbrook/status/479886014085734400)
*   [Gretty 1.0](https://twitter.com/AndreyHihlovski/status/481088938124509184) is out, with Tomcat 7 & 8 support
*   Yoav Landman announces [version 0.4 of the Gradle Bintray plugin](https://twitter.com/_yoav_/status/481202023258288130)

## Articles

*   Peter Ledbrook explains how to [contribute to the Groovy documentation](http://www.cacoethes.co.uk/blog/groovyandgrails/contributing-to-the-groovy-documentation)
*   A [detailed introduction to the Spock](http://thejavatar.com/testing-with-spock/) testing framework by Lukasz Janicki
*   Dan Woods explores [micro-services with Spring Boot and Groovy](http://www.infoq.com/articles/microframeworks1-spring-boot)
*   Alex Staveley writes about [MongoDB and Grails](http://dublintech.blogspot.ie/2014/06/mongodb-and-grails.html)
*   Further [Gradle dependecy visualization in Light Table](http://codewader.blogspot.no/2014/06/a-groovy-light-table-client-step-5.html)'s Groovy client with Dagre-D3 by Magnus Rundberget
*   MrHaki's Spocklight: [ignore specifications based on conditions](http://mrhaki.blogspot.fr/2014/06/spocklight-ignore-specifications-based.html)
*   Java build tools: [Ant vs Maven vs Gradle](http://www.javacodegeeks.com/2014/06/java-build-tools-ant-vs-maven-vs-gradle.html), by Viktor Farcic
*   [Groovy, Gradle and Vert.x on Beaglebone with GVM](http://lhuet.github.io/blog/2014/06/gvm-on-beaglebone.html) by Laurent Huet
*   Part 2 of [OAuth 2 using Grails](http://www.intelligrape.com/blog/2014/06/22/oauth-2-0-using-grails-part-2/)
*   A [recap of the Gradle Summit 2014](http://www.objectpartners.com/2014/06/18/gradle-summit-2014-recap/) by John Engelman
*   Robert Fletcher writes about how to use [Groovy's invoke dynamic support in your Gradle projects](http://blog.freeside.co/post/89759686171/gradle-and-groovys-invoke-dynamic-support)
*   Robert Fletcher explicits how to [trigger the usage Groovy's invoke dynamic support in Gradle](http://blog.freeside.co/post/89760608881/using-groovys-invokedynamic-support-in-gradle)

## Presentations

*   The [Jenkins Workflow projects is built on Groovy](http://www.cloudbees.com/sites/default/files/juc/juc2014/boston/2014-0618-Boston-Jesse_Glick-Workflow.pdf), for defining continous delivery pipelines and more, presentation given by Jesse Glick at the Jenkins User Conference Boston
*   Andrés Almiray [presents the Griffon desktop framework at the CERN](http://cds.cern.ch/record/1709713)

## News

*   [Grails Diary week 25](http://grydeske.net/news/show/51) by Jacob Aae Mikkelsen
*   A [GMavenPlus plugin for IntelliJ IDEA](http://plugins.jetbrains.com/plugin/7442?pr=idea)
*   Magnus Rundberget points us at the [contribution page](https://github.com/rundis/LightTable-Groovy/wiki/Contribute), if you want to help improve the LightTable Groovy client
*   The new [Griffon user guide is adopting a similar look'n feel and style as the new Groovy documentation](http://griffon.github.io/griffon/guide/), with Asciidoctor

## Screencasts

*   Cédric Champeau recorded a [screencast showing how to setup IntelliJ IDEA to contribute to the Groovy project](http://melix.github.io/blog/2014/06/contribute-groovy-ide.html)

## Podcasts

*   Peter Ledbrook recorded the [Groovy podcast episode 3](https://twitter.com/pledbrook/status/479702066689224704)

## Tweets

*   Already [100 stars on Github for the Groovy Android plugin for Gradle](https://twitter.com/cedricchampeau/status/479160332049727488). You can still add your own star!
*   Robert Fletcher shares a Gradle tip on how to [enable the invoke dynamic support in your Gradle build](https://twitter.com/rfletcherew/status/479909583595790336) when using the Groovy "indy" JAR
*   [Grails 2.4.1 and 2.3.10](https://twitter.com/gvmtool/status/479525410561335297) available in GVM
*   Andrés Almiray points out that [Griffon 2.0.0 application can be built with Maven](https://twitter.com/aalmiray/status/479343529500872704)
*   [Gradle 2.0 rc-2](https://twitter.com/gvmtool/status/481140386963132416) is available through GVM
*   [GVM has a logo](https://twitter.com/gvmtool/status/481161262626504705)!

## Code snippets

*   Guillaume Laforge shows a [code visitor that transforms BigDecimal literals into doubles](http://groovyconsole.appspot.com/script/5643440998055936)
*   A tiny [wiki text converter using Groovy traits](http://groovyconsole.appspot.com/script/5653164804014080/)

## Books

*   [44% off on Making Java Groovy](https://twitter.com/kenkousen/status/481227428124057601) by Ken Kousen
    
## Events

*   Guillaume Laforge shares the list of [Groovy related talks at JavaOne]({{< ref "/posts/2014/06/20/groovy-related-talks-at-javaone-2014" >}})
*   Only one week left till the [early bird pricing end of GR8Conf US](https://twitter.com/gr8confus/status/481089948951781377). Be fast!
*   [Super Early Bird registration for SpringOne2GX](http://springone2gx.com/) ends on June 30th
*   JDriven is organizing a [workshop on building REST-ful apps with Grails](http://www.jdriven.com/seminars#grails), on July 2nd (Dutch)
*   Russ Danner will give a webinar on: [conquering content-enabled web and mobile applications with Spring and Groovy](https://spring.io/blog/2014/06/12/webinar-conquering-content-enabled-web-and-mobile-applications-with-spring-and-groovy) on July 29th
# Groovy related talks at JavaOne 2014


Oracle is publishing the agenda of the upcoming JavaOne 2014 conference. And I'd like to highlight the [Groovy presentations](https://oracleus.activeevents.com/2014/connect/search.ww?eventRef=javaone#loadSearch-event=null&searchPhrase=groovy&searchType=session&tc=0&sortBy=&p=&i(10009)=10111) I've noticed that you might be attending in following if you are in San Francisco:  

*   [Groovy in the Light of Java 8 \[CON5839\]](https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=5839) With Java 8 out the door, Java developers can at last benefit from the long-awaited lambdas to taste the newly found functional flavor of the language. Streams are there to work more easily and efficiently with heaps of data. Those things are not new to developers acquainted with Groovy. But what is left to Groovy to make it attractive beyond all the aspects in which Java has caught up with Groovy? In this session, a Groovy project lead shows you how Groovy is still relevant in the JVM landscape, how similar or different Java and Groovy can be, how Groovy further improves the developer experience on top of JDK 8, and what Groovy offers beyond Java. 
*   [Groovy in 2014 and Beyond \[CON5996\]](https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=5996) With three million downloads in a year, Groovy still clearly leads the pack of alternative languages on the JVM, but it’s not resting on its laurels. The latest Groovy release, 2.3, is chock-full of useful new features and performance improvements. In particular, Groovy now supports the concept of “traits” for elegantly composing behaviors. Its JSON support is now the most performant of all the JSON libraries available to date. Groovy 2.3 introduces a new markup-based template engine, new code transformations, and much more. In this session, a Groovy project lead guides you through the latest advancements in the Groovy programming language and tells you what’s cooking for the next releases. 
*   [Exploring Groovy Metaprogramming \[CON1768\]](https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=1768) One of the key benefits of Groovy is its metaprogramming capability. The built-in features of the language enable you to realize AOP without the need for any heavyweight tools. This presentation takes an in-depth look at the metaprogramming capabilities of Groovy and explains when to use mixins, method injection, and method synthesis. 
*   [Functional Programmning the Groovy Way \[CON3538\]](https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=3538) In recent years, functional programming has gained ground over object-oriented programming, mainly due to the advancement in computing power. The JVM is no exception. You can find powerful contenders in Clojure and Scala, but Groovy is not that far back in the race. The Groovy programming language contains a wide array of APIs and features that facilitate a functional programming style, such as closure composition, memorization, trampolines, and iterator methods. This session explores all of these features that are sure to spice up your daily experience. 
*   [Rethinking API Design with Groovy Traits \[CON2425\]](https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=2425) Groovy 2.3 introduces the concept of traits in the language. Traits look like interfaces but enable the developer to add both implementation and state. They introduce multiple inheritance in the language while avoiding the diamond problem. Traits will let you rethink the way you design APIs in Groovy, by favoring composition of behaviors. This session explains what traits are, how they were implemented in Groovy, and what they have to offer to make your code more readable and maintainable. 
*   [Groovy and Grails Puzzlers: As Usual—Traps, Pitfalls, and End Cases \[CON1764\]](https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=1764) Remember the epic Java puzzlers? Here’s the Groovy version, and there are some neat ones! Even though it is totally a Grails shop, some of these had JFrog people scratching their head for days, trying to figure them out. And there is more! Contributions from the truly Groovy senseis, including @glaforge, @aalmiray, @tim\_yates, and @kenkousen, make this session an unforgettable journey to Groovy’s O\_O. You’ll get the expected dose of fun and enlightenment while hearing about mistakes and failures, great and small, in hard-core Groovy/Grails development. 
*   [Applying Groovy Closures for Fun and Productivity \[CON1769\]](https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=1769) You can program higher-order functions in Groovy quite easily by using closures, but the benefits of closures go far beyond that. Groovy has a variety of capabilities hidden in closures. This presentation unlocks that treasure and explores ways in which we can design applications by using Groovy closures to apply different design patterns, to create fluent interfaces, and even to program asynchrony. 
*   [HTML5/AngularJS/Groovy/Java and MongoDB Together: What Could Possibly Go Wrong? \[CON1703\]](https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=1703) We hear it’s common to create a minimum viable product (MVP) in a language that facilitates rapid prototyping and then migrate to the JVM when the application requires better stability and performance. In this session, the speaker uses Java to create a web application in less than hour. The JVM is a polyglot platform, and you’ll learn how to use the correct tools for this application, including AngularJS, Bootstrap, HTML5, web services, Java, MongoDB, and Groovy—it’s fully buzzword-compliant. The presentation doesn’t go into every technology in depth but demonstrates the role of each tool and how the tools interact. The session will result in a fully working mobile/browser-friendly app without compromise of design or good practice. It’s even going to have tests. 
*   [Plugging Users In: Extend Your Application with Pluggable Groovy DSL \[CON1752\]](https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=1752) It is often beneficial to enable users to extend your software with their own logic, and with dynamic languages on the JVM, it is also easy to do so. This session shares JFrog’s experience in creating a public, Groovy-authored user plug-in interface. It explains what domain-specific languages (DSLs) are, what their relevance to user plug-ins is, and how they can be implemented in Groovy or Java. It also discusses another very important aspect of pluggability: good public API design. Further, it covers security concerns and how they should be tackled. And finally, it discusses classpath isolation issues you may run into and compares different solutions to this problem. 
*   [Script Bowl 2014: The Battle Rages On \[CON2939\]](https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=2939) In this contest, languages that run on the JVM, represented by their respective language nerds, battle for bragging rights as the most popular language by showing off their shiny new features. Adding a twist to the format in which the audience members will pick this year’s winner(s): they will also vote on a language that should not return in 2015. Returning from 2013 are language gurus representing Clojure, Groovy, JRuby, and Scala. Attend this fun-filled and technically invigorating session to judge which scripting language best meets your needs. You’ll also be able to compare the respective languages and spark some thought-provoking discussions with the panelists that will be beneficial to the entire Java community. 
*   [Spring 4TW! \[CON3693\]](https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=3693) Spring 4’s here, and with it comes a bevy of new features designed to support modern web developers as well as enrich the component model and enable even-more-adaptive enterprise applications. Spring 4 also serves as the underpinning of Spring Boot, the entry point into the Spring platform. In this session, a Spring developer advocate discusses Spring 4’s new support for WebSocket (including extra support for STOMP), conditional configuration, dependency injection, Java 8 and Java EE 7 support (JCache support, the Batch JSR, ManagedExecutorService support, and so on), the Groovy language, and more. The presentation also looks at Spring Boot as a productive entry point into the Spring platform. 
*   [Writing Highly Concurrent Polyglot Applications with Vert.x \[CON7902\]](https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=7902) Vert.x is a lightweight, high-performance, polyglot, asynchronous application platform for the JVM. This session covers the design principles and motivation behind Vert.x, including its concurrency model, and discusses why Vert.x is a great fit for super-simple, highly concurrent applications. It also dives into some of the key Vert.x features, including the distributed event bus and high availability, and discusses some of the up-and-coming new features in the latest development branch for Vert.x 3.0, including distributed map support, management, and monitoring. The presentation includes demonstrations involving examples in several JVM languages such as Java, JavaScript, Scala, and Groovy.

Update: I only searched sessions with the "groovy" keyword, but other Groovy ecosystem projects are also present, like Griffon, Gradle or Spock! So let me fix that by appending some more Groovy-related sessions to my list!  

*   [Create Elegant Builds at Scale with Gradle \[CON8780\]](https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=8780) How can medium and large projects use Gradle to scale their build infrastructure? This session looks at organizations such as Netflix and LinkedIn and how they scale with Gradle across hundreds or thousands of developers. It discusses how to solve the challenges of standardization, dependency management, multilanguage builds, and automatic build infrastructure provisioning. 
*   [Gradle: Harder, Better, Stronger, Faster \[CON3531\]](https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=3531) Are you one of those people who search around the world looking for clues on how to get Maven to do your bidding, or do you just flip a coin and get lucky one more time? Maven works OK, but there’s a new tool in town that goes beyond Maven: Gradle. It’s fresh, almost aerodynamic. Once you get in contact with it, you’ll feel like doin’ it right when building a project. We kid you not, it’s an instant crush for those who have followed the Maven path, as you’ll find out in this session. This is the prime time of your life as a developer. Make the most out of it by leveraging the best tools. 
*   [Build, Test, and Deploy JavaFX Applications with Ease \[CON3553\]](https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=3553) Why is it that there are so many different options in the JVM space for building web applications but so few when it comes to desktop applications? This presentation addresses this question by showcasing a set of tools that can help you build JavaFX-powered applications without having to battle the build itself. It begins by looking at Gradle for defining the basic structure, then it covers Griffon as the means of putting all the pieces in their right place and TestFX as the testing library of choice, and finally it closes by circling back to Gradle and its deployment options. 
*   [Advanced Java Unit Testing with Spock \[CON2276\]](https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=2276) The Spock unit testing framework is on the verge of a 1.0 release and has already proven to be the next-generation thinking on how to test Java production code. Using Spock is hands-down the best way for developers to mock and test Java applications. One of Spock’s great features is the ability to write your own custom extensions. This session is a fast-paced (not for beginners), code-centric overview of how to use the advanced features in Spock, including custom extensions and interceptors. 
*   [BDD in Action: Building Software Right and Building the Right Software \[CON1579\]](https://oracleus.activeevents.com/2014/connect/sessionDetail.ww?SESSION_ID=1579) A common perception of behavior-driven development (BDD) focuses on test automation with Cucumber-style “Given..When..Then” scenarios. But this is just the tip of the iceberg: in fact BDD ranges from requirements discovery and description through to driving technical design and implementation; helping testers focus their testing efforts more effectively; and even providing reliable, useful, and accurate technical documentation. This session discusses what BDD is about, its benefits, and how it affects development teams and processes. You will see how JVM teams can effectively implement BDD with tools such as JBehave, Cucumber, Thucydides, and Spock. Come learn how much more there is to BDD than just “Given..When..Then.”
# Groovy Weekly #26


So what’s new this week?

We can highlight the first beta of Groovy 2.4 with the Android support, so users can start having a go at writing Android applications in Groovy! As well as bug fixes releases for Grails 2.3.x and 2.4.x.

Let’s also mention the launch of the Gradle plugin portal, announced last week at the Gradle Summit. And you’ll find also lots of presentations from the conference.

## Releases

*   Groovy 2.3.3 released and [Groovy 2.4.0-beta-1 with Android support]({{< ref "/posts/2014/06/11/groovy-2-3-3-and-groovy-2-4-beta-1-with-android-support" >}}) is out too
*   [Grails 2.4.1 and 2.3.10](https://twitter.com/grailsframework/status/478908515130830848) released with loads of bug fixes
*   [Spring Boot 1.1](https://spring.io/blog/2014/06/10/spring-boot-1-1-ga-released) released
*   [Spring Boot 1.1.1](https://twitter.com/springboot/status/476821967018799104) is out, fixing a little issue with the 1.1.0 release
*   Marcin Erdmann announces the [release of Geb 0.9.3](http://grails.1312388.n4.nabble.com/ANN-Geb-0-9-3-released-td4657113.html)
*   [Gretty 0.0.24](https://twitter.com/andreyhihlovski/status/476615698262007808) is out, with full support of Spring Boot 1.1.0
*   [Redis GORM 1.0.0](https://twitter.com/grailsplugins/status/477022016994672642) released
*   Cédric Champeau released a [JMH Gradle Plugin](https://github.com/melix/jmh-gradle-plugin) that integrates the JMH micro-benchmarking framework with your Gradle build

## Articles

*   Marc Palmer on the [journey from Objective-C to Groovy](http://transition.io/the-journey-from-objective-c-to-groovy/)
*   MrHaki’s [Getting Groovy extensive tutorial](http://gr8labs.org/getting-groovy/)
*   MrHaki's Spock-light: on [using an extra data variable for unroll description](http://mrhaki.blogspot.fr/2014/06/spocklight-extra-data-variables-for.html), based on Rob Fletcher's GR8Conf Europe Spock talk
*   Graeme Rocher blogs about a Gradle to [get the nice GroovyDoc style](http://grails.io/post/88656787208/generating-pretty-groovy-2-3-groovydocs-with-gradle) from Groovy 2.3+ even if your project is using Groovy 2.2 or below
*   [Docker containers with Gradle in 4 easy steps](http://thediscoblog.com/blog/2014/06/13/docker-containers-with-gradle-in-4-steps/), by Andy Glover
*   Andrés Almiray wrote about the [Griffon 2.0.0 beta](http://www.jroller.com/aalmiray/entry/griffon_2_0_0_beta)
*   [Pooling web service connections in Grails](http://www.objectpartners.com/2014/06/11/pooling-web-service-connections-in-grails/) by Jeff Sheets
*   Building enterprise Mule applications with Gradle: [part 1](http://blogs.mulesoft.org/building-mule-apps-gradle/), [part 2](http://blogs.mulesoft.org/building-mule-apps-gradle-studio/), [part 3](http://blogs.mulesoft.org/building-enterprise-apps-gradle/)

## Presentations from the Gradle Summit

*   Justin Ryan from Netflix on the [Nebula Gradle plugin, a useful test harness for Gradle plugins](http://fr.slideshare.net/quidryan/gradle-summit-2014-nebula)
*   David Carr on [cloud browser testing with Gradle and Geb](http://www.slideshare.net/davidmc24/cloud-browser-testing-with-gradle-and-geb)
*   Benjamin Muschko on [web application deployments with Gradle](https://speakerdeck.com/bmuschko/web-application-deployments-with-gradle-from-the-developers-machine-to-continuous-deployment)
*   Benjamin Muschko on [provisioning virtualized infrastructure with Gradle](https://speakerdeck.com/bmuschko/provisioning-virtualized-infrastructure-with-gradle)
*   Tobias Gesellchen shares his slides and code snippets on [moving from Maven to Gradle](http://gesellix.github.io/gradle-summit-2014/)
*   Rene Gröschke on [releasing with Gradle](http://www.slideshare.net/breskeby/releasing-with-gradle-gradle-exchange-2014)
*   Dan Woods spoke about his [Gradle provisioning plugin](https://twitter.com/varzof/status/477519220150767616)
*   Andrés Almiray was [spreading the word about Groovy, Gradle, Spock](http://grails.org.mx/2014/06/11/resumen-24ta-reunion/) and more in Mexico (Spanish content)

## News

*   Gradleware just announced the [launch of the Gradle plugin portal](http://plugins.gradle.org/)
*   Guillaume Laforge shares the [future look of the new Groovy documentation](http://beta.groovy-lang.org/docs/groovy-2.3.4-SNAPSHOT/html/documentation/)
*   Jacobe Aae Mikkelsen on the [Grails Diary week 24](http://grydeske.net/news/show/49)
*   Learn about the [GrooScript roadmap](http://grooscript.org/roadmap.html)
    
## Mailing-list posts

*   An interesting thread on [selling Groovy to your management](http://groovy.329449.n5.nabble.com/Need-help-with-quot-Groovy-sales-pitch-quot-td5720060.html)
*   A [“provided scope”](http://gradle.1045684.n5.nabble.com/Regression-list-for-1-12-td5712639.html#a5712650) might come to Gradle

## Code snippets

*   An [intentionally vulnerable Grails application](http://blog.nvisium.com/2014/06/introducing-grailsnv-vulnerable-groovy.html) for education purpose
*   A demo project show-casing the [Gradle tooling API](https://github.com/radimk/gradle-toolingApi-demo)

## Contributions

*   Grant McConnaughey contributed [documentation on Groovy “statements”](https://twitter.com/glaforge/status/478085555407040512). Thank you, Grant. To all, please don’t hesitate to help us and contribute to the documentation effort!

## Tweets

*   A good way to get started with Groovy, with the [GroovyKoans](https://twitter.com/geeky_android/status/478164163349721088)
*   The [Estonian emergency system is powered by Grails](https://twitter.com/jfarcand/status/477453724299042816) and Atmosphere
*   [Gradle 2.0 is 20% to 70% more performant](https://twitter.com/danveloper/status/477113115515953153) than Gradle 1.0
*   The [Gradle plugin portal is built with Ratpack](https://twitter.com/ratpackweb/status/477128712622579713) and RxJava
*   You can start [submitting your Gradle plugin to the Gradle plugin portal](https://twitter.com/danveloper/status/477119125966188546)
*   Cédric Champeau announces his [JMH Gradle plugin](https://twitter.com/cedricchampeau/status/478514436358275072) and showing a sample project using it
*   Andrés Almiray things the [Gradle plugin portal has been rushed a bit](https://twitter.com/aalmiray/status/477734872946319361), in time for Gradle Summit, as it's still a bit complicated to submit plugins for inclusion
*   Cédric Champeau notices only minor changes are needed to be able to [build Groovy with Gradle 2.0-rc-1](https://twitter.com/cedricchampeau/status/476638077323341824)
*   Initial work from Russell Hart bringing [Ratpack into the "Reactive Streams"](https://twitter.com/ratpackweb/status/476210105319309314) family
*   Cédric Champeau would like to see the ["new" keyword totally optional](https://twitter.com/cedricchampeau/status/476752756376891392) in Groovy, without using @Newify
*   Guillaume Laforge suggests creating an ["Enterprise" version of Groovy's "spaceshift" operator](https://twitter.com/glaforge/status/477359185253134336)
*   Magnus Rundberget [explores the Ratpack Gradle dependencies](https://twitter.com/mrundberget/status/476645367808008192) with the LightTable Groovy plugin 0.0.6
*   The Grails [GORM groovydoc](https://twitter.com/grailsframework/status/477124659574738945) is available standalone
*   Cédric Champeau is surprised when people say using [“def” makes a dynamic type (but “def” == “Object”)](https://twitter.com/cedricchampeau/status/477079037098340353)
*   Cédric Champeau remarks that [Groovy is a strongly typed language](https://twitter.com/cedricchampeau/status/477079421569212416)
*   [CRaSH 1.3.0](https://twitter.com/gvmtool/status/477425205716217856) is available in GVM
*   CrudZilla’s [HiveMind web app generator](https://twitter.com/crudzillasoft/status/477560344542334977) is written largely in Groovy through JSR-223
*   The [Gradle Node plugin](https://twitter.com/dailygrailstip/status/477860347601092610) gives you an easy way to install and run Node.JS on Continuous Integration environments
*   Burt Beckwith is going to each [Groovy and Grails again at Harvard](https://twitter.com/burtbeckwith/status/477253832120881152)

## Jobs

*   A [Groovy / Grails developer for Plano in Texas](https://twitter.com/findgrailsjobs/status/476758016680013824), USA

## Events

*   Cédric Champeau will speak about [Groovy Traits at JavaOne](https://twitter.com/CedricChampeau/status/477010580260528130)
*   JavaOne session acceptance emails are starting to flow, and the first Groovy sessions are appearing, for instance Guillaume Laforge's on the [latest & greatest Groovy, or Groovy in the light of Java 8](https://twitter.com/glaforge/status/476657140128817152)
*   MrHaki's [report on GR8Conf](http://blog.jdriven.com/2014/06/gr8conf-2014-europe-conference-report/) Europe 2014
*   Quick summary from Andrés Almiray about the [GR8Conf Europe 2014 Hackergarten](http://www.jroller.com/aalmiray/entry/hackergarten_gr8conf)
# Groovy 2.3.3 and Groovy 2.4-beta-1 with Android support


The Groovy team is very happy to announce the joint **releases of Groovy 2.3.3** and **Groovy 2.4-beta-1**.  

**Groovy 2.3.3 is a bug fix release**, particularly covering the recent issues discovered around anonymous inner classes. Please upgrade to 2.3.3 if you've been facing such issues.  

Groovy 2.4.0-beta-1 comes pretty early, as we would like to come back to releasing milestones on a more regular pace, compared with how late we released the first beta of Groovy 2.3. We really want you, our users, to be able to give us feedback as soon as possible!  

The key aspect of **Groovy 2.4.0-beta-1 is that it's the first version of Groovy that officially provides support for running Groovy on Android**.  

You can learn more about the Groovy support for Android in those two articles from Cédric's blog, and the Groovy Android Gradle plugin:

*   [Groovy on Android](http://melix.github.io/blog/2014/06/grooid.html)
*   [The technical details about Groovy on Android](http://melix.github.io/blog/2014/06/grooid2.html)
*   [Groovy Android Gradle plugin](https://github.com/melix/groovy-android-gradle-plugin)

You can have a look at the JIRA release notes:

*   [Groovy 2.3.3 JIRA release notes](https://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=20415)
*   [Groovy 2.4.0-beta-1 JIRA release notes](https://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=20369)

You can download both versions from our [download area](http://groovy.codehaus.org/Download).  

Have a look at the [latest documentation for Groovy 2.3.3](http://beta.groovy-lang.org/docs/latest/html/documentation/), and don't hesitate to contribute to it, your help will be more than welcome.  

Groovy developers, Grails developers, and other members of the Groovy ecosystem met in Copenhagen last week for a **Groovy DevCon meetup** (kindly sponsored by [GR8Conf Europe](http://gr8conf.eu/)) to speak about the ongoing development of Groovy. You might want to have a look at the [notes of the meeting](http://bit.ly/gdc10notes), to learn more about our discussions and what we'll be working on for Groovy.
# Groovy Weekly #25


[GR8Conf Europe](http://gr8conf.eu/) is over, but there’s a lot to learn from the conference, with all the interesting conference sessions that took place there in Copenhagen.

The themes for this week will be around GR8Conf, of course, but also about Groovy on Android, again the Swift language, and also the first impressive demo of Grails 3.0!

Right after the conference also took place the annual Groovy DevCon meetup, gathering core members of the Groovy team, Grails team, and members of the Groovy ecosystem. Lots of interesting tidbits about [what’s coming up in Groovy](http://bit.ly/gdc10notes)!

Fasten your seat belt, and without further ado, let’s get started!

## Releases

*   Andrés Almiray announces the [release of Griffon 2.0.0.BETA](http://griffon.markmail.org/thread/cispnhhnwqo4z5n3)
*   Cédric Champeau released [version 0.2 of the Groovy Android plugin fpr Gradle](https://twitter.com/CedricChampeau/status/475570875157458944) to simplify developments of Android apps in Groovy
*   [Gradle 2.0-RC-1](http://forums.gradle.org/gradle/topics/gradle_2_0_rc_1_is_now_available_for_testing) is available for testing
*   Bertrand Goetzmann [updated Afterburner.gfx](https://twitter.com/bgoetzmann/status/473929435469864961) to the latest GroovyFX 0.4.0 release

## Articles

*   Guillaume Laforge shared the [notes of the Groovy DevCon #10 meetup](http://bit.ly/gdc10notes) that took place in Copenhagen right after GR8Conf Europe 2014
*   See how developing mobile [Android apps in Groovy can be a streamlined](http://melix.github.io/blog/2014/06/grooid.html) in Cédric Champeau’s article
*   Cédric Champeau gives more [technical details about the Groovy on Android](http://melix.github.io/blog/2014/06/grooid2.html)
*   JAXEnter believes [Groovy is the Swift-alternative for Android](http://jaxenter.com/groovy-is-the-swift-alternative-for-android.1-50449.html)
*   Luke Daley gives a [detailed update about the status of the Ratpack](http://ldaley.com/post/87844640597/ratpack-update) project
*   [Null Object pattern](http://solidsoft.wordpress.com/2014/06/05/null-object-pattern-implementation-in-groovy-a-map-with-default-behavior/) implementation in Groovy by Marcin Zajączkowski
*   Adding [JavaScript at the bottom of a Grails page](http://groovy.dzone.com/articles/grails-adding-javascript) by Venkatt Guhesan

## Presentations — GR8Conf Europe special edition

*   [video](https://twitter.com/gr8conf/status/474164749999935489) and [slides](https://speakerdeck.com/glaforge/groovy-in-2014-and-beyond-at-gr8conf-europe-2014) of Guillaume Laforge’s Groovy update talk
*   Cédric Champeau’s presentation and code of the [first Android app in Groovy](https://twitter.com/cedricchampeau/status/474152898361049088)
*   [Idiomatic Spock](https://twitter.com/rfletcherEW/status/474262034641866753) talk by Rob Fletcher
*   Marco Vermeulen’s slides and code about his presentation on [Spring Boot microservices](https://twitter.com/marcovermeulen/status/474155245271269376)
*   Slides and source for Marco Vermeulen’s [Behavior Driven Development talk with Groovy and Cucumber](https://twitter.com/marcovermeulen/status/474158629705486337)
*   Julien Viet presented [Crash, the shell for the JVM](http://fr.slideshare.net/gr8conf/bd-2036-crashslide2)
*   slides and code from Göran Ehrsson on [Grails feature plugins](https://twitter.com/gr8conf/status/474164749999935489)
*   MrHaki’s Gradle Goodness [slides and code](https://twitter.com/mrhaki/status/474112588876640256)
*   Alexander Klein on [Vert.x with Groovy](https://twitter.com/saschaklein/status/474157270671306752)
*   Lari Hotari speaks about [Grails 3, Ratpack and Spring Boot](https://twitter.com/lhotari/status/474459744069902337)
*   Claus Ibsen on Apache [Camel, Hawtio and Groovy](http://java.dzone.com/articles/apache-camel-groovy-and-hawtio)
*   Benoît Hédiard presented a talk titled "[Running a Startup with Lean & DevOps culture](https://medium.com/@benorama/running-a-startup-with-lean-devops-culture-df50825b110b)" where his weapons of choices were Groovy and Grails

## Interview

*   [Cédric Champeau’s](https://twitter.com/gr8conf/status/474164749999935489) [interview by InfoQ about Groovy running on Android](http://www.infoq.com/news/2014/06/groovy-android)

## News

*   Jacob Aae Mikkelsen [week 22 and 23 of the Grails Diary](http://grydeske.net/news/show/48)
*   EdX is featuring a [Functional Programming class](https://twitter.com/headinthebox/status/474808090802802688) by Erik Meijer that might get a little Groovy love

## Google+ posts

*   Mark Perry created a new module for FunctionalGroovy for [improving the usage of Java 8's Optional](https://plus.google.com/b/101432359761228268146/103753917802203497881/posts/2TnU2cdFqX8?cfem=1) class
*   Magnus Rundberget reports nice contributions from GR8Conf Europe 2014's hackergarten [improving the Groovy support in Light Table](https://github.com/rundis/LightTable-Groovy/releases/tag/0.0.6), particularly around the Gradle dependency graph

## Code snippets

*   A [Flappy Bird clone for Android in Groovy](https://github.com/gregopet/flappy-gru)!
*   The Groovy Remote Control plugin is an [example of a Jenkins plugin written in Groovy](https://twitter.com/dailygrailstip/status/474060855944818688)

## Tweets

*   At GR8Conf Europe, Graeme Rocher showed a [super lean example of a RESTful micro-service in Grails 3.0](https://gist.github.com/glaforge/c44f439974b631a384e9) with just a single class!
*   Cédric Champeau gives all the links regarding [Groovy on Android](https://twitter.com/cedricchampeau/status/474314754987941888), with his presentation slides from GR8Conf, the code of the GR8Conf agenda application
*   Looks like [Groovy on Android is a hot topic in Japan](https://twitter.com/nobeans/status/474431420224393216)!
*   Graeme Rocher’s [Grails 3 goals](https://twitter.com/puneetbhl/status/474461108989075456) slide from his GR8Conf Europe presentation
*   Lari Hotari demonstrated a [Spring Boot application, inside Ratpack, using Grails GORM](https://twitter.com/ilopmar/status/474099772664852480), at GR8Conf Europe
*   During his presentation at GR8Conf Europe, MrHaki was [using the Gradle\_Language package for SublimeText](https://twitter.com/mrhaki/status/474113095733100545)
*   Dan Vega is [enhancing Apple’s Swift language with Groovy methods](https://twitter.com/cfaddict/status/474036220092497920)
*   Andrés Almiray points at the fact you can [try Crash online](https://twitter.com/aalmiray/status/474119215461314560) with the examples shown by Julien Viet during GR8Conf Europe
*   Pictures of the GR8Conf Europe 2014 event:
    *   [first day](https://twitter.com/gr8conf/status/474130035084115969)
    *   [second day](https://twitter.com/gr8conf/status/474130692012802048)
    *   [third day](http://bit.ly/gr8conf-2014-day-3)
*   Iván López notes that the [first Android application written in Groovy is the GR8Conf agenda application](https://twitter.com/ilopmar/status/474129638818856960) built by Cédric Champeau
*   Dan Woods enjoy the [method-level granularity](https://twitter.com/danveloper/status/474681276252028929) of what you decides should be dynamic or statically compiled in Groovy
*   [Gradle 2.0-rc-1](https://twitter.com/gvmtool/status/474856227965779968) available on GVM
*   Ben Edwards reminds us that the [SmartThings IoT platform is using Groovy](https://twitter.com/alttext/status/474999654762160128) as its intelligence language
*   It's easy to [create Griffon applications with GVM, Gradle, and Lazybones](https://twitter.com/theaviary/status/475624761222246400)
*   [GVM adds Crash](https://twitter.com/gvmtool/status/475751295396380672) to the list of candidates
*   [Spring Boot 1.1](https://twitter.com/gvmtool/status/476612688001662976) is available on GVM
    
## Books

*   [Gradle in Action is 50% off today](https://twitter.com/jbaruch/status/476283524337520640)
*   Greg Turnquist recently wrapped up chapter 1 ("getting started with Groovy") of his upcoming [Spring Boot book](http://blog.greglturnquist.com/2014/06/recently-wrapped-up-chapter-1-quick-start-with-groovy.html)

## Jobs

*   Searching for a [Grails developer in Berlin](https://twitter.com/findgrailsjobs/status/474561040081235969)

## Events

*   The GR8Ladies are partnering with TCGeekettes for a [GR8 workshop on June 28th](https://twitter.com/jennapederson/status/474577644336324608)
*   [More talks selected for SpringOne2GX](https://twitter.com/springcentral/status/474646591073435648) in Dallas
# Latest Groovy 2.3 coverage presented at GR8Conf Europe


I've published the slides of my "Groovy in 2014 and beyond" presentation at GR8Conf Europe.  

Slides embedded below: 

{{< speakerdeck b40bc2e0cdef01316bf51e853270e897 >}}

As well as video:

{{< youtube P63OHYc3q8s >}}
# Groovy Weekly #24


Direct live from [GR8Conf Europe](http://gr8conf.eu/)!

Several speakers already uploaded their presentation slides, as you shall see in the “presentations” sections. And the videos will be available later after the conference.

At the same time in San Francisco, Apple is running its WWDC conference and announced the creation of a new language, [Swift](https://developer.apple.com/swift/), that [looks a lot like Groovy]({{< ref "/posts/2014/06/02/apple-s-swift-programming-language-inspired-by-groovy" >}}) as several Groovy users have already noticed on Twitter. That’s nice to see Groovy also influences other languages!

## Releases

*   Guillaume Laforge announces the [Groovy 2.3.2 bug-fix]({{< ref "/posts/2014/05/28/groovy-2-3-2-released" >}}) release
*   CRaSH, the JVM shell, updated its [Grails integration](https://twitter.com/crashub/status/471630363413217281)
*   [GrooScript 0.5.1](https://twitter.com/grooscript/status/471791908839489536) with some bug fixes
*   Spring Tool Suite & [Groovy/Grails Tool Suite 3.6.0.M1](http://docs.spring.io/sts/nan/v360/NewAndNoteworthy-M1.html): with Groovy 2.3, Grails 2.4, and Gradle tooling
*   Version [0.0.1.6 of sGVM](https://twitter.com/noamtenne/status/473059113350750208) has been released, adding support for Glide
*   [Ratpack 0.9.5](http://www.ratpack.io/versions/0.9.5) is available
*   [GroovyFX 0.4.0](http://pleasingsoftware.blogspot.dk/2014/06/groovyfx-040-released.html) released
*   Marco Vermeulen released [v0.5.6 of the GVM SDK](https://twitter.com/marcovermeulen/status/473580701296508928)

## Articles

*   Guillaume Laforge shows the [similitudes between Groovy and Apple’s Swift]({{< ref "/posts/2014/06/02/apple-s-swift-programming-language-inspired-by-groovy" >}}) new programming language for iOS
*   Cédric Champeau writes about how to [use Groovy 2.3's new markup template engine in Spring Boot](https://spring.io/blog/2014/05/28/using-the-innovative-groovy-template-engine-in-spring-boot)
*   [Unit test your serverside JavaScript with Spock](http://www.objectpartners.com/2014/05/29/unit-test-your-server-side-javascript-with-spock/) by David Norton
*   Alex Staveley shares a Grails tip about how to [refactor your URLs](http://dublintech.blogspot.dk/2014/05/grails-tip-refactoring-your-urls.html)
*   Tomás Lin's [Spring Boot recipe: reading and validating lists of configuration properties](http://fbflex.wordpress.com/2014/06/02/spring-boot-recipe-reading-and-validating-lists-of-configuration-properties/)

## Presentations

*   MrHaki shares the notes and slides of his [Groovy introduction workshop](https://twitter.com/mrhaki/status/473420460399800321) at GR8Conf Europe
*   Álvaro Sánchez-Mariscal published his GR8Conf Europe presentation on [creating restful APIs with Grails and Spring Security](http://fr.slideshare.net/alvarosanchezmariscal/restful-gr8conf2014)
*   If you fancy some French, Guillaume Laforge’s presentation on [what makes Groovy groovy](http://parleys.com/play/538c3063e4b0a38a46cbec99/chapter0/about) is online on Parleys
*   Andrés Almiray shares his [Groovy Ecosystem](http://fr.slideshare.net/aalmiray/gr8conf-groovy-ecosystem) presentation from GR8Conf Europe
*   Jorge Franco Leza uploaded his GR8Conf Europe [presentation about GrooScript](https://twitter.com/jfrancoleza/status/473807095088037888), the Groovy to JavaScript compiler
*   Ryan Vanderwerf put online his [Groovy + Lego mindstorms slides and samples](https://twitter.com/ryanvanderwerf/status/473814334586761216) from GR8Conf Europe
*   Robert Fletcher talked about [hybrid views with Grails](http://freeside.co/hybrid-views-with-grails/assets/player/KeynoteDHTMLPlayer.html#0) at GR8Conf Europe
*   At GR8Conf Europe, Benoit Hédiard presented about [Lean Startup, DevOps with Grails and Amazon Web Services](https://speakerdeck.com/benorama/running-a-lean-startup-devops-and-grails-and-aws)

## Mailing-list posts

*   Cédric Champeau notes that JDK 7u60 is eventually the [first JDK 7 update release with correct invoke dynamic support](http://groovy.329449.n5.nabble.com/JDK7u60-is-out-for-indy-lovers-td5719838.html)

## News

*   [Groovy Podcast, episode 2](https://twitter.com/pledbrook/status/471545892231995394), by Peter Ledbrook, and the GR8Ladies
*   Jon Brisbin launched the [new Reactor website](http://projectreactor.org/)
*   Gradleware’s May [newsletter](http://www.gradleware.com/newsletter/gradleware-newsletter-may-2014-2/)

## Code contributions

*   The Ratpack project shares a possible contribution, for [implementing a redirect() method for chains](https://twitter.com/ratpackweb/status/472262669970337792)

## Code snippets

*   Russell Hart is showing how to [use Hystrix in Ratpack applications](https://twitter.com/rus_hart/status/473186395826434048)
*   Kenneth Endfinger gives examples of the [Groovy spread operator](https://github.com/kaendfinger/hardcore-groovy/blob/master/src/spread.groovy.md)

## Tweets

*   Pieter Niederwieser notes that Apple’s new programming language, [Swift, looks a lot like Groovy](https://twitter.com/pniederw/status/473571956441489408)
*   [Groovy mentioned during the Apple presentations about Swift](https://twitter.com/gmcconnaughey/status/473580913234690049), their new programming language
*   During his GR8Conf Europe keynote, Guillaume Laforge started with a little [comparison between Apple's Swift and Groovy](https://twitter.com/ilopmar/status/473724325653385216)
*   Guillaume Laforge updated the [Groovy Web Console with Groovy 2.3.2](https://twitter.com/glaforge/status/473396838125830144) (including traits, etc), and latest Gaelyk and App Engine SDK
*   Graeme Rocher is working on a [proof of concept of Grails 3.0 on top of Spring Boot](https://twitter.com/graemerocher/status/471582885204733952)
*   [Groovy 2.3.2](https://twitter.com/gvmtool/status/471575702148771840) is available on GVM
*   The [GR8Conf europe official beers](https://twitter.com/gr8conf/status/471599562210418688)!
*   [New location for Gretty documentation](https://twitter.com/andreyhihlovski/status/472036112362651649) (the Jetty Gradle plugin), generated with JBake and Asciidoctor
*   An ecstatic tweet by Omar Khan on how [beautiful Groovy is, and how awesome Grails](https://twitter.com/recoveringjahil/status/472143758570831872) is
*   More [integration between Ratpack and Reactor](https://twitter.com/ratpackweb/status/472263360491180033)
*   [gHipster](https://twitter.com/dailygrailstip/status/472085178899132416) is a version of the jjipster Spring Boot framework that uses Gradle instead of Maven. Also Spock.
*   but [jhipster is actually adding Gradle](http://jhipster.github.io/2014/06/02/jhipster-release-0.16.0.html) support
*   [Visualize your Gradle project dependencies graphically](https://twitter.com/mrundberget/status/473054214273642496) with the Light Table Groovy plugin
*   [Spring Boot 1.1.0 RC 1](https://twitter.com/gvmtool/status/473403577097261056) is available on GVM
*   Andrés Almiray published [pictures of the GR8Conf Hackergarten](https://twitter.com/aalmiray/status/473792051293982720)

## Books

*   The great [Groovy and Grails Goodness books](https://twitter.com/mrhaki/status/473134274582179840) from MrHaki are half the price during GR8Conf Europe!
*   Today only, there’s [50% off Gradle in Action](https://twitter.com/bmuschko/status/473894079508791296)

## Events

*   The [GR8Conf US crew is tweeting about the interesting talks](https://storify.com/glaforge/gr8conf-us-upcoming-talks) we'll get to see in Minneapolis this summer
# Apple's Swift programming language inspired by Groovy


During Apple's [WWDC](https://developer.apple.com/wwdc/) conference was announced a new programming language, called [Swift](https://developer.apple.com/library/prerelease/ios/documentation/Swift/Conceptual/Swift_Programming_Language/GuidedTour.html#//apple_ref/doc/uid/TP40014097-CH2-XID_1), targeted at developing on iOS devices (and likely Mac OS X in the future as well).  

When looking through the slides from the keynote, [online documentation](https://developer.apple.com/library/prerelease/ios/referencelibrary/GettingStarted/LandingPage/index.html#//apple_ref/doc/uid/TP40014345), and [iTunes ebook](https://itun.es/fr/jEUH0.l), an acquainted Groovy eye would immediately notice the inspiration the Swift designers took from Groovy.  

In one of the slides covering Swift, Groovy was even mentioned as one of the languages clearly making developers much more productive, although I disagree with the placement of Groovy in terms of performance as Groovy should clearly be leading the pack of the bottom right hand quadrant.  
![](/img/misc/swift.png)  

Swift is clearly a blend of various good things from many existing languages:

*   the getter / setter syntax close to the one from C#
*   the type after variable named and colon, like in Pascal-derived languages
*   string interpolation like in many scripting languages, using `\(foo)` versus Groovy's `${foo}`
*   the question mark suffix after a type to denote it can be nullable, like in Ceylon
*   the range operators .. and ... borrowed from Ruby (that Groovy also adopted and adapted for clarity, as Groovy's excluded upper bound is denoted by `..<` instead)

But Swift clearly took inspiration from Groovy on the following aspects.  

Groovy and Swift (as well as other scripting languages) do have that concept of script, where free-standing statements don't need to be bundled into some kind of class structure, making scripting languages nice for the REPL feedback loop.  

The syntax for lists and maps is the same in Swift and Groovy, with a comma-separated list of values surrounded by square brackets for lists, and key:value pairs comma-separated and surrounded again by square brackets for creating maps. The empty map is also the same with the \[:\] syntax.  

```groovy
// Swift
var shoppingList = ["catfish", "water", "tulips", "blue paint"]
shoppingList[1] = "bottle of water"
 
var occupations = [
    "Malcolm": "Captain",
    "Kaylee": "Mechanic",
]
occupations["Jayne"] = "Public Relations"
var emptyMap = [:]
var emptyList = []

// Groovy
def shoppingList = ["catfish", "water", "tulips", "blue paint"]
shoppingList[1] = "bottle of water"
 
def occupations = [
    "Malcolm": "Captain",
    "Kaylee": "Mechanic",
]
occupations["Jayne"] = "Public Relations"
def emptyMap = [:]
def emptyList = []
```

  
The sole difference here is actually the fact Groovy's using "def" instead of "var". But a nice aspect of Swift is that it's got a "let" keyword for defining constants. You can use "final" in Groovy but it's not enforced by the compiler (yet).  

Swift closures also adopt the same syntax as Groovy for its curly braces delimiters, but is using an "in" keyword to replace Groovy's arrow separating parameters from closure's body.  

Here's what an example of Swift closure looks like compared to Groovy:  

```groovy
// swift
numbers.map({
    (number: Int) -> Int in
    let result = 3 * number
    return result
})
    
// groovy
numbers.collect { int number ->
    def result = 3 * numbers
    return result
}
```

But there's also a shorter variant for both languages, with Swift's positional closure parameters, versus Groovy's "it" pseudo-keyword:  

```groovy
// swift
numbers.map({ 3 * $0 })
numbers.map({ it in 3 * it })

// groovy
numbers.collect { 3 * it }
```

Swift also adopted Groovy's syntactic rule that if a closure is the last parameter of a function or method, you can actually put that last parameter outside the parentheses like so:  

```groovy
// swift
sort([1, 5, 3, 12, 2]) { $0 > $1 }
    
// groovy
sort([1, 5, 3, 12, 2]) { a, b -> a > b }
// or possibly, if we pass an array as param
sort([1, 5, 3, 12, 2]) { it[0] > it[1] }
```

  
Another interesting aspect is named parameters. For instance, for instantiating objects:  

```groovy
// swift
var triangleAndSquare = TriangleAndSquare(size: 10, name: "another test shape")
    
// groovy
def triangleAndSquare = new TriangleAndSquare(size: 10, name: "another test shape")
```
  
Swift has a `@lazy` annotation similar to Groovy's `@Lazy` code transformation, to lazily instantiate complex fields only when they are first accessed:  

```groovy
// swift
class DataManager {
    @lazy var importer = DataImporter()
}
    
// groovy
class DataManager {
    @Lazy importer = new DataImporter()
}
```

Alongside its nullable types à la Ceylon, Swift adopted the safe navigation operator of Groovy (the next version of C# is going to support that Groovy notation as well):  

```groovy
// swift
let john = Person()
if let roomCount = john.residence?.numberOfRooms {
    println("John's residence has \(roomCount) room(s).")
} else {
    println("Unable to retrieve the number of rooms.")
}

// groovy
def john = new Person()
def roomCount = john.residence?.numberOfRooms
if (roomCount) {
    println "John's residence has ${roomCount} room(s)."
} else {
    println "Unable to retrieve the number of rooms."
}
```

  
Swift is brand new, and I haven't had much time to dive deeper yet, but it sounds like a nice and elegant language, and right out of the box, it makes me feel at home thanks to its resemblance with Groovy! It even makes me want to write Swift applications for some iOS device!
# Groovy 2.3.2 released


The Groovy team is pleased to announce the release of Groovy 2.3.2, a bug fix release for our 2.3 main branch.  

If you have already moved to Groovy 2.3, we strongly recommend you to upgrade to 2.3.2 rapidly, as our two prior 2.3 releases were using a buggy version of ASM which was generating wrong bytecode for inner classes.  

You can check this issue for more details: [https://jira.codehaus.org/browse/GROOVY-6808](https://jira.codehaus.org/browse/GROOVY-6808)  
  
Since any code compiled with Groovy 2.3.0 or 2.3.1 and using inner classes is likely to have faulty bytecode, please make sure to recompile everything with 2.3.2  
Our detailed JIRA change log: [http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=20402](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=20402)  

And go download Groovy at the usual place: [http://groovy.codehaus.org/Download?nc](http://groovy.codehaus.org/Download?nc)  

Thanks to all who contributed!
# Groovy Weekly #23


The big news of this edition is the release of Grails 2.4, with standalone GORM and GSP, with more static compilation that even understands dynamic aspects of Grails, with a new asset pipeline, with GORM sub-queries, and with a new Maven plugin.

The other big news is that next week is the GR8Conf Europe week! So you’ll certainly see lots of nice and interesting presentations being put online next week. And I hope I’ll also be able to publish this weekly news brief in time too!

## Releases

*   Graeme Rocher announces the final [release of Grails 2.4](https://spring.io/blog/2014/05/21/grails-2-4-released)
*   [Grails 2.3.9](https://grails.org/2.3.9+Release+Notes) released
*   [LightTable Groovy 0.0.5](https://github.com/rundis/LightTable-Groovy/releases/tag/0.0.5) with Gradle task execution
*   [Gretty v0.0.20](https://twitter.com/andreyhihlovski/status/469781264048746496), the Grable plugin for Jetty, by Andrey Hihlovskiy
*   Paolo Di Tommaso releases [Nextflow 0.0.8](http://nextflow.io), a workflow engine based on GPars dataflow, now including more splitting operators, updated to Groovy 2.3
*   Thibault Kruse released the [Groovysh Gradle plugin](https://github.com/tkruse/gradle-groovysh-plugin), to be able to launch Groovysh from your Gradle builds
*   [Spring Boot 1.1.0.M2](https://spring.io/blog/2014/05/27/spring-boot-1-1-0-m2-available-now) released by Dave Syer
*   Stergios Papadimitriou is adding [SciLab integration to JLabGroovy](https://code.google.com/p/jlabgroovy/wiki/SciLabInGroovyLab)

## Articles

*   Graeme Rocher explains how to [publish a POM with Gradle](http://grails.io/post/86513009278/publishing-a-pom-with-gradle)
*   Lots of MrHaki’s Goodness!
*   MrHaki's Groovy Goodness: [Implementing Traits at Runtime](http://mrhaki.blogspot.fr/2014/05/groovy-goodness-implementing-traits-at.html)
*   MrHaki's Groovy Goodness: [Chaining Traits](http://mrhaki.blogspot.fr/2014/05/groovy-goodness-chaining-traits.html)
*   MrHaki's Grails Goodness: [Exception Methods in Controllers](http://mrhaki.blogspot.fr/2014/05/grails-goodness-exception-methods-in.html)
*   MrHaki's Grails Goodness: [Run Groovy Scripts in Grails Context](http://mrhaki.blogspot.fr/2014/05/grails-goodness-run-groovy-scripts-in.html)
*   Broadleaf with [Groovy and Gradle](http://www.broadleafcommerce.com/blog/broadleaf-with-groovy-and-gradle-part-1) — Part 1
*   Broadleaf with [Groovy and Gradle](http://www.broadleafcommerce.com/blog/broadleaf-with-groovy-and-gradle-part-2) — Part 2
*   [Rapid application development with Spark, Groovy and JRebel](http://spinscale.github.io/2013-02-rapid-web-application-development-with-spark-groovy-jrebel.html) by Alexander Reelsen
*   A [Groovy DSL for Apache Wicket](http://wicketinaction.com/2014/05/groovy-dsl-for-wicket/)
*   An infographic on [6 reasons why Grails is an awesome framework](http://www.cygnet-infotech.com/infographic-6-reasons-why-grails-is-an-awesome-java-web-framework)
*   Magnus Rundberget blogs about exploring [new Gradle avenues with the Groovy Light Table](http://codewader.blogspot.no/2014/05/a-groovy-light-table-client-step-4.html) client
*   [Installing Groovy-Eclipse Compiler 2.3](http://www.javacodegeeks.com/2014/05/grails-2-4-released-installing-groovy-eclipse-compiler-2-3-in-eclipseggts.html) in Eclipse / GGTS
*   [Run Grails Commands on Heroku](http://www.objectpartners.com/2014/05/22/run-grails-commands-on-heroku/) by Brandon Fish
*   Tomás Lin writes about how to [add an optional internal Artifactory repository to Gradle](http://fbflex.wordpress.com/2014/05/24/adding-an-optional-internal-artifactory-repository-to-gradle-to-speed-up-builds/) to speed up builds
*   [Integrate Markdown plugin in Grails](http://www.oodlestechnologies.com/blogs/Integrate-Markdown-plugin-in-Grail) by Deepak Gupta
*   Iyobo Eki on [Grails: Shiro not redirecting to login page](http://deveki.com/softdev/grails-shiro-not-redirecting-to-login-page/)
*   Iyobo Eki about [Grails: 3 Simple steps to convert HTML templates into asset-pipeline layouts](http://deveki.com/softdev/grails-how-to-convert-html-templates-to-asset-pipeline-layouts/)

## Presentations

*   [Guillaume Laforge p](http://www.oodlestechnologies.com/blogs/Integrate-Markdown-plugin-in-Grail)resents [Gr](http://www.parleys.com/play/536c9780e4b0898c64d2e43e/chapter1/about)[oovy in 2014](http://www.oodlestechnologies.com/blog/filterByAuthor?author=deepakgupta) [and beyond](http://www.parleys.com/play/536c9780e4b0898c64d2e43e/chapter1/about), covering Groovy 2.3, in French, recorded at Devoxx France 2014
*   Cédric Champeau explains how [Gradle doesn’t just replace Maven](http://www.parleys.com/play/53676fb0e4b0593229b8583e/chapter1/about), but goes much beyond, in French, recorded at Devoxx France 2014

## Screencasts

*   Magnus Rundberget shows a [preview of the Gradle task integration in the Light Table Groovy plugin](https://twitter.com/mrundberget/status/469619079926808577)
    
## News

*   GradleWare features [online Gradle training](http://www.gradleware.com/services/training/gradle-virtual-training/)
*   Siemens releases a [Grails plugin for documenting RESTful APIs](https://github.com/siemens/restapidoc/)
*   [Grails Diary week 21](http://grydeske.net/news/show/46), by Jacob Aae Mikkelsen
    
## Code snippets

*   Guillaume Laforge implemented an example of [Huffman code](http://rosettacode.org/wiki/Huffman_coding#Groovy) in Groovy on Rosetta Code. You can create your own entries for the various puzzles in your favorite language!
*   Cédric Champeau implemented a [Hodor DSL](https://gist.github.com/melix/8580bdc709cdddd05277) based on Game of Thrones’ Hodor character
*   Grant McConnaughey shares a [Bash script](https://gist.github.com/grantmcconnaughey/d37b733dfd70439e17f1) that informs you when a Grails version is available on GVM
*   Peter Ledbrooks shares an example of a [multi-project Maven build for Grails](https://twitter.com/pledbrook/status/469382343112003584) applications
*   A demo of [Groovy compiled to JavaScript running in the clouds](https://twitter.com/grooscript/status/469948334862790659)

## Tweets

*   [CERN is using Grails](https://twitter.com/aalmiray/status/469141716738777089) for internal applications
*   Cédric Champeau shows that [Android development can be made much groovier](https://twitter.com/cedricchampeau/status/471338828876509184)!
*   [Grails 2.4](https://twitter.com/gvmtool/status/469139587647176704) is available in GVM
*   [Gradle support](https://twitter.com/java_hipster/status/470885227121111041) is underway for the JHipster project generator for AngularJS / Spring Boot apps
*   Ken Kousen notes a needed [dependency change if you use Groovy’s AntBuilder in Gradle](https://twitter.com/kenkousen/status/469914000156016641) when using Groovy 2.3
*   Cédric Champeau is working on an [Antlr v4 Gradle plugin](https://twitter.com/CedricChampeau/status/469404646516482048)
*   The [vscengis GIS (Geographic Information System) is using Groovy](https://twitter.com/vscenegis/status/471150776380051456) for its scripting layer
*   Rob Fletcher remarks that IntelliJ IDEA has an [intention to sort map entries alphabetically](https://twitter.com/rfletcherew/status/471310326537793536)
*   [Spring Boot 1.1.0.M2](https://twitter.com/gvmtool/status/471361060772249600) available for download on GVM

## Books

*   A [book on Reactor](https://twitter.com/j_brisbin/status/469925169398829057) is in the works at O’Reilly, by Jon Brisbin and Stéphane Maldini
    
## Events

*   If you're going to GR8Conf Europe, you can [download the GR8Conf Android app](https://twitter.com/cedricchampeau/status/471270003678117888) to prepare your program
*   The [GR8Conf Europe official beers](https://twitter.com/gr8conf/status/471255330111127552) are being bottled up!
*   The [second beer of GR8Conf Europe](https://twitter.com/sbglasius/status/471269691621916672) is called “Malt Liquor”
# Groovy Weekly #22


Releases keep coming, with a second RC for Grails 2.4, with Gaelyk and Griffon upgrading to Groovy 2.3, and already a bug-fix release of Groovy with version 2.3.1!

Don’t forget it’s the last week to [register to the GR8Conf Europe](http://gr8conf.eu) conference!

## Releases

*   [Second release candidate for Grails 2.4](https://twitter.com/grailsframework/status/466962419953446912)
*   Guillaume Laforge announces a [Groovy 2.3.1 bug-fix release]({{< ref "/posts/2014/05/19/groovy-2-3-1-is-out" >}})
*   [Gaelyk 2.1.2](http://gaelyk.appspot.com/download) released, built atop Groovy 2.3.0
*   Kunal Dabir released [version 2.1.2 of the Gaelyk template](https://twitter.com/kdabir/status/466281435892944896)
*   Andrés Almiray is upgrading [Griffon 2.0.0 beta](https://twitter.com/aalmiray/status/466297367361515520) with Groovy 2.3
*   The [Spud CMS engine for Grails](http://spudengine.com/news/2014-05-15-spud-grails-0-4-x-released-with-tons-of-new-features) released with new features
*   The [Groovy Light Table client released version 0.0.4](https://github.com/rundis/LightTable-Groovy/releases/tag/0.0.4) with further Gradle integration
*   [GMavenPlus 1.2 released](http://gmavenplus.56682.x6.nabble.com/gmavenplus-announce-GMavenPlus-1-2-Released-td137.html) for building your Groovy and Java projects with Maven

## Interviews

*   [Guillaume Laforge interviewed at the JAX conference about what makes Groovy groovy](http://jaxenter.de/videos/What-makes-Groovy-groovy-Interview-mit-Guillaume-Laforge-173539), the latest 2.3 release, and roadmap

## Presentations

*   At the JAX conference, Guillaume Laforge presented on "[what makes Groovy groovy](https://twitter.com/glaforge/status/466889089628012544)"
*   Guillaume Laforge presented the [functional aspects of Groovy](https://twitter.com/glaforge/status/466891844958572544) at the JAX conference
*   A screencast showing the [Gradle integration in the Light Table Groovy](https://twitter.com/mrundberget/status/468193954123755520) plugin

## Articles

*   Mixing [Spring Boot, Groovy, Spring Batch, Grails' GORM](http://vasya10.wordpress.com/2014/05/03/the-groovyspringbootbatchgormgroovydslbeanfactory/) together
*   An article [summarizing the latest release of Groovy 2.3](http://www.i-programmer.info/news/98-languages/7304-new-groovy.html)
*   [Grails: The Tomcat kill switch](http://www.mscharhag.com/2014/05/grails-tomcat-kill-switch.html), by Michael Scharhag
*   Michael Scharhag is blogging about [Grails Controller namespaces](http://www.mscharhag.com/2014/05/grails-controller-namespaces.html)
*   [OAuth 2.0 using Grails](http://www.intelligrape.com/blog/2014/05/13/grails-way-of-oauth-2-0-to-access-google-apis-part-1/)
*   Brandon Fish explains the [Grails R14 memory error on Heroku](http://www.objectpartners.com/2014/05/13/grails-r14-error-memory-quota-exceeded-on-heroku/)
*   Alex Staveley speaks about [Groovy’s “with”](http://dublintech.blogspot.ie/2014/05/the-magic-of-groovys-with.html)
*   [Automatically test your dirty Grails classes](http://www.objectpartners.com/2014/05/15/automatically-test-your-dirty-grails-classes/) by Igor Shults
*   [Receiving emails in a Grails](http://www.intelligrape.com/blog/2014/05/14/receive-email-using-subethasmtp-the-local-smtp-server/) app by Akash Sethi

## Code snippets

*   Kenneth Endfinger shows a [Node.js hello world written in Groovy](https://gist.github.com/kaendfinger/fdab7ab0627baaa67884) and compiled to JavaScript with GrooScript

## Tweets

*   Robert Fletcher is [ecstatic about Groovy’s closure coercion to “SAM” types and type inference](https://twitter.com/rfletcherew/status/467255461126086656), as this makes for very low ceremony code
*   Robert Fletcher remarks that you can’t use [@CompileStatic on Spock specifications](https://twitter.com/rfletcherew/status/467307293408002048), but you can on their helper methods
*   Vladimir Orany updated his "[Gliding Gaelyk](https://twitter.com/musketyr/status/466545743168540674)" presentation and demo app
*   Magnus Rundberget is [integrating Gradle in the Groovy support for the Light Table IDE](https://twitter.com/mrundberget/status/467078036438134784), showing an example of the Groovy Stream library
*   Cédric Champeau wished that [Groovy were taught more at school](https://twitter.com/cedricchampeau/status/466858251221749760)
*   Schalk Cronjé is looking into adding [Amazon S3 support to Groovy VFS](https://twitter.com/ysb33r/status/464335761161326592)
*   Peter Ledbrook is wondering [why the Spock testing framework doesn’t have a logo](https://twitter.com/pledbrook/status/468390877736763392)
*   Guillaume Laforge shows some [Spock logo ideas](https://twitter.com/glaforge/status/468455234688544768/photo/1) he proposed to Peter Niederwieser
*   Dierk König notices that Java 8 features are a notable improvement when working with JavaFX, but it's only with [Groovy and GroovyFX that it is as slick](https://twitter.com/mittie/status/468423252633980928)
*   Robert Fletcher reports a [gotcha when using Spock with fields and JUnit rules](https://twitter.com/rfletcherew/status/468422318062985216)
*   More fun from Rob Fletcher showing how he cleverly used [Groovy's alias imports to change void into "should" in his Spock](https://twitter.com/rfletcherew/status/468425797011660800) specifications
*   Baruch Sadogursky [happily converted a painful 300 lines of Java code using the Maven Aether library into 20 lines of Groovy](https://twitter.com/jbaruch/status/468356911042027520) code
*   Cédric Champeau added [“layouts” to the markup template engine](https://twitter.com/cedricchampeau/status/468438346474471424) in Groovy 2.3.1
*   [Groovy 2.3.1](https://twitter.com/gvmtool/status/468485257654976512) is available through GVM
    
## Code contributions

*   Cédric Champeau suggests possible [improvements that can be contributed](https://twitter.com/cedricchampeau/status/466243598254878720) by the community around the Groovy 2.3 markup template engine

## News

*   [Grails Diary](http://grydeske.net/news/show/44) #19 by Jacob Aae Mikkelsen
*   Luke Daley announces [Marcin Erdmann is becoming the new project lead of the Geb](https://twitter.com/ldaley/status/466884136754376704) project
*   The [Grails Diary](http://grydeske.net/news/show/45) week 20 by Jacob Aae Mikkelsen
*   Geb now offers [cloud browser testing](http://www.gebish.org/manual/snapshot/cloud-browsers.html#cloud_browser_testing) with SauceLabs and BrowserStack
*   Beaker, a [data science laboratory with Groovy integration](http://beakernotebook.com/)

## Events

*   Only a [few days left to register to attend GR8Conf](https://twitter.com/gr8conf/status/468277209677844481) Europe!
*   If you’re a student, you can get [discounts for GR8Conf Europe](https://twitter.com/gr8conf/status/468634470661500928)
*   There are currently [19 countries represented by the GR8Conf attendees](https://twitter.com/gr8conf/status/468745724696752128)
# Groovy 2.3.1 is out


The Groovy development team is happy to announce the bug fix **release of Groovy 2.3.1**.  

Lots of bugs have been reported and fixed.  

Some of the highlights among those fixes:

*   the classloader related problems with `@Grab`
*   several generics handling issues
*   a problem preventing Groovy from loading its modules on IBM mainframes
*   a problem preventing Groovy from being loaded as an OSGi module in certain OSGi containers

You can read the [JIRA release notes](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=20366), and [download](http://groovy.codehaus.org/Download) the latest distribution.
# Groovy presentations at JAX


I had the pleasure of coming back to the JAX conference after a number of years of absence, and I presented about what makes Groovy groovy, and functional Groovy, showing the functional aspects of the language.  

Here's the latest update of my What makes Groovy groovy presentation:  

{{< speakerdeck c3de6d10be4501313e6b7a86bf9f6a20 >}}

And the Functional Groovy presentation as well:

{{< speakerdeck fba3dc80be4601313e6a7a86bf9f6a20 >}}


# Groovy Weekly #21


Now that [Groovy 2.3.0 is out]({{< ref "/posts/2014/05/05/groovy-2-3-0-is-out" >}}), it’s going to be Grails turn! Graeme announced a release candidate for Grails 2.4, so take your chance to test drive it to make Grails 2.4 an awesome release!

Last but not least, you still have two weeks to buy your tickets for the [GR8Conf Europe 2014](http://gr8conf.eu/#/)!

## Releases

*   Graeme Rocher announces the [release of Grails 2.4 RC1](https://twitter.com/grailsframework/status/464401639030657025) with Groovy 2.3 and Spring Framework 4.0.4
*   [Version 0.5 of Grooscript](https://twitter.com/grooscript/status/463817185991729152) released with Groovy 2.3 traits support
*   Martin Lippert announces the [release of Groovy / Grails Tool Suite 3.5.1](https://spring.io/blog/2014/05/06/spring-tool-suite-and-groovy-grails-tool-suite-3-5-1-released) with support for Grails 2.3.8 and Groovy 2.3.0
*   [JBake 2.3.0](https://twitter.com/javabake/status/465518849748922368) is out with Groovy and Thymeleaf template support
*   Benjamin Muschko releases a [Gradle Docker plugin](https://github.com/bmuschko/gradle-docker-plugin) using the remote API for managing images and containers
*   [Gretty 0.0.16](https://twitter.com/AndreyHihlovski/status/465957295076442112) is out, the advanced Gradle plugin for running webapps on Jetty

## Interviews

*   InfoWorld's Paul Krill interviewed [Guillaume Laforge about the release of Groovy](http://www.infoworld.com/t/java-programming/one-now-two-later-groovy-updates-add-java-8-support-242229) 2.3.0

## Presentations

*   Adoption of the (groovy-based) [Job DSL plugin](https://www.youtube.com/watch?v=FeSKrBvT72c) (for Jenkins) at Netflix
*   Second part of the [Gradle Workshop](http://www.gradleware.com/news/blog/video-tutorial-part-2-gradle-workshop-peter-niederwieser) by Peter Niederwieser from the Gradle Summit 2013
*   Trisha Gee demoes [building a web application using Java, HTML5, Angular.js, Mongo.DB, Groovy and microservices](http://www.infoq.com/presentations/demo-java-javascript-mongodb) in one hour.

## Articles

*   Announcement of the [Groovy 2.3.0 release on the Spring.IO blog](https://spring.io/blog/2014/05/07/groovy-2-3-released)
*   [Gradle tip for how to attach a debugger](http://blogs.steeplesoft.com/posts/2013/09/10/gradle-tip-attaching-a-debugger/)
*   An article on [Groovy DSLs with the help of closures and delegates](http://java.dzone.com/articles/groovy-closures-owner-delegate) by Alex Staveley
*   [Spring integration testing with Spock](http://www.kubrynski.com/2014/01/spring-integration-testing-with-spock.html) by Jakub Kubrynski
*   An update on the [Groovy Light Table client](http://codewader.blogspot.no/2014/05/a-groovy-light-table-client-step-3.html)

## Code snippets

*   Cédric Champeau shows an example of [improved composition using fragments and the Markup Template Engine](https://gist.github.com/melix/240e961b6cce70d37592)

## Tweets

*   Video of the [Groovy Podcast episode 1](https://twitter.com/pledbrook/status/464403159524601856) by Peter Ledbrook
*   Peter Ledbrook also published the [audio of the Groovy podcast](https://twitter.com/pledbrook/status/464413601009508353)
*   The [interviews recorded at Greach 2014](https://twitter.com/autentia/status/463928823168253953) are now subtitled
*   Rob Fletcher calls to action to [vote for the traits support in IntelliJ IDEA](https://twitter.com/rfletcherew/status/466176067557130242)

## Mailing-lists discussions

*   The [Grails mailing-lists from Codehaus are closing](http://grails.1312388.n4.nabble.com/Deprecating-The-Grails-Mailing-Lists-td4656735.html), announced Jeff Brown. Technical questions will be headed to StackOverflow, whereas a dedicated Google Group is being created for general discussions and announcements

## Google+ Posts

*   Ryan Vanderwerf shares a little [preview of the "Getting Groovy with Lego Mindstorms EV3" workshop](https://plus.google.com/b/101432359761228268146/118206038047009918474/posts/aGHTV1MNLBG?cfem=1) at the upcoming GR8Conf Europe 2014
    
## News

*   You can try GrooScript online to [convert your Groovy code to JavaScript](https://twitter.com/grooscript/status/465188785589092352)
*   Robert Fisher proposes the [Gradle License plugin](https://github.com/RobertFischer/Gradle-License-Report/blob/master/README.md) to generate a report of the licenses of the dependencies used in your project

## Jobs

*   A startup in Paris, France, is [looking for a Grails developer](https://remixjobs.com/emploi/Developpement/Start-up-Developpeur-Java-Grails-passionne-H-F/24451)
    
## Events

*   The SpringOne2GX 2014 conference in Dallas has published most of its [agenda](https://2014.event.springone2gx.com/schedule/2014-09-09)
*   Two weeks left to [get your GR8Conf Europe ticket](https://twitter.com/gr8conf/status/466104656427745280)!
*   Meet the [GR8Conf Europe team](http://gr8conf.eu/#/about)
# Groovy Weekly #20


Tthe big news of the week is the [release of Groovy 2.3.0]({{< ref "/posts/2014/05/05/groovy-2-3-0-is-out" >}})! With traits, support for running on JDK 8, new AST transformations, lightning fast JSON support, and more!

Be sure to read the Groovy 2.3.0 [release notes](http://bitly.com/g230notes) to get all the juicy details!

And vote up the DZone link to make a bit of buzz on the small [interview of Guillaume Laforge](http://www.dzone.com/links/interview_about_the_release_of_groovy_23.html) about the release.

Also, Hubert Klein Ikking was on a blogging spree, as he wrote many new items in the Groovy Goodness series with snippets showing the new features in action. So don’t miss those examples linked below!

## Releases

*   Guillaume Laforge announces the [final release of Groovy 2.3.0]({{< ref "/posts/2014/05/05/groovy-2-3-0-is-out" >}})
*   [Ratpack 0.9.4](http://www.ratpack.io/versions/0.9.4) relased
*   Schalk Cronjé shares a pre-release of his [Groovy VFS command-line project](http://groovy.329449.n5.nabble.com/ANN-VFS-Command-line-pre-release-version-on-Bintray-td5719457.html), for copying, moving files around from multiple sources from the command-line
*   Florian Freudenberg created a [Windows Powershell port of GVM command-line](https://github.com/flofreud/posh-gvm) interface for Groovy developers using Windows, thanks to the GVM APIs
*   Latitude 1.0 has been released. [Latitude is an API to ease property reference in Groovy](https://github.com/will-lp/latitude), allowing it to be type checked and customized for use within queries, ignoring fields, etc. An IDE can auto-complete, refactor and find usages, and @TypeChecked can point typos in it.

## Interviews

*   InfoQ publishes a little [interview of Guillaume Laforge about the release of Groovy 2.3.0](http://www.dzone.com/links/interview_about_the_release_of_groovy_23.html). You can vote up the associated DZone link!

## Presentations

*   Vladimír Orany spoke about [Gaelyk and Glide](http://greach.es/speakers/vladimir-orany-gliding-gaelyk/) at Greach 2014
    
## Articles

*   Learn about all the latest [features of Groovy 2.3.0 in the detailed release notes](http://bitly.com/g230notes)
*   InfoQ features an article by Matt Raible on the [JSON performance improvements](http://www.infoq.com/news/2014/04/groovy-2.3-json) coming up in Groovy 2.3
*   [C# is getting Groovy](http://blogs.msdn.com/b/jerrynixon/archive/2014/02/26/at-last-c-is-getting-sometimes-called-the-safe-navigation-operator.aspx), borrowing Groovy's ?. null safe navigation operator (already copied by CoffeeScript)
*   David Norton writes about how to [reuse your Gradle logic across the enterprise](http://www.objectpartners.com/2014/04/24/reuse-your-gradle-logic-across-the-enterprise/)
*   MrHaki's Groovy Goodness celebrates Groovy 2.3.0!
*   [use @Sortable annotation to make classes Comparable](http://mrhaki.blogspot.dk/2014/05/groovy-goodness-use-sortable-annotation.html)
*   [extra methods for NIO path](http://mrhaki.blogspot.fr/2014/05/groovy-goodness-extra-methods-for-nio.html)
*   [more efficient tail recursion with @TailRecursive annotation](http://mrhaki.blogspot.fr/2014/05/groovy-goodness-more-efficient-tail.html)
*   [@BaseScript with abstract run script method](http://mrhaki.blogspot.fr/2014/05/groovy-goodness-basescript-with.html)
*   [use @Builder AST transformation for fluent API](http://mrhaki.blogspot.fr/2014/05/groovy-goodness-use-builder-ast.html)
*   [@Builder definition with extra type checks](http://mrhaki.blogspot.fr/2014/05/groovy-goodness-builder-definition-with.html)
*   [using @Builder to create fluent API for other classes](http://mrhaki.blogspot.fr/2014/05/groovy-goodness-using-builder-to-create.html)
*   [check configuration property is set in ConfigObject](http://mrhaki.blogspot.fr/2014/05/groovy-goodness-check-configuration.html)
*   [extend ConfigSlurper with custom environments](http://mrhaki.blogspot.fr/2014/05/groovy-goodness-extend-configslurper.html) sections
*   Grails Goodness by MrHaki: [Using Aliases as Command Shortcuts](http://mrhaki.blogspot.fr/2014/05/grails-goodness-using-aliases-as.html)
*   [Multi-factor authentication](http://www.gobloomhealth.com/multi-factor-authentication-part-1/) with Grails, part 1, by Kyle Boon
*   [GORM: bulk delete already](http://deveki.com/softdev/gorm-bulk-delete-already/)
*   [Getting SVN info using Groovy](http://octodecillion.com/blog/getting-svn-info-using-groovy/)
*   Implementing [many to many relation between domains in Grails with MongoDB](http://www.oodlestechnologies.com/blogs/Implementing-many-to-many-relation-between-domains-in-Grails-with-MongoDB)
*   [Tracking Hibernate statistics across Grails actions](http://www.objectpartners.com/2014/04/22/tracking-hibernate-statistics-across-grails-actions/) by Igor Shults
*   [Groovy implementation of the INI](http://octodecillion.com/blog/groovy-implementation-of-inix-file-format-part-2/) file format
*   [Implementing social auth with Grails](http://www.oodlestechnologies.com/blogs/Implement-SocialAuth-using-Grails) by Sumit Rathi
*   [Spring Security Permission Based framework](http://www.intelligrape.com/blog/2014/04/28/spring-security-permission-based-framework/)
*   [Debugging your Grails application in IntelliJ IDEA](http://www.intelligrape.com/blog/2014/04/22/simple-debugging-in-intellij-idea-part-1/)
*   [Facebook Oauth](http://www.intelligrape.com/blog/2014/04/28/facebook-oauth-for-fetching-page-token/) for fetching page token with Grails
*   [Groovy database resource handling](http://groovy.dzone.com/articles/groovy-database-resource) by Robert Greathouse

## Tweets

*   The link to [Guillaume Laforge's interview on DZone is promoted as a "big link"](https://twitter.com/DZoneLinks/status/463679195147538432)!
*   [Groovy 2.3.0](https://twitter.com/gvmtool/status/463356426354954240) is available through GVM
*   Ken Kousen reports the [change in the groovysh commands now starting with colons](https://twitter.com/kenkousen/status/463656597068058624)
*   Peter Ledbrook announces the [next Groovy podcast](https://twitter.com/pledbrook/status/463251293394710529) for Thursday
*   Jörn Huxhorn noticed the [reworked generics handling of Groovy 2.3 found bugs that slipped through the old type checker](https://twitter.com/huxi/status/463372504518909952)! But if you find regressions in this area, please report them!
*   Sébastien Blanc visited the [Fort Griffon in Besançon, France](https://twitter.com/sebi2706/status/461064801951952896). In honor of Andrés Almiray's work on the Griffon framework?
*   Bertrand Goetzmann shares some [Groovy examples for scripting his TiddlyWikiFx](https://twitter.com/bgoetzmann/status/461468578387349504) project
*   Peter Ledbrook reminds us with his funny tweet that it's better to [use the #groovylang hashtag on Twitter](https://twitter.com/pledbrook/status/461838863900893184) rather than #groovy as there's less noise about non-Groovy language related topics

## Google+ Posts

*   Xavier Ducrohet announces a [new version of the Gradle Android plugin](https://plus.google.com/u/0/+AndroidDevelopers/posts/QCpXF1BxKPm)

## Code Snippets

*   Tim Yates pushes a gist with variants of a [gaussian distribution with Java 8, Groovy, and GPars](https://gist.github.com/glaforge/397fc259320ffd0f7c25)
*   Tim Yates plays with a [metaprogramming addition to Java 8's LocalDate](https://gist.github.com/timyates/527e116c225b23c89e16) to support Groovy's + days addition.
*   The new [@Builder transformation](https://gist.github.com/dmahapatro/5e35e59cad2736a6723f) of Groovy 2.3 covered with its different implementation strategies

## News

*   Jacob Aae Mikkelsen posted [Grails Diary](http://grydeske.net/news/show/42) week 17
*   Jacob Aae Mikkelsen published week 18 of the [Grails Diary](http://grydeske.net/news/show/43)

## Books

*   [Grails in Action, Second Edition](https://twitter.com/manningmeap/status/461907899540074496), by Peter Ledbrook and Glen Smith, has updated all chapters & appendices

## Events

*   With all the [videos published from the Greach](https://twitter.com/greach_es/status/461414161940226048) 2014 conference, viewers accumulated 73000 minutes of viewing!
*   GR8Conf US 2014 [registration](https://twitter.com/ddelponte/status/461225051527069697) is open
*   GR8Conf Europe announces [Cygnet Infotech as sponsor](https://twitter.com/gr8conf/status/463524508176220160)
# Groovy 2.3.0 is out!


The Groovy development team is proud to announce the final release of Groovy 2.3.0!  

Groovy 2.3 is the new major release of Groovy, featuring official support for running Groovy on JDK 8, traits, new and improved AST transformations like `@TailRecursive`, `@Builder` and `@Sortable`, a new NIO2 module with Path support, lightening fast JSON parsing and building, closure parameter type inference, a new markup template engine, Groovysh and GroovyConsole ease of use improvements, a new `GroovyAssert` test utility, more `@BaseScript` class capabilities, and more.  

Please read the [Groovy 2.3.0 release notes](http://bit.ly/g230notes) for further details on all these exciting new features!  

You can [download Groovy](http://groovy.codehaus.org/Download) at the usual location.  

JIRA will give you the [detailed change log](http://bit.ly/g230jira) for this release.  

Groovy wouldn’t be what it is without your support, your bug reports and feature requests, your contributions and pull requests, so big thanks to all those who contributed to this release in a way or another, including the usual suspects of the core team (Jochen, Paul, Cédric and myself), but also André, Andres, Tim, Pascal, Johanes, Paolo, Thibault, Rick and Andrey, Jim (base script class), Damien, Kenneth and several others I’ve forgotten to mention!
# Groovy 2.3.0 RC 4 is out


To celebrate the [International Workers' Day](http://en.wikipedia.org/wiki/International_Workers'_Day) (a holiday in half of the world's countries, no less! including mine), we're announcing the release of Groovy 2.3.0-RC-4.  

Yes, RC-4 and not RC-3, as we're still having some issues with our build and deployment infrastructure which made us have to skip a bit.  

Thanks to your feedback, we managed to iron out some more issues and regressions we were having with the tricky generics handling.  

You can have a look at the [detailed JIRA release notes](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=20359) for the issues solved, and [download the latest RC](http://groovy.codehaus.org/Download) build at the usual place (or just update the Gradle or Maven dependency coordinates).
# Machine Learning à Mix-IT 2014


J'ai eu le plaisir de préparer et de présenter une conférence de 50 minutes sur le Machine Learning, avec mon ami [Didier Girard](https://plus.google.com/+DidierGirard/posts), lors de la [conférence Mix-IT 2014](http://www.mix-it.fr/) à Lyon.  

50 minutes, c'est court pour présenter un si vaste et passionnant sujet !  

J'avais fait un peu de machine learning pendant mes études, mais je n'avais jamais eu l'occasion de m'y replonger dedans depuis. Mais aujourd'hui, avec de plus en plus de données récoltées (le "big data", l' "Internet of Things"...), il faut savoir apprendre de ces données, découvrir de nouvelles tendances, prévoir un comportement, classifier ces données... et le Machine Learning est ce qui vous permet de faire tout ça !  

Donc un sujet très porteur et très prometteur en ce moment !  

La question nous avait été posée de savoir comment on pouvait en apprendre plus sur le Machine Learning, et pour y répondre également ici sur ce blog, je suggère à ceux qui sont intéressés de suivre un cours en ligne comme celui de [Andrew Ng de Stanford sur Coursera](https://www.coursera.org/course/machlearning) : une approche super didactique et passionnante.  
  
En attendant, voici les slides de la présentation :

{{< speakerdeck 5b7c368530274850b1ca5c7dad56cabf >}}
# Groovy Weekly #19


Another busy week for the Groovy ecosystem, with key releases of Groovy, Grails, Gradle, GPars, and CodeNarc! This can be labeled as a “release week”!

## Releases

*   Guillaume Laforge announces the [release candidate of Groovy 2.3]({{< ref "/posts/2014/04/24/release-candidate-for-groovy-2-3" >}})
*   Guillaume Laforge announces the [second release candidate of Groovy 2.3]({{< ref "/posts/2014/04/28/second-release-candidate-of-groovy-2-3" >}})
*   Graeme Rocher announces a Grails joint release with [Grails 2.3.8 and Grails 2.4-milestone-2](http://grails.1312388.n4.nabble.com/ANN-Grails-2-3-8-amp-2-4-0-M1-out-td4656282.html)
*   [Gradle 1.12 released](http://forums.gradle.org/gradle/topics/gradle_1_12_released) with some nice universal performance improvements, more control of the dependency resolution process, an improved API for IDE integration, Clang and CUnit support for native code and a slew of bug and compatibility fixes
*   [Release of GORM for MongoDB v3.0](https://twitter.com/grailsframework/status/459597120581144576) with MongoDB 2.6 support (new GeoJSON types, text search)
*   The CodeNarc static code analysis tool for Groovy releases [CodeNarc version 0.21, with 15 new rules](http://groovy.329449.n5.nabble.com/ANN-Announcing-CodeNarc-0-21-td5719330.html)
*   [GPars 1.2](http://gpars-user-mailing-list.19372.n3.nabble.com/GPars-1-2-0-released-td4024974.html) has been released

## Presentations

*   Jorge Franco presents [GrooScript, the Groovy to JavaScript compiler](http://greach.es/speakers/jorge-franco-grooscript/), at Greach 2014
*   Cédric Champeau gave an excellent workshop at Greach 2014 entitled "[unleashing the power of AST transformations](http://greach.es/speakers/cedric-champeau-unleashing-the-power-of-ast-transformations/)"
*   Cédric Champeau and Fabrice Matrat present about "Groovy, head in the cloud", at Greach 2014, where they show [how to secure Groovy code in a cloud and shared environment](http://greach.es/speakers/fabrice-matrat-cedric-champeau-groovy-head-in-the-cloud/)
*   Rick Hightower created a presentation on [Java JSON parser benchmarking](http://fr.slideshare.net/richardhightower/java-json-benchmakr), upon his work on the Groovy and Boon parsers performance work
*   [Grails workshop](http://greach.es/speakers/fernando-redondo-can-you-tell-me-how-to-get-to-sesame-street-i-wanna-be-a-grails-rookie-star-there/) given at Greach 2014 by Fernando Redondon

## Articles

*   MrHaki writes about [restricting script syntax with SecureASTCustomizer](http://mrhaki.blogspot.fr/2014/04/groovy-goodness-restricting-script.html)
*   MrHaki defines [compilation customizers with the builder syntax](http://mrhaki.blogspot.fr/2014/04/groovy-goodness-define-compilation.html)
*   MrHaki explains how to [customize the @ToString transform](http://mrhaki.blogspot.fr/2014/04/groovy-goodness-customize-tostring.html)
*   Using [Spock configuration with Grails](http://wordpress.transentia.com.au/wordpress/2014/04/23/using-spock-configuration-in-grails/)
*   Julien Ponge comes back on Andrey Bloschetsov and Rick Hightower [JSON benchmarks](http://julien.ponge.org/blog/revisiting-a-json-benchmark/), with a few updates to improve the reliability of the benchmarks. Boon is underlying the new JSON capabilities of Groovy 2.3 while the Groovy represented in this article refers to the pre-Groovy 2.3 parser and serializer.
    
## Tweets

*   Cédric Champeau is teasing about his work on [Groovy support for Android](https://twitter.com/CedricChampeau/status/459260216841097216)
*   Graeme Rocher shows the compelling [conciseness and readability of GORM vs raw Hibernate](https://twitter.com/graemerocher/status/461065311819554817)
*   The GR8Conf Europe team is [looking for a name for its last special conference beer brew](https://twitter.com/gr8conf/status/460508009522003968), if you’ve got suggestions
*   [Groovy 2.3-rc-1](https://twitter.com/gvmtool/status/459428432557129728) available through GVM
*   [Gradle 1.12-rc-2](https://twitter.com/gvmtool/status/459376588539576320) is available through GVM
*   [Grails 2.3.8 and 2.4.0-milestone-2](https://twitter.com/gvmtool/status/459366821783928833) now available for download on GVM
*   Dan Allen mentions that a Google Summer of Code student will be working on a [Groovy scripting frontend for Arquillian](https://twitter.com/mojavelinux/status/459500064604712961)
*   Peter Ledbrook, scratching his head, points at the [first Grails podcast episode in video](https://twitter.com/pledbrook/status/459440167263408128) form
*   Peter Ledbrook published an [MP3 version of the Grails podcast](https://twitter.com/pledbrook/status/461034693279121408) in addition to the video stream
*   Alex Sanchez remarks that lots of [Java developers are getting acquainted with Groovy thanks to Gradle and Spock](https://twitter.com/AlexSanchezSTH/status/459353715506708480)
*   Bertrand Goetzmann notes that [Grails also has a "wrapper" like Gradle](https://twitter.com/bgoetzmann/status/459062310691430400) to ease having everybody on the team run the very same version of Grails
*   Looking at the [Groovy meta-programming documentation reminds us how awesome Groovy is](https://twitter.com/gregopet/status/459617010239143936)!

## Code Snippets

*   How to [use Grails' GSP view technology in Spring Boot](https://github.com/grails/grails-boot/tree/master/sample-apps/gsp)

## News

*   Netflix is well known for its heavy use of Groovy, Grails and Gradle for their infrastructure, and they are sharing project Nebula, a [platform for handling and sharing Gradle plugins](http://nebula-plugins.github.io/)

## Events

*   [Object Partners become a sponsor of GR8Conf Europe](https://twitter.com/gr8conf/status/459445157017174016) 2014
*   The GR8Conf Europe crew is [brewing the official conference beverage](https://twitter.com/brianjohnsendk/status/460047137490075648)
*   The [agenda of GR8Conf Europe 2014](http://gr8conf.eu/#/agenda) has been posted
# Second release candidate of Groovy 2.3


The Groovy team is happy to announce the **release of Groovy 2.3.0-rc-2**. This should be the last release candidate until the final release in a couple days.  

This release ironed out a few bugs, for instance in generics handling, or made the groovydoc tool aware of traits.  

Note that the latest fixes in the traits support introduce a binary incompatibility compared to the previous release candidate.  

You can have a look at the JIRA release notes: [https://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=20357](https://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=20357)  
  
And you can download Groovy at the usual place: [http://groovy.codehaus.org/Download](http://groovy.codehaus.org/Download)  

Thanks for your attention, and keep it Groovy!
# Release candidate for Groovy 2.3


The Groovy team is happy to announce the first release candidate of Groovy 2.3!  

The major changes between this version and the last beta include:

*   a simplification of the semantics of traits, by [removing `@ForceOverride` and making it the default](http://beta.groovy-lang.org/docs/groovy-2.3.0-rc-1/html/documentation/core-traits.html#_differences_with_java_8_default_methods)
*   the [implementation of stackable traits](http://beta.groovy-lang.org/docs/groovy-2.3.0-rc-1/html/documentation/core-traits.html#_chaining_behavior) for improved composition of behavior
*   a new [`@Builder` AST transformation to generate builders for immutable classes](http://beta.groovy-lang.org/docs/groovy-2.3.0-rc-1/html/documentation/core-metaprogramming.html#_available_ast_transformations)
*   bug fixes on generics type inference

For more details on the changes in this version, please refer to the [JIRA release notes](https://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=20227). 
 
The release can be [downloaded](http://groovy.codehaus.org/Download) from the usual place.  

We're looking forward to hearing about your feedback, and unless anything super critical arises, we're targeting an imminent final release next week!
# Groovy Weekly #18


The Easter bunny is delivering the latest Groovy Weekly column!

With your chocolate eggs, you’ll get some bits of functional programming, a tutorial on Groovy traits, details of the JSON serialization performance improvements, and also get the chance of voicing your feedback on things like Groovy’s support of Java 8 lambda syntax, on the Ratpack async support, and more.

## Releases

*   groovy-comprehension is a groovy extension module / AST transformation which provides simple [list comprehension functionality](https://github.com/uehaj/groovy-comprehension) similar to that of Haskell, Scala or Python. Under the hood it’s a 'monad' comprehension but you don't care about it for use.

## Presentations

*   Guillaume Laforge gave a brand new presentation on Groovy, at Devoxx France 2014, covering the [novelties in the upcoming Groovy 2.3 release](https://speakerdeck.com/glaforge/groovy-in-2014-and-beyond-at-devoxx-france)
*   Cédric Champeau spoke about [Gradle vs Maven](https://twitter.com/CedricChampeau/status/457176735717785601) at the Devoxx France 2014 conference last week. The slides are in French, but even if you're not speaking it, you should get some interesting tidbits from the code samples and links
    
## Articles

*   Andrey Bloschetsov published follow up benchmarks after Rick's on the [JSON performance improvements](https://github.com/bura/json-benchmarks), this time for the serialization of JSON payloads
*   A [tutorial on Groovy traits](http://www.mscharhag.com/2014/04/groovy-23-introduces-traits.html) by Michael Scharhag
*   Kyle Boon on the [state of code coverage for Groovy](http://kyleboon.org/blog/2014/04/17/code-coverage-with-groovy/)
*   Marcin Gryszko's [quest for persistable Groovy immutability](http://grysz.com/2014/04/22/quest-for-persistable-groovy-immutability/)
*   Ken Kousen on the "[closure of no return](http://kousenit.wordpress.com/2014/04/16/the-closure-of-no-return/)", on the fact you can "return" from the outer scope of the closure you pass to an each or findAll method
*   Ken Kousen received some [excellent feedback on his article "the closure of no return"](http://kousenit.wordpress.com/2014/04/18/responses-to-the-closure-of-no-return/) showing the way towards the solution and best approaches
*   [Grails design best practices](http://www.javacodegeeks.com/2013/04/grails-design-best-practices.html) by Nitin Kumar
*   MrHaki on [extending the Grails IntegrateWith Command](http://mrhaki.blogspot.fr/2014/04/grails-goodness-extending-integratewith.html)

## Tweets

*   [Should Groovy support the Java 8 lambda syntax](https://twitter.com/ldaley/status/456705374775566337)? Your opinion is interesting.
*   The Ratpack team is looking for [feedback on their async support](https://twitter.com/ratpackweb/status/457122433128873984)
*   Cédric Champeau advises developers to [always use the Gradle wrapper](https://twitter.com/CedricChampeau/status/458548956025614336), in particular within OSS projects, as it makes it easier to have a consistent build experience among developers and new contributors
*   Schalk Cronjé is playing around with Greyton, [a Groovy DSL (on top of JClouds)](https://twitter.com/ysb33r/status/456189345075318785) to simplify cloud devops and is looking for feedback
*   Schalk Cronjé is looking for [volunteers to try the SMB / CIFS provider for his Groovy VFS](https://twitter.com/ysb33r/status/458558435869855744) library
*   Dierk König shares a handy [Groovy one-liner to print your local IP address](https://twitter.com/mittie/status/456189301202911232) from the command-line
*   Dan Woods fell into the trap of [using GStrings as keys for maps](https://twitter.com/danveloper/status/456708683527778305), and the follow up discussion on Twitter on the topic is worth a read
*   Russ Miles finds [Groovy elegant and simple for using nested data structures](https://twitter.com/russmiles/status/456767251572858880), adding to Spring Boot's productivity too

## Google+ posts

*   [Monadic combinators](https://plus.google.com/103753917802203497881/posts/i2JE4WZa3A6) in Groovy by Mark Perry
    
## News

*   Jacob Aae Mikkelsen on the [Grails Diary #16](http://grydeske.net/news/show/41)
*   Glu is now [hosting its binary release thanks to Bintray](https://twitter.com/glutweets/status/457587070886637568)

## Books

*   The [Grails Goodness book](http://mrhaki.blogspot.fr/2014/04/grails-goodness-notebook-is-published.html) has been published by MrHaki

## Jobs

*   James Foley is currently looking to network with an experienced (3 years plus) [Groovy/Grails Application Developer](http://sni-technology.jobs.net/job/Grails-Application-Developer/J3G74X69K69XRTS6QCQ/) for an excellent on going contract OR contract to hire scenario. 100% Remote opportunity!

## Events

*   The [SpringOne2GX 2014 conference in Dallas is now open for registration](https://twitter.com/mewzherder/status/456510357482131456), with a super early bird price
*   And of course, [GR8Conf Europe](http://gr8conf.eu/) and [US 2014](http://gr8conf.us/) are still open for registration too!
# Groovy Weekly #17


Busy conference times:

Greach is over, but we’re lucky to get the next batch of presentations and videos online on the [Greach Youtube channel](https://www.youtube.com/user/TheGreachChannel).

The [GR8Conf Europe](http://gr8conf.eu/) early bird price has been extended for another week.

And Cédric and myself (Guillaume) are heading to the Devoxx France conference to speak about Groovy and Gradle.

While at the same time, the Groovy team is delivering [a new beta for the lovely Groovy 2.3]({{< ref "/posts/2014/04/10/second-beta-for-groovy-2-3" >}}) release.

Busy times, I tell you!

## Releases

*   Guillaume Laforge announces a [second beta for Groovy 2.3.0]({{< ref "/posts/2014/04/10/second-beta-for-groovy-2-3" >}})
*   [Groovy 2.3.0-beta-2](https://twitter.com/gvmtool/status/454366295476416512) is available through GVM
*   A [Spring Boot Lazybones template](https://twitter.com/pledbrook/status/454523372756795392) available

## Interviews

*   [Interviews recorded at Greach](http://autentia.com/2014/04/15/las-entrevistas-de-greach-ya-disponibles): Alberto Vilches, Russel Winder, Cédric Champeau, Graeme Rocher, Guillaume Laforge, Sébastien Blanc, Corrine Krych and others

## Presentations

*   You can watch all the [videos and read the slides of all the presentations given at the Greach 2014 conference](https://storify.com/glaforge/greach-2014-videos-and-slides), in Madrid (Spain)
*   Cédric Champeau presents "[Making Java APIs Groovy](http://greach.es/speakers/cedric-champeau-making-java-apis-groovy/)" at Greach 2014
*   The [functional side of Groovy](http://greach.es/speakers/mario-garcia-the-functional-side-of-groovy/), by Mario Garcia, recorded at Greach 2014
*   [Architectural flexibility with Groovy](http://greach.es/speakers/david-dawson-architectural-flexibility-using-groovy/), by David Dawson, at Greach 2014
*   [Metaprogramming with Groovy](http://greach.es/speakers/ivan-lopez-metaprogramming-with-groovy/), by Ivan Lopez, at Greach 2014
*   [Micro Service Architecture with Spring Boot, Groovy](http://greach.es/speakers/marco-vermeulen-building-micro-services-using-spring-boot-and-friends/) and Friends, by Marco Vermeulen, at Greach 2014
*   Marco Vermeulen speaks about [behavior-driven-development with Cucumber and Groovy](http://greach.es/speakers/marco-vermeulen-bdd-using-cucumber-jvm-and-groovy/), at Greach 2014
*   Schalk Cronjé talks about [Groovy VFS](http://greach.es/speakers/schalk-w-cronje-groovy-vfs/), a humble DSL over the Apache VFS library
*   Russel Winder on [Groovy, GPars, @CompileStatic, invoke dynamic and Java 8](http://greach.es/speakers/russel-winder-groovy-gpars-compilestatic-and-invokedynamic-and-java-8/), recorded at Greach 2014
*   [GPars workshop](http://greach.es/speakers/mario-garcia-workshop-gpars/) presented at Greach 2014 by Mario Garcia

## Articles

*   Rick Hightower, who worked on the improved Groovy 2.3 JSON support, writes about the [high performance of Boon and Groovy JSON](http://www.dzone.com/links/r/groovy_and_boon_provide_the_fastest_json_parser_f.html) compared to Jackson
*   Michael Scharhag on the [Grails dependency injection inheritance pitfall](http://www.mscharhag.com/2014/04/the-grails-depedency-injection.html)
*   [Iterate through dates](http://www.intelligrape.com/blog/2014/04/13/iterate-through-two-distinct-dates-groovy-2-2/) the Groovy way
*   [Customizing URL formats in Grails](http://www.intelligrape.com/blog/2014/04/09/customizing-url-formats-in-grails/), making your URLs case insensitive
*   Making [Grails and Artifactory](http://wordpress.transentia.com.au/wordpress/2014/04/09/artifactory-and-grails/) work together
*   [Customizing fusion chart](http://www.intelligrape.com/blog/2014/04/09/customizing-fusion-chart-for-various-type-via-grails/) for various type via Grails

## Code snippets

*   Tim Yates plays with [Groovy traits, combining them together](https://gist.github.com/timyates/10257468) to create infinite iterators.
*   Tim Yates shows a [ping-pong hot-swapped untyped Akka actor in Groovy](https://gist.github.com/timyates/3722681)
*   Tim Yates crafted a [Pi approximation algorithm in Groovy on top of Akka](https://gist.github.com/timyates/10470012) actors
*   Tim Yates uses [GPars for calculating an approximation of Pi](https://gist.github.com/timyates/10474027)
*   Craig Burke created a [sample Ratpack application](https://twitter.com/craigburke1/status/456062168547753984) whose code you can look at on Github

## Tweets

*   Cédric Champeau points at the [documentation and the blog posts he wrote about the new markup-based template engine](https://twitter.com/cedricchampeau/status/454541228106084353)
*   Guillaume Laforge is [happy with the feedback the Groovy team is receiving](https://twitter.com/glaforge/status/454565615341408256) with the recent betas of Groovy 2.3. Feedback is really important to get the final release rock solid and ready for prime time!
*   The [Greach conference Youtube channel](https://twitter.com/greach_es/status/455664662110289920) has more followers than on Twitter, thanks to all the conference presentations it published online
*   With our hight performant JSON stack, tail recursion, the NIO support, and more, coming in Groovy 2.3, or using GPars for concurrency needs, Dierk König notes that [adding Groovy to your projects might well make it faster](https://twitter.com/mittie/status/454704508430737408)!
*   Robert Fletcher adds the ["trait" keyword to the Prism JavaScript syntax highlighting](https://twitter.com/rfletcherew/status/454529278273912832) library

## News

*   Luke Daley announces the upcoming [arrival of Gradle 2.0](http://forums.gradle.org/gradle/topics/after_1_12_comes_2_0) after Gradle 1.12, upgrading to Groovy 2.
*   Successful test anr run of [Caelyf on IBM's BlueMix Cloud Foundry platform](http://caelyf.ng.bluemix.net)
*   [Grails Diary week 15](http://grydeske.net/news/show/40) by Jacob Aae Mikkelsen
    
## Jobs

*   A [Grails / DevOps developer](http://findgrailsjobs.com/job/526-grails-devops-developer) at Retale, in Chicago, USA

## Events

*   The [Early Bird price](http://gr8conf.eu/) (35% discount) for the GR8Conf Europe conference, in Denmark, has been extended till the 21st, it’s your last chance!
*   GR8Conf Europe announces [NineConsult as gold sponsor](https://twitter.com/gr8conf/status/454347531280211970)
# Second beta for Groovy 2.3


Hot on the heels of our first beta for Groovy 2.3, here's already a second one!  

We've received a lot of feedback, which is really awesome! Thanks a lot to all those who put the first beta to its pace and reported their findings.  

The most important change in this release is that the groovy.jar no longer depends on ASM and Antlr.  
  
It's the first release ever of Groovy where the `groovy.jar` itself is _jajar-ed_ like the `groovy-all` JAR, which means that the ASM and Antlr libraries are embeded (and translated to a different package) so that you don't need to depend on those libraries in your projects, and run the risk of a version clash with other frameworks or libraries depending on differing versions.  

It's an important step for those who wish to have smaller JARs, and who don't want the whole libraries offered by Groovy, but who want to pick up just the components they are interested in.  

Please report any problem you might find, in case you're using groovy.jar instead of groovy-all.jar.  

Apart from that, several issues have been fixed, regarding traits, generics handling, a problem when running Groovy on Google App Engine.  

There is a minor breaking change with regards to whitespace handling in our XML support.  

You can check the JIRA release notes to see the issues fixed:  
[http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=20226](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=20226)  

And head to our download area to get the latest and hottest beta: [http://groovy.codehaus.org/Download?nc](http://groovy.codehaus.org/Download?nc)  

If you're using Gradle or Maven, we noticed some issues with our deployment process which made the groovy-all.jar lacking a pom.xml file on Central and JCenter. We're working on solving that issue with the JFrog team and we will let you know when it's fixed.  

Keep up the feedback coming!
# Groovy Weekly #16


After the [Groovy knights](https://plus.google.com/+GuillaumeLaforge/posts/ZcDcZ8iEvH8) in Madrid, at the Greach conference, the Groovy team delivers the [first beta of Groovy 2.3]({{< ref "/posts/2014/04/04/a-beta-release-for-groovy-2-3" >}})!

An impressive feature list: including [traits](http://beta.groovy-lang.org/docs/groovy-2.3.0-beta-1/html/documentation/core-traits.html), official JDK 8 support, tail recursion, NIO2 module, super fast JSON support, closure type inference, a new markup template engine, and much more.
  
You will also notice the [new documentation](http://beta.groovy-lang.org/docs/groovy-2.3.0-beta-1/html/documentation/) shaping up but the Groovy Core team still looks forward to contributions to help with this gigantic task, so don’t hesitate to voice your will to help!

Also double check the new style for [GroovyDoc documentation](http://beta.groovy-lang.org/docs/groovy-2.3.0-beta-1/html/groovy-jdk/) as well as [GDK documentation](http://beta.groovy-lang.org/docs/groovy-2.3.0-beta-1/html/gapi/).

In the presentations section, don’t miss the bullet linking to all the excellent presentations given at the Greach conference.

## Releases

*   Guillaume Laforge announces the [first beta of Groovy 2.3]({{< ref "/posts/2014/04/04/a-beta-release-for-groovy-2-3" >}}), and details the new features
*   [Groovy 2.3.0-beta-1](https://twitter.com/gvmtool/status/452216920889389056) is available through GVM
*   [Spring Boot 1.0.1](https://twitter.com/gvmtool/status/453146394489270272) is available through GVM
*   Thomas Hirsch publishes a new [Gradle plugin for using Geb to automate build tasks](https://github.com/thokari/gradle-geb-plugin)
*   [Glide 0.3.2](https://twitter.com/gvmtool/status/452498582260940800) is available through GVM
*   [Gretty](https://twitter.com/AndreyHihlovski/status/452169744360435712), the Gradle plugin for Jetty, released v0.0.15, with fast-reload resources, and is available from Maven Central and JCenter

## Presentations

*   You can watch all the [videos and read the slides of all the presentations given at the Greach 2014 conference](https://storify.com/glaforge/greach-2014-videos-and-slides), in Madrid (Spain)
*   [Groovy in 2014 and beyond!](http://greach.es/speakers/guillaume-laforge-groovy-in-2014-and-beyond/) — Guillaume Laforge
*   [Why reactive architecture will take over the world](http://greach.es/speakers/steve-pember-how-the-reactive-pattern-will-take-over-the-world-but-why-we-should-be-afraid-that-it-might-be-with-node-js/) — Steve Pember
*   [Groovier Data History in Groovy with Event Sourcing](http://greach.es/speakers/steve-pember-richer-data-history-in-grails-with-event-sourcing/) — Steve Pember
*   [Grails is not my domain model. Where do I put my Business Logic](http://greach.es/speakers/antonio-de-la-torre-grails-is-not-my-domain-model-where-do-i-have-to-put-my-business-logic/) — Antonio de la Torre
*   [Grails Worst Practices](http://greach.es/speakers/burt-beckwith-grails-worst-practices/) — Burt Beckwith
*   [Experiences using Grails in a micro service architecture](http://greach.es/speakers/jeff-beck-experiences-using-grails-in-a-micro-service-architecture/) — Jeff Beck
*   [Road to Grails 3.0](http://greach.es/speakers/graeme-rocher-road-to-grails-3-0/) — Graeme Rocher
*   [Understanding GORM](http://greach.es/speakers/alonso-torres-understanding-gorm/) — Alonso Torres
*   [Creating RESTful API’s with Grails and Spring Security](http://greach.es/speakers/alvaro-sanchez-mariscal-creating-restful-apis-with-grails-and-spring-security/) — Álvaro Sánchez-Mariscal
*   [Hybrid Mobile App in minutes, not days: Fast and furious II](http://greach.es/speakers/corinne-krych-fabrice-matrat-sebastien-blanc-hybrid-mobile-app-in-minutes-not-days-fast-and-furious-ii/) — Corinne Krych, Fabrice Matrat, Sébastien Blanc
*   [Startup Lesson Learned from rolling a Grails App to Millions Users](http://greach.es/speakers/james-page-startup-lesson-learned-from-rolling-a-grails-app-to-millions-users/) — James Page
*   [Hexagonal Architecture in Grails](http://greach.es/speakers/david-dawson-hexagonal-architecture-in-grails/) — David Dawson
*   [DevQA: make your testers happier with Groovy, Spock and Geb](http://greach.es/speakers/alvaro-sanchez-mariscal-devqa-make-your-testers-happier-with-groovy-spock-and-geb/) — Álvaro Sánchez-Mariscal
*   [What’s New in spring-security-core 2.0](http://greach.es/speakers/burt-beckwith-whats-new-in-spring-security-core-2-0/) — Burt Beckwith

## Articles

*   [Glu](http://devops.com/features/deployment-and-monitoring-automation-glu/), the Groovy-based deployment and monitoring automation platform developed at LinkedIn, is featured in the DevOps.com website
*   Stéphane Maldini wrote an [article on Reactor](https://twitter.com/smaldini/status/451110890939875328) for the NFJS magazine (req required)
*   Craig Atkinson created a [Spock cheat-sheet](http://www.objectpartners.com/2014/04/08/spock-mock-cheatsheet/)
*   An introduction to [what Groovy is](http://thejavatar.com/what-is-groovy/)
*   Corinne Krych blogs about her [impressions of the Greach](http://corinnekrych.blogspot.fr/2014/04/greach-2014-surprising-edition.html) conference in Madrid
*   Jacob Aae Mikkelsen, of Grails Diary fame, gives us his [impressions from Greach](http://grydeske.net/news/show/38) 2014
*   [Closure composition](http://www.mscharhag.com/2014/04/closure-composition-in-groovy.html) in Groovy by Michael Scharhag
*   Using the [Instagram login API via Grails](http://www.intelligrape.com/blog/2014/04/04/using-the-instagram-login-api-via-grails/)
*   Angel Ruiz explains how to [reference a file inside a Grails plugin](http://aruizca.com/how-to-reference-a-file-inside-a-grails-plugin/)

## Code snippets

*   Dierk König shows traits composition with an example of [multiple traits inheritance](https://gist.github.com/Dierk/10010410)
*   A [micro Spring Boot app in Groovy](https://twitter.com/springcentral/status/451414324893212672), in the span of a tweet, returning the device type used as JSON
*   Initial work has landed on an [integrated async HTTP client in Ratpack](https://twitter.com/ratpackweb/status/452964565567827968), which works great with RxJava
*   Macro Vermeulen used [Geb as a "wallpaper downloader"](https://gist.github.com/marcoVermeulen/9994607) in this code snippet
*   MrHaki shows how to [convert byte arrays to hexadecimal strings](http://mrhaki.blogspot.fr/2014/04/groovy-goodness-converting-byte-array.html)
*   MrHaki blogs about [Groovy closures as Writable](http://mrhaki.blogspot.fr/2014/04/groovy-goodness-closure-as-writable.html)
*   MrHaki covers [GStrings as Writable](http://mrhaki.blogspot.fr/2014/04/groovy-goodness-gstring-as-writable.html)

## Tweets

*   Dierk König distills the [essence of Groovy's nature](https://twitter.com/mittie/status/452814992522620928) in the 140 characters of a tweet!
*   Dierk König remarks that Groovy 2.3 traits enable "[design by capability](https://twitter.com/mittie/status/452813304176852992)"
*   Dan Woods notes that compared to Java 8 interface default methods, [Groovy 2.3 traits are stateful](https://twitter.com/danveloper/status/453031225867767808)
*   Marco Vermeulen is looking into Groovy's traits and enjoys the [new tutorial-style Groovy documentation](https://twitter.com/marcoVermeulen/status/452739684813524993)
*   Spock's Peter Niederwieser is wondering if Groovy 2.3's [traits are the new killer feature for code reuse across specifications](https://twitter.com/pniederw/status/451737521186410497)
*   Cédric Champeau announces that the ["trait" implementation has landed in the Groovy core repository](https://twitter.com/CedricChampeau/status/451627694980345856)
*   There's now a [Gradle task to install Grain themes](https://twitter.com/grainframework/status/451336989594619904)

## News

*   Pivotal opened up a page for the [commercial support for their Open Source projects](http://www.gopivotal.com/support/oss), including Groovy and Grails coverage
*   With the release of the beta of Groovy 2.3, the [GroovyDoc tool receives a face lift](http://beta.groovy-lang.org/docs/groovy-2.3.0-beta-1/html/gapi/) and produce nicer looking documentation
*   The [Groovy GDK documentation also gets a face lift](http://beta.groovy-lang.org/docs/groovy-2.3.0-beta-1/html/groovy-jdk/) with a more stylish look
*   The brand [new Groovy documentation](http://beta.groovy-lang.org/docs/groovy-2.3.0-beta-1/html/documentation/), written with Asciidoctor, is shaping up nicely, and the Groovy team welcomes contributions to help fill in the gaps
*   A [twitter account to follow about the latest Gradle plugin news](https://twitter.com/gradleplugins), by Andrés Almiray and his [Gradle plugin portal](http://aalmiray.github.io/gradle-plugins/) effort
*   Vote for this [feature request for IntelliJ IDEA to provide "traits" support](http://youtrack.jetbrains.com/issue/IDEA-123484) for the upcoming trait feature of Groovy 2.3
*   The Ratpack asks for feedback on whether to make [Java 8 the base requirement for Ratpack apps](https://twitter.com/ratpackweb/status/451852468398211072)
*   The Grails Diary [week 13](http://grydeske.net/news/show/37) by Jacob Aae Mikkelsen
*   Another Grails Diary, [week 14](http://grydeske.net/news/show/39), by Jacob Aae Mikkelsen
*   Masato Nagai informs us that GBench, the Groovy benchmarking utility, as its own [Groovy AST DSL](https://github.com/gperfutils/gbench/blob/master/src/main/groovy/groovyx/gbench/BenchmarkASTTransformation.groovy#L97), which is faster than Groovy's own AstBuilder
*   SimpleCI renamed to [DirectBuild](https://github.com/DirectBuild/DirectBuild/wiki/News#april), and will soon be getting Remote Agent Support
*   [Spring Boot 1.0](https://twitter.com/gvmtool/status/451236695992963072) is available through GVM

## Jobs

*   BlueGlue, in London (UK), is seeking a [senior Grails / Java developer](https://twitter.com/FindGrailsJobs/status/451689367883776001)

## Events

*   Barely a week left before the end of the [Early Bird price](http://gr8conf.eu/) (35% discount) for the GR8Conf Europe conference, in Denmark
*   The GR8Conf Europe organizers are announcing the [sponsors for the 2014 edition](https://storify.com/glaforge/gr8conf-europe-sponsors-announced)
*   Jon DeJong from Object Partners will present the ["New Toolchain" for building and testing single page Grails apps](http://www.meetup.com/Austin-Groovy-and-Grails-Users/events/166964742/)
# A beta release for Groovy 2.3


The Groovy team is very pleased to announce the first beta of the Groovy 2.3 release!

Groovy 2.3.0-beta-1 is actually already a feature-complete beta, so the release cycle towards the final version will be very short. Furthermore, Grails 2.4 is looking forward to integrating it rapidly as well for its upcoming major release too! So you can expect a general availability version of Groovy in the coming weeks, as we’ll move directly in “release candidate” mode after this beta. But your feedback, as usual, will be very important for trying out this beta in your respective projects, to tell us about any problem you might encounter.

In this email, below, I’ll give you a few pointers regarding the scope of the release, but we’ll be fleshing out a more detailed release notes document in the coming days and weeks with more information.

Warning: this is a lengthy email, but you’ll get to see all the new stuff and improvements the Groovy team and contributors have been working on!

The key highlights of Groovy 2.3 are:

*   Official support for running Groovy on JDK 8  This is the first version of Groovy to be officially compatible with JDK 8.  
      
    JDK 8 and its interface default methods introduced some incompatibilities with a few methods of the Groovy Development Kit, so we had to adapt to the situation, introducing minor breaking changes for the affected methods and their outcome.  
      
    Note that we’re not planning to backport the changes to older versions of Groovy, so if you want to run Groovy on JDK 8, you’ll have to upgrade to the shiniest version of Groovy! 
    
*   Traits A major highlight for Groovy 2.3 is the introduction of the concept of traits. [Traits](http://beta.groovy-lang.org/docs/groovy-2.3.0-SNAPSHOT/html/documentation/core-traits.html) are reusable components of behavior that you can make your class implement, and are an additional Object-Oriented concept alongside classes and interfaces.  
      
    Groovy traits are stateful (unlike Java 8 interface default methods).  
      
    They allow the composition of behavior without going into the “diamond inheritance” problem allowing you to decide which behavior prevails upon conflict.  
      
    Traits support inheritance, thus a trait can extend another trait or implement an interface.  
      
    Traits are compatible with static type checking and compilation, as well as our usual dynamic behavior. Trait mixed-in methods are actually “real” methods (ie. visible from Java as well) and not just dynamic.  
      
    Traits can also be implemented at runtime with “as” or with “withTraits” if you just want to add behavior of a trait to an object you’re instantiating.  
      
    You can find more information on traits in the exhaustive [trait documentation](http://beta.groovy-lang.org/docs/groovy-2.3.0-SNAPSHOT/html/documentation/core-traits.html). 
    
*   New and updated AST transformations 
    

*   `@TailRecursive` on methods adds tail recursion to methods which are recursive and call themselves at the last operation of the method body, which helps blowing up the stack with the recursive calls ([GROOVY-6570](http://jira.codehaus.org/browse/GROOVY-6570)). 
    
*   `@Sortable` on classes implement comparison methods for you, according to the declaration order of your properties ([GROOVY-6649](http://jira.codehaus.org/browse/GROOVY-6649)). 
    
*   `@Delegate` supports includes and excludes attributes so as to let you decide if certain methods should be included or excluded from the delegation ([GROOVY-6329](http://jira.codehaus.org/browse/GROOVY-6329)). 
    

*   New NIO module for Java 7+ On JDK 7 and beyond, you can benefit from the same methods as the ones of File, URLs, the various Stream classes, etc, but for the new NIO2 methods, like Path.  
      
    See [GROOVY-6377](http://jira.codehaus.org/browse/GROOVY-6377) and the [pull request](https://github.com/groovy/groovy-core/pull/260/files) for some further hints of the new methods. 
    
*   Various minor performance improvements across the board, for static compilation, the “invoke dynamic” backend, as well as “normal” dynamic Groovy 
    
*   Drastic JSON parsing and serialization performance improvements The Rick / Andrey duo spent a fair amount of time optimizing our JSON support, making Groovy 2.3’s JSON support usually faster than all the JSON libraries available in the Java ecosystem.  
      
    With [JsonSlurper](http://beta.groovy-lang.org/docs/groovy-2.3.0-beta-1/html/gapi/groovy/json/JsonSlurper.html), you’ll be able to set different [parser types](http://beta.groovy-lang.org/docs/groovy-2.3.0-beta-1/html/gapi/groovy/json/JsonParserType.html) depending on the kind of input you wish to parse, particularly if you know the size of the payload you expect to parse, or whether you want a more tolerant parser which accepts elements like comments which are not normally supported by the JSON specification ([GROOVY-6546](http://jira.codehaus.org/browse/GROOVY-6546)).  
      
    On the output front, with [JsonBuilder](http://beta.groovy-lang.org/docs/groovy-2.3.0-beta-1/html/gapi/groovy/json/JsonBuilder.html) and [StreamingJsonBuilder](http://beta.groovy-lang.org/docs/groovy-2.3.0-beta-1/html/gapi/groovy/json/StreamingJsonBuilder.html), which both use [JsonOutput](http://beta.groovy-lang.org/docs/groovy-2.3.0-beta-1/html/gapi/groovy/json/JsonOutput.html) for output generation, the serialization has also been tremendously improved ([GROOVY-6554](http://jira.codehaus.org/browse/GROOVY-6554)). 
    
*   Closure type parameter inference We closed a gap which forced you to type your closure parameters to get correct type inference with static type checking or static compilation enabled. In situations like the following, you would have to explicitly give the type of the parameter, but it’s no longer required: \['a','b'\].each { it.toUpperCase() } In the signature of your methods taking closures as arguments, you’ll also be able to annotate the closure parameter with [@ClosureParams](http://beta.groovy-lang.org/docs/groovy-2.3.0-beta-1/html/gapi/groovy/transform/stc/ClosureParams.html) to give additional hints to the type checker to infer the type of the parameters passed to your closure.  
      
    You can also find more about this in Cédric’s blog post on [closure parameter type inference](http://melix.github.io/blog/2014/01/closure_param_inference.html). 
    
*   New Markup template engine Groovy now has an additional template engine, in the form of the Markup template engine, which gives you a very fast template engine, based on the familiar Markup builder approach and notation, but also offering formatting options (indentation, escaping), internationalization, includes, as well as proposing type checked templates and models.  
      
    More details about the new [Markup template engine](http://beta.groovy-lang.org/docs/groovy-2.3.0-SNAPSHOT/html/documentation/markup-template-engine.html) in the documentation ([GROOVY-6596](http://jira.codehaus.org/browse/GROOVY-6596)), as well as in Cédric’s [blog](http://melix.github.io/blog/), if you want to learn more about the “behind the scenes” stories! 
    
*   Further Groovysh enhancements
    

 Along with some slightly reduced startup time, Groovysh has seen new improvements in its code-completion capabilities: 

*   line comment command ([GROOVY-6459](http://jira.codehaus.org/browse/GROOVY-6459))
    
*   completion for keywords ([GROOVY-6399](http://jira.codehaus.org/browse/GROOVY-6399))
    
*   completion for properties ([GROOVY-6395](http://jira.codehaus.org/browse/GROOVY-6395)) 
    

*   GroovyConsole enhancements  It is now possible to configure the font used by the console, and also to be able to run a selected snippet of code reusing the imports defined in your script making it easier to just run quick snippets of your script. 
    
*   JUnit 4 GroovyAssert class The venerable [GroovyTestCase](http://beta.groovy-lang.org/docs/groovy-2.3.0-beta-1/html/gapi/groovy/util/GroovyTestCase.html) (JUnit 3 based approach) has often been used as a base class for your test classes — unless you’ve been using the [Spock testing framework](http://www.spockframework.org/), of course. One of the drawback of this class is that your test classes can’t extend your own classes, but must derive from GroovyTestCase to benefit from the additional assertion methods.  
      
    Groovy 2.3 introduces the JUnit 4-friendly [GroovyAssert](http://beta.groovy-lang.org/docs/groovy-2.3.0-beta-1/html/gapi/groovy/util/GroovyAssert.html), which is a convenient class offering the usual assertion methods of GroovyTestCase, but in the form of static methods that you can static import in your test class.  
      
    We have not included the myriads of assertEquals method from GroovyTestCase as they have become useless with Groovy’s power assert, but it provides the handy shouldFail\*() methods ([GROOVY-6588](http://jira.codehaus.org/browse/GROOVY-6588)). 
    
*   ConfigSlurper  ConfigSlurper just supported a single “environments” non-configurational conditional block, but you couldn’t let you define your own. With Groovy 2.3 you can also create your own ones too, for instance if you wanted to support “flavors” like OS variants ([GROOVY-6383](http://jira.codehaus.org/browse/GROOVY-6383)).  
      
    In addition, the isSet() / hasSet() combo methods ([GROOVY-4639](http://jira.codehaus.org/browse/GROOVY-4639)) have been added so you can double check if a given node of your configuration has been defined. Before, whether the node wasn’t defined or containing null, you couldn’t differentiate either case easily. 
    
*   `@BaseScript` class improvements  [@BaseScript](http://beta.groovy-lang.org/docs/groovy-2.3.0-beta-1/html/gapi/groovy/transform/BaseScript.html) is a fairly recent addition in Groovy, and it allowed to annotate a variable in your script to instruct the compiler to use a particular base script class for this script. Now we have another notation which is nicer as you can annotate an import or a package ([GROOVY-6592](http://jira.codehaus.org/browse/GROOVY-6592)) to indicate that base script class: 

    ```groovy
    @BaseScript(MyScript)  
    import groovy.transform.BaseScript 
    ```

    Additionally, base script classes can now use any abstract method for the script body. This means that you can implement the run() method to implement specific behavior like setup and tear down in tests ([GROOVY-6585](http://jira.codehaus.org/browse/GROOVY-6585) and [GROOVY-6615](http://jira.codehaus.org/browse/GROOVY-6615)). 
    
*   New style for the GroovyDoc documentation of Groovy and the GDK methods GroovyDoc has been updated with a new fresh and modern skin that will be part of the future visual identity of the Groovy website. Those style updates are also available by default for your own usage of GroovyDoc, making your own documentation nicer on the eye.  
      
    You can have a look at the [GroovyDoc documentation for Groovy 2.3.0-beta-1](http://beta.groovy-lang.org/docs/groovy-2.3.0-beta-1/html/gapi/).  
      
    We also took the opportunity to apply the same stylesheet to our “DocGenerator” tool which is responsible for the generation of the GDK documentation, showing the methods the Groovy library adds on top of the JDK classes.  
      
    Please also have a look at the new [restyled GDK documentation](http://beta.groovy-lang.org/docs/groovy-2.3.0-beta-1/html/groovy-jdk/). 
    
*   New documentation We are still working on the brand [new documentation](http://beta.groovy-lang.org/docs/groovy-2.3.0-SNAPSHOT/html/documentation/) for Groovy (in Asciidoc(tor) format), so you can already have a glimpse at what’s already covered or not.  
      
    We’re looking forward for help for fleshing out the various TBD (To Be Done) sections of the documentation, as it’s a gigantic taks to re-document each and every aspect of the language and its libraries! So please shout if you want to contribute to the new documentation! All help is warmly welcome! 
    
*   Dependency upgrades 
    
    *   Gradle 1.10 for building Groovy
    *   ASM 5.0.1 library for generating our bytecode (also needed for our JDK 8 support)
    *   JLine 2.11 and JANSI 1.11 library for Groovysh 
    

  

Groovy wouldn’t be what it is without your support, your bug reports and feature requests, your contributions and pull requests, so big thanks to all those who contributed to this release in a way or another, including the usual suspects of the core team (Jochen, Paul, Cédric and myself), but also André (documentation, GroovyAssert, Groovy Console), Andres (Config slurper, @Sortable with Paul), Tim, Pascal (ConfigSlurper), Johanes (@TailRecursive), Paolo (new NIO module), Thibault (groovysh), Rick and Andrey (for the JSON support), Jim (base script class), Damien (GroovyDoc / GDK styling), Kenneth and several others I’ve forgotten to mention!

  

And in honor of this first beta release of Groovy 2.3, Cédric even decided to put his birthday on the same day, so happy birthday Cédric, and great work on this release!

  

We’re looking forward to your feedback running this beta to its pace!

It’s important to make this 2.3 release rock solid!

  

[Download Groovy 2.3-beta-1](http://groovy.codehaus.org/Download) and have a look at the [JIRA release notes](http://jira.codehaus.org/browse/GROOVY-6366?jql=project%20%3D%20GROOVY%20AND%20fixVersion%20%3D%20%222.3.0-beta-1%22%20AND%20status%20in%20(Closed%2C%20Resolved)) for additional details on issues and bug fixes closed.

  

Keep on groovy’ing!
# Groovy Weekly #15


Although it’s April Fools day, I’ll spare you with some funny incredible surprise, but I will instead focus a lot on all the great, interesting and inspiring things that happened at the Greach 2014 conference, in Spain, Madrid. Also don’t miss the various links about the incoming support of traits in Groovy 2.3!

## Releases

*   [Spring Boot 1.0](https://spring.io/blog/2014/04/01/spring-boot-1-0-ga-released) released, with its nice Groovy support
*   [Ratpack 0.9.3](http://www.ratpack.io/versions/0.9.3) released
*   [Glide 0.3.2 released](http://glide-gae.appspot.com), with latest Gaelyk 2.1.1 and Google App Engine 1.9.1 into the mix
*   A [new version of the GVM SDK](https://twitter.com/marcovermeulen/status/448494455692079104) was released
*   The completely Groovy Continuous Integration Server, [SimpleCI](https://github.com/DirectMyFile/SimpleCI), is now stable, and is on a rolling release cycle
*   Sergei Egorov shares his [MacroGroovy](https://github.com/bsideup/MacroGroovy) project, to simplify the creation of AST transformations

## Presentations

*   Guillaume Laforge presented the [present and future of Groovy](https://speakerdeck.com/glaforge/groovy-in-2014-and-beyond) at Greach 2014
*   [Metaprogramming with Groovy](https://twitter.com/strsistemas/status/449832995089047552), presentation by Iván López at Greach 2014
*   Jeff Beck presented his experience about using [Grails in microservice architecture](http://beckje01.github.io/greach-2014-micro-service-talk/#/), at Greach 2014
*   Marco Vermeulen demonstrated [BDD with Cucumber and Groovy](https://twitter.com/marcovermeulen/status/449577949269082112) at Greach 2014
*   The slides and code from Greach 2014 of Marco Vermeulen's [Micro Services with Spring Boot and Groovy](https://twitter.com/marcovermeulen/status/449936832340717568)
*   A very funny but highly interesting presentation from Burt Beckwith, given at Greach 2014, about the [worst Grails practices](http://fr.slideshare.net/burtbeckwith/grails-worst-practices)
*   Burt Beckwith detailed the [novelties in Grails spring-security-core 2.0](http://fr.slideshare.net/burtbeckwith/whats-newinspringsecurity), in this Greach 2014 presentation
*   Slides and code from Russel Winder's Greach 2014 presentation on [Groovy, GPars, @CompileStatic, "invoke dynamic" and Java 8](https://twitter.com/russel_winder/status/449982413691949056)
*   At Greach 2014, Alonso Torres presented "[understanding GORM](http://fr.slideshare.net/alotor/understanding-gorm-greach-2014)"
*   Steve Pember presented on [reactive architectures](http://fr.slideshare.net/StevePember/distributed-reactivearchitecture) at Greach 2014
*   Schalk Cronjé talked about [Groovy VFS](http://fr.slideshare.net/ysb33r/groovy-vfs-32889561) at Greach 2014
*   An [intro presentation of Groovy and Grails](https://twitter.com/JennStrater/status/449693392054652928) by the "Gr8 ladies" of Minneapolis

## Articles

*   Cédric Champeau is listening for [feedback on the upcoming Groovy 2.3 traits](https://github.com/melix/groovy-core/blob/traits-implementation/src/spec/doc/core-traits.adoc) implementation, don't hesitate to share your thoughts! (the included snippets are not displayed but can be found in the sources)
*   Brendon Anderson on a [Groovy time with UPnP and WeMo](http://www.objectpartners.com/2014/03/25/a-groovy-time-with-upnp-and-wemo/)
*   MrHaki shows how to deal with [multiple Grails bootstraps](http://mrhaki.blogspot.fr/2014/03/grails-goodness-multiple-bootstraps.html)
*   During his presentation at Greach 2014, Burt Beckwith mentioned a blog post about [hash password conversion](http://burtbeckwith.com/blog/?p=2017) he wrote
*   David Estes shows how to [dynamically find views in Grails](http://davydotcom.com/blog/2014-03-31-dynamically-finding-views-in-grails)
*   Some first impressions on [using Grails with Angular.JS](http://www.intelligrape.com/blog/2014/03/31/using-angularjs-with-grails-app-my-first-impression/)

## Code snippets

*   Cédric Champeau shows how he [replaced @Mixin with the upcoming traits](https://twitter.com/CedricChampeau/status/449620913492094976) from Groovy 2.3
*   Examples of [Groovy 2.3 runtime traits](https://github.com/melix/groovy-core/commit/41e21072a835b7bce2e9ac6bf4826518a4de616f#diff-148d63a5430b139a17b2261ca882e7a3R647) support by Cédric Champeau
*   A [Ratpack 0.9.3 example](https://github.com/ratpack/example-books/tree/master/src/main/groovy/ratpack/example/books) by Russell Hart, showing authentication at work with the pac4j module
    
## Tweets

*   Cédric Champeau [notes](https://twitter.com/cedricchampeau/status/449609875170291713) that [GrooScript](http://grooscript.org/) (the Groovy to JavaScript "transpiler") would deserve more attention!
*   If you want to [contribute to Ratpack](https://twitter.com/ratpackweb/status/449086252701069312), here's the list of contributions you can make
*   Alonso Torres remarks the [lack of Scalability talks about Grails at conferences](https://twitter.com/alotor/status/449499586487664640)... probably because Grails just scales :-)
*   A big zoom of Cédric Champeau and Guillaume Laforge on the [funny Groovy knights panel](https://twitter.com/sebi2706/status/449456237579866112) at Greach 2014[](https://twitter.com/gvmtool/status/449807218465320960)
    

## Other news

*   [GVM welcomes Glide](https://twitter.com/gvmtool/status/449807218465320960) as a new "candidate"

## Jobs

*   A [Groovy / Grails / Cassandra job in Paris](http://www.meetup.com/Paris-Groovy-Grails/messages/66851332/), France
*   Biotech startup in Boston [looking for a Grails developer](https://twitter.com/burtbeckwith/status/448732435556335616)
    
## Events

*   Who wants to be made a [Groovy knight](https://twitter.com/CedricChampeau/status/449489765159960576)? A nice panel where to put your heads was in the hallways of Greach 2014
*   Yeray Darias Camacho took [several notes on the presentations given at Greach](https://www.flickr.com/photos/ydarias/sets/72157643259187873/) 2014, and published them on flickr
*   Schalk Cronjé drawed many little [graphical notes about the sessions he attended at the Greach](https://storify.com/glaforge/in-a-nutshell-graphical-notes-of-the-greach-2014) 2014 conference
*   A [new Groovy/Grails user group in San Diego](http://www.meetup.com/San-Diego-Groovy-Grails-Group/) has launched by Vahid Pazirandeh
# Groovy Weekly #14


This week is a Spanish week! The Groovy community is moving towards Madrid (Spain) for the [Greach conference](http://greach.es/), to talk about Groovy, Grails, Gradle, Spock, GrooScript, GPars, Gaelyk and more! Enjoy the conference, for the lucky ones attending, and otherwise, have fun reading the news below.

## Releases

*   [Gaelyk 2.1 has been released](https://twitter.com/musketyr/status/448151069378740226)
*   There's a [Gradle plugin for the Grain](http://sysgears.com/grain/news/grain-gradle-plugin-released/) static website generator, for generating your site from your build
*   [Nextflow](http://nextflow.io/), a DSL for data-driven computational pipelines, based on Groovy and GPars, released in version 0.7
*   Marco Vermeulen releases [version 0.5.1 of the Gradle Spawn plugin](https://github.com/marcoVermeulen/gradle-spawn-plugin), for starting and stopping UNIX command line processes from within your build
*   [MongoDB GORM 2.0 plugin released](http://grails.org/news/1289916)
    
## Articles

*   An old question on Quora about [whether "Groovy is going away"](http://www.quora.com/Is-Groovy-going-away/answer/Rob-Fletcher?__snids__=357550680&__nsrc__=4) is re-surfacing from time to time, and Rob Fletcher recently gave a new answer for that question.
*   MrHaki is showing how to [use Groovy SQL in Grails](http://mrhaki.blogspot.fr/2014/03/grails-goodness-using-groovy-sql.html)
*   Angel Ruiz writes about the [Grails 2.2 to 2.3 migration](http://aruizca.com/migrating-from-grails-2-2-to-2-3/)
*   Alexander Reelsen believes [Spark, Groovy and JRebel make for a productive combination](http://spinscale.github.io/2013-02-rapid-web-application-development-with-spark-groovy-jrebel.html)
*   A paper in German on [using Grails for a portal framework](http://www.sigs.de/publications/newsletter/2014/03/breitfeld_kraft_soth_JS_02_14.pdf)
*   Libgdx, a Java based game framework, is [migrating to Gradle](http://www.badlogicgames.com/wordpress/?p=3336)

## Code snippets

*   Cédric Champeau has created a [Groovy solver for the 2048 game](https://gist.github.com/melix/9619800), showing a nice use of Geb usage
*   An example of [broadcasting with websockets and Ratpack](https://twitter.com/dailygrailstip/status/448358068166742016)

## Tweets

*   Dierk König says it's at the same time nice and weird to see [Java developers now being able to enjoy the benefits that Groovy has provided for the past 10 years](https://twitter.com/mittie/status/446292208048943104) already
*   Replying to Rob Fletcher about the fact that the lambda syntax from Java 8 was differing in syntax from Groovy, Neill Robbins was saying that he [prefers the legibility of Groovy's closures](https://twitter.com/boardbloke_uk/status/446557532635807744). What's your opinion?
*   Jeff Brown is working on Grails with [Groovy AST transforms and type checking extensions and finds that it makes Groovy a very powerful programming tool](https://twitter.com/jeffscottbrown/status/446673491052347392)
*   Dierk König remarks that [Groovy can be at the same time provide more static checks than Java, but also be way more dynamic](https://twitter.com/mittie/status/446675287489925120)
*   Matt Stine shares a nice [scaling demo app for Cloud Foundry using Spring Boot and Groovy](https://twitter.com/mstine/status/446407804954624000)
    
## Google+ posts

*   Richard Vowles [notes that with the latest IntelliJ IDEA 13.1 release, for your projects using the Maven Eclipse Groovy compiler](https://plus.google.com/u/0/+RichardVowles/posts/PNMikyJ6jYS), there's no need anymore for the Eclipse Groovy plugin, as IDEA recognizes the Maven layout properly now out of the box.

## Other news

*   [Grails Diary week #12](http://grydeske.net/news/show/36) by Jacob Aae Mikkelsen

## Books

*   Book Review: [Programming Groovy 2 Dynamic Productivity for the Java Developer](http://programmingitch.blogspot.dk/2014/03/book-review-programming-groovy-2.html)

## Events

*   Some of the [names of the speakers of GR8Conf Europe 2014](http://gr8conf.eu/?utm_source=glaforge&utm_medium=blog&utm_campaign=groovyweekly#/speakers)
*   The [Call for Papers of the SpringOne2GX 2014](https://twitter.com/springcentral/status/441693398152400896) conference will end on April 30th
*   The [GR8Conf US 2014 tickets are now on sale](https://twitter.com/gr8confus/status/446678741788278784), and you can get door buster tickets the following two weeks
# Groovy Weekly #13


Hot on the heels of the Java 8 general availability good news, let’s have a look at the latest news of our beloved Groovy community!

## Releases

*   Keegan Witt announces the [first enhancement release of GMavenPlus](http://docs.codehaus.org/display/GMAVENPLUS/Releases)
*   Marco Vermeulen updates [GVM SDK to 0.5.4](https://bintray.com/vermeulen-mp/gvmtool/gvm-sdk/0.5.4/view)
*   Andrés Almiray releases version 1.0 of his [Gradle quickstart lazybones template](https://twitter.com/aalmiray/status/444196810140430336)[](http://docs.codehaus.org/display/GMAVENPLUS/Releases)

## Articles

*   Jenn Strater speaks about the [Gr8Ladies mission](http://jennstrater.blogspot.fr/2014/03/gr8ladies-mission.html)
*   Dan Woods explores [Spring Boot for micro-services and also shows the Groovy support](http://www.infoq.com/articles/microframeworks1-spring-boot) with Spring Boot CLI
*   Tomás Lin's [notes on Spring Boot, Websockets, StompJS and AngularJS](http://fbflex.wordpress.com/2014/03/13/spring-boot-websockets-stompjs-and-angularjs-a-few-notes/)
*   Tomás Lin details how to [build web content JARs for Spring Boot with Gradle](http://fbflex.wordpress.com/2014/03/14/building-web-content-jars-for-spring-boot-with-gradle/)
*   Michael Scharhag shows how you can [benefit from Groovysh](http://www.mscharhag.com/2014/03/groovy-shell.html)
*   Tim Yates details the progress and [Java 8 support of the Groovy Stream](http://blog.bloidonia.com/post/79285969149/groovy-stream-updates-and-java-integration) library
*   Alex Staveley writes about the [good use of closures](http://java.dzone.com/articles/good-use-closures)
*   MrHaki explains how to [use Hibernate native SQL queries in Grails](http://mrhaki.blogspot.fr/2014/03/grails-goodness-using-hibernate-native.html)
*   Matt Cholick shows how to [use Gradle to build and apply AST transformations](http://www.cholick.com/entry/show/276)
*   MrHaki covers how to [combine Grails constraints with shared constraints](http://mrhaki.blogspot.fr/2014/03/grails-goodness-combining-constraints.html)
*   An update on [Griffon's simple-jpa plugin](http://thesolidsnake.wordpress.com/2014/02/28/whats-new-in-simple-jpa-0-6/)
*   A [sample Griffon application](http://thesolidsnake.wordpress.com/2014/02/28/a-sample-application-for-simple-jpa-laundry/) with the simple-jpa plugin
*   Using [Grails REST for authentication in an Angular.JS](http://asoftwareguy.com/2014/03/17/using-grails-rest-for-authentication-in-an-angularjs-spa/) single page application
*   Mark Reinhold while mentioning those who contributed to the Java 8 release thanks our very own [Cédric Champeau from the Groovy project for his useful bug reports for Java 8](http://mreinhold.org/blog/jdk8-ga)
*   Vivek Garg explains how to integrate [Tumblr within Grails](http://www.intelligrape.com/blog/2014/03/13/integrating-tumblr-with-grails-application/) applications
*   Uday Pratap Singh shows how to [apply layout to template at runtime in Grails](http://www.intelligrape.com/blog/2014/03/16/applying-layout-to-template-at-runtime-in-grails-application/) applications

## Presentations

*   Baruch Sadogursky discusses [creating DSLs](http://www.infoq.com/presentations/groovy-plugin-dsl) which support plugins written both in Groovy or Java, addressing good public API design practices, security, and classpath isolation. Presentation given at SpringOne2GX 2013

## Code snippets

*   Cédric Champeau created a [solver for the addictive 2048 game using Geb and Groovy](https://twitter.com/CedricChampeau/status/445967056245387264)
*   Tim Yates plays with the [RxJava's Groovy support](https://gist.github.com/timyates/9624727)
    
## Tweets

*   A handful of d[oor busters tickets for GR8Conf Europe](https://twitter.com/gr8conf/status/445513675659821056) 2014 are still available
*   MrHaki, alias Hubert Klein Hikkink, is starting work on a [Grails goodness book](https://twitter.com/mrhaki/status/443983670672908288)
*   André Steingreß noticed [how light the documentation related to Ratpack's Groovy support](https://twitter.com/asteingr/status/446019973128146945) is... perhaps it's time to help and contribute?
*   Tip on how to [set headers for a url.text](https://twitter.com/DailyGrailsTip/status/443235714239438848) Groovy call
*   If you want to learn more about [Gaelyk's developments](https://twitter.com/greach_es/status/444141558036590592) from Gaelyk's lead developer Vladimír Oraný's own mouth, don't miss this session from the Greach conference
*   Sébastien Blanc shows a screenshot of a [Grails backend using AeroGear unified push server](https://twitter.com/sebi2706/status/443678260766212096)

## Other news

*   First [speakers of the GR8Conf Europe](http://storify.com/glaforge/first-gr8conf-europe-2014-speakers-are-announced) 2014 event are being announced
*   Jacob Aee Mikkelsen’s weekly [Grails diary](http://grydeske.net/news/show/35)
*   I forgot to mention the previous week [Grails diary](http://grydeske.net/news/show/33) in my latest Groovy Weekly column

## Books

*   You can support [Hubert Klein Ikkink's Groovy and Grails goodness](https://leanpub.com/groovy-goodness-notebook) efforts by buying the Groovy goodness book
*   Orest Ivasiv [reviews Ken Kousen's "Making Java Groovy"](http://www.halyph.com/2014/03/review-making-java-groovy.html) book

## Events

*   A [GR8Ladies meetup in Minneapolis](http://www.eventbrite.com/e/gr8ladies-meetup-st-cloud-mn-tickets-10858087833?aff=twitter1), MN (USA) on March 21st
*   The [GR8Ladies will be at Women Techmakers](https://twitter.com/Gr8Ladies/status/440298407874158593), in Minneapolis, on March 22nd
*   The [Call for Papers of the SpringOne2GX 2014](https://twitter.com/springcentral/status/441693398152400896) conference will end on April 30th
*   The [Greach conference is offering 23 books and 27 ebooks](https://twitter.com/greach_es/status/441591425487364097) to win for the attendees
*   Gradleware reminds that \*you\* could be a [presenter at the Gradle Summit 2014](https://twitter.com/Gradleware/status/440380894059044864)!
*   Hubert Klein Ikkink (alias MrHaki) will be presenting a [getting started Grails university session for the NLJUG](https://twitter.com/jdriven_nl/status/440521630737911809) on March 25th
# Groovy Weekly #12


What can I tell you for this twelveth week? The Groovy ecosystem is still [looking for students for the Google Summer of Code](http://groovy.codehaus.org/GSoc+2014) program, so if you know students that could be interested, please pass the message. Also notice the nice release train of Grails with its recent 2.2 / 2.3 / 2.4 releases, congrats to the team!

## Releases

*   [Grails 2.3.7 release](http://grails.org/2.3.7%20Release%20Notes)
*   [Grain 0.6 released](http://sysgears.com/grain/news/grain-0-6-0-released/)
*   Noam Tenne releases a [Java API on top of GVM](https://github.com/noamt/sgvm)'s API
*   Andrés Almiray releases [Gipsy 0.4](https://twitter.com/aalmiray/status/441280820771565568) (Service Provider Interface simplification)
*   Schalk Cronjé releases [v0.4 of his Groovy VFS library](https://github.com/ysb33r/groovy-vfs) (Virtual File System)
*   [GVM's SDK](https://twitter.com/gvmtool/status/442751609303347202) jumps to version 0.5.2
    
## Articles

*   Marco Vermeulen blogs about the [GVM Software Development Kit](http://www.wiredforcode.com/blog/2014/03/09/the-gvm-software-development-kit/)
*   David Estes introduces Karman, a standardized, multi-provider, easy-to-use, [Grails based storage interface](http://www.davydotcom.com/blog/2014-03-10-introducing-karman), currently only supporting Amazon S3 but that should end up supporting also Rackspace CDN or Google Cloud Storage
*   [What is Groovy](http://thejavatar.com/what-is-groovy/)? is the first article of the upcoming series encouraging programmers to start writing their applications in Groovy. This particular article provides a basic background of Groovy and a number of code snippets proving its supremacy over Java.
*   Creating [paginated archives in Grain](http://sysgears.com/articles/creating-paginated-archives-in-grain/)
*   Creating a custom website or [theme with Grain](http://sysgears.com/articles/creating-a-custom-website-or-theme-with-grain/)
*   Tim Yates is enhancing his [Groovy Stream library with some further Java 8 lambda support](https://twitter.com/tim_yates/status/441715082700263424)

## Presentations

*   If you speak Spanish, you might be interested in having a look at the [recordings of past Madrid GGUG meetups](http://www.youtube.com/channel/UCgvO2jxLdGaVqHqnfPdyYzw)

## Code snippets

*   [Mixing Spring Boot and Ratpack](https://twitter.com/ratpackweb/status/443480847501381633)

## Tweets

*   Ratpack is introducing the beginnings of [integration with Newrelic](https://twitter.com/ratpackweb/status/441731677660778496) for monitoring and tracing
*   A [GVM SDK library](https://twitter.com/gvmtool/status/441702377100304384) for consumption of the GVM API
*   [Grails 2.2.5 is available on GVM](https://twitter.com/gvmtool/status/441133851667345408)
*   [Grails 2.3.7 is available through GVM](https://twitter.com/gvmtool/status/441701113847619585)
*   [Grails 2.4 milestone 1 is available on GVM](https://twitter.com/gvmtool/status/441133720897355776)
    
## Other news

*   Cédric Champeau updates its ongoing "traits" implementation for Groovy 2.3 with [trait inheritance support](https://github.com/groovy/groovy-core/pull/343). Don't hesitate to try that and report back your findings!
*   A project providing [command line access to Virgo container using Groovy](https://github.com/draghuram/groovy-osgi-console)
*   Gretty, an advanced [Gradle plugin for running web-apps on Jetty](https://github.com/akhikhl/gretty)
*   Cédric Champeau posted beta [documentation for the new Markup template engine](http://beta.groovy-lang.org/docs/groovy-2.3.0-SNAPSHOT/html/documentation/markup-template-engine.html) for Groovy

## Books

*   The [Gradle in Action print book is 43% off till March 20th](https://twitter.com/bmuschko/status/439099709940957185) with a special promo code
*   Lieven Doclo [reviews the Gradle in Action book](http://java.dzone.com/articles/book-review-gradle-action)
    
## Events

*   A [GR8Ladies meetup in Minneapolis](http://www.eventbrite.com/e/gr8ladies-meetup-st-cloud-mn-tickets-10858087833?aff=twitter1), MN (USA) on March 21st
*   The [Call for Papers of the SpringOne2GX 2014](https://twitter.com/springcentral/status/441693398152400896) conference will end on April 30th
*   The [Greach conference is offering 23 books and 27 ebooks](https://twitter.com/greach_es/status/441591425487364097) to win for the attendees
*   Gradleware reminds that \*you\* could be a [presenter at the Gradle Summit 2014](https://twitter.com/Gradleware/status/440380894059044864)!
*   Hubert Klein Ikkink (alias MrHaki) will be presenting a [getting started Grails university session for the NLJUG](https://twitter.com/jdriven_nl/status/440521630737911809) on March 25th
*   The [GR8Ladies will be at Women Techmakers](https://twitter.com/Gr8Ladies/status/440298407874158593), in Minneapolis, on March 22nd
*   If you're in the [Sacremento area](http://sacgru.com), the SacGRU Groovy/Grails user group is meeting every first Thursday of each month at 18:30
*   For those in the [Dallas / Fort Worth area](https://groups.google.com/forum/#!forum/dfw2gug), you can attend the DFW Groovy/Grails user group on every first Wednesday of each month
# Groovy Weekly #11


This is a bit of a special day for me today, as it’s my first daughter’s birthday, who just reached 6, a much younger age than my 10 years involvement in Groovy! And after eating a home-made vanilla French yogurt birthday cake, I’m happy to share with you the following news bits, in particular the nice releases of Groovy 2.2.2, of the first milestone of Grails 2.4, as well as of Ratpack 0.9.2.

## Releases

*   Cédric Champeau announces the [release of Groovy 2.2.2](http://groovy.markmail.org/thread/kssk4ti7kpf5qxcf), done through our new build and delivery infrastructure, built with JetBrains' TeamCity on the server they are sponsoring for us, delivered through JFrog's Artifactory and Bintray pipeline, towards JCenter and Maven Central for the hosting
*   Graeme Rocher announces the [first milestone release of Grails 2.4](http://grails.org/2.4.0.M1+Release+Notes), with Groovy 2.2, Spring Framework 4, the asset pipeline, and static compilation
*   [Ratpack 0.9.2 released](http://www.ratpack.io/versions/0.9.2)
*   Carlos Garcia released a [Gradle Groovy Console plugin](https://github.com/carlosgsouza/gradle-console) which allows you to run a Groovy Console and lets you play with your code and dependencies
*   Al Baker publishes version [0.7.2 of his Groovy Sparql](https://twitter.com/AlBaker_Dev/status/440555501106249728) library

## Articles

*   An article on the [Netflix Dynamic Scripting Platform](http://techblog.netflix.com/2014/03/the-netflix-dynamic-scripting-platform.html), which is using Groovy as its scripting language
*   David Turanski on [Groovy bean configuration in Spring Framework 4](https://spring.io/blog/2014/03/03/groovy-bean-configuration-in-spring-framework-4)
*   Tomás Lin shows how to [deploy Spring Boot Groovy scripts as a Jar file in Cloud Foundry](http://fbflex.wordpress.com/2014/02/28/spring-boot-jar-cloud-foundry/)
*   Jean-Baptiste Nizet writes about [generating REST API documentation with Asciidoctor and Gradle](http://blog.ninja-squad.com/2014/02/25/rest-api-doc-with-asciidoctor-and-gradle/). Also note that he could have used the [Gradle Asciidoctor plugin.](https://github.com/asciidoctor/asciidoctor-gradle-plugin)
*   David Estes writes about [faster asset compilation with Grails asset-pipeline](http://www.davydotcom.com/blog/2014-02-25-faster-asset-compilation-with-grails-asset-pipeline) plugin
*   [Groovy Integration with Adobe CQ5](http://www.intelligrape.com/blog/2014/02/27/groovy-integration-with-cq5-in-maven/) and Maven

## Presentations

*   Venkat Subramaniam speaks about the [DRY principle in Grails](https://www.agilelearner.com/presentation/124)
*   Dan Woods presented about [practical REST in Grails 2.3](http://fr.slideshare.net/danveloper/practical-rest-in-grails-23)
*   Brian Kotek advises on creating [RIA applications in Grails](http://www.infoq.com/presentations/grails-ria) using an array of technologies, including JavaScript, CoffeeScript, TypeScript, ExtJS, Dojo, REST, JSON, GSON, GORM, etc.

## Screencasts

*   Bobby Warner demonstrates the [Grails asset pipeline through a screencast](http://www.bobbywarner.com/2014/02/26/grails-asset-pipeline-plugin/)

## Code snippets

*   Tim Yates provides some examples of [usage of his Groovy Stream library](https://gist.github.com/renatoathaydes/5078535#comment-1184256) in this Haskell vs Groovy comparison Gist
*   A script showing how easy it is to use [GStorm and Groovy to crunch and consume data from REST APIs](https://gist.github.com/kdabir/9332408)
*   Cédric Champeau provides a sample [integration of the upcoming new markup template engine of Groovy 2.3 with Spring Boot](https://github.com/melix/spring-groovymarkup)

## Tweets

*   [Groovy 2.2.2 is available through GVM](https://twitter.com/gvmtool/status/438809878812172288)
*   André Steingreß points at the [Groovy support in Github's Atom text editor](https://twitter.com/asteingr/status/439652445116182528)
*   Dierk König says [Groovy experience makes for a perfect training in Java 8 lambdas](https://twitter.com/mittie/status/439740263427506176)
*   Russell Hart shows a sample of a [realtime metrics dashboard built with Ratpack](https://twitter.com/rus_hart/status/439765546796462081) and Websockets
*   A conversation triggered by Collin Harrington on [Grails @Transactional](https://twitter.com/ColinHarrington/status/438046837241806848)
*   Ludovic Champenois tweeted about the [new Gradle plugin for Google App Engine](https://twitter.com/ludoch/status/438870147017633793) which also works great in Android Studio
*   Chanwit Kaewkasi reports the creation of a [20-node Spark Hadoop cluster and is scripts it with the Groovy Console](https://twitter.com/chanwit/status/440909970448449536)
*   [Spring Boot 1.0-rc4 is available through GVM](https://twitter.com/gvmtool/status/440766140122673152)
*   Benoit Hediard releases the [CDN asset pipeline Grails plugin](https://twitter.com/benorama/status/440851116436488192) to publish assets into CDNs
*   Marco Vermeulen [updates his Gradle Heroku plugin](https://twitter.com/marcoVermeulen/status/440854403059159040)

## Google+ posts

*   Kunal Dabir shares a script to see [how Groovy developer friendly is your machine](https://plus.google.com/u/0/+KunalDabir/posts/VFwUAve5DNM?cfem=1)

## Mailing-list discussions

*   An ongoing discussion on [Gradle's upgrade path towards Groovy 2](http://gradle.1045684.n5.nabble.com/upgrade-gradle-to-groovy-2-td5712332.html) instead of the old 1.8.6

## Other news

*   Andrés Almiray is launching a [Gradle plugin portal](http://aalmiray.github.io/gradle-plugins/)
*   Maciek Opała wrote me to tell us about a [mobile build automation solution for iOS, Android and Windows phone](https://github.com/apphance/Apphance-MobilE-Build-Automation), in the form of a Gradle plugin
*   The excellent [Grails Diary](http://grydeske.net/news/show/32), like every Sunday, from Jacob Aae Mikkelsen

## Books

*   Till March 11th, you get [50% off of Gradle in Action](http://campaign.r20.constantcontact.com/render?llr=gimslwbab&v=001QGVxMVttOOarDTh0jflYxJN1lCcc6sQJTBmK4WKxc8Bf8ucTp1ky44eTr6BtW7_IyYa8R-ZU-huk-pSyoVSuKqXXHLwUdZj_Cd8_eddHh7a_gmMEsP9BrnXnSEKpzLTYYC3fWFCEbw4%3D) and other selected books
*   The [Gradle in Action print book is 43% off till March 20th](https://twitter.com/bmuschko/status/439099709940957185) with a special promo code
*   A short Amazon [review of the Grails 2: Quick Start Guide](http://www.amazon.com/review/R1NHVXJREXYDIT) book from Dave Klein

## Jobs

*   Netflix is [hiring Gradle build and plugin developers](https://twitter.com/robspieldenner/status/438513787058921472)

## Events

*   Gradleware reminds that \*you\* could be a [presenter at the Gradle Summit 2014](https://twitter.com/Gradleware/status/440380894059044864)!
*   Hubert Klein Ikkink (alias MrHaki) will be presenting a [getting started Grails university session for the NLJUG](https://twitter.com/jdriven_nl/status/440521630737911809) on March 25th
*   The [GR8Ladies will be at Women Techmakers](https://twitter.com/Gr8Ladies/status/440298407874158593), in Minneapolis, on March 22nd
# Groovy Weekly #10


Vacations won’t stop me from updating you about all the latest developments in the Groovy community! In this short introduction, I’d like to bring your attention to the fact that the Groovy ecosystem got accepted as an organization for the Google Summer of Code program. So if you are a student, or know students, or engineering schools, universities, etc, interested in contributing to projects of the Groovy ecosystem, please don’t hesitate to spread the word!

## Releases

*   Andrés Almiray releases v0.0.1 of the [LiveReload plugin for Gradle](https://github.com/aalmiray/livereload-gradle-plugin)
*   Ongoing work on the [LightTable IDE support for Groovy](https://github.com/rundis/LightTable-Groovy/releases/tag/0.0.2)
*   Vladimír Oraný releases a [Simple Fixtures](https://github.com/metadataregistry/simple-fixtures) project, similar to Grails Fixture plugin

## Articles

*   A tutorial on using [GORM from a Spring Boot](https://spring.io/guides/gs/accessing-data-gorm/) application
*   Magnus Rundberget blogs about how he's implementing [Groovy code evaluation in his Light Table](http://codewader.blogspot.no/2014/02/a-groovy-light-table-client-step-2.html) Groovy plugin
*   Howard Lewis Ship explains how to [overrule third-party dependencies](http://tapestryjava.blogspot.com/2014/02/gradle-overruling-third-party.html) in case of conflicts with Gradle

## Presentations

*   Bobby Warner discusses the features available in [Grails 2.3 to build RESTful APIs](http://www.infoq.com/presentations/grails-rest-api), at SpringOne2GX 2013
*   Jeff Beck posted his slides of the presentation he made at the Groovy MN user group about [Grails and Cassandra](http://beckje01.github.io/gum-2014-cassandra-grails-talk/#/)
*   Andrey Cheptsov explores some of the [IntelliJ IDEA’s tricky features helping Groovy&Grails developers](http://www.infoq.com/presentations/groovy-grails-intellij-idea) to be more productive. Recorded at SpringOne2GX 2013.

## Screencasts

*   Dan Vega gives an [intro to Spring Security core for Grails](http://www.danvega.org/blog/2014/2/20/Intro-to-Spring-Security-Core-for-Grails#)

## Code snippets

*   Stéphane Maldini shows an [integration of Ratpack and Reactor](https://github.com/smaldini/ratpack-reactor-gh-sample/blob/master/src/ratpack/Ratpack.groovy) for asynchronous REST
*   Kunal Dabir releases version 0.5 of Gstorm, a [mini-ORM for relational databases](https://github.com/kdabir/gstorm/blob/master/examples/using_annotations.groovy), and shows an example with the new annotations
*   An [AST Transformation for debugging scripts](https://gist.github.com/kaendfinger/9183112) which prints information at the beginning of the script, before each statement, and the end of the script

## Tweets

*   Guillaume Laforge announces the [participation of the Groovy community to the Google Summer of Code](https://twitter.com/glaforge/status/438228999903674368) program
*   Guillaume Laforge [calls for students who want to contribute to the Groovy ecosystem](https://twitter.com/glaforge/status/438232563925417985) during the Google Summer of Code. Please spread the word, if you know students, schools or universities willing to participate!
*   Tim Yates shares a [Spring Boot project using GORM](https://twitter.com/tim_yates/status/437962657061040128) configured with Hibernate and Mysql
*   Dan Woods updates his [Gradle Provisioning plugin with ISO building capability](https://twitter.com/danveloper/status/437756649453809664) and registering as HVM AMIs at Amazon
*   [Spring Boot 1.0 rc-3](https://twitter.com/gvmtool/status/436653545358884864) is available through GVM
*   The [Gradle Summit 2014 is opening its Call for Papers](https://twitter.com/gradleware/status/436643232978448384)
*   A tweet from Dierk König saying that [GPars is put to good use](https://twitter.com/mittie/status/436914778611929088), with its Agent, DataFlow, KanbanFlow and async functions, in [OpenDolphin](http://open-dolphin.org/dolphin_website/Home.html)
*   Magnus Rundberget celebrates the 330th downloads of the [Gradle Buster.JS plugin](https://twitter.com/mrundberget/status/438221883163828224), to automate running Buster.JS tests from CI and local development

## Other news

*   Keegan Witt published the [GMaven+ documentation](http://docs.codehaus.org/display/GMAVENPLUS/Home/) on Codehaus' wiki
*   Cédric Champeau developed a [Groovy build step plugin for TeamCity](https://github.com/melix/teamcity-groovy-buildstep), for the needs of the Groovy project infrastructure
*   John Engelman mentions the [new documentation for the Grails Gradle plugin](http://grails.github.io/grails-gradle-plugin/docs/manual/)
*   Jacob Aae Mikkelsen publishes the [Grails Diary](http://grydeske.net/news/show/31) with the usual updates on all things Grails

## Books

*   [Gradle in Action is now available in print](https://twitter.com/manningbooks/status/436871815164887041), and soon in ePub & Kindle edition too

## Events

*   Still [doorbusters tickets available for GR8Conf Europe 2014](http://us4.campaign-archive1.com/?u=ac7af4c02d6cec67fe3198a63&id=bc02eb8bb2&e=88c97e251c), be fast to get the best price!
*   Gradle Summit 2014 is [calling for presenters](http://www.gradle.org/gradle-summit-cfp)!
# Groovy Weekly #9


An interesting column this week thanks to the major release of Griffon 1.5, but also a minor release of Grails 2.3.6 which brings the often requested standalone GORM support!

## Releases

*   [Grails 2.3.6](http://grails.org/2.3.6+Release+Notes) released, including GORM standalone support
*   [Griffon 1.5](http://docs.codehaus.org/pages/viewpage.action?pageId=237371944) is released
    
## Articles

*   Cédric Champeau details in a two parts article his work on a [new template engine for Groovy](http://melix.github.io/blog/2014/02/markuptemplateengine.html), that is fast, can be type checked and statically compiled
*   Second part of the article from Cédric Champeau about his new markup template engine for Groovy with [advanced explanations about static type checking extensions and static compilation](http://melix.github.io/blog/2014/02/markuptemplateengine_part2.html)
*   More on the [Groovy client for the Light-Table](http://codewader.blogspot.no/2014/02/a-groovy-light-table-client-step-1.html) IDE
*   André Steingreß covers [Java-based configuration with Grails](http://blog.andresteingress.com/2014/02/14/grails-java-based-spring-config/)
*   Marco Vermeulen explains how to [deploy apps like Ratpack, Spring Boot or Dropwizard on Heroku](http://www.wiredforcode.com/blog/2014/02/11/deploy-to-heroku-with-gradle) thanks to Gradle
*   VoltDB integrates [Groovy for its datastore inline procedure language](http://voltdb.com/voltdbgroovy)
*   An article on RelProxy, a project for a [hot class reloader and scripting](http://java.dzone.com/articles/presenting-relproxy-hot-class) for Java and Groovy
*   [Enum to Switch on Class types](http://octodecillion.com/blog/use-java-enum-to-switch-on-class-types/) in Java and Groovy
    
## Presentations

*   Ken Kousen presents [advanced Groovy features](http://www.infoq.com/presentations/advanced-groovy-tips), such as closure coercion, mixins, simple runtime metaprogramming, operator overloading, drop and take, overlooked methods in the Groovy JDK, and more (recorded at SpringOne2GX 2013)
*   Greg Turnquist demoes using [Spring Mail, Security, REST, GridFS, Bootstrap and jQuery in a production grade Grails application](http://www.infoq.com/presentations/grails-case-study)
*   John Engelman presents a talk on [enterprise Grails with Spring Batch](https://speakerdeck.com/johnrengelman/enterprise-grails-spring-batch) for batch processing
    
## Mailing-list discussions

*   Rick Hightower's been working on the new JSON parser for Groovy 2.3 to [give Groovy the fastest JSON parser available on the JVM](http://groovy.329449.n5.nabble.com/Improve-serialization-speeds-of-JsonOutput-td5718316.html#a5718394), and along with Andrey Blochestov they are also looking at making the creation of JSON payloads also super fast
    
## Code snippets

*   Andrés Almiray on the [simplicity of functional testing for Griffon applications](https://twitter.com/aalmiray/status/434438930436730880)
*   Miguel de la Cruz shows his experiment with a [minimal web server implemented with Ratpack](https://github.com/mgdelacroix/ccServer/blob/master/ccServer.groovy)
    
## Tweets

*   [Griffon 1.5](https://twitter.com/gvmtool/status/433731764134363136) available through GVM
*   GVM now offers [Gradle 1.11](https://twitter.com/gvmtool/status/433280770166509568) too
*   Johannes Link, contributor of the @TailRecursive transformation for Groovy 2.3, compared the performance of @TailRecursive on methods vs trampoline() on closures, and indicate that the [performance advantage is for @TailRecursive](https://twitter.com/johanneslink/status/434057275146522625)
*   Dave Syer shows an example of a [Spring Boot controller written in Groovy that outputs JSON](https://twitter.com/david_syer/status/365367862170353667)
*   Bobby Warner notes that the [Asset pipeline plugin replaces the resources plugin](https://twitter.com/bobbywarner/status/433277222476980224) by default from Grails 2.4 onward
  
## Other news

*   The [@TailRecursive transformation](https://github.com/groovy/groovy-core/pull/315) has been contributed by Johannes Link and Cédric Champeau merged the pull request into the Groovy 2.3 branch
*   Jacob Aae Mikkelsen's Week #7 of the [Grails diary](http://grydeske.net/news/show/30)

## Books

*   The final version of the [Gradle in Action](http://www.manning.com/muschko/) eBook is available

## Events

*   [Registration for GR8Conf Europe 2014 is open](http://gr8conf.eu/)
*   You can find the [Greach conference on Lanyard](http://lanyrd.com/2014/greach/)
*   A new [Groovy user group in Warsaw](http://www.meetup.com/Warszawa-Java-User-Group-Warszawa-JUG/events/166258012/?utm_content=buffer5ada7&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer), Poland
*   Peter Ledbrook is speaking about why your build matters, and the [importance of Gradle](https://skillsmatter.com/meetups/6202-why-does-your-build-matter)
# Benefit from Groovy now: when, how, why


Last week, I was in Stockholm, Sweden, for the JFokus conference. [Mattias Karlsson](https://twitter.com/matkar) had invited me to speak about how to benefit from Groovy, how / when / why developers, projects, companies are using and adopting Groovy in their everyday life.  

So I crafted a brand new presentation illustrating those usage patterns, how they are applied, also giving some examples of existing projects or companies benefiting from Groovy in that way.  

I've published the slides on SpeakerDeck, and I'm embedding them below:

{{< speakerdeck eb56155070930131f1195e173af38d18 >}}

# Groovy Weekly #8


In Stockholm for the JFokus conference, I was happy to meet some of the members of the Groovy community, and had the chance to speak about the [Groovy usage patterns and how companies integrate Groovy](https://speakerdeck.com/glaforge/benefit-from-groovy-now-why-when-how-jfokus-2014). But while I’m having fun in Sweden (with heaps of fever though), we are laying out the new infrastructure for the Groovy project with the help of JetBrains and JFrog, or work is underway to make Groovy’s JSON support the fastest around (more infor to come soon)! So it’s been a busy week!

## Releases

*   [Gradle 1.11 release](http://www.gradle.org/docs/1.11/release-notes) announced by Luke Daley
*   A Groovy library offering a [functional Option](https://github.com/johnnywey/flipside) implementation and a matcher
    
## Articles

*   MrHaki is looking into [customizing root rlement name collections for Grails XML marshalling](http://mrhaki.blogspot.fr/2014/02/grails-goodness-customize-root-element.html)
*   André Steingreß talks about the ability to [use the Grails Environment class anywhere in BuildConfig.groovy](http://blog.andresteingress.com/2014/02/07/grails-environment-in-build-config/) since Grails 2.3
*   Tamsin Slinn explains how she created her first Groovy DSL, to [automate the management of her Jenkins jobs](http://blog.anorakgirl.co.uk/2014/02/my-first-groovy-dsl/)
*   Craig Atkinson on [Groovy convenience in JavaScript](http://www.objectpartners.com/2014/02/07/groovy-convenience-in-javascript-with-lo-dash/)
*   Andrew Taylor shows how to [set request attributes on URL requests](http://www.redtoad.ca/ataylor/2014/02/setting-headers-url-requests-with-groovy/) in Groovy
*   Options for [Grails debugging in Grails 2.3](http://www.intelligrape.com/blog/2014/02/06/grails-debugging-in-version-2-3-x-and-above/) and beyond
*   MrHaki shows how to run [Grails forked tests in IntelliJ IDEA](http://mrhaki.blogspot.fr/2014/02/grails-goodness-run-forked-tests-in.html)
*   Using Groovy [AST transformations for DSL manipulation](http://expertalks.wordpress.com/2014/02/10/using-groovy-ast-transformations-for-dsl-manipulation/)
  
## Presentations

*   Guillaume Laforge presented a talk at JFokus 2014 about the [usage patterns of Groovy](https://speakerdeck.com/glaforge/benefit-from-groovy-now-why-when-how-jfokus-2014), for scripting, testing, extension points, business rules, DSLs, and full-blown apps
*   In this presentation recorded at SpringOne2GX 2013, Joe Rinehart explains how to integrate [Twitter Bootstrap into a Grails](http://www.infoq.com/presentations/grails-twitter-bootstrap) application.
*   [Marcin Grzejszczak shares a presentation about an introduction to metaprogramming and AST transforms](http://java.dzone.com/articles/introduction-groovy-runtime)
*   [Continuous Delivery with Docker, Gradle and Jenkins](https://twitter.com/franckdepierre/status/433011063693783040)

## Mailing-list discussions

*   Guillaume Laforge wrote an update on the Groovy mailing-list about some [infrastructure news regarding the Groovy project](http://groovy.329449.n5.nabble.com/ANN-Groovy-infrastructure-update-td5718414.html) (CI server, URL, new documentation, snapshot & release publishing, etc)
*   Guillaume Laforge announces that [Groovy 2.3 will raise the JDK requirement to JDK 6](http://groovy.329449.n5.nabble.com/Groovy-JSON-Parser-update-23x-speed-improvement-for-JsonSlurper-td5718189i40.html#a5718336), compared to all other versions which had still be compatible with JDK 5 so far.
    
## Code snippets

*   Cédric Champeau has a prototype of a [potential new template engine](https://github.com/melix/groovy-core/blob/69aeea4606b272d4bcce47602cac6c04b8c72498/subprojects/groovy-templates/src/test/groovy/groovy/text/MarkupTemplateEngineTest.groovy) addition for Groovy, which is a markup builder based template engine, which also understands includes

## Tweets

*   Guillaume Laforge receives his second "[JavaOne Rock Star](https://twitter.com/glaforge/status/433158041643810816)" award, for his participation to the JavaOne 2013 conference, where he spoke about Groovy, and also represented Groovy and won the "Script Bowl" competition
*   The [Groovy project is overhauling its infrastructure](https://twitter.com/jbaruch/status/432903532669190144) and is going through OSS JFrog.org and JFrog Bintray for uploading its snapshots built with JetBrains TeamCity and soon for the releases too
*   With the new CI server sponsored by JetBrains, the Groovy project also has a build plan for [building Groovy against the future JDK 9](https://twitter.com/cedricchampeau/status/433258782177906688) releases
*   Johannes Link shares a download of his [ongoing @TailRecursive transform](https://twitter.com/johanneslink/status/431432766404976640) to be included in Groovy 2.3
*   Magnus Rundberget is experimenting with a [Groovy plugin for the LightTable IDE](https://twitter.com/mrundberget/status/432542766476713984)
*   Dan Woods published a [new plugin for Grails](https://twitter.com/danveloper/status/430692110560272384) for simplifying & streamlining the implementation of RESTful renderers
*   Burt Beckwith was noticing that [older editions of the GR8Conf conference series are available online](https://twitter.com/burtbeckwith/status/432638090373369857), if you're interested in watching past presentations and look at slide decks
*   Groovy comes with its own [permutation generator](https://twitter.com/dailygrailstip/status/432761726283440128) used by the permutations() method on collections
    
## Other news

*   Latest [Grails Diary](http://grydeske.net/news/show/29) by Jacob Aae Mikkelsen
*   Tim Yates is [documenting his Groovy stream library](http://timyates.github.io/groovy-stream/main.html) with Asciidoctor and JBake

## Books

*   The authors of the "Groovy 2 Cookbook" book are launching a little [contest for a giveaway of the book](http://groovy.aestasit.com/contest.html)
    
## Events

*   The Greach conference in Madrid [refreshed its website](http://greach.es/) look and published the full agenda
# Groovy Weekly #7


## Releases

*   [Ratpack 0.9.1 is released](http://www.ratpack.io/versions/0.9.1), with performance and memory consumption improvements, as well as an RxJava module
*   John Engelman releases [version 2.0.0 of the Grails-Gradle plugin](http://imperceptiblethoughts.com/post/74739966407/grails-gradle-plugin-2-0-0-released)
*   Cédric Champeau created a [Gradle plugin for JBake](https://github.com/melix/jbake-gradle-plugin), to be able to render static web sites as part of your Gradle build
*   Release of an [update to the Grails Api Toolkit plugin](http://grails.org/plugin/api-toolkit) helping build API with REST, RPC and HATEOAS support

## Articles

*   The [Groovy style guide](http://groovy.codehaus.org/Groovy+style+and+language+feature+guidelines+for+Java+developers) shared by Guillaume Laforge echoing a [conversation](https://twitter.com/pcarey/status/428676607109111808) on Twitter about the bad practice of putting def everywhere
*   Cédric Champeau details how to [create your own static blog with JBake, Gradle and Github](http://melix.github.io/blog//2014/02/hosting-jbake-github.html)
*   An article on [Groovy Memoization](http://www.objectpartners.com/2014/01/28/memoization-in-groovy) by Brendon Anderson
*   [Why is Groovy groovy](http://dmahapatro.blogspot.fr/2014/01/how-is-groovy-groovy.html)?
*   Burt Beckwith offers [one more approach for diagnosing spring-security-core login errors](http://burtbeckwith.com/blog/?p=2029)
*   André Steingreß [covers the Grails Audit plugin](http://blog.andresteingress.com/2014/01/31/grails-audit-logging/)
*   André Steingreß is covering [Grails testing with Cucumber](http://blog.andresteingress.com/2014/01/28/functional-testing-with-cucumber/)
*   Following up on his previous post, André Steingreß [continues his Grails testing with Cucumber](http://blog.andresteingress.com/2014/01/29/functional-testing-with-cucumber-followup/)
*   Jochen Theodorou explains [what class duplication is](http://blackdragsview.blogspot.fr/2014/01/what-class-duplication-is-and-how-it.html) and how it happens
*   Testing [Grails with Cucumber, HTTPBuilder, and RemoteControl](http://softnoise.wordpress.com/2014/01/27/grails-cucumber-with-httpbuilder-remotecontrol/)
*   Ken Kousen plays with [Groovy's date support](http://kousenit.wordpress.com/2014/02/02/groovy-groundhogs-revisited/)
*   Hubert Klein Ikkink shares some tips about [cleaning up your Grails projects](http://mrhaki.blogspot.fr/2014/02/grails-goodness-cleaning-up.html)
*   Following up on MrHaki's Grails clean-up tip, André Steingreß offers his own [Grails tip for cleaning up everything](http://blog.andresteingress.com/2014/02/03/grails-clean/) in a single rm command
*   Michael Scharhag blogs about [using database views in Grails](http://www.mscharhag.com/2014/01/using-database-views-in-grails.html)
*   A tutorial on developing a [Grails application with Facebook Connect](http://developer.cloudbees.com/bin/view/DEV/GrailsAppFacebookConnect)
*   A [broad stroke overview of Grails](http://sigma-infosolutions.blogspot.in/2014/01/a-broad-stroke-overview-of-grails-web.html) web app development framework

## Presentations

*   Hubert Klein Ikkink, alias MrHaki, [presented Getting Groovy](http://mrhaki.blogspot.fr/2014/02/getting-groovy-g8conf-2013-europe-on.html), at GR8Conf Europe 2013.
*   Ken Kousen advises Java developers [how to do similar tasks in Groovy](http://www.infoq.com/presentations/java-groovy-2gx): building and testing applications, accessing both relational and NoSQL databases, accessing web services, and more.
*   At GR8Conf US 2013, Craig Atkinson presents the advantages of using the [Geb functional testing](http://www.infoq.com/presentations/grails-geb-functional-test) library for creating robust and readable tests with both JUnit and Spock, and configuring Geb for testing across multiple browsers.
*   Recorded at GR8Conf US 2013, Kyle Boon reviews [3 frameworks for building RESTful WS](http://www.infoq.com/presentations/rest-groovy-framework) (Grails, Dropwizard and Ratpack), comparing their code readability, maintainability, deployment, metrics collection, scalability and testability.
*   At SpringOne2GX 2013, Joe Rinehart discusses some of the [essential security topics for Grails](http://www.infoq.com/presentations/grails-security) (and Java) Web applications, showing how Grails can make life easier and the pitfalls of attempting to secure highly dynamic code.
*   Ryan Vanderwerf explains setting up Terracotta and [clustering a Grails application](http://www.infoq.com/presentations/grails-terracotta-quartz) using Ehcache, HTTP Session in Tomcat, and Quartz. Recorded at GR8Conf US 2013.

## Mailing-list discussions

*   Dinko Srkoč announces the birth of his [stream extension to Groovy's Sql](http://groovy.329449.n5.nabble.com/ann-groovy-sql-Sql-and-streaming-ResultSet-td5718265.html) facility (potentially to be included in Groovy)

## Code snippets

*   Tim Yates is trying to [implement Groovy's collate() method with Java 8 streams](https://twitter.com/tim_yates/status/428488170682863616) and lambdas.
*   Tim Yates offers a little sample showing how to [display a little spinner icon in text mode](https://gist.github.com/timyates/8648011) for long running tasks

## Tweets

*   Cédric Champeau lobbies for having the [normal "groovy" JAR to also "jarjar" the mandatory basic dependencies](https://twitter.com/CedricChampeau/status/430744126955745280) of ASM, Antlr and Commons-CLI, like with the Groovy all JAR. You can vote for that JIRA issue.
*   Andrés Almiray tweets his [desire to see a Gradle portal plugin](https://twitter.com/aalmiray/status/429222410425212928) soon
*   Dierk König tweets about [Groovy being for getting things done](https://twitter.com/mittie/status/430271085486288896) rather than for showing off!
*   groovy.io are [looking for sponsors](https://twitter.com/groovyio/status/430498283547406336) for their upcoming hackathon
*   The Grain static site generator introduces [dynamic rendering anywhere](https://twitter.com/grainframework/status/428881821502144514)
*   Grails provides a command to [generate a zip file to attach to a JIRA issue](https://twitter.com/dailygrailstip/status/429848791668097024) if you need to file a bug report with a reproducible problem
*   [Gradle 1.11-rc1 is available through GVM](https://twitter.com/gvmtool/status/430464483589623809)
*   The Grails force-ssl plugin adds an [@SSLRequired](https://twitter.com/davydotcom/status/430692627323686913) annotation
*   Dan Woods published a [new plugin for Grails for simplifying & streamlining the implementation of RESTful renderers](https://twitter.com/danveloper/status/430692110560272384)

## Other news

*   Week 5 of the [Grails diary](http://grydeske.net/news/show/28) by Jacob Aae Mikkelsen

## Books

*   The [Groovy 2 Cookbook has its dedicated website](http://groovy.aestasit.com/)
*   A short [review of the "Groovy 2 cookbook"](http://shitmores.blogspot.fr/2014/02/book-review-groovy-2-cookbook.html) book
    
## Events

*   SkillsMatter, the organizer of the Groovy / Grails eXchange conference since 2007, have overhauled their website, and you can already see the page for the [upcoming GGeX 2014 edition](https://skillsmatter.com/conferences/1957-groovy-grails-exchange-2014)
*   Dan Woods is [speaking about Grails 2.3's Rest capabilities](http://www.meetup.com/San-Francisco-Grails-Centro/events/162510932/) on February 27th at the San Francisco Grails meetup
# Groovy Weekly #6


## Releases

*   The first [release candidate of Spring Boot](https://spring.io/blog/2014/01/22/spring-boot-1-0-0-rc1-released) is out, including its lean Groovy support
*   Grain releases are now [available in Maven Central](https://twitter.com/grainframework/status/425887785312976897)
*   Andrés Almiray released [version 0.3.0 of his Gipsy](https://twitter.com/aalmiray/status/426431315463110656) AST transformation for simplifying usage of the service provider interface system

## Articles

*   Pivotal posted Guillaume Laforge's article on the [3 million downloads of Groovy](http://blog.gopivotal.com/products/3-million-downloads-of-the-groovy-programming-language-in-2013) last year and his analysis
*   Kyle Boon describes [how to use meta-annotations to reduce boilerplate code](http://kyleboon.org/blog/2014/01/22/using-meta-annotations-to-dry-your-groovy/)
*   GVM, the Groovy enVironment Manager, is featured on the methods and tools website, thanks to an [article](http://www.methodsandtools.com/tools/gvm.php) from Marco Vermeulen
*   At SpringOne2GX 2013, Ryan Vanderwerf explains [how to create and deploy a Grails application on AWS VPC](http://www.infoq.com/presentations/grails-aws-vpc-2gx) using various services such as RDS, S3, autoscaling, S3FS, EBS, etc.
*   An infographic from Cygnet Infotech about [6 reasons why Grails is an awesome](http://www.cygnet-infotech.com/infographic-6-reasons-why-grails-is-an-awesome-java-web-framework) Java Web framework
*   Bert Van Den Brande writes about using [Spring Boot with Groovy](http://blog.bertvdbrande.com/java/spring-boot-applied-springmvcgroovy/)

## Presentations

*   ZeroTurnaround published a decision maker’s [comparison of Maven, Gradle and Ant + Ivy](http://zeroturnaround.com/rebellabs/java-build-tools-part-2-a-decision-makers-comparison-of-maven-gradle-and-ant-ivy/)
*   [Simpler stored procedures with Groovy](http://www.objectpartners.com/2014/01/24/simpler-stored-procedures-with-groovy/) by Jeff Sheets from Object Partners
*   Burt Beckwith explains the general process of [creating a Grails plug-in](http://www.infoq.com/presentations/grails-plugin-2gx), the different types of plug-ins, and how to deploy, release and test them.
*   Will Buck provides advice for those interested to [upgrade their applications from Grails 1.x to 2.x](http://www.infoq.com/presentations/grails-upgrade)
*   Venkat Subramaniam shows how to [implement several design patterns](http://www.infoq.com/presentations/groovy-design-patterns), including some GoF ones, using Groovy’s dynamic nature and closures.
*   Jim Driscoll shows how to create Napili, a small program accepting user scripts to [control a turtle using GroovyShell](http://www.infoq.com/presentations/turtle-groovy-dsl), the Binding, overriding behavior with set/getVariable and invokeMethod, and more, recorded at GR8Conf US 2013

## Mailing-list discussions

*   Lari Otari from the Grails team is calling for [feedback on areas where the Grails unit testing support](http://grails.1312388.n4.nabble.com/Grails-Unit-testing-improvements-for-Grails-2-4-call-for-feedback-td4653480.html) could be improved
    
## Tweets

*   Surge in [popularity for Gradle](https://twitter.com/rebellabs/status/425676447588818944) in the ZeroTurnaround analysis
*   Cédric Champeau succeeded [making Groovy build with JDK 8](https://twitter.com/cedricchampeau/status/425965163804901376), a first step forward to adding further Java 8 support in Groovy
*   Johannes Link is [reworking his @TailRecursive AST transformation for integration in Groovy 2.3](https://twitter.com/johanneslink/status/427833828229779456)
*   A funny [GORM-like tweet](https://twitter.com/yeiiowsnow/status/425317814388289536) to encourage people to order the second edition of the Grails quick-start guide book

## Jobs

*   A [remote Grails engineer](http://findgrailsjobs.com/job/475-grails-engineer-wixab-telework) for Wixab

## Other news

*   As usual, the the [Grails Diary](http://grydeske.net/news/show/27) is out, week 5 of 2014, by Jacob Aae Mikkelsen
*   A new look for the [GR8Conf Europe website](http://gr8conf.eu/)
  
## Books

*   The [final chapters of Grails in Action](https://twitter.com/manningmeap/status/425672935576453120), 2nd edition are now in Manning's Early Access Program. Peter Ledbrook tells us issues can be reported in their GitHub issue tracker (https://github.com/GrailsInAction/graina2/issues)
    
## Events

*   [First meetup of the GR8 Ladies](https://twitter.com/gr8ladies/status/426078450236260352) of Minneapolis on January 29th
*   The [Call for Papers](http://cfp.gr8conf.org/login/auth) for the GR8Conf Europe (Copenhagen, Denmark, on June 2nd-4th 2014) and GR8Conf US (Minneapolis, USA, on July 28th-29th 2014) conferences is now open
*   The Call for Papers for the [Greach](http://greach.es/) conference (Madrid, Spain, on March 28th and 29th 2014) is also open, till January 31st
# Groovy crosses the 3 million downloads a year mark


Back in 2012, I was pretty happy and proud to see Groovy being used more and more, and reaching 1.7 million downloads in 2012. But the competition with other alternative language, I was personally not sure how those figures would evolve over the course of 2013. Fortunately, thanks to the hard work of the Groovy core development team and the friendly community and ecosystem, I'm happy to report an impressive ongoing growth for 2013: Groovy crosses the 3 million downloads a year mark!  

I have compiled some statistics thanks to the Maven Central statistics, as well as through slicing and dicing the Codehaus Apache logs, and I'd like to illustrate two interesting findings.  

First, let's have a look at those download numbers, spanning both 2012 and 2013 to show the trend and growth. In the graph below (sorry for the subtitle in French) I've stacked up the Codehaus downloads (in blue) and the Maven Central downloads (in green), and put the total on top (in yellow).  

[![](/img/misc/groovy+download+evolution.png)](/img/misc/groovy+download+evolution.png)  

You'll notice that there are more downloads of Groovy "as a library" than as an installable binary distribution, as Central usually represents 3 to 4 times more downloads than Codehaus, but this is logical as Groovy is just a "dependency" to add to your project!  

The peaks you see on the graph usually correspond to major releases, for example the 2.2.0 RCs and GA releases in October 2013, or 2.1.0 end of December 2012, etc.  
The yellow line is showing the general trend in total number of downloads per month, starting from 100K+ per month in the beginning of 2012 up to 300K+ downloads a month at the end of 2013.  

Before moving to the second illustration, note that those numbers are downloads of Groovy itself. They don't account for downloads of Grails or Gradle, etc, as those projects actually bundle their own version of Groovy, and thus doesn't add downloads to our stats here. Those figures represent developer and company projects depending on Groovy or developers installing the Groovy distribution on their machines.  

Another interesting perspective is to see how the various Groovy versions are being adopted by the community. The graph below illustrates the proportion of each version being downloaded over 2012 and 2013.  

[![](/img/misc/groovy+version+adoption.png)](/img/misc/groovy+version+adoption.png)  

There have been many beta and RC releases of Groovy 2.0 in 2011 and first half of 2012, and Groovy 1.8 was really going strong, but with the release of Groovy 2.0 in June 2012, we've had a rapid adoption of Groovy 2.0, even though Groovy 1.8 has still been remaining significant (for instance, some projects like Gradle still rely on Groovy 1.8!).  
The release of Groovy 2.1 in January 2013 also induced a cliff of adoption towards the new version, dwarfing 2.0, as Groovy 2.0, 2.1 and 2.2 are very much compatible so users don't hesitate jumping their dependencies up.  

And then the release of Groovy 2.2 in November 2013 shows this version is also being nicely adopted, although perhaps less rapidly than 2.1 was -- but remember these are percentages on the graph. And as of December, Groovy 2.2 represents about 40%, slightly above the 38% of Groovy 2.1.  

What we see from this graph is that it usually takes around 4 months or so for the next major version of Groovy to be majoritarily adopted by Groovy developers.  

With the downloads almost doubling (1.7M to 3.0M) from 2012 to 2013, we see that Groovy clearly continue being very successful and widely used and deployed in tons of projects!  
Big thanks to the Groovy core team for its hard work towards this success, and to the whole community and ecosystem for fostering such a growth!
# Groovy Weekly #5


We all know the Groovy community is super active, buzzing with useful projects in the ecosystem, but it’s always interesting to see how our projects evolve in terms of usage. Guillaume Laforge, project lead of Groovy, computed some download statistics for Groovy, and showed [Groovy almost doubled its downloads, from 1.7 million downloads in 2012 up to 3 million downloads in 2013]({{< ref "/posts/2014/01/21/groovy-crosses-the-3-million-downloads-a-year-mark" >}})! All that, thanks to the hard work of the Groovy core team and the friendly and supportive community.

## Releases

*   Grails 2.3.5 has been [released](http://grails.org/2.3.5%20Release%20Notes)
*   Keegan Witt announces the [GMavenPlus 1.0 release](https://github.com/groovy/GMavenPlus/wiki/News), which offers the best support for building Groovy projects when using Maven

## Articles

*   Guillaume Laforge [analyses the ongoing growth of Groovy]({{< ref "/posts/2014/01/21/groovy-crosses-the-3-million-downloads-a-year-mark" >}}) in terms of downloads (3 million downloads in 2013) and illustrates the adoption of the various Groovy version over the past two years, with a couple pretty graphs.
*   Andrés Almiray explains all the [details about Griffon 2.0 and beyond](http://www.jroller.com/aalmiray/entry/griffon_2_0_0_and)
*   Russell Hart on [deploying Ratpack applications to Cloud Foundry](http://blog.anacoders.com/deploying-ratpack-applications-to-cloudfoundry/)
*   Mark Perry continues exploring the functional field with Groovy, with [folds and unfolds](http://mperry.github.io/2014/01/21/folds-and-unfolds.html)
*   Kunal Dabir shows how to use a [Lazybones template for your Gaelyk applications](https://github.com/kdabir/lazybone-templates#creating-a-gaelyk-project-using-the-template)
*   [Smooth integration with Github Pages is introduced in Grain](http://sysgears.com/grain/news/deployment-to-github-pages-is-introduced/), the static website generator for Groovy
*   Julian Exenberger tries to [replicate Groovy's builders using Java 8 and lambdas](http://java.dzone.com/articles/builder-pattern-using-java-8-0)
*   David Estes explains the [differences and similarities of moving from Rails to Grails](http://www.redwindsw.com/blog/2014-01-15-moving-from-rails-to-grails-differences-and-similarities)
*   Corinne Krych [reports on the recent Groovy hackergarten](http://corinnekrych.blogspot.fr/2014/01/secure-your-runtime-groovy-hackengarten.html) that took place in the south of France with Cédric Champeau, on the topic of a secure runtime AST customizer

## Presentations

*   Graeme Rocher talks through the latest [Async features offered by Grails](http://www.infoq.com/presentations/grails-rest-async) and how they can be used to create non-blocking REST APIs
*   Marco Vermeulen showcases using [BDD and Cucumber to develop GVM](http://www.infoq.com/presentations/gvm-bdd-cucumber), an open source tool for managing parallel SDK versions, during GR8Conf US 2013
*   Jeff Beck shows how to use Codenarc, Cobertura, JSLint, and other tools to perform [static analysis on Grails application](http://www.infoq.com/presentations/grails-static-analysis-tools), recorded at GR8Conf US 2013
*   Rob Fletcher explains how to [use Vert.x, WebSockets, continuous unit testing and headless end-to-end testing](http://www.infoq.com/presentations/grails-vertx-websockets) to create one-page applications in Grails, during GR8Conf US 2013

## Mailing-list discussions

*   Jochen Theodorou gives some [high-level explanations of what the future Meta-Object Protocol v2](http://groovy.329449.n5.nabble.com/Installing-a-property-through-metaclass-sometimes-does-not-work-td5718106.html#a5718134) will look like in Groovy 3.0
    
## Tweets

*   [Groovy crossed the 3 million downloads mark for 2013](https://twitter.com/glaforge/status/425299880991801344), to compare with the 1.7M downloads for 2012, that's quite a growth!
*   Cédric Champeau merged the [Groovy closure parameter type inference into master](https://twitter.com/cedricchampeau/status/423506229923962880)
*   Cédric Champeau is [setting up the new TeamCity Continuous Integration server](https://twitter.com/cedricchampeau/status/423853949821939712) for building Groovy, sponsored by JetBrains
*   Grails 2.3.5 is also [available in GVM](https://twitter.com/gvmtool/status/423896818423189504)
*   Some details on the upcoming [RxJava support in Ratpack 0.9.1](https://twitter.com/ratpackweb/status/423597717420769280)
*   Andrés Almiray crafts various [Lazybones templates for Griffon](https://twitter.com/aalmiray/status/424981529878478848)
*   The Grain static website generator is [adding Asciidoctor support](https://twitter.com/grainframework/status/425260426851409920) in the next version
*   David Dawson shares a picture of [Groovy post-it notes](https://twitter.com/davidthecoder/status/423855749165776896/photo/1)!
*   Looks like Minneapolis is always super active in the Groovy ecosystem, and a "[GR8 Ladies](https://twitter.com/gr8ladies)" initiative is seeing the light of day. You might want to follow their twitter account as the story unfolds.
*   Rob Fletcher is a fan of [Groovy 2.2's implicit closure coercion](https://twitter.com/rfletcherew/status/425340799820496896)
*   Dan Woods is [joining the Cloud Infrastructure Tools team at Netflix](https://twitter.com/danveloper/status/425343533721989120)

## Podcast

*   For those speaking French, Stéphane Maldini answers Guillaume Laforge's questions on [Grails and Reactor on this interview](https://twitter.com/lescastcodeurs/status/425366618525663232) of the French podcast "Les Cast Codeurs"
    
## Google+ post

*   Colling Harrington [mentions](https://plus.google.com/u/0/+ColinHarrington/posts/K29FVW56AzJ?cfem=1) Aaron Hanson's work on a [SimpleHTTPServer script](https://github.com/simplenotions/simple-http-server) in Groovy, in the same vein as Ratpack
    
## Code snippet

*   A Groovy script that takes a [CSV file and turns it into a List of Maps](https://gist.github.com/crazy4groovy/8438827#file-csv2list-groovy) using the GroovyCSV library
    
## Contributions

*   Cédric Champeau joined the Riviera GUG which was organizing a Groovy hackathon last week-end, and they worked and contributed to [GROOVY-6527](http://jira.codehaus.org/browse/GROOVY-6527), a secure runtime AST customizer, and made [several commits that will be contributed to the Groovy project](https://github.com/rivieragug/groovy-core/commits/secureruntime)

## Jobs

*   Dan Woods tells us about startup [Exactuals](http://www.exactuals.com/) which is [hiring a Senior Grails Developer](https://twitter.com/danveloper/status/425524216201347073) for $100k-$120k per year to work with cloud, and messaging technologies

## Other news

*   As usual, the the [Grails Diary](http://grydeske.net/news/show/26) is out, week 4 of 2014, by Jacob Aae Mikkelsen

## Books

*   A [review of Ken Kousen's Making Java Groovy book](http://www.amazon.com/review/R395UVGPILFN68/ref=cm_cr_pr_perm?ie=UTF8&ASIN=1935182943&linkCode=&nodeID=&tag=) on Amazon
    
## Events

*   A [report on the first Grails Conf India conference](http://www.pcquest.com/pcquest/news/206418/intelligrape-software-launches-indian-chapter-world-s-largest-grail-conference) organized by IntelliGrape
*   The [Call for Papers](http://cfp.gr8conf.org/login/auth) for the GR8Conf Europe (Copenhagen, Denmark, on June 2nd-4th 2014) and GR8Conf US (Minneapolis, USA, on July 28th-29th 2014) conferences is now open
*   The Call for Papers for the [Greach](http://greach.es/) conference (Madrid, Spain, on March 28th and 29th 2014) is also open, till January 31st
    
Don't forget you can [contribute to this weekly column](http://bit.ly/groovyweekly) of Groovy news, and that you can [subscribe through a newsletter](http://bit.ly/groovy-weekly-subscribe).
# Groovy Weekly #4


Here’s the fourth edition of the Groovy Weekly column! The holidays are gone, and tons of news are here for your consumption.

## Releases

*   Jim Northrop [released Caelyf 1.1.2](https://groups.google.com/forum/#!topic/caelyf/RAEXqBpDsSA), the lightweight Groovy web toolkit for Cloud Foundry

## Articles

*   Guillaume Laforge wrote a small tutorial on [how to deploy a Ratpack application to Cloud Foundry](https://github.com/glaforge/ratpack-demo-cloudfoundry/blob/master/README.md), with a dedicated buildpack developed by Ben Hale
*   Cédric Champeau blogs about the upcoming [closure parameter type inference](http://melix.github.io/blog/2014/01/closure_param_inference.html) for Groovy
*   Guillaume Laforge shares the [notes of the last Groovy developer meeting](http://bit.ly/gdc9notes) in London prior to the Groovy Grails eXchance conference, covering various topics about the roadmap of Groovy 2.3 and Groovy 3.0.
*   Peter Niederwieser authored a document explaining [how to contribute to the development of the Spock](https://github.com/spockframework/spock/blob/groovy-1.8/CONTRIBUTING.md) testing framework
*   Ken Kousen uses [Groovy, POGOs, GSON and the Open Weather API](https://weblogs.java.net/blog/manningpubs/archive/2014/01/07/groovy-weather-pogos-gson-and-open-weather-ken-kousen-making-java-groovy-45-savings)
*   Dustin Marx blogs about [identifying Gradle conventions](http://java.dzone.com/articles/identifying-gradle-conventions)
*   Noam Tenne explains how to [register new Spring beans in Grails at runtime](http://blog.10ne.org/2014/01/08/registering-new-spring-beans-in-grails-during-runtime/)
*   New Relic, the app performance management solution, adds [Groovy and Grails support to its Java agent](http://blog.newrelic.com/2014/01/08/new-relic-supports-grails/)
*   There's now a [TestFairy plugin for Gradle](http://blog.testfairy.com/testfairy-gradle-plugin/), to test Android application with the [TestFairy](http://www.testfairy.com/) platform
*   Amit Jain from IntelliGrape, organizers of the GrailsConf India conference, is listing [15 reasons why developers should use the Grails](http://www.indicthreads.com/10774/15-reasons-grails-web-application-framework/) web application framework
*   Amit Jain from IntelliGrape is writing about [Spock's @ConfineMetaClassChanges annotation](http://www.intelligrape.com/blog/2014/01/10/spock-confinemetaclasschanges-annotation-made-writing-grails-unit-test-easier/) to make writing grails unit test easier
*   The [social value of Groovy and Grails in Brazil](http://www.itexto.com.br/devkico/en/?p=47) by Henrique Lobo Weissmann
*   Dustin Marx explains how to [customize the Gradle Java plugin](http://www.javacodegeeks.com/2014/01/simple-gradle-java-plugin-customization.html)
*   Stergios Papadimitriou shows that [Fast Fourier Transforms can be performed in GroovyLab faster than plain C](https://code.google.com/p/jlabgroovy/wiki/JavaFFTvsNative), and as fast as optimized C routines
*   Peter Ledbrook [updated the Grails Searchable plugin installation instructions](http://grails.org/plugin/searchable) to show how to make it work with Grails 2.3
*   Ondrej Kvasnovsky blogs about [Grails integration with Vaadin](https://vaadin.com/blog/-/blogs/grails-integration-with-vaadin)
*   A [basic introduction to Groovy Closures](http://java.dzone.com/articles/closures-groovy) by Alex Staveley

## Presentations

*   [Grails and the realtime web](http://www.infoq.com/presentations/grails-real-time-web), presented by Stéphane Maldini at SpringOne2GX 2013
*   Jeff Brown presented [polyglot web development with Grails 2](http://www.infoq.com/presentations/polyglot-grails), during SpringOne 2GX 2013
*   Steve Pember discusses the [architecture, the frameworks and Responsive Design principles](http://www.infoq.com/presentations/grails-javascript-app) to be employed while building a single-page JavaScript application., and why use Grails for that. Presented at GR8Conf US 2013

## Screencasts

*   Screencast of the awesome [support of Gradle in IntelliJ IDEA 13](https://www.youtube.com/watch?v=3Euo6xzCwY4)
    
## Mailing-list discussions

*   Andrés Almiray follows up on the [status of Griffon 2.0](http://markmail.org/message/n5x6v5rkvsqy25pp?q=griffon+list:org%2Ecodehaus%2Egriffon%2Euser+order:date-backward&page=1)

## Tweets

*   A possible Spock contribution could be the development of a [new website for Spock using the Ratpack](https://twitter.com/ratpackweb/status/420625975672832000) web framework
*   Peter Ledbrook mentions that the [Lazybones templates for Ratpack are now managed in the Ratpack project](https://twitter.com/pledbrook/status/420501665788485632). Also, new versions are available for the Ratpack 0.9.0 release
*   Burt Beckwith [warns Grails users to avoid save(failOnError: true)](https://twitter.com/burtbeckwith/status/420940987754487808) as exceptions are costly, as demonstrated in this article on the [cost of using exceptions](http://shipilev.net/blog/2014/exceptional-performance/)
*   Baruch Sadogursky is a fan of the [Ratpack](http://www.ratpack.io/) framework and found its [website one of the most stylish](https://twitter.com/jbaruch/status/420486836818309120)
    
## Google+ post

*   Mark Perry shows example of ["lenses" and "state monads"](https://plus.google.com/b/101432359761228268146/103753917802203497881/posts/UH2XLq7WtMb?cfem=1) for some more advanced functional programming with Groovy
    
## Code snippet

*   Václav Pech [demonstrates use of GPars lazyTasks](https://github.com/GPars/GPars/blob/master/src/test/groovy/groovyx/gpars/samples/dataflow/DemoLazyTaskDependencies.groovy) to lazily and asynchronously load mutually dependent components into memory
*   Tim Yates [rewrites Carin Meier's](https://gist.github.com/timyates/8318143) (@gigasquid) [fun presentation on Monads](http://www.infoq.com/presentations/Why-is-a-Monad-Like-a-Writing-Desk) in Groovy
*   Mike Mitterer shows how to [show the Git tag version in your Gradle build version](https://plus.google.com/u/0/+MikeMitterer/posts/Wnjzg8cGLV6)
*   Tim Yates is also [playing with functional lenses](https://gist.github.com/timyates/8416286) in Groovy

## Jobs

*   Looking for a [Grails job in Gibraltar](http://findgrailsjobs.com/job/466-grails-developer)?
*   A [Grails engineering job at WIBAX in Milan](http://findgrailsjobs.com/job/467-grails-engineering), Italy
    
## Other news

*   As usual, the the [Grails Diary](http://grydeske.net/news/show/25) is out, week 2 of 2014, by Jacob Aae Mikkelsen

## Books

*   Dave Klein and Ben Klein's book, ["Grails 2: A Quick-Start Guide", is now in print and shipping](http://pragprog.com/book/dkgrails2/grails-2-a-quick-start-guide)
*   Packt Publishing is [looking for reviewers for the Groovy 2 Cookbook book](https://plus.google.com/u/0/111223528095963043865/posts/Vf6D9yexTuC?cfem=1)
    
## Events

*   Luke Daley is returning to his native Australia, but before leaving, he'll be giving one [last talk at the London Groovy Grails User Group on Gradle, Ratpack](http://www.meetup.com/london-ggug/events/155734632/) and more, on January 20th
*   The [Call for Papers](http://cfp.gr8conf.org/login/auth) for the GR8Conf Europe (Copenhagen, Denmark, on June 2nd-4th 2014) and GR8Conf US (Minneapolis, USA, on July 28th-29th 2014) conferences is now open
*   The Call for Papers for the [Greach](http://greach.es/) conference (Madrid, Spain, on March 28th and 29th 2014) is also open, till January 31st
# Groovy Weekly #3


Happy New Year best wishes are still flowing around, and new year resolutions have been sealed, but despite the busy times and good moments spent with our families, the Groovy ecosystem is still abuzz with news! You’d think it’d be a quiet third edition of the Groovy Weekly column, but no, we’ve all been busy with Groovy stuff! So what’s in store?

## Releases

*   [Ratpack 0.9.0](http://www.ratpack.io/versions/0.9.0/) has been released
*   Peter Ledbrook published [version 0.6 of Lazybones](https://bintray.com/pledbrook/lazybones-templates/lazybones/0.6/release) with support for multiple template engines
*   Gernot Starke released [v1.0 of pdfStamper](https://bitbucket.org/arc42/pdfstamper/overview), a small Griffon / Groovy-based utility to add page / chapter / header to pdf files
*   Ken Krebs released his version of [gsheets](https://github.com/kktec/gsheets), a lightweight DSL wrapper over Apache POI, that is intended to make extracting data from, or pushing data to spreadsheets simple and declarative. It can be used with Groovy 1.8, Grails 2 and Java 6+.
*   Yoshiya Hinosawa created a [Gradle plugin](https://github.com/kt3k/coveralls-gradle-plugin) for [CoverAlls.IO](https://coveralls.io/), a service which gathers your code coverage for history and analytics purpose

## Articles

*   Alex Staveley covers [Groovy's "smooth operators"](http://java.dzone.com/articles/groovys-smooth-operators): Elvis, spaceship, safe navigation, spread, field access, method references
*   Mark Perry blogs about [referentially transparent input / output in Groovy](http://mperry.github.io/2014/01/03/referentially-transparent-io.html)
*   Ben Limmer explains how to [automatically publish to Sonatype with Gradle and Travis CI](http://benlimmer.com/2014/01/04/automatically-publish-to-sonatype-with-gradle-and-travis-ci/)
*   Michael Scharhag covers [how to use Hibernate filters in Grails](http://www.mscharhag.com/2014/01/grails-hibernate-filters.html)
*   Cyril Mottier shows the [Android Gradle build in action](https://plus.google.com/118417777153109946393/posts/WRgB2shaeuu)

## Presentations

*   In this SpringOne2GX presentation, Hans Dockter [discusses build systems](http://www.infoq.com/presentations/compare-build-tools) from a declarative vs. imperative perspective, the importance of a rich execution model and problems with POM, providing examples from Gradle, Maven and Ant
*   Ken Sipe spoke about Spock during the JavaZone conference and covers [mocking, stubbing and spying with Spock](http://vimeo.com/74553183)
*   At GR8Conf US 2013, Marco Vermeulen explains using [Cucumber and Groovy to apply BDD to a project](http://www.infoq.com/presentations/bdd-cucumber-groovy), using Gherkin for writing scenarios, Groovy for step definitions, Spock for new features, and running Cucumber features
*   At SpringOne2GX 2013, in his [Application Architecture in Groovy](http://www.infoq.com/presentations/groovy-app-architecture) talk, Dan Woods presented the strengths and flexibility in Groovy, including its dynamic nature, categories and mixins, to create a powerful, maintainable, and simple application architecture
*   At GR8Conf US 2013, Zan Thrash advises on [using some of the Node.js tools in order to improve Grails development](http://www.infoq.com/presentations/grails-nodejs): lint, concat, minify, testing JavaScript files, etc.

## Mailing-list discussions

*   Andrés Almiray gives a [status on the future Griffon 2.0](http://markmail.org/message/h6g4sarojl7b7mi6?q=griffon+user+list:org.codehaus.griffon.user+order:date-backward&page=1) and asks for feedback

## Tweets

*   [Lazybones 0.6 is available through GVM](https://twitter.com/gvmtool/status/419840537924210688)
*   Peter Ledbrook is adding [Handlebars templating support to Lazybones](https://twitter.com/pledbrook/status/417986426882777088)
*   Peter Ledbrook has [pushed the Groovy Handlebars template engine into Bintray JCenter](https://twitter.com/pledbrook/status/419021400327077888)
*   Anton Arhipov tweeted about the [latest update of the GMaven Groovy Maven plugin](https://twitter.com/antonarhipov/status/419614242333917184)
*   [Work has started](https://twitter.com/ratpackweb/status/419045750396694528) on getting Ratpack in the [TechEmpower framework benchmark](http://www.techempower.com/benchmarks/)
*   [Testing Ratpack modules](https://twitter.com/ratpackweb/status/417318063957377024) and subsystem in isolations
*   [reStructuredText support via JRst and PegDown markdown parser](https://twitter.com/grainframework/status/418021109066248192) are integrated into 0.6.0-SNAPSHOT of the [Grain](http://sysgears.com/grain/) static website generator
    
## Code snippet

*   Kenneth Endfinger wished us all a [Happy New Year with some Groovy asciiart](https://plus.google.com/u/0/+KennethEndfinger/posts/g4nPwfoBGeu) ([snippet](https://gist.github.com/kaendfinger/8220577))!

## Jobs

*   Antony Jones is looking for [Grails contractors in London](https://twitter.com/antony/status/419055221365415936)
    
## Other news

*   First [Grails diary](http://grydeske.net/news/show/24) of the year by Jacob Aae Mikkelsen
*   The [Ratpack reference documentation](http://www.ratpack.io/manual/current/api/) has just had a facelift

## Events

*   [GrailsConf India](http://grailsconf.in/), organized by [IntelliGrape Software](http://www.intelligrape.com/), is taking place in New Delhi, India, on January 11th
*   The [Call for Papers](http://cfp.gr8conf.org/login/auth) for the GR8Conf Europe (Copenhagen, Denmark, on June 2nd-4th 2014) and GR8Conf US (Minneapolis, USA, on July 28th-29th 2014) conferences is now open
*   The Call for Papers for the [Greach](http://greach.es/) conference (Madrid, Spain, on March 28th and 29th 2014) is also open, till January 31st
*   Russel Winder is going to present a [workshop on Spock](http://nordevcon.com/#russel_winder) at the Nordev conference
*   Guillaume Laforge is speaking at JFokus 2014 about how to [benefit form using Groovy, when, why and how](http://www.jfokus.se/jfokus/talks.jsp#BenefitfromGroovynow)
*   Cédric Champeau is speaking (in French, at the Riviera Groovy/Grails user group) about [how to contribute to Groovy](http://www.meetup.com/Riviera-Groovy-Grails-User-Group/events/154634302/)
    
Don't forget you can [contribute](http://bit.ly/groovyweekly) to this weekly column of Groovy news, and that you can [subscribe through a newsletter](http://bit.ly/groovy-weekly-subscribe).
# Groovy Weekly #2


For the second Groovy Weekly column, on the eve of a new year, I’d like to wish you a very Groovy year, and share with you the following links, hoping you’ll have some spare time to look into them while you’re celebrating.

## Releases

*   A new project appeared on the Groovy ecosystem radar: Grain, [announced](http://groovy.329449.n5.nabble.com/ANN-Grain-0-5-0-released-td5717888.html) by Victor Vlasenko on the Groovy mailing-list. [Grain](http://sysgears.com/grain/) is a promising lightweight and yet powerful static website generator for Groovy which purpose is to make demanding site implementation an intuitive and enjoyable. Grain framework is equally well-suited for any static website, whether it is a complex and sophisticated company site or a simple and neat blog. The framework applies elegant website building concepts and allows to develop rapidly by making and seeing changes on the fly.
*   Kunal Dabir created a [Lazybone template for creating Groovy libraries](https://github.com/kdabir/lazybone-templates/blob/master/templates/groovy-lib/README.md) readily publishable to Bintray, CI with Travis-CI, with a Gradle build and wrapper, a .gitignore file and more.
*   Last week we mentioned the release of CodeNarc 0.20, and the associated [CodeNarc Eclipse plugin](http://groovy.329449.n5.nabble.com/ANN-Announcing-Eclipse-CodeNarc-Plugin-0-20-0-td5717876.html) has also been released
*   Andrés Almiray released [Gipsy](https://github.com/aalmiray/gipsy), an AST transformation to simplify the use of the Service Provider Interface, similar to the [Jipsy](https://github.com/aalmiray/jipsy) annotation processing toolkit he also created:
*   Stergios Papadimitriou shares with us his project, [GroovyLab](https://code.google.com/p/jlabgroovy/), a MATLAB-like environment for the Java Virtual Machine. GroovyLab is an open source project based on the Groovy language. GroovyLab is efficient and can be an interesting open-source alternative to commercial packages, especially for the scientific community familiar with Java. The article introduces the architecture of GroovyLab and presents some examples of using GroovyLab to do useful work.
    
## Articles

*   A very extensive [Groovy / Grails eXchange wrapdown post](http://danveloper.github.io/ggx-wrapdown.html) by Dan Woods covering all the talks he attended in detail
*   Dustin Marx covers some [Gradle command-line conveniences](http://java.dzone.com/articles/gradle-command-line)
*   Dustin Marx [reviews the book by Tim Berglund: "Gradle, beyond the basics"](http://java.dzone.com/articles/book-review-gradle-beyond)

## Presentations from SpringOne2GX

*   In this presentation on InfoQ, recorded at SpringOne2GX, Burt Beckwith discusses performing [transactions in Grails](http://www.infoq.com/presentations/grails-transaction-2gx), covering services, customizing transaction attributes (isolation, propagation levels), two-phase commit, using JMS, and testing the code
*   Again recorded at SpringOne2GX, Paul King speaks about [leveraging Groovy for capturing business rules](http://www.infoq.com/presentations/groovy-dsl-business-rule), illustrated with various DSLs written in Groovy, highlighting several logic solving APIs and looks at the pros and cons of the various approaches (including tool support, flexibility, lock-in)

## Interviews

*   Stephen Chin [interviews Luke Daley](http://nighthacking.com/interview-with-luke-daley-on-geb-and-ratpack/) during the Devoxx conference, about Ratpack, Gradle, Geb

## Mailing-list discussions

*   Thibault Kruse discusses [possible improvements to the groovysh](http://groovy.329449.n5.nabble.com/groovysh-improvements-td5717851.html) command-line shell in this mailing-list discussion. Don't hesitate to provide your input!
    
## Tweets

*   Luke Daley mentions his testing of the [Waffle.IO service](https://waffle.io/) (a nice kanban board representation of Github issues) to organize and keep track of the [backlog, ongoing development of Ratpack](https://waffle.io/ratpack/ratpack)
*   Dan Woods [joins the Ratpack project as a new committer](https://twitter.com/ratpackweb/status/416501698119892992)
*   Ratpack now supports [“fat jar” deployment](https://twitter.com/ratpackweb/status/416854893677514752)
*   Bert van den Brande used the [Gradle Shadow plugin](https://github.com/johnrengelman/shadow) to create an executable JAR in no time
*   Václav Pech, GPars project lead, is [sprinkling a few Groovy's few @DelegatesTo annotations over the GPars codebase operators](https://twitter.com/vaclav_pech/status/417944625643782144) to make them more @CompileStatic-friendly
    
## Job

*   Dan Woods relays the job post from @good\_technology that is [looking for a Grails developer in San Francisco](http://www.startuply.com/Jobs/Software_Architect_SaaS_Platform_6473_3.aspx), with mobile skills as well

## Other news

*   The last [Grails diary](http://grydeske.net/news/show/23) of the year from by Jacob Aae Mikkelsen, if you want to be up-to-date on all Grails plugins news
*   Bobby Warner contributes [support for the PATCH method to the Ratpack](https://github.com/ratpack/ratpack/pull/222) project

## Events

*   [GrailsConf India](http://grailsconf.in/), organized by [IntelliGrape Software](http://www.intelligrape.com/), is taking place in New Delhi, India, on January 11th
*   The [Call for Papers](http://cfp.gr8conf.org/login/auth) for the GR8Conf Europe (Copenhagen, Denmark, on June 2nd-4th 2014) and GR8Conf US (Minneapolis, USA, on July 28th-29th 2014) conferences is now open
*   The Call for Papers for the [Greach](http://greach.es/) conference (Madrid, Spain, on March 28th and 29th 2014) is also open, till January 31st

## Happy New Year!

Almost the end of the year! On behalf of the Groovy development team, let me wish you the best and grooviest year for 2014!
# Groovy Weekly #1


Welcome to the Groovy Weekly news brief!

As the name implies, I’m going to try to make regular (in theory on a weekly basis) column of all the interesting news, presentations, code snippets, events, conferences related to the Groovy ecosystem.

And as a Christmas present, here’s the first issue!

Your feedback is important, and we’d be happy to hear about your thoughts on a regular column about Groovy related news: what are your expectations, what you’d like to hear about, what news bits are of higher interest to you, how you would like this information to be delivered, etc.

As a first step, we’ll cover links to articles, blog posts, tweets, presentations, releases, events, books, code snippets. But you can contribute too! I’ve setup a Google Form where you can fill in a few fields with a link, a description, the kind of information you’re sharing, etc. So feel free to submit interesting information through this form here:

[http://bit.ly/groovyweekly](http://bit.ly/groovyweekly)

The first Groovy Weekly edition will be posted on my personal blog, and the link will be spread on various channels (mailing-list, twitter, Google+, etc) but I’m wondering how to best deliver this information. I’m thinking particularly of setting up a newsletter format, for instance with a service like Mailchimp, so that people could opt in and subscribe to receive this weekly column directly in their inbox.

In the meantime, and on behalf of the Groovy development team, we wish you the best for the holidays! A Groovy Christmas and a Groovy New Year!

## Releases

*   a bug fix release with [Grails 2.3.4](http://grails.org/2.3.4%20Release%20Notes)
*   [Gradle 1.10](http://forums.gradle.org/gradle/topics/gradle_1_10_released) was released with improved progress reporting, executing specific tests from the command-line, shouldRunAfter task ordering, further C and C++ support
*   a new version of the [CodeNarc 0.20](http://groovy.329449.n5.nabble.com/ANN-Announcing-CodeNarc-0-20-td5717822.html) static analysis tool for Groovy with new rules, as well as updated and enhanced rules

## Articles

*   The [Groovy roadmap](http://groovy.codehaus.org/Roadmap) page has recently been udpated, giving a better view of the coming releases of Groovy 2.3 and 3.0, and their respective content
*   Burt Beckwith explains how to automatically [convert password hashes in Grails spring-security-core](http://burtbeckwith.com/blog/?p=2017)
*   Roy Clarkson shows how you can easily [serve static web content with Spring Boot](https://spring.io/blog/2013/12/19/serving-static-web-content-with-spring-boot), thanks to a little Groovy Spring controller
*   Dusting Marx covers how to [search Subversion logs with Groovy](http://java.dzone.com/articles/searching-subversion-logs)
*   MrHaki demonstrates [how to use the @PackageScope transformation with methods, fields and classes](http://mrhaki.blogspot.dk/2013/12/groovy-goodness-using-package-scoped.html)
*   Dustin Marx writes about the [sublime simplicity of scripting with Groovy](http://www.javacodegeeks.com/2013/12/sublime-simplicity-of-scripting-with-groovy.html)
*   Simon Temple talks about [sandboxing Groovy code](http://simontemple.blogspot.co.uk/2013/12/groovy-in-cloud-sandboxing-and-more.html) through an AST transformation that examines all method invocations to check if they are allowed or not
*   Lieven Doclo demonstrates [rapid REST prototyping with Groovy](http://groovy.dzone.com/articles/rest-prototyping-spark-and) and the [Spark](http://www.sparkjava.com/) micro web framework for the Java platform
*   Interview about how "[VMware surmounts learning curve by developing Project NEE platform](http://searchvmware.techtarget.com/feature/VMware-surmounts-learning-curve-by-developing-Project-NEE-platform)" with Groovy and Grails

A particular highlight for Jacob Aae Mikkelsen who continues Burt Beckwith original “this week in Grails” column, in the form of the [Grails diary](http://grydeske.net/news/show/22). This “Groovy Weekly” column obviously overlaps a bit with the Grails diary, but the Grails diary has a particular focus on Grails which you might be interested in, especially with regards to the latest news regarding the Grails plugins ecosystem. Be sure to check it out if you’re developing with Grails.

Last but not least, Trisha Gee published three interesting articles on the Spock testing framework:

*   [mocking with Spock](http://mechanitis.blogspot.co.uk/2013/07/spock-is-awesome-seriously-simplified.html)
*   [stubbing with Spock](http://mechanitis.blogspot.co.uk/2013/07/spock-passes-next-test-painless-stubbing.html)
*   [data-driven testing with Spock](http://mechanitis.blogspot.com.es/2013/12/spock-data-driven-testing.html)

## Groovy / Grails eXchange 2013 special

On the 12th and 13th of December, took place the [Groovy / Grails eXchance conference](http://skillsmatter.com/event-details/home/groovy-grails-exchange-2013), in London, UK, organized by the fine folks of [SkillsMatter](http://skillsmatter.com/), gathering the Groovy ecosystem crowd, to speak about Groovy, Grails, Gradle, Ratpack, and more.

What’s special about this conference is that it’s been SkillsMatter which organized the first ever conference on the Groovy ecosystem back in 2007! Also, what’s double nice is that they record everything and that the presentations are available in matter of hours at no cost. So let me guide you through all the presentations that took place at the conference:
  
### First day

*   [The Groovy update](http://skillsmatter.com/podcast/home/keynote-guillaume-laforge) by Guillaume Laforge
*   [Making Java APIs Groovy](http://skillsmatter.com/podcast/home/making-java-apis-groovy) by Cédric Champeau
*   [DevQA, make your testers happier with Groovy, Spock, and Geb](http://skillsmatter.com/podcast/home/devqa-make-your-testers-happy-with-groovy-spock-and-geb) by Alvaro Sanchez Mariscal
*   [Modern Groovy enterprise stack](http://skillsmatter.com/podcast/home/modern-groovy-enterprise-stack) by Marcin Edmann
*   [Creating architectural flexibility with Groovy](http://skillsmatter.com/podcast/home/creating-architectural-flexibility-using-groovy) by David Dawson
*   [Ratpack, a toolkit for JVM web applications](http://skillsmatter.com/podcast/home/ratpack-a-toolkit-for-jvm-web-applications) by Luke Daley
*   [NoSQL with Grails](http://skillsmatter.com/podcast/home/nosql-with-grails) by Joseph Nusairat
*   [Developing single-page applications with Grails and AngularJS](http://skillsmatter.com/podcast/home/developing-spi-applications-using-grails-and-angularjs) by Alvaro Sanchez Mariscal
*   [Polyglot programming in Grails](http://skillsmatter.com/podcast/home/polyglot-programming-in-grails-2) by Jeff Brown
*   [Is Groovy static or dynamic](http://skillsmatter.com/podcast/home/is-groovy-static-or-dynamic) by Russel Winder
*   [Message driven architecture in Grails](http://skillsmatter.com/podcast/home/message-driven-architecture-in-grails) by Dan Woods
    
## Second day

*   [The road to Grails 3.0](http://skillsmatter.com/podcast/home/road-to-grails-3-0) by Graeme Rocher
*   [Build Grails applications with Gradle](http://skillsmatter.com/podcast/home/build-grails-applications-with-gradle) by Luke Daley
*   [Metaprogramming with the Groovy runtime](http://skillsmatter.com/podcast/home/metaprogramming-with-groovy-compiler) by Jeff Brown
*   [Restful async with Grails 2.3](http://skillsmatter.com/podcast/home/restfully-async-with-grails-2-3) by Graeme Rocher
*   [Open Source and you](http://skillsmatter.com/podcast/home/open-source-and-you) by Peter Ledbrook
*   [Reactor, a foundation for asynchronous applications on the JVM](http://skillsmatter.com/podcast/home/reactor) by Stéphane Maldini
*   [Groovy for system administrators](http://skillsmatter.com/podcast/home/groovy-for-system-administrators) by Dan Woods
*   [Building lightning fast REST services with Dropwizard and Groovy](http://skillsmatter.com/podcast/home/building-lightning-fast-rest-services-with-dropwizard-and-groovy) by Tomas Lin
*   [How Gradle saved the day at a major company](http://skillsmatter.com/podcast/home/how-gradle-saved-the-day-at-a-major-company) by Joseph Nusairat
*   [Application architecture in Groovy](http://skillsmatter.com/podcast/home/application-architecture-in-groovy-4945) by Dan Woods
*   [Groovy micro services with Spring Boot](http://skillsmatter.com/podcast/home/groovy-micro-services-with-spring-boot) by David Dawson

## Other presentations

Other presentations are also available from other conferences, in particular, InfoQ has been publishing SpringOne2GX 2013 and GR8Conf US talks on a regular basis. Here’s a recent selection of talks they released:

### SpringOne2GX

*   Core Groovy committers Paul King & Guillaume Laforge gave a presentation on [creating Domain-Specific Languages in Groovy that developers can actually use](http://www.infoq.com/presentations/groovy-dsl-mars)
*   Burt Beckwith discusses the security risks web applications may face (XSS, CRSF, SQL injection) and the libraries and plugins that developers can use to [secure their Grails applications](http://www.infoq.com/presentations/security-grails-apps)
*   Baruch Sadogursky [overviews and compares search and testing tools available to Grails developers](http://www.infoq.com/presentations/grails-search-test-tools)

### GR8Conf US

*   [Advanced Groovy tips & tricks](http://www.infoq.com/presentations/groovy-tips) by Ken Kousen, author of [Making Java Groovy](http://www.manning.com/kousen/)
*   [Programming in the Cloud - Groovy as an Extension Language for Oracle ADFm](http://www.infoq.com/presentations/groovy-adfm) by Jim Driscoll
*   Luke Daley presents the [Ratpack micro web framework](http://www.infoq.com/presentations/ratpack)
*   Peter Ledbrook speaks about [application architectures with Grails](http://www.infoq.com/presentations/grails-app-architecture)
    
### Øredev

Andrés Almiray shows the [functional aspects of the Groovy](http://vimeo.com/79868215) programming language in this presentation from Øredev.

On that functional theme, you can also have a look at:

*   Paul King’s [Functional Groovy](http://fr.slideshare.net/paulk_asert/functional-groovy) at SpringOne2GX
*   Guillaume Laforge’s [Functional Groovy](https://speakerdeck.com/glaforge/functional-groovy) at Scala.IO (slides available, but video not yet published)

### JAX London

Guillaume Laforge talks about [what makes Groovy groovy](http://jaxenter.com/guillaume-laforge-what-makes-groovy-groovy-49157.html). He also gave an updated presentation at Devoxx which is [published on Parleys](http://www.parleys.com/play/52a10c8be4b039ad2298ca76/chapter1/about), but it’s viewable for a fee (unless you attended the Devoxx conference) until it’s released publicly, but the [slides](https://speakerdeck.com/glaforge/what-makes-groovy-groovy-devoxx-2013) are available on speakerdec.

## Code snippets

*   [Reactive Rock Paper Scisors](https://gist.github.com/timyates/7823738) by Tim Yates, using Groovy and RxJava
*   Marcin Erdmann [developed](https://github.com/geb/geb/tree/master/doc/site) the new version of the [Geb website](http://www.gebish.org/) with Ratpack, deployed on Heroku
*   Luke Daley published a snippet of a [self contained Groovy script to bootstrap a Ratpack server](https://gist.github.com/alkemist/7943781)
    

## Tweets

*   Guillaume Laforge tweeted about Graeme Rocher’s [4 R's of Grails controllers: return, render, redirect and now respond for Rest](https://twitter.com/glaforge/status/411426080407711744)

## Mailing-list discussions

Cédric Champeau shows the current work in progress around [providing further type inference for methods taking closure arguments](http://groovy.329449.n5.nabble.com/Closure-parameter-type-inference-td5717804.html), as closures don't really offer a signature (a return type thanks to generics, yes, but no way to specify the type of the arguments).

Example of methods that we'll be able to type checked:
  
```groovy
@TypeChecked
void foo(List list) {
    println list.collect { it.toUpperCase() }
}
```

Before, the type checker would complain that it didn’t know the type of the implicit ‘it’, but by decorating the collect() method implementation with new dedicated annotations, it’s possible to instruct the type checker about the type of the closure parameters.

## Books

The [Groovy Goodness notebook](https://leanpub.com/groovy-goodness-notebook/) from MrHaki has been [udpated with the Groovy 2.2 features](http://mrhaki.blogspot.fr/2013/12/groovy-goodness-notebook-updated-with.html).

## Events

*   The [Call for Papers](http://cfp.gr8conf.org/login/auth) for the GR8Conf Europe (Copenhagen, Denmark, on June 2nd-4th 2014) and GR8Conf US (Minneapolis, USA, on July 28th-29th 2014) conferences is now open
*   The Call for Papers for the [Greach](http://greach.es/) conference (Madrid, Spain, on March 28th and 29th 2014) is also open, till January 31st
    
## Closing thoughts

Again, best wishes from the Groovy team for the holidays, and we’re looking forward to your feedback on this “Groovy Weekly” column, and to your contribution through the form: [http://bit.ly/groovyweekly](http://bit.ly/groovyweekly)
# Groovy 2.2 released


This is with great pleasure that the Groovy team is announcing today the **release of Groovy 2.2**, the latest version of the Groovy programming language.

Groovy 2.2 features:

*   Implicit closure coercion
*   `@Memoized` AST transformation for methods
*   Define base script classes with an annotation
*   New `DelegatingScript` base class for scripts
*   New `@Log` variant for the Log4j2 logging framework
*   `@DelegatesTo` with generics type tokens
*   Precompiled type checking extensions
*   Groovysh enhancements
*   Bintray's JCenter repository
*   OSGi manifests for the “invoke dynamic” JARs
*   And other minor bug fixes, enhancements and performance improvements

You can read more [detailed release notes](http://bit.ly/g22notes)﻿ as well as have a look at all the [JIRA issues fixed](http://bit.ly/g22jira)﻿.

Then [download Groovy 2.2](http://bit.ly/g22dl)﻿ while it's hot!

Thanks a lot to all the users, contributors, developers who contributed to that release!
# Interview on JAXenter about Groovy


Following up my [presentations from JAX London]({{< ref "/talks/2013/11/04/groovy-presentations-at-conferences" >}}), I was interviewed about Groovy for JAXenter, with questions about what Groovy brings to Java developers, the recent surge in popularity as [Groovy broke the TIOBE index top 20 languages]({{< ref "/posts/2013/10/11/groovy-enters-top-20-of-the-tiobe-language-index" >}}), my favorite projects in the Groovy ecosystem.  

[![](/img/misc/jaxenter-interview.png)](http://jaxenter.com/a-one-to-one-with-the-groovy-project-manager-48667.html)
# Groovy presentations at conferences


Last week, I was in London for the [JAX London 2013](http://jaxlondon.com/) conference. I gave a presentation on what makes the Groovy programming language... groovy! It's essentially an introduction to Groovy, its language constructs, its ecosystem, etc. It's not focusing particularly on new features or on metaprogramming, but tries to bring the audience to the boilerplate killer that is Groovy. I've posted the slides on SpeakerDeck and I embed them below:  
  
I also had the chance to do a special speech at the London Java Community night during the conference about some (obvious) advice I could give developers, that I learnt through my working in Open Source, on the Groovy project, etc, illustrated with some quotes that I like. Again, slides embedded below:  
  
And last but not least, I also wanted to mention that my [presentation on the Groovy 2.x line](https://speakerdeck.com/glaforge/lift-off-with-groovy-2) from SpringOne2GX had just been posted to InfoQ.  

[![](https://glaforge.appspot.com/media/infoq-liftoff-groovy-talk.png)](http://www.infoq.com/presentations/groovy-2-1-2gx)

{{< speakerdeck b499eea0213b013151e34a4948aa6526 >}}

# Functional Groovy presentation


I've had the pleasure of being invited at the [Scala.IO](http://scala.io/) conference to speak about the functional aspects of Groovy, as the conference was also open to other functional language.  

The Groovy programming language, since its inception, has always been pretty functional, in particular with the cornerstone that our Closures represent to serve as first-class citizen functions in the language.  

Inspired by other nice talks from Andrés, Paul, Arturo, I've created my own deck that I've posted on SpeakerDeck and that I embed below. Please be sure to have a look at the "resources" section of that deck, for further pointers on functional programming with Groovy.  

The talk has been recorded and should be published on InfoQ sometime soon.

{{< speakerdeck b499eea0213b013151e34a4948aa6526 >}}

# Interview about Groovy's popularity boost


I was interviewed by Darryl Taft from eWeek yesterday about the Groovy programming language's recent popularity boost. You can read the two-page long interview here:  
[Groovy programming language sees major boost in popularity](http://www.eweek.com/developer/groovy-programming-language-sees-major-boost-in-popularity.html)  

You'll certainly be interested in the answers to some of the questions, in particular who's using Groovy, or for which use cases Groovy is being used:  

> **--- Why do you think Groovy has gained in popularity over the last year?**   
>
> Groovy's widely used in the industry as the 1.7 million downloads a year can attest, but there's been an interesting surge in popularity recently. In particular, as you could see at SpringOne2GX in September, Groovy was nicely featured in the Pivotal's[Spring IO](http://spring.io/) platform for example in the upcoming Spring Framework 4.0 version, in [Spring Boot](https://spring.io/blog/2013/08/06/spring-boot-simplifying-spring-for-everyone), or [Reactor](https://spring.io/blog/2013/05/13/reactor-a-foundation-for-asynchronous-applications-on-the-jvm) and other projects. There's a lot of buzz around the Groovy ecosystem: with the [Grails](http://grails.org/) web framework ongoing growth, or the [Gradle](http://www.gradle.org/) build automation system that is being used by [Google for the building Android application](http://tools.android.com/tech-docs/new-build-system).  
>   
> **--- What makes Groovy an attractive language to use?**   
>
> Groovy's main goals has always been to simplify the life of developers, and particularly Java developers.  
>   
> Its syntax is based off of the Java language itself, so it's very straightforward and intuitive to learn, but at the same time offers various shortcuts and APIs to make developers much more productive, help them write more concise and more readable code, easier to maintain and evolve in the long run.  
>   
> It's also the alternative language on the Java Virtual Machine that offers the best and most seamless integration and interoperability with the Java platform, as developers don't need to convert from one system to the other as Groovy classes are plain Java classes and vice versa.  
>   
> Groovy's overall well suited for many situations, for writing small scripts to building more complex applications, for designing Domain-Specific Languages (DSLs) for business rules, etc.  
>   
> **--- What types of applications is Groovy most suited for?**   
>
> There are different use cases for applying Groovy in your projects.  
> Often Groovy is introduced in companies and projects thanks to the nice testing tools it offers and how readable tests can become thanks to them — for example, with the [Spock testing framework](http://docs.spockframework.org/en/latest/). Other shops adopt [Gradle](http://www.gradle.org/) for building complex applications where other tools like Ant or Maven show their weaknesses.  
>   
> Groovy is also often used for "scripting" or customizing applications through extension points featuring Groovy scripts.  
>   
> The Internet of Things world is using Groovy for scripting home automation, for interacting with the various nodes of the mesh network ([SmartThings](http://www.smartthings.com/) and [Carriots](https://www.carriots.com/) are integrating Groovy for that purpose).  
> You can also customize the Jenkins continuous integration platform with Groovy, or interact with the ElasticSearch search engine with a Groovy API, etc.  
>   
> Another interesting use case is for business rules.  
> I already briefly mentioned business rules and DSLs, but it's one of the key use cases for Groovy.  
>   
> I've seen several financial institutions, insurance companies, travel or energy companies use Groovy for describing their business rules — actuaries defining rules for loan grants, scientists creating scientific simulations (nuclear risks, disease evolutions, etc.), travel agents customizing booking processes, and more.  
>   
> The easy Groovy syntax plus its ability to write almost plain English sentences which are valid Groovy statements makes it simple to write readable business rules.  
>   
> Of course, also, beside just "integrating" Groovy in existing apps to extend their capabilities or writing business rules, you can also build full blown applications totally in Groovy, like when you build a big web application with the Grails web stack.  
>   
> **--- Are there any big Groovy applications out there, or any major companies using it?**   
>
> I was recently asked a similar question on Quora, where you can read my more [detailed answer](http://www.quora.com/Whos-using-Groovy-in-production).  
>   
> Above, I've listed a few of the key use cases where Groovy is often used, and in that question on Quora I'm giving a few examples of those scenarios.  
>   
> To name a few companies using Groovy:  
>   
> * **Netflix** is using Groovy in their [Asgard](http://netflix.github.io/asgard/) cloud automation platform (a case study will soon be published on Pivotal's blog by the way), as well as for other handy libraries like [Glisten](http://techblog.netflix.com/2013/09/glisten-groovy-way-to-use-amazons.html) to interact with Amazon's Simple Workflow Service.  
>   
> * **Google** have moved the **Android** application build over to Gradle which uses Groovy as the build language, so all Android developers will soon be using Groovy for building their Android applications  
>   
> * **LinkedIn** developed [Glu](http://pongasoft.github.io/glu/docs/latest/html/index.html) (their open source deployment and monitoring platform) in Groovy, but they are also using Grails web applications for recruiters using the LinkedIn platform and profile database  
>   
> * Various financial institutions like **JPMorgan**, **MasterCard**, **Crédit Suisse**, **Fanny Mae**, **Mutual of Omaha**   
> * The **European Patent Office** is using Groovy for collecting patents from all over the world, extract / transform all those patent formats in some kind of pivot formats, all that with Groovy  
> And many more... but the above are some of the more famous names that I know about.  
>   
> **--- What are you doing with Groovy these days?**   
>
> These days, we are ironing out the latest details of the Groovy 2.2 final release.  
>   
> We are also working on future versions of Groovy at the same time, and investigating and experimenting other areas where Groovy could offer some nice productivity boosts for developers (think simplifying Android development, big data manipulation and analyses, etc.)
# Release candidate for Groovy 2.2


Yesterday, the Groovy programming language team released the release candidate for Groovy 2.2, as well as a bug-fix release of Groovy 2.1.8.  

Here's the announcement I sent on the various communication channels:  

> The Groovy team is happy to announce the release of the release candidate of Groovy 2.2, as well as a bug-fix release for Groovy 2.1.8.   
>
> As you can guess with this release candidate, the final version of Groovy 2.2 is fast approaching, and we'd be happy to get as much feedback on this release as possible, to squash potential bugs before the general availability of 2.2. So please be sure to test your applications with this release candidate.   
> 
> For both releases, we've made a small update to the default Grab configuration which is to use Bintray's JCenter repository as the first in the chain of resolvers, as Bintray's JCenter repository is noticeably faster and more responsive than Maven Central, offers dependencies always with their checksums, and stores and caches dependencies it wouldn't have for faster delivery the next time a dependency is required. This should make your scripts relying on @Grab faster when downloading dependencies for the first time.   
> 
> An interesting feature in the release candidate only is the ability for scripts to define their base script class. All scripts usually extend the groovy.lang.Script abstract class, but it's possible to set up our own base script class extending Script through CompilerConfiguration. A new AST transformation is introduced in Groovy 2.2 which allows you to define the base script class as follows:   

```groovy
import groovy.transform.BaseScript  

abstract class DeclaredBaseScript extends Script { 
    int meaningOfLife = 42 

}  
@BaseScript DeclaredBaseScript baseScript  

assert meaningOfLife == 42
```

Again for 2.2, a new @Log variant has been added to support Log4j2, with the @Log4j2 AST transformation:  

```groovy
import groovy.util.logging.Log4j2  

@Log4j2 class MyClass { 
    void doSomething() { 
        log.info "did something groovy today!"
    } 
}
```

For more details on those two releases, please have a look at the release notes on JIRA:

*   [Groovy 2.1.8 JIRA release notes](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=19570)
*   [Groovy 2.2.0-rc-1 JIRA release notes](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=19569)

Go download Groovy 2.1.8 and test drive 2.2.0-rc-1 while they're hot, in the [download area](http://groovy.codehaus.org/Download?nc)!   

Thanks a lot for your contributions to those releases, in terms of bug reports, discussions on the mailing-lists, code contributions and pull requests!
# Groovy enters top 20 of the TIOBE language index


For the first time, [Groovy enters the top 20 of the TIOBE programming language index](http://www.tiobe.com/index.php/content/paperinfo/tpci/index.html), as you can see in the table below: 

![](/img/misc/TIOBE+2.png)  

As the headline and first paragraph indicate:

> TIOBE Programming Community Index for October 2013   
> October Headline: Lightweight Java language Groovy enters top 20  
> Programming language  
>   
> Groovy enters the top 20 for the first time. Groovy is an object-oriented scripting language that runs on the Java Virtual Machine. It is fully compatible with Java, making it easy to combine Java programs with Groovy. There is quite some competition in this field of lightweight languages that fit together with Java. Groovy beats other well-known JVM languages such as Scala (#36), JavaFX Script (#41) and Clojure (#76). Let's see whether it can keep its top 20 position the next few months.

  
There was a lot of buzz last month around Groovy being an important theme of the Pivotal [Spring.IO](https://spring.io/) stack, while we were at the [SpringOne2GX conference](http://springone2gx.com), that this buzz certainly helped increase Groovy's position in this index.  

A few words of caution, however, as I don't think we can really read too much into those numbers, as the ranking algorithm is essentially just ranking the buzz or hype around a given language at a given point in time.  

From a given month to another, Groovy moved between 20th something to 50th, then back in the 30th... So it's not really reliable or meaningful. It's not really able to compare real actual usage of a programming language, otherwise it wouldn't move so much from month to month. We'll see if we hold that position next month!  

But with 1.7 million downloads of Groovy last year, Groovy is no small player in the field!
# Second beta for Groovy 2.2


The Groovy team is happy to announce the **releases of the second beta of Groovy 2.2**, along with a **bug fix release of Groovy 2.1.7**.

We're close to moving towards RC mode for the upcoming Groovy 2.2 release, and we'd be happy to **hear about your feedback about this new version** when used in your projects. Please have a moment to test it against your code, and tell us if you notice any problem or regression.

Groovy 2.2.0-beta-2 is pretty much feature complete by now, with only a few minor improvements, and both 2.2.0-beta-2 and 2.1.7 contain a great deal of bug fixes around our static type checker and compilation support.

You can have a look at the JIRA release notes for the details:

*   [Groovy 2.1.7](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=19430)
*   [Groovy 2.2.0-beta-2](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=19431)

Those two Groovy versions are available in the [download area](http://groovy.codehaus.org/Download) of the website.

Thanks a lot to all those who contributed to this release, and we're looking forward to hearing your feedback about the upcoming 2.2!

We'd also be happy to see you at next week's [SpringOne2GX conference](http://www.springone2gx.com/conference/santa_clara/2013/09/register) if you're around! So don't hesitate to come and say hi to the Groovy team members who will be present — and there are quite a few of us there!
# GPars 1.1 is out


[Václav Pech](http://www.jroller.com/vaclav/) just announced the release of GPars 1.1, the multi-paradigm concurrency and parallel Groovy-friendly toolkit:  

> The GA release of GPars 1.1.0 has just been published and is ready for you to grab. It brings gradual improvements into dataflow as well as a few other domains. Some highlights:  
>   
> *   `LazyDataflowVariable` added to allow for lazy asynchronous values
> *   Timeout for Selects
> *   Added a Promise-based API for value selection through the Select class
> *   Enabled listening for bind errors on DataflowVariables
> *   Minor API improvement affecting Promise and DataflowReadChannel
> *   Protecting agent's blocking methods from being called from within commands
> *   Updated to the latest 0.7.0 GA version of Multiverse
> *   Migrated to Groovy 2.0
> *   Used `@CompileStatic` where appropriate
> *   A few bug fixes
> 
> You can [download](http://gpars.codehaus.org/Download) GPars 1.1.0 directly or [grab it from the maven repo](http://gpars.codehaus.org/Integration).  
>   
> Have a lot of fun trying out GPars 1.1.0!
# Glace à la menthe maison


![](/img/misc/d7a50452ecab11e2a64d22000a9f1590_7.jpg)  

C'est l'été, il fait très chaud, et j'ai plein de menthe dans mon jardin... d'où l'idée de faire un dessert rafraîchissant : une glace à la menthe maison !  

Un petit problème aussi : je n'ai pas de sorbetière, donc il faut faire sans !  

Alors que nous faut-il :  

*   25 cl de lait
*   une bonne grosse poignée de feuilles de menthe fraîche
*   2 oeufs (2 jaunes et 2 blancs)
*   60 g de sucre en poudre, ou idéalement sucre glace (10 g + 50 g)
*   25 cl de crème liquide (non allégée)
*   1 pincée de sel

Tout d'abord, il faut laisser infuser la menthe dans le lait, dans une casserole, pendant une bonne vingtaine de minutes, à couvert, sans faire bouillir le lait. Cela nous donnerait un bon lait au goût de menthe !  

Par ailleurs, nous devons préparer une chantilly, avec la crème (non allégée, car sinon la chantilly ne montera pas, car c'est la matière grasse qui permet à la chantilly de prendre) avec les 25 cl de crème fraîche et 50 g de sucre. Autre petit conseil pour la chantilly, si vous faites ça dans un saladier, un cul de poule, etc, mettez le d'abord au frais, ce sera plus facile pour réussir sa chantilly.  

Dans un bol, séparer les blancs et les jaunes. Avec les jaunes, mélanger les 10 g de sucre restant, et battre le tout pour que cela blanchisse un peu.  

Une fois la menthe bien infusée dans le lait, réservez le lait menthe. Puis lorsqu'il a refroidit un peu, vous pourrez le verser et mélanger avec les jaunes d'oeufs sucrés.  
Mélanger ensuite le lait, les jaunes avec votre crème chantilly.  

Enfin, à côté, préparer des blancs en neige, pour donner un peu de volume. Donc avec les blancs, rajouter une pincée de sel, et avec le batteur, montez les blancs en neige jusqu'à ce qu'ils deviennent bien ferme.  

Une fois les blancs prêts, vous devez incorporer délicatement ces blancs en neige dans la préparation précédente (notre mélange jaune, lait et crème chantilly), avec un mouvement circulaire du fond vers le dessus, pour garder le volume et l'air des blancs.  

Ensuite, vous mettez tout cela à congeler dans votre congélateur pendant quelques heures.  

Après quelques heures, si vous êtes patients, vous pourrez ressortir votre glace pour la mixer dans un mixeur pour la rendre plus onctueuse, puis la remettre au congélateur. Si vous voulez, avant de la remettre une seconde fois au congélateur, vous pourrez y rajouter des copeaux de chocolat noir, voire quelques feuilles de menthe fraîche bien hachées très finement (de trop gros bouts de feuille ne seraient pas très agréables sous la langue).  

Cette recette est grosso modo pour 3 personnes. Ca nous donne environ 6-8 boules de glace. On peut évidement doubler les proportions si on en veut plus.  

Dernière petite chose, vous remarquerez que la glace à la menthe n'est pas... verte, comme on peut l'imaginer ! Le vert des glaces ou des sirops est donné par les colorants ! Alors comme votre glace est plutôt beige (grâce à la couleur du jaune d'oeuf), si vous en avez, vous pouvez rajouter 3 gouttes de colorant alimentaire bleu, pour obtenir un joli vert !  

Et voila, le tour est joué, bonne dégustation !
# Groovy on instantserver.io thanks to GVM


I recently came across [InstantServer.io](http://instantserver.io/), a nice little service that allows you to instantiate an Ubuntu server for testing, for 35 minutes, on Amazon EC2. You click on the green button, and you're given an account and a password, as well as the details to connect onto the machine through SSH.  

Please note that the service seems to be victim of its success, as requesting a new server takes more and more time it seems.  
  
I immediately thought about installing and launching Groovy on those remote servers, using [GVM](http://gvmtool.net/). However, there's no "unzip" command installed, and there's no JDK as well. So there are a few extra steps to be taken. I wanted to blog about the details (which I'm actually doing now!), but Tim Yates beat me to it with his detailed instructions!  

So my task is now simplified, and I'll simply copy the instructions here, thanks Tim!  

*   Create an instant server at [http://instantserver.io/](http://instantserver.io/)
*   Log into it using the username/password they supply
*   Run:

    ```bash
    sudo apt-get install unzip
    ```

*   And when that's done, run:

    ```bash
    sudo apt-get install openjdk-7-jre-headless export JAVA\_HOME=/usr/lib/jvm/java-7-openjdk-amd64
    ```
  
*   Then, install GVM:

    ```bash
    curl -s get.gvmtool.net | bash
    ```
  
*   And source the GVM script:

    ```bash
    source "/home/ubuntu/.gvm/bin/gvm-init.sh"
    ```

*   Install Groovy with GVM:

    ```bash
    gvm install groovy
    ```
  
*   And test:

    ```bash
    groovy -e "println 'Hello'"
    ```
  
Voilà !
# My GR8Conf presentation on Groovy


[GR8Conf Europe 2013](http://gr8conf.eu/index) was such a blast! With close to well over 160 attendees, the conference was a real success, and went flawlessly thanks to the great organization of Søren and his crew. Big congrats to his team! And for the 5th anniversary of the conference, the [Groovy cakes](http://www.flickr.com/photos/steveonjava/8803004028/) were so delicious! It was a pleasure to be back in Copenhagen to meet all my friends from the Groovy community.  

I had a chance to speak about Groovy 2 and beyond, and I'm embedding the slides below, if you want to have a look at them. Also, if all goes well, we should even get a video recording of the presentation(s) this year, so fingers crossed!

{{< speakerdeck 38ba7100a5be013000c342db8da5a4ed >}}

# Which JDK versions do you use?


On the [Groovy](http://groovy.codehaus.org) project team, we were wondering about which base JDK to support.  

So far, even the latest and greatest Groovy (version 2.1.4 just released today), we still support JDK 5 — despite being an End-of-Life'd product for a long while already.  

At conferences, I often ask the question on which versions of the JDK attendees are using, locally and in production, and it seems that JDK 5 has almost totally vanished off the face of the planet, but despite JDK 7 being quite mature now, it's still JDK 6 that's more widely deployed.  

To know more about the situation, my Groovy colleague [Cédric](http://www.jroller.com/melix/) crafted a little Google form to run a [survey](https://docs.google.com/forms/d/1KYMG09CFBwn4m4xN2VfGuhWw2VPs39S87IRbIfPwRWw/viewform?pli=1&edit_requested=true) among our users, with three key questions:

> 1.  What version of Java do you use in production?
> 2.  What version of Java do you use for development?
> 3.  What version of Java do you plan to use in the next 12 months?

You can view the [detailed results](https://docs.google.com/forms/d/1KYMG09CFBwn4m4xN2VfGuhWw2VPs39S87IRbIfPwRWw/viewanalytics) (and you can actually still vote), but to sum it up, luckily, there's nobody still using Java 1.4, which is good news, and only a handful of people still stuck with JDK 5 (4% in production). Thus Java 6 and 7 are safe bets as a base for your projects, with roughly 57% of Java 6 and and 39% of Java 7 in production, this Java 6 still winning by almost 50% over 7! And in development, developers are more eager to using the latest JDK, with twice as much Java 7 than Java 6.  

[![](/img/misc/jdk-versions-adoption.png)](https://docs.google.com/forms/d/1KYMG09CFBwn4m4xN2VfGuhWw2VPs39S87IRbIfPwRWw/viewanalytics) 

As for the Groovy project, we're thinking of mandating Java 7 (essentially because of "invoke dynamic") as the base Java version for Groovy 3, and as this release is slated for late Q1 next year, the adoption of Java 7 should have increased significantly in production — and anyway, we'll still support Groovy 2.X in parallel for "older" JDKs. But the question was more for the upcoming Groovy 2.2, which should be released in a couple of months or so, if we should go with Java 6 as the base requirement. We haven't yet made our decision, but considering 96% of respondents are using Java 6 or newer, that's not a risky bet to make that decision!
# Gaelyk 2.0 is released


This is with great pleasure that the Gaelyk team announces the **release of Gaelyk 2.0**, the lightweight toolkit for developing applications on Google App Engine with the Groovy dynamic language.  

For the impatient, go directly to the [download page](http://gaelyk.appspot.com/download)!  

It's been long in the making, and there are quite a lot of new features to speak about, like the **migration to Groovy 2.1 and GAE 1.8**, the new **Search DSL**, **improvements to the URL routing system**, various **performance optimizations**, and more.  

Please be sure to have a look at the list of [changes on the release notes section of the download page](http://gaelyk.appspot.com/download). In particular, be sure to have a look at the **breaking changes** which might affect your application when upgrading.  

We're very happy to have Gaelyk 2.0 now officially available in your hands, and we'd like to thank you for your support, for your contributions, and for such a friendly community!  

Enjoy!
# Creating a new project with Gradle


Since I started using [Gradle](http://www.gradle.org/) for building my projects, as soon as I needed to create a brand new project from scratch, I wished that Gradle guided my hand and created the right directory structure and minimal Gradle build script.

A bit less than two years ago, I was inspired by Dierk's [gist](https://gist.github.com/Dierk/1271516) providing a basic build that provided two tasks, one for creating the directory layout, and the other one to create the Gradle wrapper. I turned that gist into a [blog post of my own]({{< ref "/posts/2011/11/25/handy-gradle-startup-script" >}}), with just minor version updates, as I wanted to remember how to do that the next time I'd create a new Gradle-based project.

But we were not the only ones missing this capability in Gradle!

More recently, [Marcin leveraged the init script capabilities of Gradle](http://blog.proxerd.pl/article/my-gradle-init-script) to make the process a bit smoother, so that we don't have to blindly and stupidly copy and paste the same sample build script each time. With his approach, we add the project layout and wrapper creation in the ~/.gradle/init.gradle script, so that it's available in your new projects by default.

Last but not least, just the other day, Erik came up with a [similar approach](http://www.jworks.nl/2013/04/16/creating-projects-with-gradle/) as the original gist for creating projects, with some more flags to customize which directories we want created.

As it seems we're all reinventing the wheel, I wondered on twitter [how come this basic functionality wasn't already included in Gradle](https://twitter.com/glaforge/status/324484467911704576)! And in matter of minutes, I got some additional pointers about other archetypes and template solutions, like the [dt\_java](https://github.com/svene/dt_java) project which provides templates for Gradle-based projects amon other things, the [Gradle templates plugin](https://github.com/townsfolk/gradle-templates).

But the good news is that this often needed feature is actually getting some attention from our Gradle(ware) friends, and we're going to see some form of project creation in Gradle 1.6 soon, as shown in this [design document](https://github.com/gradle/gradle/blob/master/design-docs/build-initialisation.md).
Ultimately, creating a template project and a Gradle wrapper will likely be as simple as:

```bash
gradle setupBuild --type groovy-library
gradle wrapper
```

And then, no more hacks needed, you'll have a nice and ready-to-build project in matter of mere seconds, without resorting to our various tactics listed above!
I'm looking forward to Gradle 1.6 even if just for that new capabilities we've all been longing for!
# Contribute a dedicated CI server for Groovy


The Groovy team is always looking at ways to further improve and encourage the collaboration and contributions from the community.  

Today, the we are** looking for a sponsor for a dedicated server** that would host our **new Continuous Integration server**. If you or your company is interested in helping Groovy by contributing hardware and/or hosting, please contact us.  

The details of the project are available [here](http://docs.codehaus.org/display/GROOVY/A+new+CI+server+for+the+Groovy+project).  

On behalf of the Groovy team, thanks in advance for your help and support!
# Joins us for GR8Conf Europe! Early bird price ending soon.


Like every year, [GR8Conf Europe](http://gr8conf.eu/) takes place in the beautiful city of Copenhagen in Denmark. It's where all the talented and cool Groovy ecosystem folks meet, and spread the love about their technologies, including Groovy, Grails, Gradle, Spock, GPars, and more.  

I'll be speaking about the latest developments on the Groovy 2.x branch, and what our plans are going forward. You can also have a look at the preliminary [agenda](http://gr8conf.eu/Agenda) published on the GR8Conf website, to see familiar [names](http://gr8conf.eu/Speakers) like Jürgen Höller, Venkat Subramaniam, Dierk König, Graeme Rocher, Burt Beckwith, Mr Haki, Luke Daley, Russel Winder... You're sure to find some great content delivered by the experts themselves!  

I'd also like to highlight that you should hurry up to [register](http://gr8conf.eu/Registration) if you want to benefit from the Early Bird registration price! This agressive price last for a couple more days, so be fast!
# Groovy 2.1 is released


Here's my announcement for the Groovy 2.1 release, and be sure to check out the [full release notes of the release](http://bit.ly/groovy21notes)!

> The Groovy team is pleased to announce the **release of Groovy 2.1.0**.  
> With over **1.7 million downloads in 2012**, a **strong ecosystem**, Groovy continues its development and adoption, refines existing features and evolves new ones.  
>   
> In this new release, Groovy 2.1:
> 
> *   **offers full support for the JDK 7 “invoke dynamic”** bytecode instruction and API,
> 
> *   goes beyond conventional static type checking capabilities with a **special annotation to assist with documentation and type safety of DSLs** and adds **static type checker extensions**,
> 
> *   provides **additional compilation customization** options,
> 
> *   features a **meta-annotation facility** for combining annotations elegantly,
> 
> *   and provides various other enhancements and minor improvements.
> 
> Please read all the details about the **new features and improvements** in the **Groovy 2.1 release notes** document:  
> [http://bit.ly/groovy21notes](http://bit.ly/groovy21notes)  
>   
> You can **download Groovy 2.1.0** from the Download area:  
> [http://groovy.codehaus.org/Download?nc](http://groovy.codehaus.org/Download?nc)  
>   
> And have a look at the **JIRA tickets** we worked on:  
> [http://bit.ly/groovy21jira](http://bit.ly/groovy21jira)  
>   
> Thanks a lot to all our users, contributors and committers who made this release possible.  
>   
> I'd particularly like thank our **new committers**: Pascal Schumacher, André Steingreß and Tim Yates, for all their feedback and various contributions. Welcome to the team!  
>   
> The Groovy team is looking forward to your feedback on this new release!  
>   
> Keep on groovy'ing!
# Brownie dans un mug


L'autre jour sur Facebook, je suis tombé sur cette [liste de "life-hacks"](http://twistedsifter.com/2013/01/50-life-hacks-to-simplify-your-world/), dont certains sont vraiment malins... et parmi eux, il y avait une recette de brownie dans un mug. Je l'ai retrouvée [là](http://blog.gopromos.com/how-to-make-brownie-in-a-mug/), mais j'ai également trouvé d'autres variantes, comme [celle de Lindt](http://a-cuisiner.lindt.fr/recettes-a-cuisiner/desserts-gourmands/brownie-fondant-coulant-dans-un-mug/imprimer).  

Du coup, par gourmandise et pour faire plaisir à ma fille, nous nous sommes concocté notre propre version de ces deux recettes, que je vous livre aujourd'hui !  

Déjà, les ingrédients :  

*   8 carrés de chocolat dessert (1/4 ou 1/5 de tablette)
*   1 cuillère de beurre
*   3 cuillères à soupe d'eau
*   4 cuillères à soupe de farine
*   3 cuillères à soupe de sucre
*   1 pincée de sel
*   2 noix

D'abord, mettre le chocolat, le beurre et l'eau ensemble au fond d'un mug. Faire fondre le tout pendant environ 30 secondes dans le micro-onde. Après cela, rajouter la farine, le sucre et le sel, et bien mélanger le tout pour faire un mélange homogène. Le petit plus, deux noix pour rajouter un peu de croquant ! Enfin, remettre le tout dans le micro-onde pour une bonne minute, et le tour est joué.
# First beta of Groovy 2.1 released


Since the world didn't seem to end today, it is with great pleasure that we bring under your Christmas tree the following presents: the **release of Groovy 2.1.0-beta-1 and Groovy 2.0.6**.  
Groovy 2.0.6 is a bug fix release for our Groovy 2.0.X line, whereas Groovy 2.1.0-beta-1 contains new features.  
You can download Groovy at the usual location: [http://groovy.codehaus.org/Download](http://groovy.codehaus.org/Download)  
  
The JIRA release notes can be found here:

*   Groovy 2.1.0-beta-1: [http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=18598](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=18598)  
    
*   Groovy 2.0.6: [http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=18852](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=18852)

More extensive release notes will be available for the final Groovy 2.1.0 release, but please let me highlight the following key new features:

*   **complete invoke dynamic support** when running with the "indy" JAR on JDK 7
*   **upgrade to GPars 1.0**: the Groovy distribution now bundles the GPars 1.0 final release
*   **`@DelegatesTo` annotation**: to help IDEs and the static type checker and compiler to know that method calls in a method parameter closure are delegated to another parameter of the method -- nice for DSLs like in Gradle build files
*   **custom type checking extensions**: so you can type check your DSLs at compile-time with your own logic
*   a **meta-annotation** system: which allows you to define a new annotation actually combining several others -- which also means being able to apply several AST transformations with a single custom annotation
*   **custom base script class flag** for the groovyc compiler: to set a base script class when compiling Groovy scripts
*   **compiler configuration script**: to let you define various configuration options for the Groovy compiler, like specifying custom file extensions, various compilation customizers to apply, etc.
*   **compilation customizer builder**: a special builder for specifying compilation customizers
*   `jar://`, `file://`, `http://` prefix support for launching Groovy scripts from the command line

Although more details will be provided later on for the final release, please don't hesitate to ask questions about those new features and improvements till then.  

A little reminder on the roadmap, we intend on releasing a release candidate of Groovy 2.1 the second week of January, and if all goes well (if we don't need another RC for some last minute issues), we'll go straight to the final release at the end of January.  
  
Thanks a lot for your feedback, your bug reports, your contributions, your pull requests! It's with such a great community of users that we make Groovy a joy to use in our every day projects.  

The whole development team joins me to wish you the best for the holidays and for next year! A Groovy Christmas and a Happy New Year to all!
# GPars reaches 1.0!


Václav Pech just [announced the final release of GPars 1.0](http://www.jroller.com/vaclav/entry/i_like_the_smell_of), the concurrency and parallel toolkit for Groovy and Java.  

We'll bundle [GPars 1.0](http://gpars.codehaus.org/) in the Groovy 2.1 distribution coming very soon!  
  
Let me quote some of the key changes and enhancements of this release (quoting from the "what's new" section of the [user guide](http://www.gpars.org/1.0.0/guide/guide/gettingStarted.html#gettingStarted_what'sNew)):

> Asynchronous functions
> 
> *   Allowed for delayed and explicit thread pool assignment strategies for asynchronous functions
> *   Performance tuning to the asynchronous closure invocation mechanism
> 
> Parallel collections
> 
> *   Added a couple of new parallel collection processing methods to keep up with the innovation pace in Groovy
> *   Merged the extra166y library into GPars
> 
> Actors
> 
> *   StaticDispatchActor has been added to provide easier to create and better performing alternative to _DynamicDispatchActor_
> *   A new method _sendAndPromise_ has been added to actors to send a message and get a promise for the future actor's reply
> 
> Dataflow
> 
> *   Operator and selector speed-up
> *   Kanban-style dataflow operator management has been added
> *   Chaining of Promises using the new _then()_ method
> *   Exception propagation and handling for Promises
> *   Added a DSL for easy operator pipe-lining
> *   Lifecycle events for operators and selectors were added
> *   Added support for custom error handlers
> *   A generic way to shutdown dataflow networks
> *   An shutdown poison pill with immediate or delayed effect was added
> *   Polished the way operators can be stopped
> *   Added synchronous dataflow variables and channels
> *   Read channels can report their length
# Groovy 2.0 and beyond at Groovy Grails eXchange


Last week, I had the pleasure to attend and keynote at the 5th edition of the [Groovy / Grails eXchange conference](http://skillsmatter.com/event/groovy-grails/groovy-grails-exchange-2012), in London. I presented a talk around the [new features of Groovy 2.0 and the upcoming 2.1 release](http://skillsmatter.com/podcast/groovy-grails/keynote-speech), as well as a few words about what's coming up next.  

You can watch the video online, as [SkillsMatter](http://skillsmatter.com/), the organizer of the conference, have put all the presentations online in record time!  

And you can have a look at the slides hosted on Speakerdeck below:

{{< speakerdeck bcf46160275f0130d81c12313d1a713a >}}

# InfoQ's readers JVM languages research


[InfoQ](http://www.infoq.com) is running a reader-driven survey titled "[What's your next JVM language](http://www.infoq.com/research/next-jvm-language)".  

Among the candidates to be ranked, you'll find:

*   Groovy
*   Java 8
*   Ceylon
*   Kotlin
*   Clojure
*   Scala
*   Xtend
*   Fantom
*   Mirah

As well as the languages ported to the JVM like:

*   JRuby
*   Jython
*   Javascript (Rhino and soon Nashorn)
*   Erlang
*   Scheme

The interesting aspect of the survey is that it's not just a mere poll, but you can rank those JVM languages across two criterion: the percentage of lines of code (less or more), and the adoption (like now, in 3 months, in a year). It certainly gives more perspective than a mere poll on your favorite language. The downside might be that it's too easy to rank the ones you dislike negatively without objectivity, but well, polls are like that too :-)  

If you're a Groovy fan like me, be sure to put Groovy in the lower left hand corner ;-)
# Groovy 2.0 online webinar


On Thursday, at 15:30 GMT+1, I'll have the pleasure to present a Groovy 2.0 update presentation live, online, in the form of a webinar. The webinar will be showcased through [webex here](http://bit.ly/groovy2webinar). The video will later be made available on [SpringSource's YouTube channel](http://www.youtube.com/user/SpringSourceDev), for those who want to see it afterwards at a more convenient time.  

In the meantime, here's the title and abstract of that [presentation](http://bit.ly/groovy2webinar):

> What's new in Groovy 2.0?  
>   
> Groovy is a very popular alternative language for the JVM that continues to bring more developer productivity and more performance after each release. In this webinar, we'll dive through the new developments in the recently released Groovy 2.0.   
>
> A lot of the Groovy users are using the language as a Java scripting language, or sometimes as a better Java. First of all, not all of them need the dynamic capabilities, nor do they need all the library improvements provided by Groovy. For the latter, Groovy becomes more modular with smaller core modules that you can compose. For the former, in addition to its usual dynamic features, Groovy 2.0 adds static type checking, allowing you to ensure the correctness of your code before it ships and quickly spot early errors at compile time. Also, not everybody needs dynamic features at all times, and the natural extension to static type checking is static compilation. With static compilation, Groovy 2.0 generates fast and performant bytecode like Java, and shields key parts of your code base from possible interferences of dynamic features, making critical paths both faster and immune to monkey patching. But when you need fast and performant dynamic logic, Groovy 2.0 also features the integration of the "invoke dynamic" support coming up with JDK 7 and beyond.

**Update:** You can look at the [slides on Slideshare](http://fr.slideshare.net/glaforge/groovy-20-webinar) and [watch the video on YouTube](http://www.youtube.com/watch?v=MwnjnOv9jVE&list=UU7yfnfvEUlXUIfm8rGLwZdA&index=1&feature=plpp_video) on SpringSource's dev channel
# SpringOne2GX Groovy presentations aftermath


Last week, I was in Washington DC for the [SpringOne2GX conference](http://www.springone2gx.com/conference/washington/2012/10/2gx/event_schedule).  

I've had the pleasure of presenting twice: first time on an update on Groovy 2.0 (and a recap on key features of Groovy 1.8), and a second time with my friends and colleagues Paul King (Groovy core committer) and Andrew Eisenberg (Groovy/Grails Eclipse tooling lead) about Domain-Specific Languages in Groovy. 

Please see the slides published below:  

{{< slideshare 14753365 >}}

{{< slideshare 14759852 >}}
# Groovy sessions at JavaOne 2012


Monday I'll be flying to San Francisco for the JavaOne conference, where there will be [tons of sessions and BOF speaking about Groovy](https://oracleus.activeevents.com/connect/search.ww?event=javaone#loadSearch-event=javaone&searchPhrase=groovy&searchType=session&tc=0&sortBy=titleSort&p=&i(11424)=&i(10050)=&i(10090)=&i(10092)=&i(11842)=&i(10086)=) or mentioning it, and where I'll be participating at two sessions, one of the novelties of Groovy 2 and the ScriptBowl.  

Let me highlight a few of those sessions:  

*   [What's new in Groovy 2](https://oracleus.activeevents.com/connect/sessionDetail.ww?SESSION_ID=6505)  
    Shameless plug, that's my session, where I speak about some of the key features of Groovy 1.8, and then quickly delve into the major features of Groovy 2
*   [What's new in Grails 2](https://oracleus.activeevents.com/connect/sessionDetail.ww?SESSION_ID=7945)  
    Graeme Rocher will cover and demo the key features of Grails 2.x
*   [Griffon, up close and personal](https://oracleus.activeevents.com/connect/sessionDetail.ww?SESSION_ID=5106)  
    Andres Almiray will tell us all about the Griffon rich desktop application framework
*   [The Groovy Ecosystem](https://oracleus.activeevents.com/connect/sessionDetail.ww?SESSION_ID=5100)  
    Again, Andres on stage here, to speak about the many projects built atop Groovy, for your build, for testing and more
*   [Walk through Groovy's AST transformations](https://oracleus.activeevents.com/connect/sessionDetail.ww?SESSION_ID=5102)  
    Andres walks us through Groovy's mechanism to plugin into the compiler to bring powerful compile-time metaprogramming abilities to your classes
*   [Design patterns in Groovy](https://oracleus.activeevents.com/connect/sessionDetail.ww?SESSION_ID=3469)  
    Venkat Subramaniam revisits classical design patterns as well as new ones
*   [Improving your Groovy kung-fu](https://oracleus.activeevents.com/connect/sessionDetail.ww?SESSION_ID=4857)  
    Dierk König highlight key features of the Groovy language and nice library you can leverage to make you a better and more productive Groovy developer
*   [A common development framework, from JSP to GSP, at CERN](https://oracleus.activeevents.com/connect/sessionDetail.ww?SESSION_ID=5045)  
    The CERN research center (the great hadron collider, etc) talk about their usage of Groovy and Grails, with concrete examples, screenshots and more
*   [GroovyFX: making JavaFX Groovy](https://oracleus.activeevents.com/connect/sessionDetail.ww?SESSION_ID=2813)  
    Jim Clarke and Dierk talk about the GroovyFX library, a thin DSL on top of JavaFX to express your creativity with JavaFX in a nice Groovy idiom
*   [Grezi and GroovyFX](https://oracleus.activeevents.com/connect/sessionDetail.ww?SESSION_ID=5486)  
    Bertrand Goetzmann and Stephen Chin speak about GroovyFX and show a concrete usage with the Grezi framework, to build powerful visual and interactive presentations
*   [ScriptBowl: the battle of the JVM based languages](https://oracleus.activeevents.com/connect/sessionDetail.ww?SESSION_ID=3257)  
    I'll finish with the ScriptBowl, a friendly 2-round battle comparing some of the popular languages of the JVM platform. Hopefully, I'll try to win again this year, but the competition is tough! Fingers crossed! Come in number to support me and make Groovy win again!
# Groovy 2.0.4 is out


The Groovy development team's just **released Groovy 2.0.4**, a bug fix for our Groovy 2.0 branch.  

It fixes some important issues we've had with generics with the stub generator, as well as several fixes related to the static type checking and static compilation features. We also worked on the recompilation issues with the GroovyScriptEngine.  

You can download Groovy 2.0.4 here: [http://groovy.codehaus.org/Download](http://groovy.codehaus.org/Download)  

The artifacts are not yet on Maven Central, but will shortly.  

Also, the online JavaDoc and GroovyDoc are still being uploaded as I write this, but will hopefully be online in a few hours.  

You can have a look at the issues fixed in this release on JIRA: [https://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=18777](https://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=18777)  

If you're curious why we've jumped from 2.0.2 to 2.0.4, skipping 2.0.3, it's because of some issues with the release of 2.0.3 which I had mistakenly built with JDK 6 instead of JDK 7, which ruled out all our invoke dynamic support. So we quickly moved to 2.0.4.  

We'll certainly also release a 1.8.9 soon, especially for the stub generator fixes which might be useful for those affected with the issues we've fixed.
# Groovy 2.0.2 and 1.8.8


I'll echo here the two new releases of the [Groovy programming language](http://groovy.codehaus.org):

> This is with great pleasure that the Groovy development team announces the **releases of Groovy 2.0.2 and Groovy 1.8.8**.   
> 
> Those two releases are essentially just **bug fix releases**, with only minor improvements. In particular, work has been done in the area of the static type checker and static compilation, in the GroovyScriptEngine, as well as further performance improvements for the "invoke dynamic" support as well as plain Groovy. We also upgraded the version of GPars of the distribution to use the newly released 1.0-beta-3.   
>
> For the details of both releases, please have a look at the JIRA changelog here: for Groovy 2.0.2: [http://bit.ly/gr202](http://bit.ly/gr202), and for Groovy 1.8.8: [http://bit.ly/gr188](http://bit.ly/gr188)   
> As usual, you can **download Groovy **in our download area: [http://groovy.codehaus.org/Download](http://groovy.codehaus.org/Download)  
>   
> Thanks a lot to all those who contributed to those releases.   
>
> I'd also like to seize this opportunity to highlight our contribution page, to those who are **interested in contributing to Groovy**: [http://groovy.codehaus.org/Contributing](http://groovy.codehaus.org/Contributing)   
>
> Going forward, we're going to propose a list of JIRA issues you might have a look at, if you want to get started working on the Groovy project: [http://bit.ly/gcontrib](http://bit.ly/gcontrib)   
>
> And on the contribution page mentioned above, at the bottom of the page, we feature a table containing wider goals or side projects that you might be interested in contributing to.   
>
> So don't hesitate to come back to us with ideas or with questions regarding those possible areas of contributions, and we'll gladly welcome your help!
# Also back to vi... MacVim actually


Some of my friends are going back to vi like me, for instance Hibernate's [Emmanuel](http://emmanuelbernard.com/blog/2012/08/01/i-succumbed-to-the-cult-of-vi/) and IzPack's [Julien](http://log.julien.ponge.info/post/28914211607/tweaking-macvim). I also mentioned a few good links about that move on the French [Les Castcodeurs podcast](http://lescastcodeurs.com/2012/07/19/les-cast-codeurs-podcast-episode-62-rod-va-sur-l-ile-de-larry/). And to be precise, I'm using [MacVim](http://code.google.com/p/macvim/) on my MacBook Pro laptop, but also vim on the command-line.  

Emmanuel and Julien gave some good tips and links too, and like Julien, I'm going to show you my current `.vimrc` in case anyone's interested:  

```javascript
let mapleader = ","
let g:mapleader=","

if has("gui_running")
   color solarized
endif

set background=dark

set number

set expandtab
set shiftwidth=4
set tabstop=4
set smarttab

set ai "Auto indent
set si "Smart indent

set ruler

set hlsearch

set nocompatible

set bs=2

set autoread

set so=7

filetype on
filetype indent on
filetype plugin on

set guifont=Inconsolata:h16

autocmd! bufwritepost .vimrc source ~/.vimrc

syntax enable

au BufNewFile,BufRead *.gradle set filetype=groovy

function! RunGroovy()
    let gfname=@%
    botright new
    setlocal buftype=nofile bufhidden=wipe nobuflisted noswapfile nowrap
    let gtmpf = tempname()
    let gcmd = ':!groovy ' . gfname . ' > ' . gtmpf
    silent execute gcmd
    silent execute '0r ' . gtmpf
endfunction

map   :call RunGroovy()
nmap @ :NERDTree

```
# Three joint releases of Groovy!


The Groovy development team is happy to announce the **releases of Groovy 2.0.1, 1.8.7 and 1.7.11**! That's the first time we release three versions at the same time.  

Those three versions are essentially just bug fix releases. The 1.8.7 release contains a lot of the bugfixes that were already integrated in Groovy 2.0.0, so it's just an alignment with the Groovy 2 branch. In the future, Groovy 1.8.x and Groovy 2.x will be maintained in parallel. But the Groovy 1.7 branch is now in end-of-life and won't be maintained further.  

In terms of improvements, you might notice some performance gains with the "invoke dynamic" version, or you'll notice that you can use the Groovy Console in full-screen mode on Mac OS X.  

A lot of attention has particularly been put into the bug fixes of the new features of Groovy 2.0. In particular, the static type checking and static compilation features got the lion share of fixes.  

We also restored the OSGi manifest information. So if you're using OSGi, please report back to us if you see any remaining quirk when using Groovy in an OSGi container. However, there's still a known issue for the "invoke dynamic" JARs of Groovy, as neither the OSGi Gradle plugin nor the underlying bnd library have been updated to cope with the "invoke dynamic" bytecode instruction, so we'll have to wait for the releases of both before being able to get proper OSGi support in our "indy" deliverables.  

You can download those latest Groovy versions from here: [http://groovy.codehaus.org/Download](http://groovy.codehaus.org/Download)  

And here are the JIRA release notes for 2.0.1 in particular (but you'll find the notes for 1.8.7 and 1.7.11 on the download page too): [https://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=18599](https://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=18599)  

Thanks a lot for your attention, and big thanks to all those who contributed to those releases!  

Keep on groovying!
# Algorithms for collaborative editing


Over the weekend, I was brainstorming some ideas about what a second generation [Groovy Web Console](http://groovyconsole.appspot.com/) could look like. I was particularly thinking about collaborative editing Groovy snippets of code in the cloud.  

There's a trend towards IDEs in the Cloud, like for instance [Cloud-IDE](http://cloud-ide.com/), allowing you to work on your projects remotely, on the cloud, from the comfort of your browser, even letting you push new versions of your apps in your favorite PaaS.  

And just a few days ago, another interesting project in this field was open-sourced: [Collide](http://code.google.com/p/collide/). It's a collaborative IDE running on [Vert.x](http://vertx.io/), using the [Operational Transform](http://en.wikipedia.org/wiki/Operational_transformation) approach popularized by the defunct Google Wave project whose remains are [incubating at Apache](http://incubator.apache.org/wave/). Funnily, it's yet again the remains of some internal project from Google that got axed as [explained on Google+](https://plus.google.com/u/0/114130972232398734985/posts/82BktQAKzcN).  

As I was interested in the topic, I wanted to learn a bit more about the technologies and algorithms behind that. That's why I wanted to post here my findings, in case someone's interested and for future reference shall I dive deeper into that matter! I'm not covering the details of each algorithm, but instead, I'm giving links that you can harvest for further information.  

When working collaboratively on the same document, instead of sending the whole document with your changes to the other collaborators, you usually just send differences through the wire. Probably the most used [diff algorithm](http://en.wikipedia.org/wiki/Diff) is the [one from Eugene Myers](http://www.xmailserver.org/diff2.pdf).  

Using the diff approach, techniques like [differential synchronization](http://neil.fraser.name/writing/sync/) using [diff / match / patch](http://code.google.com/p/google-diff-match-patch/) are interesting (it's using the diff algorithm from Myers above). Neil Fraser (from Google again) gives some more [details on the approach](http://neil.fraser.name/writing/sync/).  

So let's continue our journey with [Operational Transformations](http://en.wikipedia.org/wiki/Operational_transformation), called OT for short. As I said earlier, it's been used in Google Wave. Basically, each client connected to a common document send units of changes like an insertion of (some) character(s), or a deletion. Because of latency between the time you receive the difference and the moment you've made some changes locally, you need to transform the change you've received so it can still be applied to your own copy of the document.  

In order to know in which order a particular change happened before the other (so that you can apply the changes as they should), there are also specific algorithms. For one, [Lamport timestamps](http://en.wikipedia.org/wiki/Lamport_timestamps) can be used to keep track of that precedence or causality property.  

But you might more likely have heard of [vector clocks](http://en.wikipedia.org/wiki/Vector_clock) to maintain that happen-before relation between events, as this algorithm is often used by the various NoSQL datastores forconsistency purpose. I found an implementation of [vector clocks in voldemort](http://code.google.com/p/project-voldemort/source/browse/trunk/src/java/voldemort/versioning/VectorClock.java?r=170), as well as in this [Google code project](https://code.google.com/p/tud-in4150-fp-ass2b/source/browse/trunk/src/in4150/mutex/VectorClock.java). There's also a brief article on the [superiority of vector clocks over Lamport timestamps](http://skipperkongen.dk/2011/07/26/vector-clocks-vs-lamport-timestamps/) as they give more information about the precedence.  

Last but not least, it seems that another approach is even more interesting: interval tree clocks (for which I've found a [small library here](http://code.google.com/p/itc4j/) implementing it). Vector clocks are great but seem to need more memory to hold the state and don't accomodate too well when the number of participants is changing, and interval tree clocks seem to address that problem.  

The journey ends here with those few links to different algorithms and code samples. Perhaps I'll explore more an approach or the other later on if time permits. Happy reading! 

Don't hesitate to share your own experience, links, corrections, etc, in the comments below.
# Minor new features of Groovy 2.0


Although I've gone at length through the [key major features of Groovy 2.0](http://bitly.com/groovy2)in the InfoQ article, there have been a few smaller ones which are interesting to note. And groovy guys like [Tim Yates](http://blog.bloidonia.com/), [André Steingress](http://blog.andresteingress.com/) or [Mr Hakki](http://mrhaki.blogspot.fr/) were quick to blog about them!  

*   [`inject()` method with a default initial value](http://blog.bloidonia.com/post/26065857945/whats-new-in-groovy-2-0-inject-with-default)
*   [`takeWhile()` and `dropWhile()` methods](http://blog.bloidonia.com/post/26065074691/whats-new-in-groovy-2-0-takewhile-and-dropwhile)
*   [`withDefault()`, `withEager()` methods](http://blog.andresteingress.com/2012/06/29/groovy-2-0-love-for-grails-command-objects/)
*   [`matchesPartially()` method for matchers](http://mrhaki.blogspot.fr/2012/06/groovy-goodness-partial-matches.html) (to see if a string might match a pattern given more input)
*   [`@NotYetImplemented` transformation for test cases](http://blog.andresteingress.com/2012/03/04/using-notyetimplemented-in-test-cases/)
*   [an iterable `collectEntries()` variant](https://jira.codehaus.org/browse/GROOVY-5387)
*   [`first()` and `last()` working with iterables as well](https://jira.codehaus.org/browse/GROOVY-5407)
*   [`collate()` method](https://jira.codehaus.org/browse/GROOVY-5283) (although it's also in 1.8.6 actually) (see [coverage by Tim](http://blog.bloidonia.com/post/18073244930/whats-new-in-groovy-1-8-6-the-collate-method) and [Mr Hakki](http://mrhaki.blogspot.co.uk/2012/04/groovy-goodness-collate-list-into-sub.html))
*   [calendar ranges](https://jira.codehaus.org/browse/GROOVY-3916) (useful for iterating over days of a certain period)

Those are some smaller features compared to the big highlights of Groovy 2.0, but they are definitely useful and make you more productive every day!
# Building your Groovy 2.0 projects with Maven


There are various options for building your Groovy projects: including Ant with the [Groovyc Ant task](http://groovy.codehaus.org/The+groovyc+Ant+Task), or with [Gradle Groovy plugin](http://www.gradle.org/docs/current/userguide/groovy_plugin.html). But today, I'd like to speak about Maven. You have actually two possible choices: [GMaven](http://gmaven.codehaus.org/) or the [Groovy Eclipse Maven plugin](http://groovy.codehaus.org/Groovy-Eclipse+compiler+plugin+for+Maven).

## GMaven

GMaven 1.4 already allowed you to use Groovy 2.0 even before the final release of Groovy, although a new 1.5 version is about to be released soon, which should also include the option to use the "invoke dynamic" support which is currently missing for GMaven 1.4.

Keegan Witt, the lead of the GMaven project, just recently [posted an example POM to configure GMaven with Groovy 2.0](http://groovy.329449.n5.nabble.com/Groovy-Eclipse-compiler-plugin-for-Maven-replacing-gmaven-td5709858.html#a5710494):

```xml
<properties>
  <gmavenVersion>1.4</gmavenVersion>
  <gmavenProviderSelection>2.0</gmavenProviderSelection>
  <groovyVersion>2.0.0</groovyVersion>
</properties>
<dependencies>
  <dependency>
    <groupId>org.codehaus.groovy</groupId>
    <artifactId>groovy-all</artifactId>
    <version>${groovyVersion}</version>
  <dependency>
</dependencies>
<build>
  <plugins>
    <plugin>
      <groupId>org.codehaus.gmaven</groupId>
        <artifactId>gmaven-plugin</artifactId>
        <version>${gmavenVersion}</version>
        <configuration>
          <providerSelection>${gmavenProviderSelection}</providerSelection>
          <sourceEncoding>UTF-8</sourceEncoding>
        </configuration>
        <executions>
          <execution>
            <goals>
              <goal>generateStubs</goal>
              <goal>compile</goal>
              <goal>generateTestStubs</goal>
              <goal>testCompile</goal>
            </goals>
          </execution>
        </executions>
        <dependencies>
         <dependency>
           <groupId>org.codehaus.groovy</groupId>
           <artifactId>groovy-all</artifactId>
           <version>${groovyVersion}</version>
         </dependency>
       </dependencies>
    </plugin>
  </plugins>
</build>
````

Stay tuned for version 1.5 of the GMaven plugin.

## Groovy Eclipse compiler plugin for Maven

The alternative solution is to use the compiler from the Groovy Eclipse project, which can be used as a Maven plugin. Not long ago, I changed a Maven-powered project to use Groovy Eclipse instead of GMaven, and it worked flawlessly, and I was quite happy with the result.

The [Groovy Eclipse compiler plugin for Maven](http://groovy.codehaus.org/Groovy-Eclipse+compiler+plugin+for+Maven) is very well documented, so be sure to have a look at it for all the details on how to best configure it.

In the meantime, the simplest way to build your Groovy 2.0 sources can be achieved with this simpler configuration, as it's using 2.0 by default:

```xml
<build>
...
<plugins>
  <plugin>
    <artifactId>maven-compiler-plugin</artifactId>
    <version>2.3.2</version>
    <configuration>
      <compilerId>groovy-eclipse-compiler</compilerId>
    </configuration>
    <dependencies>
      <dependency>
        <groupId>org.codehaus.groovy</groupId>
        <artifactId>groovy-eclipse-compiler</artifactId>
        <version>2.7.0-01</version>
      </dependency>
    </dependencies>
  </plugin>
  ...
</plugins>
</build>
```
# Groovy 2.0 support in Eclipse


Right after the [release of Groovy 2.0]({{< ref "/posts/2012/06/28/groovy-2-0-released" >}}), our intrepid Eclipse team released a new version of the Groovy Eclipse plugin. The big highlights are, of course, the Groovy 2.0 support, but also the support of Juno and the move of the sources of the plugin to GitHub, plus some new refactorings and quickfixes.  
Here's [Andrew](http://contraptionsforprogramming.blogspot.fr/)'s full announcement:

> Hot on the heels of Groovy 2.0, we are pleased to announce the release of Groovy-Eclipse 2.7.0.   
>
> The major parts to this release are our Groovy 2.0 support, Eclipse Juno support, and our move to github. We've also implemented a few new refactorings and quickfixes. You can find the glorious details here: [http://docs.codehaus.org/display/GROOVY/Groovy-Eclipse+2.7.0+New+and+Noteworthy](http://docs.codehaus.org/display/GROOVY/Groovy-Eclipse+2.7.0+New+and+Noteworthy)  
>
> We have also released v2.7.0 of the groovy-eclipse-compiler plugin for maven. This version now has Groovy 2.0 support.   
>
> Thanks everyone for trying out snapshot releases and raising issues. Please keep the feedback coming!

  
Get it while it's hot! And be sure to read what's new in the link above for all the details.
# What's new in Groovy 2.0


The newly released Groovy 2.0 brings key static features to the language with **static type checking** and **static compilation**, adopts JDK 7 related improvements with **Project Coin syntax enhancements** and the **support of the new "invoke dynamic"** JVM instruction, and becomes **more modular** than before. In this article, we're going to look into those new features in more detail.

## A "static theme" for a dynamic language

## Static type checking

Groovy, by nature, is and will always be a dynamic language. However, Groovy is often used as a "Java scripting language", or as a "better Java" (ie. a Java with less boilerplate and more power features).

A lot of Java developers actually use and embed Groovy in their Java applications as an extension language, to author more expressive business rules, to further customize the application for different customers, etc. For such Java-oriented use cases, developers don't need all the dynamic capabilities offered by the language, and they usually expect the same kind of feedback from the Groovy compiler as the one given by javac. In particular, they want to get compilation errors (rather than runtime errors) for things like typos on variable or method names, incorrect type assignments and the like. That's why Groovy 2 features **static type checking support**.

## Spotting obvious typos

The static type checker is built using Groovy's existing powerful AST (Abstract Syntax Tree) transformation mechanisms but for those not familiar with these mechanisms you can think of it as an optional compiler plugin triggered through an annotation. Being an optional feature, you are not forced to use it if you don't need it. To trigger static type checking, just use the `@TypeChecked` annotation on a method or on a class to turn on checking at your desired level of granularity. Let's see that in action with a first example:

```groovy
import groovy.transform.TypeChecked

void someMethod() {}

@TypeChecked
void test() {
    // compilation error:
    // cannot find matching method sommeeMethod()
    sommeeMethod()

    def name = "Marion"

    // compilation error:
    // the variable naaammme is undeclared
    println naaammme
}
```

We annotated the `test()` method with the `@TypeChecked` annotation, which instructs the Groovy compiler to run the static type checking for that particular method at compilation time. We're trying to call `someMethod()` with some obvious typos, and to print the name variable again with another typo, and the compiler will throw two compilation errors because respectively, the method and variable are not found or declared.

## Check your assignments and return values

The static type checker also verifies that the return types and values of your assignments are coherent:

```groovy
import groovy.transform.TypeChecked

@TypeChecked
Date test() {
    // compilation error:
    // cannot assign value of Date
    // to variable of type int
    int object = new Date()

    String[] letters = ['a', 'b', 'c']
    // compilation error:
    // cannot assign value of type String
    // to variable of type Date
    Date aDateVariable = letters[0]

    // compilation error:
    // cannot return value of type String
    // on method returning type Date
    return "today"
}
```


In this example, the compiler will complain about the fact you cannot assign a `Date` in an `int` variable, nor can you return a `String` instead of a `Date` value specified in the method signature. The compilation error from the middle of the script is also interesting, as not only does it complain of the wrong assignment, but also because it shows type inference at play, because the type checker, of course, knows that `letters[0]` is of type `String`, because we're dealing with an array of `Strings`.

## More on type inference

Since we're mentioning type inference, let's have a look at some other occurrences of it. We mentioned the type checker tracks the return types and values:

```groovy
import groovy.transform.TypeChecked

@TypeChecked
int method() {
    if (true) {
        // compilation error:
        // cannot return value of type String
        // on method returning type int
        'String'
    } else {
        42
    }
}
```


Given a method returning a value of primitive type `int`, the type checker is able to also check the values returned from different constructs like `if / else `branches, `try / catch` blocks or `switch / case` blocks. Here, in our example, one branch of the `if / else` blocks tries to return a `String `value instead of a primitive `int`, and the compiler complains about it.

## Common type conversions still allowed

The static type checker, however, won't complain for certain automatic type conversions that Groovy supports. For instance, for method signatures returning `String, boolean` or `Class`, Groovy converts return values to these types automatically:

```groovy
import groovy.transform.TypeChecked

@TypeChecked
boolean booleanMethod() {
    "non empty strings are evaluated to true"
}

assert booleanMethod() == true

@TypeChecked
String stringMethod() {
    // StringBuilder converted to String calling toString()
    new StringBuilder() << "non empty string"
}

assert stringMethod() instanceof String

@TypeChecked
Class classMethod() {
    // the java.util.List class will be returned
    "java.util.List"
}

assert classMethod() == List
```

The static type checker is also clever enough to do **type inference**:

```groovy
import groovy.transform.TypeChecked

@TypeChecked
void method() {
    def name = " Guillaume "

    // String type inferred (even inside GString)
    println "NAME = ${name.toUpperCase()}"

    // Groovy GDK method support
    // (GDK operator overloading too)
    println name.trim()

    int[] numbers = [1, 2, 3]
    // Element n is an int
    for (int n in numbers) {
        println
    }
}
```

Although the `name` variable was defined with `def`, the type checker understands it is of type `String`. Then, when this variable is used in the interpolated string, it knows it can call `String's toUpperCase()` method, or the `trim()` method later one, which is a method added by the Groovy Development Kit decorating the `String `class. Last, when iterating over the elements of an array of primitive `ints`, it also understands that an element of that array is obviously an `int`.

## Mixing dynamic features and statically typed methods

An important aspect to have in mind is that using the static type checking facility restricts what you are allowed to use in Groovy. Most runtime dynamic features are not allowed, as they can't be statically type checked at compilation time. So adding a new method at runtime through the type's metaclasses is not allowed. But when you need to use some particular dynamic feature, like Groovy's builders, you can opt out of static type checking should you wish to.

The `@TypeChecked` annotation can be put at the class level or at the method level. So if you want to have a whole class type checked, put the annotation on the class, and if you want only a few methods type checked, put the annotation on just those methods. Also, if you want to have everything type checked, except a specific method, you can annotate the latter with `@TypeChecked(TypeCheckingMode.SKIP) `- or `@TypeChecked(SKIP)` for short, if you statically import the associated enum. Let's illustrate the situation with the following script, where the `greeting()` method is type checked, whereas the `generateMarkup()` method is not:

```groovy
import groovy.transform.TypeChecked
import groovy.xml.MarkupBuilder

// this method and its code are type checked
@TypeChecked
String greeting(String name) {
    generateMarkup(name.toUpperCase())
}

// this method isn't type checked
// and you can use dynamic features like the markup builder
String generateMarkup(String name) {
    def sw = new StringWriter()
    new MarkupBuilder(sw).html {
        body {
            div name
        }
    }
    sw.toString()
}

assert greeting("Cédric").contains("<div>CÉDRIC</div>")
```

## Type inference and instanceof checks

Current production releases of Java don't support general type inference; hence we find today many places where code is often quite verbose and cluttered with boilerplate constructs. This obscures the intent of the code and without the support of powerful IDEs is also harder to write. This is the case with `instanceof `checks: You often check the class of a value with instanceof inside an `if` condition, and afterwards in the `if `block, you must still use casts to be able to use methods of the value at hand. In plain Groovy, as well as in the new static type checking mode, you can completely get rid of those casts.

```groovy
import groovy.transform.TypeChecked
import groovy.xml.MarkupBuilder

@TypeChecked
String test(Object val) {
    if (val instanceof String) {
        // unlike Java:
        // return ((String)val).toUpperCase()
        val.toUpperCase()
    } else if (val instanceof Number) {
        // unlike Java:
        // return ((Number)val).intValue().multiply(2)
        val.intValue() * 2
    }
}

assert test('abc') == 'ABC'
assert test(123) == '246'
```

In the above example, the static type checker knows that the val parameter is of type `String` inside the `if `block, and of type` Number` in the else if block, without requiring any cast.

## Lowest Upper Bound

The static type checker goes a bit further in terms of type inference in the sense that it has a more granular understanding of the type of your objects. Consider the following code:

```groovy
import groovy.transform.TypeChecked

// inferred return type:
// a list of numbers which are comparable and serializable
@TypeChecked test() {
    // an integer and a BigDecimal
    return [1234, 3.14]
}
```

In this example, we return, intuitively, a list of numbers: an `Integer` and a `BigDecimal`. But the static type checker computes what we call a *"lowest upper bound"*, which is actually a list of numbers which are also serializable and comparable. It's not possible to denote that type with the standard Java type notation, but if we had some kind of intersection operator like an ampersand, it could look like `List<Number & Serializable & Comparable>.`

## Flow typing

Although this is not really recommended as a good practice, sometimes developers use the same untyped variable to store values of different types. Look at this method body:

```groovy
import groovy.transform.TypeChecked

@TypeChecked test() {
    def var = 123             // inferred type is int
    var = "123"               // assign var with a String

    println var.toInteger()   // no problem, no need to cast

    var = 123
    println var.toUpperCase() // error, var is int!
}
```

The `var` variable is initialized with an `int`. Then, a `String` is assigned. The *"flow typing"* algorithm follows the flow of assignment and understands that the variable now holds a` String`, so the static type checker will be happy with the `toInteger()` method added by Groovy on top of `String`. Next, a number is put back in the var variable, but then, when calling `toUpperCase()`, the type checker will throw a compilation error, as there's no `toUpperCase()` method on `Integer`.

There are some special cases for the flow typing algorithm when a variable is shared with a closure which are interesting. What happens when a local variable is referenced in a closure inside a method where that variable is defined? Let's have a look at this example:

```groovy
import groovy.transform.TypeChecked

@TypeChecked test() {
    def var = "abc"
    def cl = {
        if (new Random().nextBoolean()) var = new Date()
    }
    cl()
    var.toUpperCase() // compilation error!
}
```

The `var` local variable is assigned a `String`, but then, `var` might be assigned a `Date` if some random value is true. Typically, it's only at runtime that we really know if the condition in the if statement of the closure is made or not. Hence, at compile-time, there's no chance the compiler can know if `var` now contains a `String` or a `Date`. That's why the compiler will actually complain about the `toUpperCase()` call, as it is not able to infer that the variable contains a `String` or not. This example is certainly a bit contrived, but there are some more interesting cases:

```groovy
import groovy.transform.TypeChecked

class A           { void foo() {} }
class B extends A { void bar() {} }

@TypeChecked test() {
    def var = new A()
    def cl = { var = new B() }
    cl()
    // var is at least an instance of A
    // so we are allowed to call method foo()
    var.foo()
}
```

In the `test()` method above, `var` is assigned an instance of` A`, and then an instance of `B` in the closure which is call afterwards, so we can at least infer that var is of type `A`.

All those checks added to the Groovy compiler are done at compile-time, but the generated bytecode is still the same dynamic code as usual - no changes in behavior at all.

Since the compiler now knows a lot more about your program in terms of types, it opens up some interesting possibilities: what about compiling that type checked code statically? The obvious advantage will be that the generated bytecode will more closely resemble the bytecode created by the javac compiler itself, making statically compiled Groovy code as fast as plain Java, among other advantages. In the next section, we'll learn more about Groovy's static compilation.

## Static compilation

As we shall see in the following chapter about the JDK 7 alignments, Groovy 2.0 supports the new *"invoke dynamic"* instruction of the JVM and its related APIs, facilitating the development of dynamic languages on the Java platform and bringing some additional performance to Groovy's dynamic calls. However, unfortunately shall I say, JDK 7 is not widely deployed in production at the time of this writing, so not everybody has the chance to run on the latest version. So developers looking for performance improvements would not see much changes in Groovy 2.0, if they aren't able to run on JDK 7. Luckily, the Groovy development team thought those developers could get interesting performance boost, among other advantages, by allowing type checked code to be compiled statically.

Without further ado, let's dive in and use the new `@CompileStatic` transform:

```groovy
import groovy.transform.CompileStatic

@CompileStatic
int squarePlusOne(int num) {
    num * num + 1
}

assert squarePlusOne(3) == 10
```

This time, instead of using `@TypeChecked`, use `@CompileStatic`, and your code will be statically compiled, and the bytecode generated here will look like javac's bytecode, running just as fast. Like the `@TypeChecked annotation, @CompileStatic `can annotate classes and methods, and `@CompileStatic(SKIP) `can bypass static compilation for a specific method, when its class is marked with `@CompileStatic`.

Another advantage of the javac-like bytecode generation is that the size of the bytecode for those annotated methods will be smaller than the usual bytecode generated by Groovy for dynamic methods, since to support Groovy's dynamic features, the bytecode in the dynamic case contains additional instructions to call into Groovy's runtime system.

Last but not least, static compilation can be used by framework or library code writers to help avoid adverse interactions when dynamic metaprogramming is in use in several parts of the codebase. The dynamic features available in languages like Groovy are what give developers incredible power and flexibility but if care is not taken, different assumptions can exist in different parts of the system with regards to what metaprogramming features are in play and this can have unintended consequences. As a slightly contrived example, consider what happens if you are using two different libraries, both of which add a similarly named but differently implemented method to one of your core classes. What behaviour is expected? Experienced users of dynamic languages will have seen this problem before and probably heard it referred to as *"monkey patching"*. Being able to statically compile parts of your code base - those parts that don't need dynamic features - shields you from the effects of monkey patching, as the statically compiled code doesn't go through Groovy's dynamic runtime system. Although dynamic runtime aspects of the language are not allowed in a static compilation context, all the usual AST transformation mechanisms work just as well as before, since most AST transforms perform their magic at compilation time.

In terms of performance, Groovy's statically compiled code is usually more or less as fast as javac's. In the few micro-benchmarks the development team used, performance is identical in several cases, and sometimes it's slightly slower.

Historically, thanks to the transparent and seamless integration of Java and Groovy, we used to advise developers to optimize some hotspot routines in Java for further performance gains, but now, with this static compilation option, this is no longer the case, and people wishing to develop their projects in full Groovy can do so.

## The Java 7 and JDK 7 theme

The grammar of the Groovy programming language actually derives from the Java grammar itself, but obviously, Groovy provides additional nice shortcuts to make developers more productive. This familiarity of syntax for Java developers has always been a key selling point for the project and its wide adoption, thanks to a flat learning curve. And of course, we expect Groovy users and newcomers to also want to benefit from the few syntax refinements offered by Java 7 with its *"Project Coin"* additions.

Beyond the syntax aspects, JDK 7 also brings interesting novelties to its APIs, and for a first time in a long time, even a new bytecode instruction called *"invoke dynamic"*, which is geared towards helping implementors develop their dynamic languages more easily and benefit from more performance.

## Project Coin syntax enhancements

Since day 1 (that was back in 2003 already!) Groovy has had several syntax enhancements and features on top of Java. One can think of closures, for example, but also the ability to put more than just discrete values in `switch / case` statements, where Java 7 only allows `Strings `in addition. So some of the Project Coin syntax enhancements, like `Strings `in switch, were already present in Groovy. However, some of the enhancements are new, such as binary literals, underscore in number literals, or the multi catch block, and Groovy 2 supports them. The sole omission from the Project Coin enhancements is the "try with resources" construct, for which Groovy already provides various alternatives through the rich API of the Groovy Development Kit.

## Binary literals

In Java 6 and before, as well as in Groovy, numbers could be represented in decimal, octal and hexadecimal bases, and with Java 7 and Groovy 2, you can use a binary notation with the "0b" prefix:

```groovy
int x = 0b10101111
assert x == 175

byte aByte = 0b00100001
assert aByte == 33

int anInt = 0b1010000101000101
assert anInt == 41285
```

## Underscore in number literals

When writing long literal numbers, it's harder on the eye to figure out how some numbers are grouped together, for example with groups of thousands, of words, etc. By allowing you to place underscore in number literals, it's easier to spot those groups:

```groovy
long creditCardNumber = 1234_5678_9012_3456L
long socialSecurityNumbers = 999_99_9999L
double monetaryAmount = 12_345_132.12
long hexBytes = 0xFF_EC_DE_5E
long hexWords = 0xFFEC_DE5E
long maxLong = 0x7fff_ffff_ffff_ffffL
long alsoMaxLong = 9_223_372_036_854_775_807L
long bytes = 0b11010010_01101001_10010100_10010010
```

Multicatch block
----------------

When catching exceptions, we often replicate the catch block for two or more exceptions as we want to handle them in the same way. A workaround is either to factor out the commonalities in its own method, or in a more ugly fashion to have a catch-all approach by catching `Exception`, or worse, `Throwable`. With the multi catch block, we're able to define several exceptions to be catch and treated by the same catch block:

```groovy
try {
    /* ... */
} catch(IOException | NullPointerException e) {
    /* one block to handle 2 exceptions */
}
```

## Invoke Dynamic support

As we mentioned earlier in this article, JDK 7 came with a new bytecode instruction called *"invoke dynamic"*, as well as with its associated APIs. Their goal is to help dynamic language implementors in their job of crafting their languages on top of the Java platform, by simplifying the wiring of dynamic method calls, by defining *"call sites"* where dynamic method call section can be cached, *"method handles"* as method pointers, *"class values"* to store any kind of metadata along class objects, and a few other things. One caveat though, despite promising performance improvements, "invoke dynamic" hasn't yet fully been optimized inside the JVM, and doesn't yet always deliver the best performance possible, but update after update, the optimizations are coming.

Groovy brought its own implementation techniques, to speed up method selection and invocation with "call site caching", to store metaclasses (the dynamic runtime equivalent of classes) with its metaclass registry, to perform native primitive calculations as fast as Java, and much more. But with the advent of "invoke dynamic", we can rebase the implementation of Groovy on top of these APIs and this JVM bytecode instruction, to gain performance improvements and to simplify our code base.

If you're lucky to run on JDK 7, you'll be able to use a new version of the Groovy JARs which has been compiled with the "invoke dynamic" support. Those JARs are easily recognizable as they use the "-indy" classifier in their names.

## Enabling invoke dynamic support

Using the "indy" JARs is not enough, however, to compile your Groovy code so that it leverages the "invoke dynamic" support. For that, you'll have to use the --indy flag when using the "groovyc" compiler or the "groovy" command. This also means that even if you're using the indy JARs, you can still target JDK 5 or 6 for compilation.

Similarly, if you're using the groovyc Ant task for compiling your projects, you can also specify the indy attribute:

```xml
<taskdef name="groovyc"
        classname="org.codehaus.groovy.ant.Groovyc"
        classpathref="cp"/>
...
<groovyc srcdir="${srcDir}" destdir="${destDir}" indy="true">
    <classpath>
...
    </classpath>
</groovyc>
```

The Groovy Eclipse Maven compiler plugin hasn't yet been updated with the support of Groovy 2.0 but this will be the case shortly. For GMaven plugin users, although it's possible to configure the plugin to use Groovy 2.0 already, there's currently no flag to enable the invoke dynamic support. Again, GMaven will also be updated soon in that regard.

When integrating Groovy in your Java applications, with `GroovyShell`, for example, you can also enable the invoke dynamic support by passing a `CompilerConfiguration` instance to the `GroovyShell` constructor on which you access and set the optimization options:

```java
CompilerConfiguration config = new CompilerConfiguration();
config.getOptimizationOptions().put(**"**indy**"**, true);
config.getOptimizationOptions().put(**"int"**, false);
GroovyShell shell = new GroovyShell(config);
```

As invokedynamic is supposed to be a full replacement to dynamic method dispatch, it is also necessary to disable the primitive optimizations which generate extra bytecode that is here to optimize edge cases. Even if it is in some cases slower than with primitive optimizations activated, future versions of the JVM will feature an improved JIT which will be capable of inlining most of the calls and remove unnecessary boxings.

## Promising performance improvements

In our testing, we noticed some interesting performance gains in some areas, whereas other programs could run slower than when not using the invoke dynamic support. The Groovy team has further performance improvements in the pipeline for Groovy 2.1 however, but we noticed the JVM isn't yet finely tuned and still has a long way to go to be fully optimized. But fortunately, upcoming JDK 7 updates (in particular update 8) should already contain such improvements, so the situation can only improve. Furthermore, as invoke dynamic is used for the implementation of JDK 8 Lambdas, we can be sure more improvements are forthcoming.

## A more modular Groovy

We'll finish our journey through the new features of Groovy 2.0 by speaking about modularity. Just like Java, Groovy is not just a language, but it's also a set of APIs serving various purposes: templating, Swing UI building, Ant scripting, JMX integration, SQL access, servlet serving, and more. The Groovy deliverables were bundling all these features and APIs inside a single big JAR. However, not everybody needs everything at all times in their own applications: you might be interested in the template engine and the servlets if you're writing some web application, but you might only need the Swing builder when working on a rich desktop client program.

## Groovy modules

So the first goal of the modularity aspect of this release is to actually split the original Groovy JAR into smaller modules, smaller JARs. The core Groovy JAR is now twice as small, and we have the following feature modules available:

-   **Ant**: for scripting Ant tasks for automating administration tasks
-   **BSF**: for integrating Groovy in your Java applications with the old Apache Bean Scripting Framework
-   **Console**: module containing the Groovy Swing console
-   **GroovyDoc**: for documenting your Groovy and Java classes
-   **Groovysh**: module corresponding to the Groovysh command-line shell
-   **JMX**: for exposing and consuming JMX beans
-   **JSON**: for producing and consuming JSON payloads
-   **JSR-223**: for integrating Groovy in your Java applications with the JDK 6+ javax.scripting APIs
-   **Servlet**: for writing and serving Groovy script servlets and templates
-   **SQL**: for querying relational databases
-   **Swing**: for building Swing UIs
-   **Templates**: for using the template engine
-   **Test**: for some test support, like the GroovyTestCase, mocking, and more
-   **TestNG**: for writing TestNG tests in Groovy
-   **XML**: for producing and consuming XML documents

With Groovy 2, you're now able to just pick up the modules you're interested in, rather than bringing everything on your classpath. However, we still provide the "all" JAR which contains everything, if you don't want to complicate your dependencies for just a few megabytes of saved space. We also provide those JARs compiled with the "invoke dynamic" support as well, for those running on JDK 7.

Extension modules
-----------------

The work on making Groovy more modular also yielded an interesting new feature: extension modules. By splitting Groovy into smaller modules, a mechanism for modules to contribute extension methods has been created. That way, extension modules can provide instance and static methods to other classes, including the ones from the JDK or third-party libraries. Groovy uses this mechanism to decorate classes from the JDK, to add new useful methods to classes like `String, File`, streams, and many more - for example, a `getText()` method on URL allows you to retrieve the content of a remote URL through an HTTP get. Notice also that those extension methods in your modules are also understood by the static type checker and compiler. But let's now have a look at how you can add new methods to existing types.

Contributing an instance method
-------------------------------

To add new methods to an existing type, you'll have to create a helper class that will contain those methods. Inside that helper class, all the extension methods will actually be `public` (the default for Groovy but required if implementing in Java) and `static` (although they will be available on instances of that class). They will always take a first parameter which is actually the instance on which this method will be called. And then following parameters will be the parameters passed when calling the method. This is the same convention use for Groovy categories.

Say we want to add a `greets()` method on `String,` that would greet the name of the person passed in parameters, so that you could that method as follow:

```groovy
assert "Guillaume".greets("Paul") == "Hi Paul, I'm Guillaume"
```

To accomplish that, you will create a helper class with an extension method like so:

```groovy
package com.acme

class MyExtension {
    static String greets(String self, String name) {
        "Hi ${name}, I'm ${self}"
    }
}
```

## Contributing a static method

For static extension methods, this is the same mechanism and convention. Let's add a new static method to Random to get a random integer between two values, you could proceed as in this class:

```groovy
package com.acme

class MyStaticExtension {
    static String between(Random selfType, int start, int end) {
        new Random().nextInt(end - start + 1) + start
    }
}
```

That way, you are able to use that extension method as follows:

```groovy
Random.between(3, 4)
```

## Extension module descriptor

Once you've coded your helper classes (in Groovy or even in Java) containing the extension methods, you need to create a descriptor for your module. You must create a file called `org.codehaus.groovy.runtime.ExtensionModule` in the `META-INF/services` directory of your module archive. Four essential fields can be defined, to tell the Groovy runtime about the name and version of your module, as well as to point at your helper classes for extension methods with a comma-separated list of class names. Here is what our final module descriptor looks like:

```
moduleName = MyExtension
moduleVersion = 1.0
extensionClasses = com.acme.MyExtension
staticExtensionClasses = com.acme.MyStaticExtension
```

With this extension module descriptor on the classpath, you are now able to use those extension methods in your code, without needing an import or anything else, as those extension methods are automatically registered.

Grabbing an extension
---------------------

With the @Grab annotation in your scripts, you can fetch dependencies from Maven repositories like Maven Central. With the addition of the @GrabResolver annotation, you can specify your own location for your dependencies as well. If you are "grabbing" an extension module dependency through this mechanism, the extension method will also be installed automatically. Ideally, for consistency, your module name and version should be coherent with the artifact id and version of your artifact.

Summary
-------

Groovy is very popular among Java developers and offers them a mature platform and ecosystem for their application needs. But without resting still, the Groovy development team continues to further improve the language and its APIs to help its users increase their productivity on the Java platform.

Groovy 2.0 responds to three key themes:

-   **More performance**: with the **support of JDK 7 Invoke Dynamic** to speed up Groovy for those lucky to have JDK 7 already in production, but also with **static compilation** for JDK 5 and beyond for everyone, and particularly those ready to abandon some aspects of dynamicity to shield themselves from the reach of "monkey patching" and to gain the **same speed as Java**.
-   **More Java friendliness**: with the support of the **Java 7 Project Coin enhancements** to keep Groovy and Java as close syntax cousins as ever, and with the **static type checker** to have the same level of feedback and type safety as provided by the javac compiler for developers using Groovy as a Java scripting language
-   **More modularity**: with a new level of modularity, Groovy opens the doors for **smaller deliverables**, for example for integration in **mobile applications** on Android, and allowing the Groovy APIs to grow and evolve with newer versions and newer extension modules, as well as allowing users to contribute extension methods to existing types.
# Groovy 2.0 released!


The Groovy development team is very pleased to announce the release of Groovy 2.0, the highly popular dynamic language for the Java platform.  
  
For the key highlights of this important milestone, Groovy 2.0 comes packed with:  

*   a static type checker to let the compiler tell you about the correctness of your code,
*   static compilation for the performance of the critical parts of your application,
*   modularity, splitting the Groovy JAR into smaller feature-oriented JARs and letting you create your own extension modules,
*   JDK 7 Project Coin syntax enhancements, so that Groovy is still as friendly as possible with its Java cousin,
*   and JDK 7 Invoke Dynamic integration to benefit from the support of the JVM for dynamic languages.

  
To learn more about all those great key new features, please [read the Groovy 2.0 article on InfoQ](http://bit.ly/groovy2) that I’ve written, detailing and explaining all those novelties.  
  
To download Groovy 2.0, go to the [download area](http://groovy.codehaus.org/Download?nc=1) of the Groovy website.  
  
For further information on all the JIRA issues fixed in this release and the various betas and release candidates, you can have a look at the [JIRA changelog](http://bit.ly/groovy2jira).  
  
We’d like to thank all our users, all the contributors and committers who made this important release a reality, thanks to their feedback, their support, and their contributions.  
  
Have a Groovy day!  
  
Guillaume Laforge, on the behalf of the Groovy team.
# A bit of functional tests and concurrency for Gaelyk


Along with the [release of Gaelyk 1.2]({{< ref "/posts/2012/05/30/gaelyk-1-2-is-out" >}}), I'd like to share two interesting links about running functional tests with Geb, and concurrency / parallelism with GPars on [Gaelyk](http://gaelyk.appspot.com).  
Gaelyk functional testing with Geb  

In the Groovy ecosystem, we're all aware of the [Spock](http://code.google.com/p/spock/) testing framework. On top of Spock, you can use the [Geb](http://www.gebish.org/) browser automation library, to easily create functional tests for your web applications, in a nice, readable and expressive fashion.  

Thanks to [Marcin Erdmann](http://blog.proxerd.pl/), the [Gradle GAE plugin](https://github.com/bmuschko/gradle-gae-plugin) (used by the [Gaelyk template project](http://gaelyk.appspot.com/tutorial/template-project)) has been enhanced with support for running functional tests with Spock and Geb. Marcin (who's blog is actually a fork of my [Bloogaey](https://github.com/glaforge/bloogaey) app) has written a [small tutorial on how to get started](http://blog.proxerd.pl/article/funcational-testing-of-gae-lyk-applications-with-geb).  

## Concurrency and parallelism with GPars  

Another great library of the Groovy universe is [GPars](http://gpars.codehaus.org/), which is bundled with the Groovy distribution. GPars offers a ton of features for your concurrency and parallelism needs: actors, fork/join abstractions, dataflow concurrency, agents, etc.  

On Google App Engine, until recently, it wasn't allowed to spawn threads in your applications. So it was impossible to use a library like GPars in your Gaelyk applications. Fortunately, Google introduced a [ThreadManager class](https://developers.google.com/appengine/docs/java/javadoc/com/google/appengine/api/ThreadManager) so that you can spawn up to 10 threads in your incoming requests.  

Gaelyk committer [Vladimír Oraný](https://twitter.com/musketyr) teamed up with Vacláv Pech (lead of GPars) to work on an extension library to allow GPars to use that thread manager for GPars' own thread pools. Vacláv tells us about this story on [his blog](http://www.jroller.com/vaclav/entry/gpars_actors_and_dataflow_for) and even points at the [GPars web console](http://gparsconsole.appspot.com/) where you can try some parallel / concurrent features from GPars.
# Release candidate of Groovy 2.0 available


This is with great pleasure that the development team announces the release candidate of Groovy 2.0.  

For the impatient among you, you can download Groovy 2.0 RC-1 in the [download area](http://groovy.codehaus.org/Download?nc) of the Groovy website. 
And read the [JIRA changelog](https://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=18472).  

The big change in this release candidate is the modularity aspect. We've now fully switched to Gradle, as our build tool, to build a more modular Groovy. You still have a big "all" JAR, but if you're interested in just picking the core JAR and the needed modules for your project, you can now do so.  

The following modules, also available as Maven artifacts, have been created and extracted: `ant`, `bsf`, `console`, `docgenerator`, `groovydoc`, `groovysh`, `jms`, `json`, `jsr-223`, `servlet`, `sql`, `swing`, `templates`, `test`, `testng`, `xml`.  

Also, it's possible for you to create your own extension modules, which will provide additional methods to JDK or third-party classes, just like Groovy does with the Groovy Development Kit.  

For more information on this extension module system, please have a look at this [page](http://docs.codehaus.org/display/GROOVY/Creating+an+extension+module) explaining the details.  

We're looking forward to your feedback on this release! This is very important that you test this release within your projects to report anything, any bug or issue that you may encounter, so that we can make a great 2.0 release.  

We're particularly interested in feedback on the invoke dynamic support, the static type checking, the static compilation, as well as the new modularity of Groovy.  

Thanks a lot for your attention and precious time helping us releasing a great new milestone of the project!  

And big thanks to all those who contributed to this release!  

On behalf of the Groovy development team, we hope you'll all keep on groovy'ing :-)
# Gaelyk 1.2 is out!


![](/img/misc/gaelyk.png)

I'm very pleased to announce the release of [Gaelyk 1.2](http://gaelyk.appspot.com)!  
  
For the impatient, you'll be able to find the new JAR and Template Project here, as well as the changelog: [http://gaelyk.appspot.com/download](http://gaelyk.appspot.com/download)  
  
You'll notice that the new template project uses Twitter Bootstrap now, to make it a bit fancier and nicer on the eye!  

![](/img/misc/gaelyk+template+bootstrap.png)  

We also upgraded to the latest and greatest of Groovy and App Engine's SDK.  
  
In terms of new features, I'd like to particularly highlight:  

*   the gradle gaelyk plugin offers [pre-compilation of groovlets and templates](https://github.com/bmuschko/gradle-gaelyk-plugin#tasks) for faster startup times
*   the [integration of the search service](http://gaelyk.appspot.com/tutorial/app-engine-shortcuts#search) with some nice syntax sugar for simplifying its usage
*   the [binary plugins](http://gaelyk.appspot.com/tutorial/plugins#binaryplugins) feature
*   the [`@Entity` transform](http://gaelyk.appspot.com/tutorial/app-engine-shortcuts#pogo-entity-coercion-annotations) to add datastore CRUD operations to your Groovy classes
*   the new [`geo` variables](http://gaelyk.appspot.com/tutorial/views-and-controllers#lazy) in the binding to know where your users are coming from
*   and a few other improvements and fixes

Thanks a lot to the Gaelyk committers, and in particular to Vladimir who helped me a lot on the finish line of this release!  
  
Have fun with Gaelyk!  

And we're looking forward to hearing about your feedback and experience with this new release.
# Why coming to #GR8Conf?


I was reading [MrHaki's interview](http://gr8conf.eu/blog/Interview-with-MrHaki) on the [GR8Conf website](http://gr8conf.eu) this morning, and he had some nice words and good points about why it's important to attend the conference. You get to meet the creators and developers of the projects you're interested in and have great content (emphasis mine):  

> I am looking forward to meeting all the great people that make up the Groovy ecosystem. Everybody is always nice, friendly and ready to help. The atmosphere is always nice and laid back.   
> 
> The presentations always are high level and mostly done by the creators of the projects and frameworks. So the information is really from the source and that means you always get the latest information first at the conference.

And on what attendees should expect (again emphasis mine):

> If you are using Groovy, Grails, Gradle or any of the other Groovy-related technologies, or you plan to do so, you should really come to the conference. This is your chance to meet the people that create the great products and use it in their daily development. You will get inside information and experience real-life usage of these technologies.   
> 
> After the conference you will be inspired and ready to apply your newly learned knowledge in your daytime job or projects.

I'm looking forward to meeting you there!
# Vert.x 1.0 released with its Groovy support


[Tim Fox](https://twitter.com/#!/timfox) yesterday announced [the release of Vert.x 1.0](http://vertxproject.wordpress.com/2012/05/09/vert-x-1-0-final-is-released/).  

[Vert.x](http://vertx.io/) is a kind ofasynchronous application development environment and server. It works on the JVM, with JDK 7, and supports several languages like Java, [Groovy](http://vertx.io/groovy_web_tutorial.html), Ruby or JavaScript.  

As the website puts it, vert.x can be defined along the following axis:

*   **polyglot**: supporting Java, Groovy, Ruby and JavaScript or a mix and match of any of these even in a single application
*   **simplicity**: just a few lines of code to create your servers and components, without any XML configuration or anything like that, without being too simplistic
*   **scalability**: with Netty under the hood, with a message passing approach, it's taking full advantage of the cores of your CPU(s)
*   **concurrency**: vert.x provides a simple concurrency-model so you don't mess with traditional multithreaded programming

Vert.x competes directly with Node.js here, and Tim also positions it against the Play! 2 / Akka combo.  

What's also worth looking at is the [benchmark](http://vertxproject.wordpress.com/2012/05/09/vert-x-vs-node-js-simple-http-benchmarks/) that he ran against Node.js, showing that vert.x clearly outperforms Node.js. Also interesting is the fact that when using Groovy, there's just a very small overhead over using Java, although the simple benchmark didn't even use the upcoming static compilation feature of Groovy 2.0.  

Congratulations to the vert.x team for the release!  

I'm impatient to play with it on [Cloud Foundry](http://cloudfoundry.com/), once it supports JDK 7.
# Slides for Domain-Specific Languages in Groovy


During the Cloud Foundry Open Tour conference in Moscow, I presented a new presentation of [Domain-Specific Languages in Groovy](http://www.slideshare.net/glaforge/going-to-mars-with-groovy-domainspecific-languages). I've already shared the link here and there (twitter, Google+, mailing-list), but not yet on my blog. So consder this fixed now. This new presentation is inspired from the beta DSL chapter from the second edition of Groovy in Action, where you'll learn how to create a DSL for a little Mars robot. This is a pretty practical approach, bottom-up, as you progressively build the DSL, rather than listing all the existing techniques and illustrate them. I feel the flow is a bit better that way. Anyway... enjoy: 

{{< slideshare 12700368 >}}
# Groovy at Devoxx France


Last week saw the first edition of [Devoxx France](http://www.devoxx.fr/display/FR12/Accueil). And what a success it was! The conference was sold out at 1200 persons. There was a great wealth of interesting topics and many passionate attendees to talk to. Overall, I come back home impressed that the first edition worked out so well, flawlessly, and was such a joy to attend. So a big thank you and congrats to all those involved in making Devoxx France such a great event!  

Along with [Cédric Champeau](http://www.jroller.com/melix/), I had the pleasure to present the novelties of Groovy 2.0 (and a bit of retrospective on some of the key features of Groovy 1.8). We covered quickly the invoke dynamic support and modularization, and went into more depth into the static type checking and static compilation aspects.  

I've pushed the [slides of that presentation](http://www.slideshare.net/glaforge/groovy-20-devoxx-france-2012) on Slideshare, please see below for the embedded presentation.  

What was also interesting was to update my informal benchmarks which looked at the performance of Groovy in a certain number of situations:

*   without particular improvements (ie Groovy 1.7 and before),
*   with the primitive optimizations (Groovy 1.8),
*   and with static compilation.

The results are pretty good and show that in static compilation mode, Groovy's performance is as good as Java in most cases. There are still some improvements we can make, some bytecode to clean up, some bugs to iron out, etc, but overall, the goal of attaining Java's performance is reached. 

For my benchmark, I took some Java implementations of the Fibonaci suite, the calculation of Pi (quadrature style), and a binary tree implementation. I converted them to Groovy (often, it's just a file extension rename, plus removing some semicolons for good measure), without really trying to optimize them in a Groovy manner. And the results I got looked as follows:  

Fibonaci Pi (quadrature) Binary trees Java 143 ms 93 ms 4.5 s Groovy with static compilation 145 ms 96 ms 6.9 s Groovy with primitive optimizations 271 ms 103 ms 29.6 s Groovy without optimizations 3200 ms 2590 ms 50.0 s So that's pretty good news for those who are looking for performance, and more generally it'll benefit anyone as well in any case.  

And now... the slides!  

{{< slideshare 12628457 >}}
# Run a Groovy script in Vi


In the Vi vs Emacs war, I'm in the Vi camp. I'm using Vim on the command-line to quickly edit files, and I'm also using MacVim on my Mac as my text editor. When I'm not using an IDE or the Groovy Console, I also want to be able to edit and run my Groovy scripts in my text editor. It's not too difficult to run a Groovy script from Vi, you can simply do:

```vi
:!groovy %
```

You use the colon to enter the command mode, then use the bang to issue a shell command. Here, obviously, I'm going to run the groovy command. And I can then pass the script I'm editing as parameter thanks to the percent sign, which points at the current file in my buffer.  

The drawback is that the output is the command area, but I wanted to get the output in its own buffer. So I spent a bit of time to flesh out my Vi skills, and came up with a function to open a new scratch buffer and output the result of the script execution in that new buffer, with the following script that I added in my `.vimrc` configuration:

```javascript
// the function to run my groovy scripts 
function! RunGroovy() 
    // copy the current buffer file name in a variable 
    let gfname=@% 
    // open a new buffer in my window below 
    botright new 
    // define the buffer to be a mere scratch buffer not intended to be edited or saved 
    setlocal buftype=nofile bufhidden=wipe nobuflisted noswapfile nowrap 
    // create a temporaty file name to hold the output of the execution of my Groovy script 
    let gtmpf = tempname() 
    // define the command line to launch my Groovy script and retrieve its output in the temporary file 
    let gcmd = ':!groovy ' . gfname . ' > ' . gtmpf 
    // execute the groovy command 
    silent execute gcmd 
    // insert the content of the output from the temporary file in my buffer 
    silent execute '0r ' . gtmpf
endfunction   

// add F5 as the shortcut for executing my Groovy scripts 
map :call RunGroovy()
```

I'm definitely not a Vi expert, and this script can be improved greatly probably. But it's good enough for now. But I'm open to improvements if the Vi experts reading this blog want to join in and give me advice!
# Come to GR8Conf for half the price!


This is this time of the year where all the Groovy hackers and fans are meeting together in Denmark, Copenhagen, for the [GR8Conf conference](http://gr8conf.eu/). A conference dedicated to [Groovy](http://groovy.codehaus.org), Grails, Gradle, Griffon, Spock, GPars and all the Groovy ecosystem. If you're interested in these technologies or are already using them, this is the opportunity you shouldn't miss.  

Also, you're pretty lucky, because I have a ticket for half the price to offer you! But there's just one seat I can offer at that price. So if you're interested, please add a nice comment to this post, that may be fun, or explaining why you'd like to come, and in a few weeks, I'll tell you who deserves to win this prize!  

Ready, Steady, Groovy!
# bash tip: find and grep through files


It happens once in a while that I want to find all files containing a certain string. I know command-line tools such as grep, cat, and find, but I never remember the right combination to achieve that task. So as to remember and reference it later, I write this small blog post to remind me how to do it:

```bash
find . -type f -exec grep YOURSTRING /dev/null {} \;
```

The `find .` part will search from the current directory (and all its subdirectories), `- type f` to search for files (not directories or links, etc), `-exec` to use the grep command to find through the files, with YOURSTRING as query string, /dev/null to throw away the errors you don't care about, and `{}` is the current file to search into with grep.

**Update:** a simple approach proposed in the comments is:

```bash
grep -r YOURSTRING \*
```
# Incomplete string regex matching


Once in a while, I stumble upon the need of being able to tell whether a string could match a certain regular expression pattern, if it were given some more characters.  

For example, a user is typing a time in an input field, following the pattern of 2 digits, a colon, and 2 other digits. He enters the first two digits and the colon, and we're wondering if the time could be valid if he entered some more keystrokes.  

I found the [JRegex](http://jregex.sourceforge.net/) project and its documentation about [incomplete matching](http://jregex.sourceforge.net/gstarted-advanced.html#imatching) which showed me that it was possible to achieve such a goal. But using JRegex is adding another library on the classpath for such a small requirement, that I started wondering if there was a way to emulate that with Java's own regex support.  

We're used to methods like [`matches()`](http://docs.oracle.com/javase/6/docs/api/java/util/regex/Matcher.html#matches()) / [`find()`](http://docs.oracle.com/javase/6/docs/api/java/util/regex/Matcher.html#find()) on [`Matcher`](http://docs.oracle.com/javase/6/docs/api/java/util/regex/Matcher.html), but not so much with some of the other methods. I thought [`lookingAt()`](http://docs.oracle.com/javase/6/docs/api/java/util/regex/Matcher.html#lookingAt()) could be of help, but it's only interesting if you want to check that the beginning of an input string matches a pattern... whereas we want a full string to match the beginning of a pattern instead.  

After twitting about my quest, Fred Martini came up with the [solution](https://twitter.com/#!/adiguba/status/184649138464493569) to my problem. Thanks Fred! And the winner is... [`hitEnd()`](http://docs.oracle.com/javase/6/docs/api/java/util/regex/Matcher.html#hitEnd()). Looking at the JavaDoc, it's not that explicit how it could be used...  

> `public boolean hitEnd()`
>   
> Returns true if the end of input was hit by the search engine in the last match operation performed by this matcher.   
>
> When this method returns true, then it is possible that more input would have changed the result of the last search.  
>   
> **Returns:** true iff the end of input was hit in the last match; false otherwise  

When the matcher is trying to match the pattern against the input stream, it arrives at the end of the input stream before it could really say if the string matched that pattern or not. And as the JavaDoc says, perhaps that with some more input, the search could have succeeded.  

More concretely, let's have a look at a quick example, coded in Groovy for simplicity sake:  

```groovy
def input = /12:/ 
def pattern = Pattern.compile(/\\d{2}:\\d{2}/) 
def matcher = pattern.matcher(input) 

assert matcher.matches() || matcher.hitEnd()
```

Or for a more idiomatic Groovy version:  

```groovy
def matcher = /12:/ =~ /\\d{2}:\\d{2}/  
assert matcher.matches() || matcher.hitEnd()
```

Thinking about it... we could even add a `matchesPartially()` to the GDK!
# Groovy 2.0 presentation at 33rd Degree


Here are the slides of the Groovy 2.0 presentation I've given at the 33rd Degree conference in Krakow.  

{{< slideshare 12092341 >}}
# Speaking of Groovy 2.0 at 33rd Degree, in Poland


Tomorrow I'm flying to Krakow, in Poland, to [speak about the upcoming Groovy 2.0](http://2012.33degree.org/talk/show/17) release, at the [33rd Degree conference](http://2012.33degree.org/). I'm looking forward to meeting some of you there!  
Here's my abstract for What's new in Groovy 2.0?  

> After a quick look at the key features of Groovy 1.8, including more readable Domain-Specific Languages, concurrency capabilities with the GPars library, and built-in JSON support, we'll dive right into the most important features of Groovy 2.0!   
> A lot of the Groovy users are using the language as a Java scripting language, or sometimes as a better Java. First of all, not all of them need the dynamic capabilities, nor do they need all the library improvements provided by Groovy. For the latter, Groovy becomes more modular with smaller core modules that you can compose. For the former, in addition to its usual dynamic features, Groovy 2.0 adds static type checking, allowing you to ensure the correctness of your code before it ships and quickly spot early errors at compile time.   
> Also, not everybody needs dynamic features at all times, and the natural extension to static type checking is static compilation. With static compilation, Groovy 2.0 generates fast and performant bytecode like Java, and shields key parts of your code base from possible interferences of dynamic features, making critical paths both faster and immune to monkey patching. But when you need fast and performant dynamic logic, Groovy 2.0 also features the integration of the "invoke dynamic" support coming up with JDK 7 and beyond.

# Mac trick: change Time Machine backup interval


If you think Time Machine is backing up your Mac too often, you can customize the interval between two automatic scheduled backups. I found that trick on [MacYourself](http://www.macyourself.com/2010/02/21/how-to-change-time-machine-backup-interval-backup-manually/).  

Open up a Terminal, and change the value, in seconds, of the interval (here 7200 seconds == 2 hours instead of the standard one hour):  

```bash
sudo defaults write /System/Library/LaunchDaemons/com.apple.backupd-auto StartInterval -int 7200
```

**Update:** This doesn't seem to work on Mac OS X Lion, although it worked in previous versions (like Leopard). Till we find a good workaround, Thomas, in the comments, suggested looking at this nice little utility: [Time Machine Scheduler](http://www.klieme.com/TimeMachineScheduler.html).
# Groovy news bits: API additions, contributing to the project, Eclipse plugin


With the recent [release of Groovy 1.8.6]({{< ref "/posts/2012/02/09/groovy-1-8-6-released" >}}), Groovy contributor Tim Yates, posted a few blog posts about some of the little useful enhancements that found their way in the release:

*   [`Array#contains()`](http://blog.bloidonia.com/post/18186368994/whats-new-in-groovy-1-8-6-array-contains)
*   [`Byte[]#encodeHex()`](http://blog.bloidonia.com/post/18125339463/whats-new-in-groovy-1-8-6-byte-encodehex)
*   the very useful [`collate()` method](http://blog.bloidonia.com/post/18073244930/whats-new-in-groovy-1-8-6-the-collate-method)

Tim also wrote a really great and detailed blog post explaining [how to contribute to the Groovy project](http://blog.bloidonia.com/post/17711808015/submitting-code-to-the-groovy-language). Be sure to check it out if you've always wanted to contribute to the project. Tim shows how to get started, to propose a new feature or bug fix through JIRA, how to submit a pull request through GitHub, etc.  

[Tim Yates' blog](http://blog.bloidonia.com/) is worth subscribing to!  

And last but no least, hot from the oven, Andrew Eisenberg from the Groovy Eclipse team covers the [latest enhancements to the Groovy Eclipse plugin](http://docs.codehaus.org/display/GROOVY/Groovy-Eclipse+2.6.1+New+and+Noteworthy): with various inferencing enhancements, new quick fixes and quick assists, and more.
# Don't forget the GR8Conf Call for Papers


(http://gr8conf.org/), the Groovy ecosystem conference series, are coming to Denmark and to the USA in a few months. You'll learn about the latest novelties about tons of great Groovy-based technologies, like Groovy, Grails, Gaelyk, Gradle, GPars, Griffon, Spock, CodeNarc and more. It's the best place to engage with the community, get to know the developers of those projects, and present your success stories, and more.  

If you're willing to speak at the conference about all those topics, please head over to the GR8Conf Call for Papers. And hurry up, there's less than one week left!  

*   [GR8Conf Europe Call for Paper](http://gr8conf.eu/cfp)
*   [GR8Conf US Call for Paper](http://gr8conf.us/Presentation-Proposal)

I'm really looking forward to seeing you there!
# Groovy 1.8.6 released


The Groovy development team is pleased to announce the release of Groovy 1.8.6.

Groovy 1.8.6 is a maintenance release essentially, with a few minor improvements and new features.

You can see the details in the JIRA release notes here:  
[http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=18245](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=18245)

You can download Groovy 1.8.6 in the Download section of the Groovy website:  
[http://groovy.codehaus.org/Download](http://groovy.codehaus.org/Download)

Thanks a lot to all those who contributed to this release!

Next in line should be a new beta of Groovy 2.0 ;-)
# Static type checking and compilation in Groovy 2


[Cédric Champeau](https://twitter.com/cedricchampeau), the Groovy core developer working on static type checking and static compilation for Groovy 2, recently gave a very interesting and instructive presentation on this topic at the [Paris Groovy / Grails User Group](http://www.meetup.com/Paris-Groovy-Grails/), at the VMware offices.  

You can have a look at his [blog post about the presentation](http://www.jroller.com/melix/entry/static_type_checking_talk_from), including some additional comments regarding the method dispatch logic, some status update and directions.  

And you should also have a look at Cédric's [analysis of the polls](http://www.jroller.com/melix/entry/static_compilation_for_groovy_poll) embedded in the presentation which asked a few questions about people's preferences and expectations with regards to statuc type checking and compilation. Don't hesitate to add your own input, as the poll is not closed and feedback is always welcome.
# GR8Conf Europe Call for Paper open


[GR8Conf Europe 2012](http://gr8conf.eu/content/eu2012/index) will take place in Copenhagen, on June 6th-8th. It's the best place to meet all the Groovy folks, from Groovy itself, and from the wealth of the Groovy Ecosystem (Grails, Gradle, GPars, Griffon, Spock, GContracts, CodeNarc, Gaelyk/Caelyf, etc). It's also the best opportunity to stay up-to-date with the latest developments, and discover what's cooking!  

The Call for Paper is open. So don't hesitate to [submit your proposal](http://gr8conf.eu/content/eu2012/cfp).  

Some useful links:

*   [GR8Conf Europe website](http://gr8conf.eu/content/eu2012/index)
*   GR8Conf Europe [Call for Paper](http://gr8conf.eu/content/eu2012/cfp)
*   [Follow @GR8Conf](https://twitter.com/#!/gr8conf) on Twitter to be notified about the latest news
# Mon One Man Show au Paris JUG


Lors de l'[enregistrement du 50ème](http://lescastcodeurs.com/2011/12/les-cast-codeurs-podcasts-episodes-50-lanniversaire/) épisode des [Cast Codeurs](http://lescastcodeurs.com/) au [Paris JUG](http://www.parisjug.org/xwiki/bin/view/Main/WebHome), j'ai eu le plaisir de faire un petit "one man show" comique (enfin j'ai essayé) sur notre métier d'informaticien, les tendances du moment, les news et autres scoops, etc.  

Cette idée est partie d'une discussion avec [Nicolas Martignole](http://www.touilleur-express.fr/) il y a 6 mois où l'on s'était dit que ce serait amusant de plaisanter un peu sur notre métier, les technos que l'on utilise, etc, et d'en faire une présentation humoristique. Et encouragé par les Cast Codeurs, je me suis lancé ce défi d'essayer de faire rire mon auditoire. A vous de juger si j'ai réussi ! Et je tiens à dire que les rires que vous entendrez sur l'enregistrement n'ont pas été rajoutés après coup ;-)  

J'en profite pour dire un grand merci à Charles et David pour l'enregistrement et la post-production pour pouvoir offrir [cette présentation sur Parleys](http://www.parleys.com/#st=5&id=2957&sl=0) !  

La présentation commence vraiment après les 2 premières minutes, à cause de quelques petits problèmes techniques avec mon ordinateur.
# Hans Dockter interview on Gradle


While at the [Groovy/Grails eXchange conference]({{< ref "/posts/2011/12/17/videos-and-slides-of-groovy-grails-exchange-2011" >}}) in London last month, I had the pleasure and honour to interview [Hans Dockter](http://gradleware.com/team), creator of [Gradle](http://gradle.org) and CEO of [GradleWare](http://gradleware.com/). This [interview was recorded](http://skillsmatter.com/podcast/home/interview-on-gradle/js-3210) and published by [SkillsMatter](http://skillsmatter.com/).  

Here's a list of questions I had the chance to ask Hans:  

*   What's Gradle?
*   Any new about Gradle 1.0 and what's being worked on?
*   Why is Gradle using Groovy for its DSL?
*   Is it possible to enforce conventions and standards à la Maven?
*   Some words on IDE integration, roadmap, etc?

Check the [video](http://skillsmatter.com/podcast/home/interview-on-gradle/js-3210)!
# Tweets sympas sur Free Mobile


Xavier Niel a annoncé en fanfare l'arrivée de [Free Mobile](http://mobile.free.fr/index.html) après un long suspense et un buzz savamment orchestré. Et j'ai retenu quelques tweets qui m'ont bien fait rire :  

*   [Enfin on peut dire t'as un forfait à 2 balles mon gars](https://twitter.com/#!/Nanaki43/status/156754481328033793)
*   [Quand les mouettes changent d'opérateur, c'est qu'elles pensent qu'elles sont devenues des pigeons #Cantona](https://twitter.com/#!/Assia_H/status/156745335186792449)
*   [Je ne regarderais plus jamais une pièce de 2€ de la même manière](https://twitter.com/#!/75_Scientifique/status/156740776703959041)
*   [#Freemobile 19,99€ en tout illimité. A ce prix là, on va enfin pouvoir se faire 5 #Free et légumes par jour.](https://twitter.com/#!/TilltheCat/status/156653694312644608)
*   [#Free vient de faire plus pour le pouvoir d'achat en 5 minutes que Nicolas #Sarkozy en 5 ans...](https://twitter.com/#!/ChristopheGen/status/156659272422408192)
*   [Au resto à midi on a failli laisse un pourboire de 2€. Puis on s'est dit que c'était quand même un mois de forfait...](https://twitter.com/#!/Thinkit/status/156720751502835712)

On verra si Orange se presse de réagir ou s'il voit rouge, si Bouygues bétonne ses offres ou si SFR va se laisser faire...
# Caelyf 0.1, a lightweight Groovy toolkit for Cloud Foundry


I'm very happy to announce the release of [Caelyf](http://caelyf.cloudfoundry.com) 0.1, a lightweight Groovy toolkit for Cloud Foundry.  

Caelyf is inspired by the [Gaelyk](http://gaelyk.appspot.com) project, and actually borrows most of its code base. Its goal is to let you write apps using Groovy scripts and templates, and then deploy them on the Cloud Foundry platform.  

Caelyf is Open Source, released under the Apache 2 license.  

Its source code is hosted on GitHub: [https://github.com/glaforge/caelyf](https://github.com/glaforge/caelyf) Which means you will also be able to use the issue tracker from GitHub to file bugs or feature requests. And of course, if you want to contribute to the project, you're just one pull request away!  

We're using [Google groups](https://groups.google.com/group/caelyf) for interacting with our upcoming users.  

Caelyf is obviously very young (ie. that's its first release), so it might be rough around the edges, and I'd appreciate if you provide me with some feedback as you delve into the project and deploy your first applications.  

As a proof of concept, the first application written with Caelyf is the Caelyf website itself: [http://caelyf.cloudfoundry.com](http://caelyf.cloudfoundry.com) It's always great to be able to eat one's own dog food!  

On the [Caelyf website](http://caelyf.cloudfoundry.com), you'll find a [detailed tutorial](http://caelyf.cloudfoundry.com/tutorial) explaining what you can do with the framework, and how to use it. I haven't included the steps to get setup on Cloud Foundry, but you'll find the link to the Cloud Foundry documentation for that purpose.  

You will also find the links for downloading a template project, or just a JAR if you prefer that: [http://caelyf.cloudfoundry.com/download](http://caelyf.cloudfoundry.com/download)  

Well, that's pretty much it, so, have fun, tell me what your experience is, and Merry Christmas :-)
# Groovy 1.8.5 and second beta of 2.0 out


The Groovy development team has just announced a joint release of Groovy 1.8.5 and a second beta of the upcoming 2.0 release.  
We'd be happy to hear your feedback on the static type checking support and the experimental static compilation as well.  
Here's the [official announcement](http://docs.codehaus.org/display/GROOVY/2011/12/23/Groovy+1.8.5+and+2.0-beta-2+released):

> The Groovy development team is happy to deliver two new releases as early Christmas presents: Groovy 1.8.5 and 2.0-beta-2.  
>   
> While we work hard on Invoke Dynamic support, Static Type Checking and some experimental static compilation, we also find time to fix a good load of bugs and some minor improvements, as those two releases here are essentially minor incremental versions.  
>   
> You can have a look at the tickets closed here, for 1.8.5:  
> [http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=18071](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=18071)  
>   
> And here for 2.0-beta-2:  
> [http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=18072](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=18072)  
>   
> You can download both distributions at the usual place:  
> [http://groovy.codehaus.org/Download?nc](http://groovy.codehaus.org/Download?nc)  
>   
> If you want to play with the experimental static compilation, you can do so by following the instructions from the GEP-10 page:  
> [http://docs.codehaus.org/display/GroovyJSR/GEP+10+-+Static+compilation](http://docs.codehaus.org/display/GroovyJSR/GEP+10+-+Static+compilation) Look for the "testing" paragraph in the middle of the document, which contains a link to the experimental JAR, as well as some basic explanations.  
>   
> Thanks a lot to all those who contributed to this release: developers, contributors, users, bug reporters.  
>   
> On behalf of the Groovy development team, we'd like to wish you a Groovy Christmas and a very Happy New Year.
# Videos and slides of Groovy / Grails eXchange 2011


A week ago ended the latest edition of the [Groovy & Grails eXchange 2011](http://skillsmatter.com/event/groovy-grails/groovy-grails-exchange-2011/js-3132) conference in London, organized by the fine and lovely folks of [SkillsMatter](http://skillsmatter.com/).  

The organizers have a great setup which allows them to record and publish all the presentations almost live! And I'd like in this post to give you a link to each and every presentation that was given during the conference:  

First day:  

*   [Groovy 1.8, 2.0 and beyond](http://skillsmatter.com/podcast/groovy-grails/talk-by-guillaume-laforge-2475) by Guillaume Laforge
*   [Discobot: Groovy on Android](http://skillsmatter.com/podcast/groovy-grails/groovy-android) by Erik Pragt and Marcin Erdmann
*   [A Gaelyk update](http://skillsmatter.com/podcast/groovy-grails/gaelyk) by Guillaume Laforge
*   [Getting Groovy on the web and desktop](http://skillsmatter.com/podcast/groovy-grails/effective-groovy) by Andres Almiray
*   [Enterprise Gradle](http://skillsmatter.com/podcast/groovy-grails/enterprise-gradle) by Hans Dokter
*   [Advanced Gradle](http://skillsmatter.com/podcast/groovy-grails/advanced-gradle) by Hans Dokter
*   [Painless desktop application development with Griffon](http://skillsmatter.com/podcast/groovy-grails/griffon) by Andres Almiray
*   [Smarter testing with Spock](http://skillsmatter.com/podcast/groovy-grails/spock) by Luke Daley
*   [Asynchronous IO on the web with vert.x](http://skillsmatter.com/podcast/groovy-grails/groovy-vert-x) by Peter Ledbrook
*   [Just keep passing the messages with GPars](http://skillsmatter.com/podcast/groovy-grails/gpars) by Russel Winder
*   [Powerful metaprogramming techniques with Groovy](http://skillsmatter.com/podcast/groovy-grails/metaprogramming-groovy) by Jeff Brown

Second day:  

*   [Better productivity with Grails 2.0](http://skillsmatter.com/podcast/groovy-grails/grails-2-0) by Peter Ledbrook
*   [Using Weceem, an embeddable CMS](http://skillsmatter.com/podcast/groovy-grails/using-weceem-an-embeddable-grails-cms) by Marc Palmer
*   [Hacking the Grails Spring Security plugin](http://skillsmatter.com/podcast/groovy-grails/hacking-the-spring-security-plugin) by Burt Beckwith
*   [Tackling day to day Grails decisions](http://skillsmatter.com/podcast/groovy-grails/tackling-day-to-day-grails-decisions) by Andreas Arledal
*   [Grails data mapping, make your NoSQL store GORM compliant](http://skillsmatter.com/podcast/groovy-grails/grails-data-mapping-making-your-nosql-database-gorm-compliant) by Stefan Armbruster
*   [A year in the life of a Grails startup](http://skillsmatter.com/podcast/groovy-grails/grails-as-mobile-backend) by Tomas Lin and Donovan Frew
*   [Testing HTTP dependencies with BetaMax](http://skillsmatter.com/podcast/groovy-grails/testing-http-dependencies-with-betamax) by Robert Fletcher
*   [Continuous delivery in the cloud with CloudBees](http://skillsmatter.com/podcast/groovy-grails/continuous-delivery-in-the-cloud-with-cloudbees) by Marco Vermeulen and Nicolas de Loof
*   [Productive Grails functional testing](http://skillsmatter.com/podcast/groovy-grails/productive-grails-functional-testing) by Luke Daley
*   [A cloud for developers: Cloud Foundry](http://skillsmatter.com/podcast/groovy-grails/grails-cloud-foundry) by Peter Ledbrook
*   [Maintaining test suites with Groovy and Twist](http://skillsmatter.com/podcast/groovy-grails/talk-to-be-confirmed-2810) by Andrew Kemp
*   [Keeping Grails one step ahead](http://skillsmatter.com/podcast/groovy-grails/keeping-grails-one-step-ahead) by Marc Palmer

And there's also my little [interview of Hans Dokter about Gradle](http://skillsmatter.com/podcast/groovy-grails/interview-on-gradle)!
# InfoQ interview: Latest Happenings and Future of Groovy


I had the pleasure of being interviewed by Rick Hightower for InfoQ, on the features of Groovy 1.8, and also what we're working on for Groovy 2.0.  

If you're interested, here's the article: [Latest Happenings and Future of Groovy 1.8, 2.0 and Beyond](http://www.infoq.com/news/2011/11/groovy-updates)
# Handy Gradle startup script


[Dierk](https://twitter.com/mittie) published a [gist](https://gist.github.com/1271516) on GitHub with a handy Gradle build script to help you bootstrap a Gradle-built project from scratch, without having to create the directory layout manually, or install the Gradle wrapper.

This is pretty neat and should be integrated in Gradle to ease the creation of projects!

I've [updated the gist](https://gist.github.com/1393868) with a more recent version of Groovy and Gradle.

And so that I never forget about this handy Gradle build script, I'm blogging about it and reproducing it here, to save me precious minutes finding it again the next time I need it! So without further ado, here's the script in question:

```groovy
apply plugin : 'groovy'
apply plugin : 'idea'

repositories { mavenCentral() }

dependencies {
    groovy 'org.codehaus.groovy:groovy-all:1.8.4'
}

task makeDirs(description : 'make all dirs for project setup') << {
    def sources = [sourceSets.main, sourceSets.test]
    sources*.allSource\.srcDirs.flatten().each { File srcDir ->
        println "making $srcDir"
        srcDir.mkdirs()
    }
}
task wrap(type : Wrapper, description : "create a gradlew") {
    gradleVersion = '1.0-milestone-6'  }
```
# Coming back to the new Google App Engine pricing policy


In a recent article, I was [complaining about the new Google App Engine pricing policy]({{< ref "/posts/2011/09/01/google-app-engine-s-new-pricing-model" >}}). Obviously, as I have a few applications deployed on App Engine, and as I'm developing [Gaelyk](http://gaelyk.appspot.com), a lightweight toolkit for this platform, I was worried about being heavily affected by those changes.  

In this article, I'd like to do a short summary of my experience so far.  

I have close to 10 applications deployed on Google App Engine. Most are just demos that nobody ever accesses. But three of them are quite important to me:

*   [the Gaelyk website](http://gaelyk.appspot.com)
*   [my blog]({{< ref "/" >}})
*   [the Groovy Web Console](http://groovyconsole.appspot.com)

The two key aspects that are bothersome are: the instance hours and the datastore reads. That's usually those two limits that we tend to hit — at least, that was the case for me.  

Despite the policy changes, the Gaelyk website wasn't affected, and was staying under the quotas. It's essentially a pretty static website, although the pages are templates (hence dynamic), but since the pages are cached, through the [routes.groovy configuration](http://gaelyk.appspot.com/tutorial/url-routing#caching), and that there's no datastore access, everything is fine here — just a few datastore reads for the memcache access.  

For my blog, I was a bit below the datastore reads level, but the frontend instance hours were more problematic. The fact of moving the max idle instance knobs and latency knobs to their opposite, helped me a lot. And although the website is up and running 24h/24, App Engine doesn't spin up too many instances anymore with those knob settings, and I'm now under the 28 hours limit. So all is fine for my blog too.  

And the biggest problem was the Groovy Web Console...  

For the frontend instance hours, I'm always at the limit, but with the knobs to the opposite, it's okay, but really short... Also, the pricing policy moving to instance hours rather than CPU consumption was a good thing for the application, as users can execute long-running scripts (< 60 seconds). 
 
For the datastore reads, that was the most painful aspect, as the Google Search bots and friends are doing a ton of reads when harvesting all the Groovy scripts that are published.  

I must confess the application wasn't very well written, so for example, I was doing three queries (basically the same one) to list the latest scripts published, the scripts by authors, the scripts by tags. Three queries which were essentially the same, more or less, that were totalling 5 read operations each (on op for the query + 2 \* two ops because of the indexed columns I was sorting / filtering on). So I had like 15 operations or so just to build up the pages that you see when you click on the link "recent scripts".  

Despite the fact my pages were cached (using just one read operation from memcache), it happened often that pages were not in the cache, and that my app needed those 15 operations. So I had to optimize my application. Instead of doing three different queries, I ended up doing just one, and then I apply some sorting / filtering / grouping in memory with the results I got from the query. I ended up with just 5 operations instead of 15.  

Then, I also went a step further by putting the results of the queries in memcache, so instead of 5 ops, most of the time I ended up getting only one read operation. In the end, I reduced my datastore reads by a factor of 15 or so. And with those changes, I only consume about 40% of the datastore read operations quota!  

You can see what my quotas look like when I'm at the end of the day, thanks to those optimizations:  

![](/img/misc/gae-console-billing.png)  

I almost reach the frontend instance hours limit, but I'm still below 28 hours, and I only used 38% of my datastore read quota.  

So all in all, I'm quite happy that all my apps stayed free, thanks to the few updates that Google made to the pricing policy to accomodate all the complaints they received!  

What has been your experience with the new pricing policy? Did you have to optimize your apps, if yes, what solutions did you find?  

I'm looking forward to your feedback!
# Gaelyk 1.1 released


Gaelyk 1.1 has just been released!  
[Gaelyk](http://gaelyk.appspot.com) is a lightweight toolkit for writing and deploying Groovy apps on Google App Engine.  
In this version, all the components have been updated to their latest versions:

*   [Groovy 1.8.4]({{< ref "/posts/2011/11/11/latest-groovy-releases-and-roadmap-update" >}})
*   [GAE SDK 1.6.0](http://googleappengine.blogspot.com/2011/11/app-engine-160-out-of-preview-release.html)

This blog is now running Gaelyk 1.1 pretty happily!  
You should be able to see the [announcement](http://groups.google.com/group/gaelyk/browse_thread/thread/b91556a6c2238646) on the Gaelyk Google group for the details, but here's the list of changes:

> *   Upgraded to Groovy 1.8.4 and App Engine SDK 1.6.0
> 
> *   The [new `get()` methods on the datastore service](http://gaelyk.appspot.com/tutorial/app-engine-shortcuts#datastore-get) now also work with the asynchronous datastore.
> 
> *   Added an `unindexed` property on entities to set unindexed properties: `person.unindexed.bio = "..."`
> 
> *   [Three annotations to customize the bean / entity coercion](http://gaelyk.appspot.com/tutorial/app-engine-shortcuts#pogo-entity-coercion-annotations)
>  (`@Key`, `@Unindexed` and `@Ignore`)
> 
> *   Part of the work with the async datastore `get()`, whenever you have a `Future` to deal with, for example when the async datastore returns a `Future` , you can call any property on the `Future` object, and it will proxy those property access to the underlying object returned by the `get()` call on the future.
> 
> *   In addition to `datastore.query{}` and `datastore.execute{}`, there is now a `datastore.iterate{}` method that returns an `Iterator` instead of a list, which is friendlier when your queries return a large number of results.
> 
> *   Added the prospective search service to the binding
> 
> *   You can access the [asynchronous Memcache](http://gaelyk.appspot.com/tutorial/app-engine-shortcuts#async-memcache) service with `memcache.async`
> 
> *   Additional [convenience methods for the file service](http://gaelyk.appspot.com/tutorial/app-engine-shortcuts#files-misc)
> 
> *   Added an [each and collect method on blobstore](http://gaelyk.appspot.com/tutorial/app-engine-shortcuts#blobstore-each-collect) to iterate over all the blobs from the blobstore, or to collect some values from all blob infos stored.

I'll just highlight one of the nice little additions mentioned above, which is the refinement of the POGO / Entity coercion mechanism. You can now use three annotations to further customize that conversion: @Key, @Unindexed and @Ignore, to respectively specify the key property, properties that should not be indexed by the datastore, and properties that should be ignored and not saved in the datastore.  
Here's what a class annotated with those annotations could look like:

```groovy
@Canonical  
class Person {  
    @Key String login  
    String firstName  
    String lastName  
    @Unindexed String bio  
    @Ignore String getFullName() { "$firstName $lastName" }   
}
```

And then you can use the as operator to convert between beans and entities.  
If you've read thus far, it's time to go [download Gaelyk](http://gaelyk.appspot.com/download) and have fun!
# Latest Groovy releases and roadmap updates


On [this post on the Groovy website](http://docs.codehaus.org/pages/viewpage.action?pageId=227053189), we've announced the releases of Groovy 1.8.4 and the first beta of 2.0, as well as cover some updates on the roadmap.  

In a nutshell, the big highlights are the static type checking support and invoke dynamic support. We're also going to investigate whether it makes sense to also cover static compilation. And we've also announced a new version numbering scheme, to move Groovy forward.  

Here's what the announcement said:

> It is with great pleasure that we are announcing another joint release today!  
>   
> We have **released Groovy 1.8.4**, that includes fixes and minor improvements to correct problems the Grails web framework and the Gradle build automation tool were having with 1.8.3.  
>   
> In addition, we are also pleased to announce the **release of Groovy 2.0-beta-1!** **Groovy's updated version numbering scheme**  Yes, you heard it, a Groovy 2.0 beta! But what's going on, weren't we working on the 1.9 line? Yes, we were, but with the substantial number of new features coming up in the 1.9 release, we thought it was time to start using an updated numbering scheme.   
> Historically, Groovy's "major" versions have always been "dot" versions, which is a bit uncommon in our industry, in the sense that major versions are expected to have a new major digit each time. So the Groovy version numbering scheme has always been a bit odd for strangers and newcomers -- furthermore, from a marketing perspective, if we ever decide to release a 1.10 version, it would be lexicographically backward (1.10 < 1.9 in math)! This isn't the first time a major change in version numbers has happened: Groovy went from 1.1 to 1.5 and recently Grails changed from 1.4 to 2.0 for its next major release.  
>   
> So instead of speaking of the mythical "2.0" version of Groovy that never seems to arrive, this next major release will be 2.0. For further versions, we'll probably release some 2.x versions as well, but we will also adopt the same strategy regarding major version numbers, releasing a major version more or less every year. Thus, given **2.0 final should be out in early 2012**, the following major version will be released afterwards in 2013 and will become 3.0. But don't worry, we won't adopt the lightning fast numbering schemes of Google Chrome or Mozilla Firefox!  
>   
> **So what will be inside 2.0 that makes it so special?** **Static type checking** We have been working on the **static type checking support for Groovy**.  
>   
> On several occasions, we have noticed that Groovy was used in Java projects as a simple yet powerful scripting language for Java APIs, in ways that don't particularly leverage the dynamic aspects of the language but instead as a better syntax for Java somehow. With this approach, developers often prefer a stricter approach to type checking, in the sense it should complain when you have typos in your method names, parameters or variables or when you make invalid assignments, etc. The compiler should complain at compile time, rather than having Groovy complain at execution time later on, thus giving you earlier feedback about those errors — particularly useful when you are using APIs that may change.  
>   
> Static type checking has already been discussed on a few threads on the Groovy mailing-lists, and we appreciate your feedback on how it's being implemented, how it should behave, and so on. Please don't hesitate to come back to us with your thoughts and ideas on this topic.  
>   
> We have also created a GEP (Groovy Extension Proposal) covering this new aspect:  
> [http://docs.codehaus.org/display/GroovyJSR/GEP+8+-+Static+type+checking](http://docs.codehaus.org/display/GroovyJSR/GEP+8+-+Static+type+checking) And Cédric, who joined Jochen and myself at SpringSource/VMware and who's been working on this feature, wrote a very nice and detailed blog post about the current work-in-progress here:[http://www.jroller.com/melix/entry/groovy\_static\_type\_checker\_status](http://www.jroller.com/melix/entry/groovy_static_type_checker_status)   
> Be sure to read those two documents, as they will guide you through some interesting samples showing how you can get started using static type checking with Groovy 2.0.0-beta-1! Please also note that this is still in beta, and that APIs are subject to change and evolve depending on your feedback.  
>   
> **Static compilation** With static type checking, type inference capabilities, sensitive flow typing, and so on, the Groovy compiler is now way smarter in figuring out what your code is actually doing. In the case of scripting Java APIs that we mentioned above, we could let the compiler generate direct method calls à la Java, instead of going through Groovy's Meta-Object Protocol, allowing **the same performance as Java**!  
> We're going to investigate **static compilation** in 2.0, leveraging the new smarts of the compiler and its infrastructure, by creating a new git branch with initial support that you'll be able to monitor to watch our progress on that front.  
>   
> **But what about Groovy++?** Thanks to the great work of Alex Tkachman and Roshan Dawrani, the Groovy++ extension project definitely inspired us and ended up convincing us that it was important to support static type checking and compilation in Groovy.  
>   
> We couldn't simply integrate Groovy++ directly in Groovy 2.0, as it differed in spirit from our ideas for Groovy core, for example by covering more ground than we wanted and needed (persistent collections, new operators, traits, new map-style classes, etc.). We also wanted to evolve the Groovy compiler infrastructure so that it fits nicely with the primitive optimizations work, static type checking and compilation, as well as invoke dynamic support, and we would have needed to refactor Groovy++ heavily for our needs. That said, we of course would welcome collaboration with the Groovy++ team to learn from their experiences building Groovy++.  
>   
> We engaged the community to discuss various aspects of static type checking and inference so as to make it closer to the usual Groovy semantics as much as possible, without introducing new data structures or restricting existing features (like closures with non-final variables), so that Groovy developers feel at ease with static type checking and compilation, and are the least impacted by differences in semantics between this additional mode and the classical dynamic mode.  
>   
> **Invoke dynamic support** Lastly, we've started working on **"invoke dynamic" support**, the new JVM bytecode instruction and APIs of JDK 7 developed for dynamic languages, with the goal of **improving the performance of all the dynamic aspects of Groovy in significant ways**. This is still early days, and this first beta of 2.0 doesn't yet contain particular changes that you'd notice. We are working on the "indy" branch of Git (and mirrored on GitHub) for that support.  
>   
> **And beyond 2.0?** With static type checking and compilation, as well as invoke dynamic support, we thought that it was really worth a Groovy 2.0 moniker! But what's next?  
>   
> Among the things we want to tackle for 2.x / 3.0 and beyond, we're interested in **moving the Groovy grammar from Antlr 2.x to a newer version**. Antlr 3 has been available for a while, but our summer attempt at migrating to it haven't been fruitful so far. But we will investigate this move once 2.0 is out, and decide if we go with Antlr 3 or Antlr 4 which should be available when we want to release 3.0.  
>   
> In the past, we've mentioned several times a redesigned Meta-Object Protocol (MOP 2). With the lessons learned in the invoke dynamic support of Groovy 2.0 and with the ironing out of the invoke dynamic performance of the JIT, we should be able to have a better vision of how to rearchitect the MOP so that it fully takes advantage of invoke dynamic, for **faster dynamic features**.  
>   
> There are many other things we'd like to have a look at, but it's still a bit too early to tell what's going to be in Groovy 3 and beyond, as of today. We have time to see what's interesting to add to Groovy to **continue helping you being more productive developers**, and we will continue to **welcome and appreciate your feedback** and what you'd like to have in Groovy in the future to **simplify your life**.  
> **Groovy is what it is today thanks to your ideas and contributions!** **Important links** You can view the changelog on JIRA for the details:
> 
> *   Groovy 1.8.4:
> [http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=17852](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=17852)
> 
> *   Groovy 2.0 beta 1:
> [http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=17925](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=17925)
> 
> And you can download the new releases from the usual download area on the Groovy website:  
> [http://groovy.codehaus.org/Download?nc](http://groovy.codehaus.org/Download?nc) Thanks a lot to everybody involved, and we're looking forward to your feedback!  
>   
> The Groovy development team
# Présentation sur PrettyTime et GPars au Paris JUG


Warning: Sorry, this time, I'll blog in French to share my slides of the presentation in French that I made yesterday at the [Paris JUG](http://www.parisjug.org/xwiki/bin/view/Main/WebHome) about the [PrettyTime](http://ocpsoft.com/prettytime/) library and the [GPars](http://gpars.codehaus.org/) concurrency / parallelism toolkit.  

Hier soir, j'ai eu le plaisir de retrouver les passionnés du [Paris JUG](http://www.parisjug.org/xwiki/bin/view/Main/WebHome) pour parler sur le thème des "petites librairies" utiles que l'on peut utiliser sur nos projets. J'avais proposé de parler de [PrettyTime](http://ocpsoft.org/prettytime/), qui permet d'écrire des dates relatives du genre _"il y a 3 minutes"_ ou _"dans 4 jours"_. Et j'avais aussi suggéré de couvrir le sujet de la concurrence et de la parallèlisation avec [GPars](http://gpars.codehaus.org/).  

J'ai publié ma présentation sur slideshare :

{{< slideshare 10084466 >}}

Au passage, un grand merci à Paul King et Václav Pech, committers sur GPars, grâce à qui j'ai pu réaliser le contenu sur GPars ! (je leur ai même piqué des slides et des exemples)
# A Groovy page on Google+


With Google+ releasing its new ["page" feature](http://googleblog.blogspot.com/2011/11/google-pages-connect-with-all-things.html), I've created a [page for the Groovy project on Google+](https://plus.google.com/u/0/101432359761228268146/posts). The idea is to post some regular updates on what's going on in the [Groovy](http://groovy.codehaus.org) project, its ecosystem, and share any interesting article that's of interest to those using Groovy.
# Gaelyk presentation at SpringOne2GX


After sharing my slides for the [DSL](http://glaforge.appspot.com/article/groovy-domain-specific-languages-in-chicago) talk, and the [Groovy update](http://glaforge.appspot.com/article/what-s-new-in-groovy-1-8-and-beyond) presentation, I'll finish the tour with my presentation on [Gaelyk](http://gaelyk.appspot.com).

{{< slideshare 9974808 >}}

# What's new in Groovy 1.8 and beyond?


Last week, at the [SpringOne2GX conference](http://www.slideshare.net/glaforge), in Chicago, I gave an update on the new features of the recently released Groovy 1.8, as well as new features we're working on for upcoming versions of the language and its APIs.  

I've uploaded my slides on Slideshare: 

{{< slideshare 9973780 >}}

I'm covering:  

*   Nicer DSLs with command chains
*   Runtime performance improvements
*   GPars bundled for taming multicore
*   Closure enhancements (functional flavor and closure annotation parameters)
*   The builtin JSON support
*   The new AST transformations
*   The alignment with JDK 7 (Project Coin)
*   InvokeDynamic support coming up
*   Static type checking
*   And other minor improvements
# Groovy Domain-Specific Languages in Chicago


With my friend [Paul King](https://plus.google.com/105508550588099229829/about), we ran our [Groovy Domain-Specific Languages](http://www.slideshare.net/glaforge/groovy-dsls-from-beginner-to-expert-guillaume-laforge-and-paul-king-springone2gx-2011) talk again this year in Chicago, for the [SpringOne2GX conference](http://springone2gx.com/conference/chicago/2011/10/2gx/event_sessions). I've uploaded the slides on Slideshare, and Paul has pushed the [examples on Github](https://github.com/paulk-asert/DSLsFromBeginnerToExpert). The room was packed, and we had lots of fun doing our little dialogue between the customer and Groovy DSL developer, improving our DSLs, showing new techniques along the way, to suit the requirements as they evolved.  

{{< slideshare 9957057 >}}

# SpringOne2GX, Chicago, this week


It's the conference season. After JavaOne, comes [SpringOne2GX](http://springone2gx.com/conference/chicago/2011/10/home), in Chicago, this week (October 25th till 28th). Then [Greach](http://greach.es/) in Madrid (Spain), [Devoxx](http://devoxx.com/display/DV11/Home) in Antwerp (Belgium) and we'll finish with [Groovy/Grails eXchange](http://skillsmatter.com/event/java-jee/groovy-grails-exchange-2011) in London (UK).  

In Chicago this week, we'll have 4 tracks dedicated to Groovy, Grails, and the big Groovy ecosystem (Gradle, Griffon, Spock, Geb...) over three days. That's a lot of sessions and speakers ready to tell you all about what's rocking in our world!  

Be sure to check the [agenda](http://springone2gx.com/conference/chicago/2011/10/2gx/event_sessions) and the nice line-up of [speakers](http://springone2gx.com/conference/chicago/2011/10/speakers).  

I'll be presenting three talks:

*   Groovy Update: What's new in Groovy 1.8 and what's coming
*   Groovy DSLs, from beginner to expert, with my friend Paul King, that'll be a new edition of our past year's talk
*   Gaelyk, Groovy coding to the cloud

I'm looking forward to meeting you all in Chicago!
# Groovy 1.8.3 and 1.9-beta-4 released


The [Groovy](http://groovy.codehaus.org) development team has just released Groovy 1.8.3 and 1.9-beta-4.  

For the impatients:

*   download it on the [Groovy download page](http://groovy.codehaus.org/Download)
*   check the [JIRA release notes for 1.8.3](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=17657) and [1.9-beta-4](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=17656)
*   or read the [official announcement](http://markmail.org/message/ugk5244bdqkzxfil)

Those two releases are essentially about bug fixes and minor enhancements, but we also have interesting developments going on for static type checking your Groovy code, and for invoke dynamic support for performance of our dynamic core. But it'll be better that I save those topics for some future posts!  

Here, I just wanted to highlight some of the minor enhancements in those two new releases. Such enhancements sometimes go unnoticed, so I thought it would be nice to put them a bit more in the spotligh.  

Customize your groovysh prompt A pretty [old request](http://jira.codehaus.org/browse/GROOVY-2832) was about the ability to customize your groovysh prompt, so that instead of `groovy`, you could have your own message. This can be handy for people reusing the groovy shell infrastructure to embed that somehow in their applications, offering various pre-defined variables in the binding, etc.  

If you want to customize your groovysh prompt, there are two approaches: either you export an environement variable called `GROOVYSH_PROMPT`, or you pass the `-Dgroovysh.prompt=myMessage` argument to your groovysh launch command.  

Here's a screenshot showing how one can use fancy characters from a Mac OS X console:  

![](/img/misc/groovysh+prompt.png)  

Launching remote Groovy scripts The groovy command usually takes a file as argument, pointing at the script or class you want to run. But it's now also possible to run remote scripts available on the net somewhere.  

For example, with the [Groovy Web Console](http://groovyconsole.appspot.com), scripts can be viewed with the following URL: [http://groovyconsole.appspot.com/script/110001](http://groovyconsole.appspot.com/script/110001). But there's also another URL that you can use to get the raw content of that script: [http://groovyconsole.appspot.com/raw/110001](http://groovyconsole.appspot.com/raw/110001).  

So just type the following, to run a remote Hello World script!

```bash
groovy http://groovyconsole.appspot.com/raw/110001
```

And it'll just print hello on the console.  

As a little warning though, don't run blindly any remote script that someone sends you the link of :-)  

Formatting dates for a specific time zone Groovy's had some nice shortcuts for quickly formatting dates and calendar instances. And there's a new little variant for printing a particular date and time according to a certain time zone.  

I'm currently in GMT+2, and I want to print the current date and time with my particular time zone, here's how I could do it:

```groovy
def d = new Date()  
def tz = TimeZone.getTimeZone('GMT+2')  
println d.format('yyyy-MM-dd HH:mmZ', tz)  
// prints for me now: "2011-10-13 00:53+0200"
```

Now onto two new features which are exclusively on Groovy 1.9.  

Viewing the generated bytecode from the Groovy console This capability is probably more interesting for the Groovy developers themselves, as most of your time, you won't really need to know what the groovy compiler generates in terms of bytecode — not even mentioning that this might be a little bit scary. But if you're using the Groovy Swing console, that you're launching the AST browser, it'll show you the bytecode as well, as shows the following screenshot. 

![](/img/misc/bytecode+view.png) 

So first step, launch your Groovy console with the groovyconsole command. Then open a script or class whose bytecode you want to have a look at. Click on the AST browser menu item, or hit `CTRL-T`. At that point, make sure you use the "class generation" phase from the drop-down box, and also select a _class node_ in the AST tree (otherwise you won't see any bytecode at all).  

Control over Global AST Transformations Global AST transformations like Grape's or the AST builder are not necessarily needed when you embed Groovy in your application. They incur a pretty small overhead of compilation time. Or perhaps on your classpath you use a library that has a global transform but that you are not using and don't want to be impacted by it. Now you are able to disable such transformations through the CompilerConfiguration object.  

Here's an excerpt of our unit test covering this new capability:

```groovy
import org.codehaus.groovy.control.CompilerConfiguration  

def config = new CompilerConfiguration()  

config.disabledGlobalASTTransformations =   
    ['org.codehaus.groovy.ast.builder.AstBuilderTransformation']  

def script = '''  
    import org.codehaus.groovy.ast.builder.AstBuilder  
    new AstBuilder().buildFromCode { "Hello" }  
'''

// witout a specific configuration, the AST builder works  
def shell = new GroovyShell()  

assert shell.evaluate(script).class == ArrayList  

// now with the configuration in place,   
// the AST builder transform is not applied  
shell = new GroovyShell(config)  

shouldFail {  
    shell.evaluate(script)  
}
```
# Google announces Dart, new language for the web


Google [announces Dart](http://blog.chromium.org/2011/10/dart-language-for-structured.html), at the [Goto Conference](http://gotocon.com/aarhus-2011/presentation/Opening%20Keynote:%20Dart,%20a%20new%20programming%20language%20for%20structured%20web%20programming): a new programming language for "structured web programming", for building web applications. Google also launched the [Dart website](http://www.dartlang.org/), where you can read about the rationale of the language, the [specification](http://www.dartlang.org/docs/spec/dartLangSpec.pdf), and play with some live examples.  

## The team behind Dart  

Reknown engineers [Lars Bak](http://gotocon.com/aarhus-2011/speaker/Lars+Bak) and [Gilad Bracha](http://gotocon.com/aarhus-2011/speaker/Gilad+Bracha) are on stage to present the language. Lars Bak worked on many virtual machines like Sun's HotSpot or more recently [Google V8](http://code.google.com/p/v8/), whereas Gilad Bracha is also famous for his work on the Java specification, his Smalltalk background, and the creation of a recent language called [Newspeak](http://newspeaklanguage.org/) (a flavour of Smalltalk). So with such a team of VM and language experts, you can expect some interesting outcome.  

But beyond those two well known figures, it seems Google has aligned a [big list of engineers](http://code.google.com/p/dart/people/list?num=100&start=0) to work on the project, as you can see on the Google code page. What is interesting as well, is that Bob Nystrom is also part of the team: Bob created the [Magpie language](http://magpie.stuffwithstuff.com/), which is a really creative, elegant, and innovative language. I hope Dart can get pattern matching as nicely as Magpie has it.  
What's Dart?  

Dart is a simple Object-Oriented language with single inheritance, class-based, with optional static types, and is single threaded. Dart resembles a mix of Java and JavaScript, when you look at the samples on the [Dart website](http://www.dartlang.org/).  
Dart's objectives are:

> *   Create a **structured yet flexible** language for web programming.*   Make Dart feel **familiar and natural** to programmers and thus easy to learn.*   Ensure that Dart delivers **high performance** on all modern web browsers and environments ranging from small handheld devices to server-side execution.

  
## Optional static types  

The choice of optional static typing is interesting, as it's also a choice we made with [Groovy](http://groovy.codehaus.org). As Gilad coined it: "you are innocent until proven guilty on types". Types are there when you need them, especially for larger-scale applications, where types simplify refactoring types, for example. But types don't get in the way when you don't need them.  

Using types will help developers express their intent more clearly, will help IDEs and other tools to better understand the structure of your applications, and less documentation will be needed as types will serve as a cue of what your objects at hand are all about. But in places where you don't need types (think inside your method bodies, and quick scripts or prototypes, etc), you can just omit the type information, and you'll only get warnings from the compiler if you make mistakes with the types.  

## Dedicated VM or compiled to JavaScript  

Dart code will be able to run either on a dedicated VM, or compiled to JavaScript so as to run on any modern browser (Chrome, Safari 5+, Firefox 4+). At some point, the VM might be integrated in Google Chrome. And you'll also be able to run Dart on the server-side, like this is the case with JavaScript and Google V8, for instance.  

## Isolates, an actor-like concurrency model  

Although Dart is single-threaded, its answer to concurrency comes without locking or shared memory, in the form of an actor-like model of concurrency, like in [Groovy's GPars](http://gpars.codehaus.org/Actor?nc). Those actors are actually called "isolates".  

## Miscelanous  

Here are some additional notes I took while looking at the documentation on the Dart website:  

*   Dart supports interpolated strings like [Groovy's GString](http://groovy.codehaus.org/Strings+and+GString), supporting both ${name} or $name like Groovy.
*   The visibility is quite simple, with just public and private. Private fields or classes are actually following a naming convention: prefixed with an underscore.
*   Dart requires semicolons, what a pity!
*   Dart has functions / closures, with a syntax like `(var a, var b) { body }`. Think JavaScript's function, but without the function keyword.
*   Dart supports getters and setters with a C#-like approach.
*   A fat arrow \=> is used for returning a value (when you don't need a full curly-braced function body but just want to return a value, for example for getters).
*   There's just one constructor for your classes, but you can somehow add additional named constructors with a method named prefixed by the class name.
*   The [grammar](https://code.google.com/p/dart/source/browse/branches/bleeding_edge/dart/language/grammar/Dart.g) was developed with Antlr.
*   There are a [bunch of samples](http://www.dartlang.org/samples/index.html) to look at that are available on Google Code.

## Status and more  

Dart is not quite done yet, and it seems certain aspects still need to be worked on, like reflection support, rest arguments, enums, pattern matching, etc. But it seems those features are also waiting for user support, as the Dart team is looking for feedback from the community. But despite its unfinished state, it seems Dart is already quite fast, as Dart is already faster than V8 JavaScript when it was initially launched. 

I'm sure the [Twitter account for Dart](https://twitter.com/#!/dart_lang) will quickly get a lot of followers. It's always interesting to follow the birth and evolution of new languages!  

## Update:

*   A [nice analysis on the language features](http://jlouisramblings.blogspot.com/2011/10/musings-on-dart.html)
*   The draft [Dart language specification](http://www.dartlang.org/docs/spec/dartLangSpec.pdf) is also interesting to read (although the document needs some concrete examples in various places to make it more readable)
*   The [slides of the presentation](http://gotocon.com/dl/goto-aarhus-2011/slides/GiladBracha_and_LarsBak_OpeningKeynoteDartANewProgrammingLanguageForStructuredWebProgramming.pdf) at GotoCon
# GR8Conf is coming to Australia


The now famous [GR8Conf](http://gr8conf.org) conference dedicated to all things [Groovy](http://groovy.codehaus.org), is now [coming to Australia](http://www.gr8conf.org/blog/2011/10/04/111), as announced on the [GR8Conf blog](http://www.gr8conf.org/blog/list)! It will take place in Canberra, side by side with the [Open Source Developers Conference](http://osdc.com.au/) (OSDC), on November 15th.  

The [GR8Conf Australia website](http://gr8confau.org/) is already up and is running a Call for Papers. So if you have a presentation on Groovy, Grails, Griffon, Gradle, Spock, CodeNarc, Gaelyk, etc, with introductions, deep dives, case studies, and so on, feel free to submit a talk!
# Groovy AST transformations tutorials


[Groovy](http://groovy.codehaus.org) is a powerful language that gives the opportunity to its users to plugin into the compilation process to create what we call AST transformations, ie. the ability to customize the Abstract Syntax Tree representing your programs before the compiler walks this tree to generate Java bytecode.  

Since Groovy 1.6, many useful such transformations have been added to Groovy, like [@Delegate](http://groovy.codehaus.org/Delegate+transformation) to implement delegation, [@Immutable](http://groovy.codehaus.org/Immutable+transformation) to make your types immutable, or [@Grab](http://groovy.codehaus.org/Grape) to add dependencies to your scripts, and many more. However, mastering the Groovy AST and compiler APIs is not such a simple task, and requires some advanced knowledge of the inner workings of Groovy.  

[Joachim Baumann](http://joesgroovyblog.blogspot.com/), Groovy committer and [German Groovy book](http://www.dpunkt.de/buecher/2610.html) author, wrote a very nice series of articles on the topic of authoring AST transformations, covering:

*   [compiler phases and syntax trees](http://joesgroovyblog.blogspot.com/2011/09/ast-transformations-compiler-phases-and.html)
*   [prerequisites and annotations](http://joesgroovyblog.blogspot.com/2011/09/ast-transformations-prerequisites-and.html)
*   [the implementation of the example transformation itself](http://joesgroovyblog.blogspot.com/2011/09/ast-transformations-transformation.html)
*   [testing and error messages](http://joesgroovyblog.blogspot.com/2011/09/ast-transformations-testing-and-error.html)
*   [creating a complex AST transformation](http://joesgroovyblog.blogspot.com/2011/10/ast-transformation-using-astbuilder.html)

If you're interested in writing your own transformations, those very well written articles are really a great start that should get you up to speed very rapidly.
# Lots of Gradle news and activity


The [Gradle](http://gradle.org) project is moving quickly towards its final version and we hear more and more projects adopting or migrating to Gradle for their build and project automation.
Gradle founder Hans Dokter pushed very interesting posts those past days:

*   [On our way to Gradle 1.0](http://forums.gradle.org/gradle/topics/on_our_way_to_gradle_1_0): where he explains the current features being worked on before being able to reach 1.0, with a strong focus on three key aspects: the new dependency cache, the daemon, and performance improvements.
*   In [Welcome to the new Gradle dependency cache](http://forums.gradle.org/gradle/topics/welcome_to_our_new_dependency_cache), Hans details the current critical issues that all other build systems face with the non-reproducability of their builds due to the poor design of the current dependency cache solutions, and then goes on to explain how Gradle's new solution solves all these problems in an elegant way.

Last but not least, you should also check out the "[week in Gradle](http://forums.gradle.org/gradle/tags/this_week_in_gradle)" column, which will give you the latest news on everything Gradle every week, starting [this week](http://forums.gradle.org/gradle/topics/this_week_in_gradle_2011_39), covering the interesting project development, job offerings, appearance at conferences, tweets, articles, and more.

**Update #1:** Gradle now has a new logo! So I updated the picture in my post as well.

**Update #2:** There is now a special [Roadmap page](http://gradle.org/roadmap) to see what's planned for upcoming versions and releases.
# Groovy on GitHub


Groovy completed successfully its move to the Git SCM this summer, thanks to [Matthew](http://ambientideas.com/)'s help. For helping everybody get up-to-speed with Git, I've added a [page about Git on the Groovy wiki](http://groovy.codehaus.org/Git).  

We also now have a **"groovy" organization on GitHub**: [https://github.com/groovy/groovy-core](https://github.com/groovy/groovy-core)  

Our three main branches have been pushed there: master, `GROOVY_1_8_X` and `GROOVY_1_7_X`. But I've not pushed the tags though.  

The **GitHub repository serves as a mirror**, and the Groovy despots will be able to regularly push the latest changes to GitHub, and deal with pull requests and such.  

**Update #1:** The branches as well as all the tags have been pushed to the GitHub mirror as well.  

**Update #2:** We've even had our first pull requests! Hooray :-)
# Playing with the Google+ APIs in Groovy


As soon as I heard about the [opening of the Google+ APIs](http://googleplusplatform.blogspot.com/2011/09/getting-started-on-google-api.html), letting us access public posts in our Google+ streams, I wanted to play with them, and integrate my posts in my social stream on my blog.  

First of all, a little screenshot, where you'll see the Google+ item at the bottom:  

![](/img/misc/gplus-social.png)  

Now, a bit of code? Yeah, of course. First of all, you'll need to follow the explanations of the Google+ API portal to get your own API key (I'll hide mine in this example so you don't use mine). Then, it's really just a handful lines of Groovy code to get the integration goin, thanks to [Groovy's Json support](http://docs.codehaus.org/display/GROOVY/Groovy+1.8+release+notes#Groovy1.8releasenotes-NativeJSONsupport).  

```groovy
import groovy.json.\*  
import java.text.SimpleDateFormat  
// date format: 2011-09-09T08:34:07.000Z  
def sdf = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSS'Z'")  
// my top secret API key  
def myKey = "..."  
// that's the ID you'll find in your Google+ profile URL  
def myProfileId = "114130972232398734985"  
// and this is the URL of my activities  
def myActivities = "https://www.googleapis.com/plus/v1/people/${myProfileId}/activities/public?key=${myKey}".toURL().text  
// I simply parse the JSON payload  
def root = new JsonSlurper().parseText(myActivities)  
// I iterate over all the items, and print the date, the URL of the post, and the title  
root.items.each {   
    println "${sdf.parse(it.published)} - ${it.url} - ${it.title.replaceAll(/\\s+/, ' ')}"   
}
```
# Groovy, fastest growing language according to eWeek


I've just come across [eWeek's latest article on programming languages](http://www.eweek.com/c/a/Application-Development/Groovy-JavaScript-Ruby-Among-Fastest-Growing-Programming-Languages-505803/) trends, and they announce that Groovy is the fastest growing language!

> The data shows the percentage of jobs that have increased (or decreased) for various programming languages since November 2009. In the time frame this slide show depicts, Groovy saw the largest increase in jobs, followed by C# and—surprisingly—COBOL.

Of course, we still have a lot of work to do to continue growing, and stay the most popular and successful alternative language for the JVM, but it's great to see such confirmations on a famous online business journal.
# The many ways to lace your shoes


In my feed reader, I came across this nice image showing the [many ways to lace your shoes](http://pics.kuvaton.com/kuvei/17_ways.jpg)!  
I selected one of those that I'd like to try some day, it's very nice looking:  

![](/img/misc/lace-your-shoes.png)

I think I've been using essentially the 4th and 7th for years.  

Which lacing scheme do you use?  

**Update:** There are even [sites dedicated to shoe lacing](http://www.fieggen.com/shoelace/index.htm)!
# A new skin for the Groovy website


In the coming months, the Groovy team will be working on a nicer website with a web designer and better and up-to-date documentation. Obviously, this will take quite some time (especially for the content, more than for the look), but in the meantime, I wanted to refresh the look of the [Groovy website](http://groovy.codehaus.org) a bit. So I spent several hours today and tonight playing with CSS3!  

I used Twitter's [Bootstrap grid system](http://twitter.github.com/bootstrap/) which is quite neat. Not only does it provides an easy to use grid system, but it also takes care of typography, menus, and much more. And I used [highlight.js](http://softwaremaniacs.org/soft/highlight/en/) for the Groovy syntax highlighting (the same that I use on this blog).  

And the result looks like this now:  

![](/img/misc/new-groovy-skin.png)

Disclaimer: I'm not a profesional web designer!
# Groovy 1.8.2 and 1.9-beta-3 are in the wild


This is with great pleasure that the Groovy development team announces the joint releases of Groovy 1.8.2 and 1.9-beta-3. The big highlight of this release is the completion of the primitive type arithmetics performance optimizations. Microbenchmarks affictionados should be happy, and those wanting to do some number crunching should see better results with these improvements. Other than that, those two releases are essentially about bug fixes.  

You can have a look at the release notes here: [http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=17494](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&version=17494)  

And you can download Groovy 1.8.2 and 1.9-beta-3 on the download page: [http://groovy.codehaus.org/Download](http://groovy.codehaus.org/Download)  

In other news, thanks to Git expert [Matthew McCullough](http://ambientideas.com/), we completed our complex migration to Git. You can learn about the details to access and clone the Git repo here: [http://xircles.codehaus.org/projects/groovy/repo/git/repo](http://xircles.codehaus.org/projects/groovy/repo/git/repo) Later on, we'll also provide a mirror on GitHub.  

Small remark on the new beta of the 1.9 branch: due to a glitch a beta-2 was accidentally released in sync'ed with Maven Central, so we bumped the beta number to 3, rather than sticking with 2, as Central won't allow us to override an existing version.  

Thank you everybody for your feedback and contributions to those two releases.
# Google App Engine's new pricing model


I'm quite disappointed by [Google App Engine](http://code.google.com/appengine/)'s new [pricing model](http://www.google.com/enterprise/cloud/appengine/pricing.html).  

I was aware of the changes, the upcoming prices and quotas, but I wasn't expecting my small low-trafic apps to go beyond the free quotas, and force me to have to pay for those small [Gaelyk](http://gaelyk.appspot.com) apps!  

The big problem is the cost of the "frontend instance hours". An app running all the time, with low trafic, but enough to keep a frontend instance running all day will cost you 30 bucks a month with this new pricing policy.  

Let me show you an example, of a small Gaelyk application: the [Groovy Web Console](http://groovyconsole.appspot.com). It's a simple application that features an editor to author some Groovy scripts, that you can then share publicly with others.  

So far, the billing / quota details would show me the following results:  

![](/img/gae-pricing/before-gae-pricing-change.png)  

This application has always been below the free quotas, and even if the CPU time was a bit high, it was only half away from the free quota of CPU usage. So all was fine. Now, with the new pricing model, here's what you get:  

![](/img/gae-pricing/after-gae-pricing-change.png)  

I'd be paying $1.43 for that specific day, because of the always-on frontend instance, as well as the datastore reads, which have become also quite expensive as well. So if I'd have to pay one or two dollars a day, resulting in 30 or 60 bucks a month.  

And the worst thing is that it's just a transitional step, as the screenshot shows, the frontend instance hours are currently at 50% their end price till November, so the cost will almost double.  

As soon as your app will be up all the time, even with low trafic, you'll easily get to $30 a month. I think that's on purpose, to force users to go with the first paid tier of the [new pricing model](http://www.google.com/enterprise/cloud/appengine/pricing.html). To avoid those outrageous cost, you'll have to go with the $9 / month plan, and you will be far from reaching the quotas included in that plan, so you'll pay really $9 even if you only use a dollar or two. Nine bucks is better than 30 or 60, but it still sounds expensive for me for a small blog, and a small utility app that are free content or services.  

Really disappointed. And I'm now wondering what I shall be doing with my brand new blog, and the Groovy web console... Even putting ads all over the place won't pay for the fees...  

Now I hope that the [Cloud Foundry](http://cloudfoundry.org/) model will be more friendly for small personal apps!  

You can read more on the outraged comments here:

*   a guy saying he'll [leave the plaform](http://groups.google.com/group/google-appengine/browse_thread/thread/76908543757c0507#)
*   the thread on the [GAE google group](http://groups.google.com/group/google-appengine/browse_thread/thread/a1b7c68db2243932#)
*   a [Google+ post from Russel Beattie](https://plus.google.com/104961845171318028721/posts/DamjzZBVxd7)
*   another post about the [backlash over the pricing](http://srirangan.net/2011-09-google-faces-backlash-for-new-app-engine-pricing)
# CamelCaseCon Groovy conference in Germany


If you're in Germany, don't miss the [CamelCaseCon](http://www.camelcasecon.de/) conference in Düsseldorf! A conference dedicated to the Groovy ecosystem: [Groovy](http://groovy.codehaus.org), [Grails](http://grails.org), [Gradle](http://gradle.org), [CodeNarc](http://codenarc.sourceforge.net) and [Spock](http://spockframework.org).  
Dierk König, Hans Dokter, Peter Niederwieser, Joachim Bauman, Stefan Glase, will cover all these Groovy-related topics, so you'll hear the latest news from renowned experts.
# On CloudFoundry micro-cloud


VMware released the announced [CloudFoundry micro-cloud](http://blog.cloudfoundry.com/post/9331377393/we-shrunk-the-cloud-introducing-micro-cloud-foundry).  
First, what is that micro-cloud about? From the announcement on the website:

> Micro Cloud Foundry is a complete version of Cloud Foundry that runs in a virtual machine on a developer’s Mac or PC. It is a full instance of Cloud Foundry that provides the flexibility of local development while preserving your options for future deployment and scaling of your applications.

I'm quite happy that this virtualized version of the real CloudFoundry is available, as this will greatly simplify the process for developing and testing your application locally.  

One of the big pains I've had with an environment like [Google App Engine](http://code.google.com/appengine/) when developing [Gaelyk](http://gaelyk.appspot.com) is that the local development environment is not really an image of the production server. So there are various differences between the two environments that lead you to wasting tons of precious hours figuring out why something works locally, but not in production, and vice versa, sometimes things work in production but not locally! I think an virtual image should reflect way more the original environment and smooth out most differences that could lie around.  

I haven't downloaded it yet, but I'm impatient to try micro-cloud soon!  

Make sure to read Peter Ledbrook's article on [Grails on micro-CloudFoundry](http://blog.springsource.com/2011/08/24/using-micro-cloud-foundry-from-grails/).
# Already 8 years of Groovy!


Today is the 8th birthday of the [Groovy dynamic language](http://groovy.codehaus.org) project!  

I hardly believe I've been involved with the project for almost as long! I started contributing to the project very early, but only became committer 4 months or so later. It's been such a great fun, great ride, meeting all those great persons, and seeing the community forming around the project, and further along, the wealth of satellite projects!  

There are still so many good things ahead of us, but we already have a solid, healthy, successful and popular project project, and that's also thanks to all our users, and those who contributed in a way or another. So thanks to you all for all those great years!  

Keep on groovy'ing!
# Gaelyk 1.0 is out


I'm very happy to announce the final release of Gaelyk 1.0, the lightweight [Groovy](http://groovy.codehaus.org) toolkit for [Google App Engine](http://code.google.com/appengine/)!  
It took some time to get to 1.0, but it's now here, with the key feature I've been missing since the beginning of the project, in particular the [Query DSL](http://gaelyk.appspot.com/tutorial/app-engine-shortcuts#query) which allows you to write queries like this one:

```groovy
def latestArticles = datastore.execute {  
    select all from articles  
    sort desc by dateCreated  
    where author == params.author  
    limit 10  
}
```

If you want to learn more about this lightweight framework, head over to: [http://gaelyk.appspot.com/](http://gaelyk.appspot.com/)  
You can learn everything through the [tutorial](http://gaelyk.appspot.com/tutorial).  

And [download the JAR or the template project](http://gaelyk.appspot.com/download).  

Should you want to ask questions on the [Google Groups](http://groups.google.com/group/gaelyk), get involved in the community, participate in the [development of this Open Source project](https://github.com/glaforge/gaelyk), have a look at our [community page](http://gaelyk.appspot.com/community).  

This release wouldn't have been possible with all the great contributions of you all, your pull requests on [GitHub](https://github.com/glaforge/gaelyk), your Gradle plugins, your bug reports, your questions on the Google Group, etc. So I'd like to tell you all a big thank you for all your work and contributions. They were very much appreciated, and keep them coming!  
The change log:  

*   GAE SDK updated to 1.5.2 and Groovy to 1.8.1
*   Introduction of a [Query DSL for creating SQL-like queries](http://gaelyk.appspot.com/tutorial/app-engine-shortcuts#query) against the datastore
*   Updated [template project](http://gaelyk.appspot.com/tutorial/template-project) with a Gradle build, the usage of Gradle GAE / Gaelyk plugins, and the support of Spock for testing Groovlets
*   Introduction of the [plugins page](http://gaelyk.appspot.com/plugins) in the Gaelyk website, for referencing known plugins
*   By annotating classes with GaelykBindings, the same [services and variables are injected in your classes as properties](http://gaelyk.appspot.com/tutorial/views-and-controllers#gaelykBindings), as the ones which are injected in Groovlets and templates
*   The [validation closures](http://gaelyk.appspot.com/tutorial/url-routing#path-variable-validation) of the routes in your URL mapping have access to the request, so you can validate a URL depending on what's in your request (attribute, session, etc.)
*   Added a DSLD file (DSL descriptor) for Eclipse for easing code-completion and navigation
*   Added a [get() method on Key](http://gaelyk.appspot.com/tutorial/app-engine-shortcuts#delete-get-on-key), as well as on lists of keys
*   Ability to convert [lists to Keys](http://gaelyk.appspot.com/tutorial/app-engine-shortcuts#list-to-key-coercion)
*   Added two encoded [string and key conversion](http://gaelyk.appspot.com/tutorial/app-engine-shortcuts#key-string-conversion) utilities
*   [Additional datastore.get() methods](http://gaelyk.appspot.com/tutorial/app-engine-shortcuts#datastore-get) to retrieve entities by their keys more concisely
*   Problems with the recent XMPP support fixed
*   Fixed inability to access the various services and variables from within binding/before/after blocks in plugin descriptors

Additionally, this very blog post you are now reading is actually powered by a new sample app, the bloogaey blog engine, developed with Gaelyk 1.0.  

If you're interested in this blog engine, head over to the [bloogaey project on GitHub](https://github.com/glaforge/bloogaey). You're welcome to fork it to suit your needs, and to help improving it with pull requests!
# Blog.reboot()


It was time I rebooted my old blog! It used to be in PHP, and it's time to move to the next millenium with a blog engine written in [Groovy](http://groovy.codehaus.org), using the [Gaelyk](http://gaelyk.appspot.com) lightweight toolkit, and deployed on [Google App Engine](http://code.google.com/appengine/).  

# Groovy 1.8-final is out the door!


The Groovy development team is really pleased and proud to announce the release of the **final version of Groovy 1.8.0**!

After a lot of work and efforts throughout four betas and four release candidates, version 1.8 of Groovy has been long in the making, but is packed with **tons of new features and enhancements**, for your productivity, and your pleasure. In particular, you'll be happy to learn about:

*   the new [Domain-Specific Language authoring capabilities](http://bit.ly/groovy-18#Groovy1.8releasenotes-CommandchainsfornicerDomainSpecificLanguages) for more readability and expressivity of your business rules,
*   the [runtime performance improvements](http://bit.ly/groovy-18#Groovy1.8releasenotes-Performanceimprovements),
*   the [bundling of the GPars parallel and concurrency library](http://bit.ly/groovy-18#Groovy1.8releasenotes-GParsbundledwithintheGroovydistribution),
*   the [built-in JSON support](http://bit.ly/groovy-18#Groovy1.8releasenotes-NativeJSONsupport),
*   the new [compile-time meta-programming features](http://bit.ly/groovy-18#Groovy1.8releasenotes-NewASTTransformations) (several new useful AST transformations),
*   the new [functional programming aspects of closures](http://bit.ly/groovy-18#Groovy1.8releasenotes-Closureenhancements),
*   and much more.

To get all the details, with code samples, we have prepared an in-depth [release notes](http://bit.ly/groovy-18) document. Please have a look at it to learn more about the features listed above, and discover other smaller enhancements as well.

You can download Groovy 1.8 in our [JIRA tickets](http://groovy.codehaus.org/Download%3Edownload%20section%3C/a%3E%C2%A0and%20you%20can%20have%20a%20look%20at%20the%20list%20of%20%3Ca%20href=) that have found their way into this major release.

We'd like to thank all those who participated and contributed to this release: users, contributors, committers, framework writers, IDE developers, book authors. Without you all, Groovy wouldn't be the great productive language it is now. And again, without you all, Groovy wouldn't be surrounded by its **vibrant, active and rich ecosystem**, giving you advanced tools and frameworks for building web applications ([Grails](http://grails.org/), [Gaelyk](http://gaelyk.appspot.com/)) or rich desktop applications ([Griffon](http://griffon.codehaus.org/)), for building your own projects ([Gradle](http://www.gradle.org/)), for testing your projects ([Spock](http://spockframework.org/), [Geb](http://geb.codehaus.org/)), for tackling the concurrency and parallel problems on our multi-core / multi-processor architectures ([GPars](http://gpars.codehaus.org/)), or for improving the quality of your Groovy code bases ([CodeNarc](http://codenarc.sourceforge.net/) for static code analysis, [GContracts](https://github.com/andresteingress/gcontracts/wiki/) for design by contract).

Enjoy this release!
# GR8Conf Europe 2011 - a conference dedicated to the Groovy Ecosystem


![](http://www.eu2011.gr8conf.org/a/125x125_banner_animated.gif)It is this time of the year: [GR8Conf Europe 2011](http://gr8conf.eu/) is ready to rock the Groovy world!

[Register now](http://www.eu2011.gr8conf.org/register) to **save €300** with the Early Bird rate!

Three days packed with **Groovy, Grails, Griffon, Gradle, Spock, GPars, Gaelyk, AST transformations, GContracts, Grails Plugins development**, and lots of other gr8 stuff.

This year, the **conference is growing**. We kick of the conference with a **university day**, with two tracks, one intermediate and one advanced, with workshops and hands-on training:

*   The intermediate will kickstart your Groovy and Grails development skills with a **Groovy workshop**, followed by a **Grails workshop**.
*   The advanced track will feature an **AST transformations workshop**, followed by a **Grails plugin development workshop**.

Note: The university day is optional, if you only want to attende the two main conference days.

The [conference agenda](http://www.eu2011.gr8conf.org/agenda/list) will feature updates from Groovy, Grails, Griffon, Gradle, Spock and others, by the founders and developers of these tools and frameworks.

**You will learn all about those groovy-powered project of the ecosystem from the horse’s mouth**. If you want to meet and chat with guys like Guillaume Laforge, Jochen “blackdrag” Theodorou, Paul King, Dierk König and Hamlet D’Arcy (Groovy), like Andres Almiray (Griffon), like Peter Ledbrook and Burt Beckwith (Grails), like Peter Niederwieser (Gradle and Spock), or Václav Pech (GPars), and many more, this is the best opportunity for you to interact with the gang!

There will be **case studies** from various companies, telling about **real life projects**, and there will be lots of sessions covering various topics in the Groovy ecosystem. To cram this in to two days, the conference is going to be **two-tracked**, compared to the previous editions.

To top it off, we feature [Hackergarten](http://hackergarten.net/) — an open event, where you can come and hack your favorite Open Source project. You can attend even if you are not a conference attendee!

The conference takes place in **Copenhagen**, Denmark, on **May 17th-19th**.

You can benefit from the interesting **Early Bird** rate until **April 14th** and **save €300**! That’s a bargain you shouldn’t miss!

Register at [http://gr8conf.eu](http://gr8conf.eu/) now!

Søren Berg Glasius and myself are looking forward to meeting you there!

Follow GR8Conf on twitter: [@gr8conf](http://twitter.com/gr8conf)
# New important milestone for Gaelyk, with version 0.6 released


I'm very pleased to announce the release of Gaelyk 0.6.

This new version is a pretty significant milestone, both in terms of features and quality. We're really approaching a final 1.0 version!

Here's a list of the novelties, updates, and bug fixes.

*   Updated to GAE SDK 1.4.0 and Groovy 1.7.6
*   Channel service added in the binding and added a convenient method for sending messages
*   Ability to specify the "warmup request" handler through a route definition
*   Added app.gaelyk.version in the binding
*   Use a servlet context listener for initializing the plugin system
*   Initial support for the asynchronous datastore
*   Updated the task queue enhancements to use the new package (as task queues migrated from labs)
*   Introduced a Gradle build script for building Gaelyk itself
*   Increased the code coverage of the project to over 82%
*   Added before{} request and after{} request lifecycle hooks to plugins
*   Added initial Eclipse project files in the template project
*   Fixed a bug with ignore URL routes which triggered NPEs after the capabilities routing was added
*   Corrected typos in the tutorials

Be careful, however, as there are two breaking changes compared to previous versions:

*   Compared to the previous version of the toolkit, the handling of incoming emails and incoming jabber messages has changed. The GaelykIncomingEmailServlet and GaelykXmppServlet are gone. It is no longer required to have dedicated servlets for those two purposes, instead you must use the URL routing system to indicate the handlers that will take care of the incoming messages. If you were relying on those two servlets, please make sure to upgrade, and read the updated tutorial on URL routing and incoming email and jabber messages.
*   The initialization of the plugin system is not done anymore by the Groovlet and template servlet, but is done by a servlet context listener. So you'll have to update your web.xml file to specify that listener. Please have a look at the template project or the documentation on how to setup the new context listener.

You will also notice that the Gaelyk website has been updated:

*   You will find some "quick links" to go more directly to the information that matters.
*   On the front page, a list of a few live Gaelyk websites in the wild is displayed
*   A ["search" section](http://gaelyk.appspot.com/search) has been implemented, using Google's custom search engine, which will let you search through the Gaelyk website, the GitHub content, as well as the Gaelyk Google Group messages
*   You now have a [single-page documentation](http://gaelyk.appspot.com/tutorial/print) option for those who wish to print the documentation (please think about the trees before printing)
*   And a [PDF of the whole documentation](http://gaelyk.appspot.com/gaelyk.pdf) is available, which is handy for offline browsing.

Please download Gaelyk 0.6 here: [http://gaelyk.appspot.com/download](http://gaelyk.appspot.com/download)

Contribute to Gaelyk:

*   [Discussions](http://gaelyk.appspot.com/community#discuss)
*   [Code repository](http://gaelyk.appspot.com/community#repository)
*   [Bug tracker](http://gaelyk.appspot.com/community#bugtracker)

Thanks a lot for your attention and enjoy!
# Gaelyk 0.4.4 out with namespace/multitenancy support


I'm pleased to announce the release of Gaelyk 0.4.4!

What's new?

*   Updated the Google App Engine SDK to the latest 1.3.7 version
*   Jabber and incoming email groovlets now have their implicit logger (gaelyk.email and gaelyk.jabber)
*   Plugins are now impacting Jabber and incoming email groovlets as well
*   Fixed a bug the conversion of String to Datastore's Category type
*   Internal refactorings of the caching logic
*   Added namespace support for multitenancy, added in SDK 1.3.7:
    *   a namespace is added in the binding, pointing at NamespaceManager, the SDK class dealing with namespaces
    *   a new method `namespace.of("customerA") { ... }` to execute a closure in the context of a specific namespace

Although I haven't mentioned it in the notes above (on on the download page), some of the internal refactorings of the caching and routing logic have also helped solving problems with the blobstore support. Please report back to me if it's working as expected, for text content as well as binary content stored in blobstore (the latter was problematic in 0.4.3).

Make sure to download the latest and greatest version of Gaelyk here: [http://gaelyk.appspot.com/download](http://gaelyk.appspot.com/download)

Thanks a lot to all those who contributed to this release!

I'm still looking for some help for some acute eyes to see why we still have this dangling includes issue when mixing includes and cache. I still haven't found the cause, and would gladly accept help to find out what's going on! (I was hoping my internal refactorings would help, but I've not succeeded so far)
# Nicer DSLs in Groovy 1.8 thanks to Extended Command Expressions


A quick heads-up to tell you about an upcoming Groovy 1.8 feature which will allow us to make nicer DSLs. This feature will be available in Groovy 1.8-beta-2, which will probably be released before JavaOne.

Lidia Donajczyk was our Google Summer of Code student this year, working on the implementation of GEP-3, an extension to Groovy's command expressions. You can have a look at the [GEP-3 page](http://docs.codehaus.org/display/GroovyJSR/GEP+3+-+Command+Expression+based+DSL) for the guiding ideas behind this enhancement proposal.

Just like you could use simple command expressions before, like:

```groovy
println "hello"
move left
make coffee
drink tea
```

GEP-3 extends this for more complex sentences such as:

```groovy
drink tea with sugar and milk  
move left by 30.centimeters  
sendFrom "Guillaume" to "Jochen"  
send from: "Jochen" to "Lidia"  
Email.from "Lidia" to "Guillaume" withBody "how are you?"  
contact.name "Guillaume" age 33  
move left by 30.centimeters  
sell 100.shares of MSFT  
take 2.pills of chloroquinine in 6.hours  
blend red, green of acrylic  
artist.paint "wall" with "Red", "Green", and: "Blue" at 3.pm  
wait 2.seconds and execute { assert true }  
concat arr\[0\] with arr\[1\] and arr\[2\]  
developped with: "Groovy" version "1.8-beta-2"
```

A more [thourough example](http://groovyconsole.appspot.com/script/214001) is this:

```groovy
Recipe.instructions {
    take medium_bowl
    combine soy_sauce, vinegar, chili_powder, garlic
    place chicken into sauce
    turn once to coat
    marinate 30.minutes at room_temperature
}
```

## Summary of the pattern

*   A command-expression is composed of an even number of elements
*   The elements are alternating a method name, and its parameters (can be named and non-named parameters, and a mix of them)
*   A parameter element can be any kind of expression (ie. a method call `foo()`, `foo{}`, or some expression like `x+y`)
*   All those pairs of method name and parameters are actually chained method calls (ie. `send "hello" to "Guillaume"` is two methods chained one after the other as `send("hello").to("Guillaume"))`

## Current limitations

*   Extended command expressions are not yet allowed on the RHS (righ-hand side) of assignments, so you can't yet do: `def movement = move left by 30.centimeters`
*   Also, we can't yet use methods with zero-arguments.

Hopefully, we'll work on those limitations before the final release of Groovy 1.8. One of the nice aspects of this extended command expression pattern is that it should play nicely with most Java APIs following the Java builder pattern.
# GR8Conf: the European conference dedicated to the Groovy ecosystem is back!


The [GR8Conf](http://eu.gr8conf.org/eu2010/) is back! A conference dedicated to [Groovy](http://groovy.codehaus.org/), [Grails](http://grails.org/), [Griffon](http://griffon.codehaus.org/), [Gradle](http://www.gradle.org/), [Spock](http://www.spockframework.org/) and more! This second edition of the conference [takes place in Copehagen, Denmark](http://eu.gr8conf.org/eu2010/information/show/4), again like last year. And it's solely **dedicated to the Groovy Ecosystem**, and all the _GR8_ technologies based on it.

Over [two days, in a single track](http://eu.gr8conf.org/eu2010/agenda/index) (to avoid missing important sessions because of too much choice), you'll hear about:

*   the **Groovy** dynamic language for the JVM
*   the **Grails** web application stack based on Spring, Tomcat and Hibernate
*   the **Griffon** swing application framework for rich desktop applications
*   the **[Gaelyk](http://gaelyk.appspot.com/)** lightweight toolkit for easily developing and deploying small applications to Google App Engine
*   the **Gradle** build solution system
*   the **GPars** parallel library for Groovy

And some advanced talk on:

*   how to use Grails for the mobile web
*   how Grails works under the hood
*   how we're working on Groovy's core system
*   how to do advanced meta-programming with Groovy
*   how to use IntelliJ IDEA to develop with those GR8 technologies

There will also be a pretty interesting case study, on how European Patent Office has leveraged the Groovy dynamic language on its platform, showing once again how Groovy is used for serious enterprise work.

As the [agenda](http://eu.gr8conf.org/eu2010/agenda/index) there's a lot of very rich content for everybody on all those projects, and all those presentations are done by the [makers, leaders and experts](http://eu.gr8conf.org/eu2010/speaker/list) of these projects themselves! To name a few of the [speakers](http://eu.gr8conf.org/eu2010/speaker/list):

*   **Jochen Theodorou** - Groovy Tech Lead
*   **Graeme Rocher** - Grails Project Lead
*   **Andres Almiray** - Griffon project lead
*   **Sébastien Blanc** - Developer of a mobile Grails plugin
*   **Hubert K. Ikkink** (Mr. HaKi) - the famous G&G blogger with tons of great tips
*   **Hamlet D'Arcy** - Groovy committer
*   **Hans Dokter** - the founder of Gradle
*   **Vaclav Pech** - lead of the GPars project
*   **Philippe Delebarre** - from the European Patent Office
*   **Søren Berg Glasius** - the organizer of the conference
*   **Guillaume Laforge** (yours truely) - Groovy Project Manager

With excellent content, star speakers, friendly sponsors, in a nice European location, you really can't afford missing this great event if you're interested in Groovy related technologies!

I'm looking forward to meeting you there, so please, [register now](http://eu.gr8conf.org/eu2010/register)
# Final release of Groovy 1.7!


The Groovy development team and [SpringSource](http://www.springsource.com/) are very pleased to announce the **final release of Groovy 1.7**, the most popular and successful dynamic language for the JVM! After two betas and two release candidates, we're are happy to deliver this new and very important milestone to our ever growing user base.

Over the years, the Groovy project has managed to grow a community, but not only that, a **very rich and active ecosystem** of Groovy-related projects: the[Grails](http://grails.org/) web stack, the [Griffon](http://griffon.codehaus.org/) swing application framework, the [Gant](http://gant.codehaus.org/) and [Gradle](http://gradle.org/) build solutions, the [Gaelyk](http://gaelyk.appspot.com/) lightweight toolkit for Google App Engine, the [Gpars](http://gpars.codehaus.org/)parallel system, the [Easyb](http://easyb.org/) and [Spock](http://www.spockframework.org/) testing frameworks and the [GMock](http://gmock.org/) mocking library, the [CodeNarc](http://codenarc.sourceforge.net/) and [GMetrics](http://gmetrics.sourceforge.net/) quality tools, and many more! With all these initiatives, the world is even groovier and we're thankful these projects have helped us shape what Groovy is today.

Groovy 1.7 provides the following new major features and enhancements:

*   **Anonymous Inner Classes** and **Nested Classes**, for more Java-friendliness
*   **Annotation enhancements**, with the ability to put annotations on imports, packages and variable declarations)
*   **Grape enhancement** (the Groovy module system)
*   **Power Asserts**, for more readable and expressive assertions
*   AST (Abstract Syntax Tree) enhancements with the **AST Viewer** and **AST Builder**, for easing the creation of AST transformations
*   Various dependency upgrades (including the ASM bytecode library to get ready for the JSR-292 InvokeDynamic bytecode instructions)
*   A **rewrite of the GroovyScriptEngine** for more flexibility and rapidity
*   Several **GroovyConsole enhancements**, like line numbers, a new output view, and more
*   Various **SQL improvements**, like batch updates and transaction support
*   and many more enhancements!

You can **learn more about all these features** in the [Groovy 1.7 release notes](http://docs.codehaus.org/display/GROOVY/Groovy+1.7+release+notes).

For further details, you can have a look at our [JIRA release notes](http://jira.codehaus.org/sr/jira.issueviews:searchrequest-printable/temp/SearchRequest.html?jqlQuery=project+%3D+GROOVY+AND+fixVersion+in+%28%221.7.0%22%2C+%221.7-rc-2%22%2C+%221.7-rc-1%22%2C+%221.7-beta-2%22%2C+%221.7-beta-1%22%29+AND+status+in+%28Resolved%2C+Closed%29+ORDER+BY+priority+DESC&tempMax=1000) for some more details.

You can download Groovy in the [download section](http://groovy.codehaus.org/Download) of our website.

The Groovy development team would particularly thank all the users, contributors and committers who helped us all along to improve the quality and usefulness of the language and its APIs, as well as all those projects in the Groovy ecosystem who influenced us and inspired us.

We're offering our community this new release as a Christmas present, hoping you'll enjoy it as much as we did when working on it, and **we wish you all a very Groovy Christmas**, and all **the best for the coming year**!  
Enjoy this new release, and stay tuned for all the upcoming improvements we'll bring you in the future: a more modular and even faster Groovy, additional abilities for more readable and expressive DSLs, and many more exciting features!
# Release train: Grails 1.1.2, Groovy 1.6.6 and 1.7-RC-1, as well as Gaelyk 0.3.2


Big release days!

*   Yesterday, [Grails 1.1.2](http://www.grails.org/1.1.2+Release+Notes) was pulled from the oven, while waiting for Spring 3 to be available to release 1.2.
*   Today, we [released Groovy 1.6.6 and 1.7-RC-1](http://docs.codehaus.org/display/GROOVY/2009/11/27/Groovy+1.6.6+and+1.7-RC-1+released), bringing use closer to the final 1.7 release, which would take place before Christmas.
*   And tonight, I've also updated [Gaelyk 0.3.2](http://groups.google.com/group/gaelyk/browse_thread/thread/fe09f18440e3812d), the lightweight Groovy toolkit for developing applications on Google App Engine. In particular, have a look at the URL routing support and the few bug fixes and also at my [presentation at the Devoxx conference](http://glaforge.free.fr/weblog/index.php?itemid=286).

Have fun and enjoy those releases!
# Devoxx presentation on Google App Engine, Groovy and Gaelyk


I'm back from Devoxx, where I had a very pleasant stay, nice discussions with many attendees and speakers, and it's always a great opportunity to meet friends you haven't seen in a while! And this time, I was there with my friend Patrick Chanezon from Google, to speak about [Google App Engine](http://code.google.com/intl/fr/appengine/), [Groovy](http://groovy.codehaus.org/) and [Gaelyk](http://gaelyk.appspot.com/). I've uploaded our slides on Slideshare, and you can view them embedded here on this blog:

[Google App Engine Java, Groovy and Gaelyk](http://www.slideshare.net/glaforge/google-app-engine-java-groovy-baby)

A bit before the presentation, I also fixed a little but annoying bug with the XMPP support in Gaelyk, bumping the version number to 0.3.1, so if you're using 0.3 already, and need incoming XMPP messaging support, please [upgrade to 0.3.1](http://gaelyk.appspot.com/download/).

The presentation at Devoxx seems to have been pretty well received and attended (I think we reached about 800 geeks in the audience, my new personal record) and people seemed to have appreciated the talk and content, as well as my final [Gaelyk demo](http://groovydemos.appspot.com/), interacting with the app through XMPP. This was quite a lot of fun, and just a few hours of work at night to get the demo ready.

**Update:** I've pushed a [zip file of the demo](http://glaforge.free.fr/groovy/gaelyk-devoxx-demo.zip) I've run online, in case you wanna have a look at that code sample.
# Gaelyk 0.3 released -- a lightweight Groovy toolkit for Google App Engine


Following the _conference-driven development_ principle, right in time for the [Devoxx](http://www.devoxx.com/) conference and my [session](http://www.devoxx.com/display/DV09/Google+Appengine+Java+-+Groovy+baby) with my friend [Patrick Chanezon](http://www.devoxx.com/display/DV09/Patrick+Chanezon) on Google App Engine Java and Gaelyk/Groovy, I've just released a new version (0.3) of the [Gaelyk](http://gaelyk.appspot.com/) lightweight Groovy toolkit for Google App Engine.

This new version fixes a bug, adds some new capabilities, and bring a small change:

*   The Google services bound to the Groovlets and templates through the binding have been renamed (except userService) to remove the service suffix
*   There are some new methods for working with the memcache service, so you can use the map notation (subscript) to access elements of the cache, as well as using the 'in' keyword to check whether a key is present in the cache.
*   Since GAE SDK 1.2.6, incoming email support has been added, so Gaelyk 0.3 also adds support for incoming emails.
*   There was an issue since the birth of Gaelyk with sending emails, it has now been fixed.

Please make sure to check the [tutorial](http://gaelyk.appspot.com/tutorial/), as it's been updated with new sections on these changes and new features.

You can download the latest [JAR](http://gaelyk.appspot.com/download/) and the latest [template project](http://gaelyk.appspot.com/download/) directly from GitHub.

The [Gaelyk website](http://gaelyk.appspot.com/) uses that new version of Gaelyk, as well as the latest 1.2.6 SDK for Google App Engine -- The [Groovy Web Console](http://groovyconsole.appspot.com/) has not yet to been updated.

Please let me also thank some of the contributors to this release, such as Sean Gilligan, Kazuchika Sekiya, Jinto, for their help with improving the tutorial, and to all those who contributed on the mailing-list or elsewhere. For instance, well done to the Averone company for migrating its [website](http://www.averone.com.br/en/empresa.html) to Gaelyk, or the the[Phone4Water](http://phone4water.appspot.com/) website also on Gaelyk!
# Gaelyk 0.2 released -- a lightweight toolkit for Google App Engine


[Gaelyk](http://gaelyk.appspot.com/) is a lightweight toolkit for developing and deploying applications on [Google App Engine](http://code.google.com/appengine/).

As Google recently released an [updated version of their Google App Engine SDK](http://googleappengine.blogspot.com/2009/09/app-engine-sdk-125-released-for-python.html), providing support for [XMPP/Jabber messaging](http://code.google.com/appengine/docs/java/xmpp/overview.html) and [Task Queues](http://code.google.com/appengine/docs/java/taskqueue/overview.html), I've worked on a new Gaelyk version providing support for these new features, with a Groovy touch.

Gaelyk can be downloaded here: [http://gaelyk.appspot.com/download/](http://gaelyk.appspot.com/download/)

You can have a look at the latest [tutorial](http://gaelyk.appspot.com/tutorial/) updated with coverage of:

*   sending / receiving XMPP/Jabber messages,
*   using Task Queues,
*   also an example of how to do queries on the datastore has been added. Read the tutorial here: [http://gaelyk.appspot.com/tutorial/](http://gaelyk.appspot.com/tutorial/)

The [Gaelyk website](http://gaelyk.appspot.com/) uses that new version of Gaelyk, as well as the latest 1.2.5 SDK for Google App Engine. The [Groovy Web Console](http://groovyconsole.appspot.com/) will also be updated shortly to use that new version.

Have fun with Gaelyk!
# Griffon, the holy grail of Swing, is one year old


Time flies, soooo fast! [Griffon](http://griffon.codehaus.org/), the Groovy MVC framework for building desktop applications, is already one year old. Developers know [Groovy](http://groovy.codehaus.org/) and [Grails](http://grails.org/) very well, but there are many other Groovy-based tools and frameworks, and Griffon is a very nice and successful animal of the Groovy ecosystem.

Others are already celebrating this first anniversary on [twitter](http://search.twitter.com/search?q=griffon), as well as in the blogosphere, like some of the Griffon developers:

*   [Jim Shingler](http://jshingler.blogspot.com/2009/09/griffon-celebrates.html)
*   [James Williams](http://jameswilliams.be/blog/entry/155)
*   [Andres Almiray](http://www.jroller.com/aalmiray/entry/happy_birthday_griffon)
*   [Josh Reed](http://josh-in-antarctica.blogspot.com/2009/09/happy-birthday-griffon.html)
*   [Danno Ferrin](http://shemnon.com/speling/2009/09/taking-flight-a-year-of-griffo-1.html)

With tons of plugins, books in the writing, Griffon is really gaining a lot of momentum and mindshare!

Happy Birtday! Long live the Griffon!
# Le podcast des Cast Codeurs est sorti !


Une fois n'est pas coutume, je bloguerai en français dans cette catégorie tech, pour vous annoncer la sortie du podcast des [Cast Codeurs](http://lescastcodeurs.com/) !

Les Cast Codeurs, c'est un podcast en français dans le code sur Java par Emmanuel Bernard (JBoss / Hibernate), Guillaume Laforge (SpringSource / Groovy), Antonio Goncalves (freelance / Paris JUG lead) et Vincent Massol (XWiki / Maven).

Restez informés sur les sujets brûlants de l'industrie Java. Plongez sur un sujet précis avec l'interview de l'éposiode. Supportez les radotages de vos hôtes.

Ecoutez-nous et faites passer le message au tour de vous ! Le JavaPosse n'a qu'à bien se tenir (ou alors faut qu'ils se mettent à parler français !!!)

*   Web : [http://lescastcodeurs.com/](http://lescastcodeurs.com/)
*   iTunes : [http://itunes.apple.com/WebObjects/MZStore.woa/wa/viewPodcast?id=312239675](http://itunes.apple.com/WebObjects/MZStore.woa/wa/viewPodcast?id=312239675)
*   Podcast syndication : [http://lescastcodeurs.com/podcast-rss](http://lescastcodeurs.com/podcast-rss)
*   Blog feed : [http://lescastcodeurs.com/feed/](http://lescastcodeurs.com/feed/)
*   Vos commentaires : [commentaire@lescastcodeurs.com](http://glaforge.free.fr/weblog/commentaire@lescastcodeurs.com)
# Write Groovy applications on Google App Engine!


The news has already spread all around, even on our mailing-lists, but let me echo it again here:

**Groovy is now supported in the newly released Google App Engine Java platform!**

My friend Didier Girard beats me to it and had already [blogged about the support of both Java and Groovy](http://www.insideit.fr/post/2009/04/08/Java-et-Groovy-sont-maintenant-supportes-par-Google-App-Engine) (in French). He was quicker than me... or at least woke up earlier than me ;-)

SpringSource's worked with Google to ensure that Groovy would run well on their platform. Big thanks to the work of Jochen Theodorou, [Matt Taylor](http://weblog.dangertree.net/) and myself, for making this possible!

We [released Groovy 1.6.1](http://docs.codehaus.org/display/GROOVY/2009/04/07/Groovy+1.5.8+and+1.6.1+are+out), with key fixes, for that purpose, yesterday, in time for the big news!

If you want to have a go at it, be quick, as they will only allow 10000 developers to access AppEngine Java initially.

I've written a [tutorial for your first steps for Groovy on AppEngine](http://blog.springsource.com/2009/04/07/write-your-google-app-engine-applications-in-groovy/).

I've also written a small [Google Maps / Geocoding service / Flickr demo in 90 lines of Groovy code](http://myowngroovy.appspot.com/demo.groovy).

Enjoy!
# Announcing the GR8 Conference: a conference dedicated to Groovy, Grails and Griffon


I'm pleased to announce here the organization of a European conference dedicated to Groovy, Grails and Griffon:GR8 Conference — Copenhagen — May 2009  

The **GR8 Conference** is an affordable two-day conference taking place in [Copenhagen, Denmark](http://www.gr8conf.org/location.gsp), on [May 18th and 19th 2009](http://www.gr8conf.org/agenda.gsp), organized by [Javagruppen](http://www.javagruppen.dk/)(Danish JUG) and [SpringSource](http://www.springsource.com/g2one), dedicated to the **Groovy** dynamic language, the **Grails** web framework, the **Griffon** Swing framework, and other great technologies — hence the pun and code name GR8.

* Groovy dynamic language
* Grails agile web application framework
* Griffon Swing framework

## Speakers and audience

All the sessions and labs of the [agenda](http://www.gr8conf.org/agenda.gsp) will be presented by [experts in the field](http://www.gr8conf.org/speakers.gsp) and makers of those technologies, and will give you — developers, tech leads and architects — a practical and **hands-on experience** on all topics covered.

## Registration

If you [register](http://www.gr8conf.org/registration/index) before April 1st, you'll benefit from our **Early Bird rate**, whereas after that date, the regular price will apply. So be sure to register in advance, both for the **affordable price** and because the **seats are limited**!

## Our mission statement

Our goals organizing the conference are the following:

*   Spread the word on those great technologies
*   Help you learn how to best leverage and **integrate those technologies**
*   Get **up-to-speed quickly** for developing your next project
*   Make you come back to work **proficient and productive** with Groovy, Grails and Griffon

## Why you should attend

Here are several reasons why you should attend this conference, beyond just learning more about Groovy, Grails and Griffon:

*   Learn directly **from the experts**
*   **Get up-to-speed rapidly** on Groovy, Grails and Griffon
*   Meet other enthusiasts and share your experiences with them
*   Foster a community around those technologies
*   **Sharpen your skills** in a down economy to get ready when the tables are turning back

## The benefits

Beyond learning more about Groovy, Grails and Griffon, all attendees will bring back home:

*   a 90-day evaluation **license for IntelliJ IDEA**, the best IDE for developing with Groovy, Grails and Griffon
*   a chance to win a free [SpringSource training](http://www.springsource.com/training) on Groovy & Grails, and a **discount** if you decide to follow one of those training courses
*   **coupons** for discounts on major Groovy and Grails books
*   a special edition of [GroovyMag](http://www.groovymag.com/), the Groovy/Grails/Griffon developer magazine
*   all **code samples** of the conference on a **USB key**
*   a brochure on **deploying Grails applications in the cloud**, on the [Morph AppSpace](http://www.mor.ph/grails?utm_source=gr8&utm_medium=cpc&utm_campaign=gr8) cloud computing platform
*   access to all the **video recordings of the sessions** on [Parleys.com](http://www.parleys.com/) after the conference

  
We're looking forward to meeting you at the conference.  
  
The GR8 Conference organizers.
# Lots of Groovy related news!


There's always a lot of activity around Groovy and Groovy-related technologies, but these days, it's pretty hot!

First of all, InfoQ released my "[What's new in Groovy 1.6?](http://www.infoq.com/articles/groovy-1-6)" article going in depth into all the new features of Groovy 1.6, with explanations and code samples. Please [vote for it on DZone](http://www.dzone.com/links/whats_new_in_groovy_16_detailed_article_on_infoq.html) (Guerilla Marketing rulezzz)

If you want to attend a [Groovy / Grails / Griffon dedicated conference](http://www.gr8conf.org/), you should definitely go to the GR8 Conference, in Copenhagen, Denmark, in May. It's going to rock, with star speakers, hands-on sessions, several interesting benefits in the attendee package, and more. Check it out!

And to finish, there are tons of releases:

*   [Groovy 1.6](http://glaforge.free.fr/weblog/index.php?itemid=263)
*   [GMaven 1.0-rc-5: Groovy Maven plugin](http://docs.codehaus.org/display/GROOVY/2009/02/27/GMaven+1.0-rc-5+released)
*   [Griffon 0.1-rc2](http://groovy.dzone.com/announcements/griffon-01-rc2-builds)
*   [Grails 1.1 RC2](http://grails.org/news/14369)

And if you've got some artistic talent or if you know some talented designers, the [Griffon team is still looking for a logo](http://griffon.codehaus.org/Logo+Contest)!
# What's new in Groovy 1.6


[Groovy](http://groovy.codehaus.org/) is a very successful and powerful **dynamic language for the Java Virtual Machine** that provides **seamless integration with Java**, and has its roots firmly planted in Java itself for the syntax and APIs and other languages such as Smalltalk, Python or Ruby for its dynamic capabilities.

Groovy is used in many Open Source projects such as [Grails](http://grails.org/), [Spring](http://www.springframework.org/), JBoss Seam and more, as well as **integrated in commercial products** and **Fortune 500 mission-critical applications** for its scripting capabilities offering a nice extension mechanism to these applications, or for its ability to let subject matter experts and developers author embedded Domain-Specific Languages to **express business concepts in a readable and maintainable fashion**.

In this article, [Guillaume Laforge](http://www.springsource.com/people/glaforge), Groovy Project Manager and Head of Groovy Development at [SpringSource](http://www.springsource.com/), will go through an overview of the novelties offered by the newly released Groovy 1.6.

## Overview of Groovy 1.6

As we shall see in this article, the main highlights of this Groovy 1.6 release are:

-   **Greater compile-time and runtime performance improvements**
-   Multiple assignments
-   Optional return in `if`/`else` and `try`/`catch` blocks
-   Java 5 annotation definition
-   **AST transformations** and all the provided transformation annotations like `@Singleton`, `@Lazy`, `@Immutable`, `@Delegate` and friends
-   The Grape module and dependency system and its `@Grab` transformation
-   Various Swing builder improvements, thanks to the Swing / [Griffon](http://griffon.codehaus.org/) team, as well as several Swing console improvements
-   The integration of **JMX builder**
-   Various **metaprogramming improvements**, like the EMC DSL, per-instance metaclasses even for POJOs, and runtime mixins
-   **JSR-223** scripting engine built-in
-   Out-of-the-box **OSGi readiness**

All those improvements and new features serve one goal: **helping developers be more productive and more agile**, by:

-   Focusing more on the task at hand than on boiler-plate technical code
-   Leveraging existing Enterprise APIs rather than reinventing the wheel
-   Improving the overal performance and quality of the language
-   Enabling developers to customize the language at will to derive their own Domain-Specific Languages

But beyond all these important aspects, **Groovy is not just a language, it's a whole ecosystem**.

The improvements in Groovy's generated bytecode information helps capable tools coverage like [Cobertura](http://docs.codehaus.org/display/GROOVY/Test+Coverage) and its Groovy support, or pave the way for new utilities like [CodeNarc](http://codenarc.sourceforge.net/) for static code analysis for Groovy.

The malleability of the syntax of the language and its metaprogramming capabilities give birth to advanced testing tools such as the [Easyb](http://easyb.org/) Behavior-Driven-Development project, the [GMock](http://code.google.com/p/gmock/) mocking library or the [Spock](http://code.google.com/p/spock/) testing and specification framework.

Again, Groovy's flexibility and expressivity and its scripting capabilities open the doors to advanced build scripting or infrastructure systems for your continuous integration practices and project build solutions, such as [Gant](http://gant.codehaus.org/) and [Graddle](http://www.gradle.org/).

At the tooling level, Groovy also progresses, for instance with its `groovydoc` Ant task to let you generate proper JavaDoc covering, documenting and interlinking both your Groovy and Java source files for your Groovy/Java mixed projects.

And at the same time, IDE makers improve their support for Groovy, by giving users powerful weapons such as cross-language code refactoring, profound understanding of dynamic language idioms, code completion, and more, to make developers productive when using Groovy in their projects.

Now, armed with this knowledge of the Groovy world, it's time to dive into the novelties of Groovy 1.6!

## Performance improvements

A lot of care has been taken to improve both the compile-time and runtime performance of Groovy, compared to previous releases.

The **compiler is 3 to 5 times faster** than in previous releases. This improvement has also been backported in the 1.5.x branch, so that both the old maintenance branch and the current stable branch benefit from this work. Thanks to class lookup caches, the bigger the project, the faster the compilation will be.

However, the most noticeable changes will be in the general runtime performance improvements of Groovy. We used several benchmarks from the [Great Language Shootout](http://shootout.alioth.debian.org/) to measure our progress. On those we selected, compared to the old Groovy 1.5.x line, the **performance improvements ranged from 150% to 460%**. Micro-benchmarks obviously rarely reflect the kind of code you have in your own projects, but the overal performance of your projects should improve significantly.

## Multiple assignments

In Groovy 1.6, there is only one syntax addition for being able to define and assign several variables at once:

```groovy
def (a, b) = [1, 2]

assert a == 1
assert b == 2
```


A more meaninful example may be methods returning longitute and latitude coordinates. If these coordinates are represented as a list of two elements, you can easily get back to each element as follows:

```groovy
def geocode(String location) {
    // implementation returns [48.824068, 2.531733] for Paris, France
}

def (lat, long) = geocode("Paris, France")

assert lat == 48.824068
assert long == 2.531733
```

And you can also define the types of the variables in one shot as follows:

```groovy
def (int i, String s) = [1, 'Groovy']

assert i == 1
assert s == 'Groovy'
```

For the assignment (with prior definition of the variables), just omit the `def` keyword:

```groovy
def firstname, lastname

(firstname, lastname) = "Guillaume Laforge".tokenize()

assert firstname == "Guillaume"
assert lastname == "Laforge"
```

If the list on the right-hand side contains more elements than the number of variables on the left-hand side, only the first elements will be assigned in order into the variables. Also, when there are less elements than variables, the extra variables will be assigned null.

So for the case with more variables than list elements, here, `c` will be `null`:

```groovy
def elements = [1, 2]
def (a, b, c) = elements

assert a == 1
assert b == 2
assert c == null
```

Whereas in the case where there are more list elements than variables, we'll get the following expectations:

```groovy
def elements = [1, 2, 3, 4]
def (a, b, c) = elements

assert a == 1
assert b == 2
assert c == 3
```

For the curious minds, supporting multiple assignments also means we can do the standard school swap case in one line:

```groovy
// given those two variables
def a = 1, b = 2

// swap variables with a list
(a, b) = [b, a]

assert a == 2
assert b == 1
```

## Annotation definition

Actually, when I said that multiple assignments were the sole syntax addition, it's not entirely true. Groovy supported the syntax for annotation definition even in Groovy 1.5, but we had not implemented the feature completely. Fortunately, this is now fixed, and it wraps up all the Java 5 features supported by Groovy, such as **static imports**, **generics**, **annotations**, and **enums**, making Groovy the **sole alternative dynamic language for the JVM supporting all those Java 5 features**, which is critical for a seamless Java integration story, and for the usage in Enterprise frameworks relying on annotations, generics and more, like JPA, EJB3, Spring, TestNG, etc.

## Optional return for `if`/`else` and `try`/`catch`/`finally` blocks

It is now possible for `if`/`else` and `try`/`catch`/`finally` blocks to return a value when they are the last expression in a method or a closure. No need to explicitly use the `return` keyword inside these constructs, as long as they are the latest expression in the block of code.

As an example, the following method will return `1`, although the `return` keyword was omitted.

```groovy
def method() {
    if (true) 1 else 0
}

assert method() == 1
```

For `try`/`catch`/`finally` blocks, the last expression evaluated is the one being returned. If an exception is thrown in the `try` block, the last expression in the `catch` block is returned instead. Note that `finally` blocks don't return any value.

```groovy
def method(bool) {
    try {
        if (bool) throw new Exception("foo")
        1
    } catch(e) {
        2
    } finally {
        3
    }
}

assert method(false) == 1
assert method(true) == 2
```

## AST Transformations

Although at times, it may sound like a good idea to extend the syntax of Groovy to implement new features (like this is the case for instance for multiple assignments), most of the time, we can't just add a new keyword to the grammar, or create some new syntax construct to represent a new concept. However, with the idea of AST (Abstract Syntax Tree) Transformations, we are able to tackle new and innovative ideas without necessary grammar changes.

When the Groovy compiler compiles Groovy scripts and classes, at some point in the process, the source code will end up being represented in memory in the form of a Concrete Syntax Tree, then transformed into an Abstract Syntax Tree. The purpose of AST Transformations is to let developers hook into the compilation process to be able to modify the AST before it is turned into bytecode that will be run by the JVM.

**AST Transformations provides Groovy with improved compile-time metaprogramming capabilities** allowing powerful flexibility at the language level, without a runtime performance penalty.

There are two kinds of transformations: global and local transformations.

-   Global transformations are applied to by the compiler on the code being compiled, wherever the transformation apply. A JAR added to the classpath of the compiler should contain a service locator file at `META-INF/services/org.codehaus.groovy.transform.ASTTransformation` with a line with the name of the transformation class. The transformation class must have a no-args constructor and implement the `org.codehaus.groovy.transform.ASTTransformation` interface. It will be run against every source in the compilation, so be sure to not create transformations which scan all the AST in an expansive and time-consuming manner, to keep the compiler fast.

-   Local transformations are transformations applied locally by annotating code elements you want to transform. For this, we reuse the annotation notation, and those annotations should implement `org.codehaus.groovy.transform.ASTTransformation`. The compiler will discover them and apply the transformation on these code elements.

Groovy 1.6 provides several local transformation annotations, in the Groovy Swing Builder for data binding (`@Bindable` and `@Vetoable`), in the Grape module system for adding script library dependencies (`@Grab`), or as general language features without requiring any syntax change to support them (`@Singleton`, `@Immutable`, `@Delegate`, `@Lazy`, `@Newify`, `@Category`, `@Mixin` and `@PackageScope`). Let's have a look at some of these transformations (`@Bindable` and `@Vetoable` will be covered in the section related to the Swing enhancements, and `@Grab` in the section about Grape).

### @Singleton

Whether the singleton is pattern or an anti-pattern, there are still some cases where we need to create singletons. We're used to create a private constructor, a `getInstance()` method for a static field or even an initialized `public static final` field. So instead of writing code like this in Java:

```java
public class T {
    public static final T instance = new T();
    private T() {}
}
```

You just need to annotate your type with the `@Singleton` annotation:

```groovy
@Singleton class T {}
```

The singleton instance can then simply be accessed with `T.instance` (direct public field access).

You can also have the lazy loading approach with an additional annotation parameter:

```groovy
@Singleton(lazy = true) class T {}
```

Would become more or less equivalent to this Groovy class:

```groovy
class T {
    private static volatile T instance
    private T() {}
    static T getInstance () {
        if (instance) {
            instance
        } else {
            synchronized(T) {
                if (instance) {
                    instance
                } else {
                    instance = new T ()
                }
            }
        }
    }
}
```

Lazy or not, once again, to access the instance, simply do `T.instance` (property access, shorcut for `T.getInstance()`).

### @Immutable

Immutable objects are ones which don't change after initial creation. Such objects are frequently desirable because they are simple and can be safely shared even in multi-threading contexts. This makes them great for functional and concurrent scenarios. The rules for creating such objects are well-known:

-   No mutators (methods that modify internal state)
-   Class must be final
-   Fields must be private and final
-   Defensive copying of mutable components
-   `equals()`, `hashCode()` and `toString()` must be implemented in terms of the fields if you want to compare your objects or use them as keys in e.g. maps

Instead of writing a very long Java or Groovy class mimicking this immutability behavior, Groovy lets you just write an immutable class as follow:

```groovy
@Immutable final class Coordinates {
    Double latitude, longitude
}

def c1 = new Coordinates(latitude: 48.824068, longitude: 2.531733)
def c2 = new Coordinates(48.824068, 2.531733)

assert c1 == c2
```

All the boiler-plate code is generated at compile-time for you! The example shows that to instantiate such immutable coordinates, you can use one of the two constructors created by the transformation, one taking a map whose keys are the properties to set to the values associated with those keys, and the other taking the values of the properties as parameters. The `assert` also shows that `equals()` was implemented and allows us to properly compare such immutable objects.

You can have a look at the [details of the implementation](http://groovy.codehaus.org/Immutable+AST+Macro) of this transformation. For the record, the Groovy example above using the `@Immutable` transformation is over 50 lines of equivalent Java code.

### @Lazy

Another transformation is `@Lazy`. Sometimes, you want to handle the initialization of a field of your clas lazily, so that its value is computed only on first use, often because it may be time-consuming or memory-expensive to create. The usual approach is to customize the getter of said field, so that it takes care of the initialization when the getter is called the first time. But in Groovy 1.6, you can now use the `@Lazy` annotation for that purpose:

```groovy
class Person {
    @Lazy pets = ['Cat', 'Dog', 'Bird']
}

def p = new Person()
assert !(p.dump().contains('Cat'))

assert p.pets.size() == 3
assert p.dump().contains('Cat')
```

In the case of complex computation for initializing the field, you may need to call some method for doing the work, instead of a value like our pets list. This is then possible to have the lazy evaluation being done by a closure call, as the following example shows:

```groovy
class Person {
    @Lazy List pets = { /* complex computation here */ }()
}
```

There is also an option for leveraging Soft references for garbage collection friendliness for expensive data structures that may be contained by such lazy fields:

```groovy
class Person {
    @Lazy(soft = true) List pets = ['Cat', 'Dog', 'Bird']
}

def p = new Person()
assert p.pets.contains('Cat')
```

The internal field created by the compiler for `pets` will actually be a Soft reference, but accessing `p.pets` directly will return the value (ie. the list of pets) held by that reference, making the use of the soft reference transparent to the user of that class.

### @Delegate

Java doesn't provide any built-in delegation mechanism, and so far Groovy didn't either. But with the `@Delegate` transformation, a class field or property can be annotated and become an object to which method calls are delegated. In the following example, an `Event` class has a date delegate, and the compiler will delegate all of `Date`'s methods invoked on the `Event` class to the `Date` delegate. As shown in the latest `assert`, the `Event` class has got a `before(Date)` method, and all of `Date`'s methods.

```groovy
import java.text.SimpleDateFormat

class Event {
    @Delegate Date when
    String title, url
}

def df = new SimpleDateFormat("yyyy/MM/dd")

def gr8conf = new Event(title: "GR8 Conference",
                          url: "[http://www.gr8conf.org](http://www.gr8conf.org/)",
                         when: df.parse("2009/05/18"))
def javaOne = new Event(title: "JavaOne",
                          url: "<http://java.sun.com/javaone/>",
                         when: df.parse("2009/06/02"))

assert gr8conf.before(javaOne.when)
```

The Groovy compiler adds all of `Date`'s methods to the `Event` class, and those methods simply delegate the call to the `Date` field. If the delegate is not a final class, it is even possible to make the `Event` class a subclass of `Date` simply by extending `Date`, as shown below. No need to implement the delegation ourselves by adding each and every `Date` methods to our `Event` class, since the compiler is friendly-enough with us to do the job itself.

```groovy
class Event extends Date {
    @Delegate Date when
    String title, url
}
```

In the case you are delegating to an interface, however, you don't even need to explictely say you implement the interface of the delegate. The `@Delegate` transformation will take care of this and implement that interface. So the instances of your class will automatically be `instanceof` the delegate's interface.

```groovy
import java.util.concurrent.locks.*

class LockableList {
    @Delegate private List list = []
    @Delegate private Lock lock = new ReentrantLock()
}

def list = new LockableList()

list.lock()
try {
    list << 'Groovy'
    list << 'Grails'
    list << 'Griffon'
} finally {
    list.unlock()
}

assert list.size() == 3
assert list instanceof Lock
assert list instanceof List
```

In this example, our `LockableList` is now a composite of a list and a lock and is `instanceof` of `List` and `Lock`. However, if you didn't intend your class to be implementing these interfaces, you would still be able to do so by specifying a parameter on the annotation:

```groovy
@Delegate(interfaces = false) private List list = []
```

### @Newify

The `@Newify` transformation proposes two new ways of instantiating classes. The first one is providing Ruby like approach to creating instances with a `new()` class method:

```groovy
@Newify rubyLikeNew() {
    assert Integer.new(42) == 42
}

rubyLikeNew()
```

But it is also possible to follow the Python approach with omitting the `new` keyword. Imagine the following tree creation:

```groovy
class Tree {
    def elements
    Tree(Object... elements) { this.elements = elements **as** List }
}

class Leaf {
    def value
    Leaf(value) { this.value = value }
}

def buildTree() {
    new Tree(new Tree(new Leaf(1), new Leaf(2)), new Leaf(3))
}

buildTree()
```

The creation of the tree is not very readable because of all those `new` keywords spread across the line. The Ruby approach wouldn't be more readable, since a `new()` method call for creating each element is needed. But by using `@Newify`, we can improve our tree building slightly to make it easier on the eye:

```groovy
@Newify([Tree, Leaf]) buildTree() {
    Tree(Tree(Leaf(1), Leaf(2)), Leaf(3))
}
```

You'll also notice that we just allowed `Tree` and `Leaf` to be *newified*. By default, under the scope which is annotated, all instantiations are *newified*, but you can limit the reach by specifying the classes you're interested in. Also, note that for our example, perhaps a Groovy builder may have been more appropriate, since its purpose is to indeed create any kind of hierarchical / tree strucutre.

If we take another look at our coordinates example from a few sections earlier, using both `@Immutable` and `@Newify` can be interesting for creating a path with a concise but type-safe manner:

```groovy
@Immutable final class Coordinates {
    Double latitude, longitude
}

@Immutable final class Path {
    Coordinates[] coordinates
}

@Newify([Coordinates, Path])
def build() {
    Path(
        Coordinates(48.824068, 2.531733),
        Coordinates(48.857840, 2.347212),
        Coordinates(48.858429, 2.342622)
    )
}

assert build().coordinates.size() == 3
```

A closing remark here: since a `Path(Coordinates[] coordinates)` was generated, we can use that constructor in a *varargs way* in Groovy, just as if it had been defined as `Path(Coordinates... coordinates)`.

### @Category and @Mixin

If you've been using Groovy for a while, you're certainly familiar with the concept of Categories. It's a mechanism to extend existing types (even final classes from the JDK or third-party libraries), to add new methods to them. This is also a technique which can be used when writing Domain-Specific Languages. Let's consider the example below:

```groovy
final class Distance {
    def number
    String toString() { "${number}m" }
}

class NumberCategory {
    static Distance getMeters(Number self) {
        new Distance(number: self)
    }
}

use(NumberCategory) {
    def dist = 300.meters

    assert dist instanceof Distance
    assert dist.toString() == "300m"
}
```

We have a simplistic and fictive `Distance` class which may have been provided by a third-party, who had the bad idea of making the class `final` so that nobody could ever extend it in any way. But thanks to a Groovy Category, we are able to decorate the `Distance` type with additional methods. Here, we're going to add a `getMeters()` method to numbers, by actually decorating the `Number` type. By adding a getter to a number, you're able to reference it using the nice property syntax of Groovy. So instead of writing `300.getMeters()`, you're able to write `300.meters`.

The downside of this category system and notation is that to add instance methods to other types, you have to create `static` methods, and furthermore, there's a first argument which represents the instance of the type we're working on. The other arguments are the normal arguments the method will take as parameters. So it may be a bit less intuitive than a normal method definition we would have added to `Distance`, should we have had access to its source code for enhancing it. Here comes the `@Category` annotation, which transforms a class with instance methods into a Groovy category:

```groovy
@Category(Number)
class NumberCategory {
    Distance getMeters() {
        new Distance(number: this)
    }
}
```

No need for declaring the methods `static`, and the `this` you use here is actually the number on which the category will apply, it's not the real `this` of the category instance should we create one. Then to use the category, you can continue to use the `use(Category) {}` construct. What you'll notice however is that these kind of categories only apply to one single type at a time, unlike classical categories which can be applied to any number of types.

Now, pair `@Category` extensions to the `@Mixin` transformation, and you can mix in various behavior in a class, with an approach similar to multiple inheritance:

```groovy
@Category(Vehicle) class FlyingAbility {
    def fly() { "I'm the ${name} and I fly!" }
}

@Category(Vehicle) class DivingAbility {
    def dive() { "I'm the ${name} and I dive!" }
}

interface Vehicle {
    String getName()
}

@Mixin(DivingAbility)
class Submarine implements Vehicle {
    String getName() { "Yellow Submarine" }
}

@Mixin(FlyingAbility)
class Plane implements Vehicle {
    String getName() { "Concorde" }
}

@Mixin([DivingAbility, FlyingAbility])
class JamesBondVehicle implements Vehicle {
    String getName() { "James Bond's vehicle" }
}

assert new Plane().fly() ==
       "I'm the Concorde and I fly!"
assert new Submarine().dive() ==
       "I'm the Yellow Submarine and I dive!"

assert new JamesBondVehicle().fly() ==
       "I'm the James Bond's vehicle and I fly!"
assert new JamesBondVehicle().dive() ==
       "I'm the James Bond's vehicle and I dive!"
```

You don't inherit from various interfaces and inject the same behavior in each subclass, instead you mixin the categories into your class. Here, our marvelous James Bond vehicle gets the flying and diving capabilities through mixins.

An important point to make here is that unlike `@Delegate` which can *inject* interfaces into the class in which the delegate is declared, `@Mixin` just does runtime mixing --- as we shall see in the metaprogramming enhancements further down in this article.

### @PackageScope

Groovy's convention for properties is that any *field* without any visibility modifier is exposed as a property, with a getter and a setter transparently generated for you. For instance, this `Person` class exposes a getter `getName()` and a setter `setName()` for a private `name` field:

```groovy
class Person {
    String name
}
```

Which is equivalent to this Java class:

```groovy
public class Person {
    private String name;
    public String getName() { return name; }
    public void setName(name) { this.name = name; }
}
```

That said, this approach has one drawback in that you don't have the possibility to define a field with package-scope visibility. To be able to expose a field with package-scope visibility, you can now annotate your field with the `@PackageScope` annotation.

## Grape, the Groovy Adaptable / Advanced Packaging Engine

To continue our overview of the AST transformations, we'll now learn more about Grape, a mechanism to add and leverage dependencies in your Groovy scripts. Groovy scripts can require certain libraries: by explicitly saying so in your script with the `@Grab` transformation or with the `Grape.grab()` method call, the runtime will find the needed JARs for you. With Grape, you can easily distribute scripts without their dependencies, and have them downloaded on first use of your script and cached. Under the hood, Grape uses Ivy and Maven repositories containing the libraries you may need in your scripts.

Imagine you want to get the links of all the PDF documents referenced by the Java 5 documentation. You want to parse the HTML page as if it were an XML-compliant document (which it is not) with the Groovy `XmlParser`, so you can use the TagSoup SAX-compliant parser which transforms HTML into well-formed valid XML. You don't even have to mess up with your classpath when running your script, just *grab* the TagSoup library through Grape:

```groovy
import org.ccil.cowan.tagsoup.Parser

// find the PDF links in the Java 1.5.0 documentation
@Grab(group='org.ccil.cowan.tagsoup', module='tagsoup', version='0.9.7')
def getHtml() {
    def tagsoupParser = new Parser()
    def parser = new XmlParser(tagsoupParser)
    parser.parse("http://java.sun.com/j2se/1.5.0/download-pdf.html")
}

html.body.'**'.a.@href.grep(~/.*\.pdf/).each{ println it }
```

For the pleasure of giving another example: let's use the [Jetty servlet container](http://www.mortbay.org/jetty/) to expose [Groovy templates](http://groovy.codehaus.org/Groovy+Templates) in a few lines of code:

```groovy
import org.mortbay.jetty.Server
import org.mortbay.jetty.servlet.*
import groovy.servlet.*

@Grab(group = 'org.mortbay.jetty', module = 'jetty-embedded', version = '6.1.0')
def runServer(duration) {
    def server = new Server(8080)
    def context = new Context(server, "/", Context.SESSIONS);
    context.resourceBase = "."
    context.addServlet(TemplateServlet, "*.gsp")
    server.start()
    sleep duration
    server.stop()
}

runServer(10000)
```

Grape will download Jetty and its dependencies on first launch of this script, and cache them. We're creating a new Jetty `Server` on port 8080, then expose Groovy's `TemplateServlet` at the root of the context --- Groovy comes with its own powerful template engine mechanism. We start the server and let it run for a certain duration. Each time someone will hit `http://localhost:8080/somepage.gsp`, it will display the `somepage.gsp` template to the user --- those template pages should be situated in the same directory as this server script.

Grape can also be used as a method call instead of as an annotation. You can also install, list, resolve dependencies from the command-line using the `grape` command. For [more information on Grape](http://groovy.codehaus.org/Grape), please refer to the documentation.

## Swing builder improvements

To wrap up our overview of AST transformations, let's finish by speaking about two transformations very useful to Swing developers: `@Bindable` and `@Vetoable`. When creating Swing UIs, you're often interested in monitoring the changes of value of certain UI elements. For this purpose, the usual approach is to use JavaBeans `PropertyChangeListener`s to be notified when the value of a class field changes. You then end up writing this very common boiler-plate code in your Java beans:

```java
import java.beans.PropertyChangeSupport;
import java.beans.PropertyChangeListener;

public class MyBean {
    private String prop;

    PropertyChangeSupport pcs = new PropertyChangeSupport(this);

    public void addPropertyChangeListener(PropertyChangeListener l) {
        pcs.add(l);
    }

    public void removePropertyChangeListener(PropertyChangeListener l) {
        pcs.remove(l);
    }

    public String getProp() {
        return prop;
    }

    public void setProp(String prop) {
        pcs.firePropertyChanged("prop", this.prop, this.prop = prop);
    }

}
```

Fortunately, with Groovy and the `@Bindable` annotation, this code can be greatly simplified:

```groovy
class MyBean {
    @Bindable String prop
}
```

Now pair that with Groovy's Swing builder new `bind()` method, define a text field and bind its value to a property of your data model:

```groovy
textField text: bind(source: myBeanInstance, sourceProperty: 'prop')
```

Or even:

```groovy
textField text: bind { myBeanInstance.prop }
```

The binding also works with simple expressions in the closure, for instance something like this is possible too:

```groovy
bean location: bind { pos.x + ', ' + pos.y }
```

You may also be interested in having a look at [ObservableMap](http://groovy.codehaus.org/api/groovy/util/ObservableMap.html) and [ObservableList](http://groovy.codehaus.org/api/groovy/util/ObservableList.html), for a similar mechanism on maps and lists.

Along with `@Bindable`, there's also a `@Vetoable` transformation for when you need to be able to veto some property change. Let's consider a `Trompetist` class, where the performer's name is not allowed to contain the letter 'z':

```groovy
import java.beans.*
import groovy.beans.Vetoable

class Trumpetist {
    @Vetoable String name
}

def me = new Trumpetist()
me.vetoableChange = { PropertyChangeEvent pce ->
    if (pce.newValue.contains('z'))
        throw new PropertyVetoException("The letter 'z' is not allowed in a name", pce)
}

me.name = "Louis Armstrong"

try {
    me.name = "Dizzy Gillespie"
    assert false: "You should not be able to set a name with letter 'z' in it."
} catch (PropertyVetoException pve) {
    assert true
}
```

Looking at a more thorough Swing builder example with binding:

```groovy
import groovy.swing.SwingBuilder
import groovy.beans.Bindable
import static javax.swing.JFrame.EXIT_ON_CLOSE

class TextModel {
    @Bindable String text
}

def textModel = new TextModel()

SwingBuilder.build {
    frame( title: 'Binding Example (Groovy)', size: [240,100], show: true,
          locationRelativeTo: null, defaultCloseOperation: EXIT_ON_CLOSE ) {
        gridLayout cols: 1, rows: 2
        textField id: 'textField'
        bean textModel, text: bind{ textField.text }
        label text: bind{ textModel.text }
    }
}
```

Running this script shows up the frame below with a text field and a lable below, and the label's text is bound on the text field's content.

![@Bindable Swing builder demo](https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/groovy-1-6/en/resources/bindable-example.png)

SwingBuilder has evolved so nicely in the past year that the Groovy Swing team decided to launch a new project based on it, and on the Grails foundations: project [Griffon](http://griffon.codehaus.org/) was born. Griffon proposes to bring the *Convention over Configuration* paradigm of Grails, as well as all its project structure, plugin system, gant scripting capabilities, etc.

If you are developing Swing rich clients, make sure to have a look at [Griffon](http://griffon.codehaus.org/).

## Swing console improvements

Swinging along the topic of UIs, the Swing console has also evolved:

-   The console can be run as an Applet (`groovy.ui.ConsoleApplet`).
-   Beyond syntax highlighting, the editor also supports code indentation.
-   Drag'n droping a Groovy script over the text area will open the file.
-   You can modify the classpath with which the script in the console is being run, by adding a new JAR or a directory to the classpath as shown in the screenshot below.

    ![Swing console: Add a JAR in the classpath](https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/groovy-1-6/en/resources/sc-add-jar.png)

-   A couple options have been added to the view menu item: for showing the script being run in the output area, and for visualizing the execution results.

    ![Swing console: visualization options](https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/groovy-1-6/en/resources/sc-options.png)

-   When an exception is thrown in your script, the lines of the stacktrace relative to your script are clickable, for easy navigation to the point where the error occurred.

    ![](https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/groovy-1-6/en/resources/sc-click-stack.png)

-   Also, when your script contains compilation errors, the error messages are clickable too.

    ![](https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/groovy-1-6/en/resources/sc-click-comp-error.png)

Back on the visualization of the results in the script output area, a fun system was added to let you customize how certain results are rendered. When you execute a script returning a map of Jazz musicians, you may see something like this in your console:

![](https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/groovy-1-6/en/resources/sc-without-visu.png)

What you see here is the usual textual representation of a `Map`. But, what if we enabled custom visualization of certain results? The Swing console allows you to do just that. First of all, you have to ensure that the visualization option is ticked: `View -> Visualize Script Results` --- for the record, all settings of the Groovy Console are stored and remembered thanks to the Preference API. There are a few result visualizations built-in: if the script returns a `java.awt.Image`, a `javax.swing.Icon`, or a `java.awt.Component` with no parent, the object is displayed instead of its `toString()` representation. Otherwise, everything else is still just represented as text. Now, create the following Groovy script in `~/.groovy/OutputTransforms.groovy`:

```groovy
import javax.swing.*

transforms << { result ->
    if (result instanceof Map) {
        def table = new JTable(
            result.collect{ k, v -<
                [k, v?.inspect()] **as** Object[]
            } **as** Object[][],
            ['Key', 'Value'] **as** Object[])
        table.preferredViewportSize = table.preferredSize
        return new JScrollPane(table)
    }
}
```

The Groovy Swing console will execute that script on startup, injecting a `transforms` list in the binding of the script, so that you can add your own script results representations. In our case, we transform the `Map` into a nice-looking Swing `JTable`. And we're now able to visualize maps in a friendly and attractive fashion, as the screenshot below shows:![](https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/articles/groovy-1-6/en/resources/sc-with-visu.png)

The Swing console is obviously not to be confused with a real full-blown IDE, but for daily scripting tasks, the console is a handy tool in your toolbox.

## Metaprogramming enhancements

What makes Groovy a dynamic language is its Meta-Object Protocol and its concept of metaclasses which represent the runtime behavior of your classes and instances. In Groovy 1.6, we continue improving this dynamic runtime system, bringing several new capabilities into the mix.

### Per instance metaclass even for POJOs

So far, Groovy POGOs (Plain Old Groovy Objects) could have a per-instance metaclass, but POJOs could only have one metaclass for all instances (ie. a per-class metaclass). This is now not the case anymore, as POJOs can have a per-instance metaclass too. Also, setting the metaclass property to null will restore the default metaclass.

### ExpandoMetaClass DSL

Initially developed under the [Grails](http://grails.org/) umbrella and integrated back into Groovy 1.5, ExpandoMetaClass is a very handy way for changing the runtime behavior of your objects and classes, instead of writing full-blow `MetaClass` classes. Each time, we want to add / change several properties or methods of an existing type, there is too much of a repetition of `Type.metaClass.xxx`. Take for example this extract of a [Unit manipulation DSL](http://groovy.dzone.com/news/domain-specific-language-unit-) dealing with operator overloading:

```groovy
Number.metaClass.multiply = { Amount amount -> amount.times(delegate) }
Number.metaClass.div =      { Amount amount -> amount.inverse().times(delegate) }

Amount.metaClass.div =      { Number factor -> delegate.divide(factor) }
Amount.metaClass.div =      { Amount factor -> delegate.divide(factor) }
Amount.metaClass.multiply = { Number factor -> delegate.times(factor) }
Amount.metaClass.power =    { Number factor -> delegate.pow(factor) }
Amount.metaClass.negative = { -> delegate.opposite() }
```

The repetition, here, looks obvious. But with the ExpandoMetaClass DSL, we can streamline the code by regrouping the operators per type:

```groovy
Number.metaClass {
    multiply { Amount amount -> amount.times(delegate) }
    div      { Amount amount -> amount.inverse().times(delegate) }
}

Amount.metaClass {
    div <<   { Number factor -> delegate.divide(factor) }
    div <<   { Amount factor -> delegate.divide(factor) }
    multiply { Number factor -> delegate.times(factor) }
    power    { Number factor -> delegate.pow(factor) }
    negative { -> delegate.opposite() }
}
```

A `metaClass()` method takes a closure as single argument, containing the various definitions of the methods and properties, instead of repeating the `Type.metaClass` on each line. When there is just one method of a given name, use the pattern `methodName { /* closure */ }`, but when there are several, you should use the append operator and follow the patten `methodName << { /* closure */ }`. Static methods can also be added through this mechanism, so instead of the classical approach:

```groovy
// add a fqn() method to Class to get the fully
// qualified name of the class (ie. simply Class#getName)
Class.metaClass.static.fqn = { delegate.name }

assert String.fqn() == "java.lang.String"

You can now do:

Class.metaClass {
    'static' {
        fqn { delegate.name }
    }
}
```

Note here that you have to quote the `static` keyword, to avoid this construct to look like a static initializer. For one off method addition, the classical approach is obviously more concise, but when you have several methods to add, the EMC DSL makes sense.

The usual approach for adding properties to existing classes through ExpandoMetaClass is to add a getter and a setter as methods. For instance, say you want to add a method that counts the number of words in a text file, you could try this:

```groovy
File.metaClass.getWordCount = {
    delegate.text.split(/\w/).size()
}

new File('myFile.txt').wordCount
```

When there is some logic inside the getter, this is certainly the best approach, but when you just want to have new properties holding simple values, through the ExpandoMetaClass DSL, it is possible to define them. In the following example, a `lastAccessed` property is added to a `Car` class --- each instance will have its property. Whenever a method is called on that car, this property is updated with a newer timestamp.

```groovy
class Car {
    void turnOn() {}
    void drive() {}
    void turnOff() {}
}

Car.metaClass {
    lastAccessed = null
    invokeMethod = { String name, args ->
        def metaMethod = delegate.metaClass.getMetaMethod(name, args)
        if (metaMethod) {
            delegate.lastAccessed = new Date()
            metaMethod.doMethodInvoke(delegate, args)
        } else {
            throw new MissingMethodException(name, delegate.class, args)
        }
    }
}

def car = new Car()
println "Last accessed: ${car.lastAccessed ?: 'Never'}"

car.turnOn()
println "Last accessed: ${car.lastAccessed ?: 'Never'}"

car.drive()
sleep 1000
println "Last accessed: ${car.lastAccessed ?: 'Never'}"

sleep 1000
car.turnOff()
println "Last accessed: ${car.lastAccessed ?: 'Never'}"
```

In our example, in the DSL, we access that property through the `delegate` of the closure, with `delegate.lastAccessed = new Date()`. And we intercept any method call thanks to `invokeMethod()`, delegating to the original method for the call, and throwing an exception in case the method doesn't exist. Later on, you can see by executing this script that `lastAccessed` is updated as soon as we call a method on our instance.

### Runtime mixins

Last metaprogramming feature we'll cover today: runtime mixins. `@Mixin` allowed you to mixin new behavior to classes you owned and were designing. But you could not mixin anything to types you didn't own. Runtime mixins propose to fill that gap by letting you add a mixin on any type at runtime. If we think again about our example of vehicles with some mixed-in capabilities, if we didn't *own* James Bond's vehicle and give it some diving ability, we could use this mechanism:

```groovy
// provided by a third-party
interface Vehicle {
    String getName()
}

// provided by a third-party
class JamesBondVehicle implements Vehicle {
    String getName() { "James Bond's vehicle" }
}

JamesBondVehicle.mixin DivingAbility, FlyingAbility

assert new JamesBondVehicle().fly() ==
       "I'm the James Bond's vehicle and I fly!"
assert new JamesBondVehicle().dive() ==
       "I'm the James Bond's vehicle and I dive!"
```

One or more mixins can be passed as argument to the static `mixin()` method added by Groovy on `Class`.

## JSR-223 Groovy Scripting Engine

Before Groovy 1.6, if you wanted to integrate Groovy in your Java projects through JSR-223 / `javax.script.*`, you had to download a Groovy script engine implementation from java.net, and put the JAR in your classpath. This additional step wasn't very developer friendly, requiring some additional work --- the JAR wasn't even provided in the Groovy distribution. Thankfully, 1.6 comes with an implementation of the `javax.script.*` APIs.

Below, you'll find an example evaluating Groovy expressions (the code is in Groovy, but it's straightforward to convert it back to Java):

```groovy
import javax.script.*

def manager = new ScriptEngineManager()
def engine = manager.getEngineByName("groovy")

assert engine.evaluate("2 + 3") == 5
```

Please note that the `javax.script.*` APIs are available only on Java 6.

## JMX Builder

Originiating as an [external Open-Source project](http://code.google.com/p/groovy-jmx-builder/) hosted on Google Code, JMX Builder has been integrated in Groovy 1.6, to simplify the life of developers needing to interact or expose JMX services. JMX Builder features:

-   Domain Specific Language (DSL) for JMX API using Builder pattern
-   Simplified JMX API's programmability
-   Declaratively expose Java/Groovy objects as JMX managed MBeans
-   Support class-embedded or explicit descriptors
-   Inherent support for JMX's event model
-   Seamlessly create JMX event broadcasters
-   Attach event listeners as inline closures
-   Use Groovy's dynamic nature to easily react to JMX events notifications
-   Provides a flexible registration policy for MBean
-   No special interfaces or class path restrictions
-   Shields developer from complexity of JMX API
-   Exposes attribute, constructors, operations, parameters, and notifications
-   Simplifies the creation of connector servers and connector clients
-   Support for exporting JMX timers

You can find [more information on JMX Builder](http://groovy.codehaus.org/Groovy+JmxBuilder) and its very extensive coverage of the JMX system. Lots of examples will show you how to create a JMX connector server or client, how to easily export POGOs as JMX managed beans, how to listen to JMX events, and much more.

## Improved OSGi support

The Groovy jar files are released with correct OSGi metadata, so they can be loaded as a bundle into any OSGi compliant container, such as Eclipse Equinox or Apache Felix. You can find [more information on how to use Groovy and OSGi](http://docs.codehaus.org/display/GROOVY/OSGi+and+Groovy) on the Groovy project website. This tutorial will explain how to:

-   Load Groovy as an OSGi service
-   Write a Groovy OSGi service
-   Incude the Groovy JAR within a bundle
-   Plublish a service written in Groovy
-   Consume a service from Groovy
-   Troubleshoot in case you're encountering any problem along the way

You may also be interested in, for instance, how you can [use different versions of Groovy in your application](http://hamletdarcy.blogspot.com/2008/12/beginners-guide-to-osgi-on-desktop.html), thanks to OSGi.

## Summary

Groovy continues its march towards the goal of **simplifying the life of developers**, providing various new features and improvements in this new release: AST transformations reducing dramatically the number of lines of code to express certain concerns and patterns and opening the language to developers for further extension, several **metaprogramming enhancements to streamline your code** and let you write **more expressive business rules**, and **support for common enterprise APIs** such as Java 6's scripting APIs, JMX management system, or OSGi's programming model. All of this is done obviously **without compromising on the seamless integration with Java**, and furthermore, with a **level of performance way higher than previous releases**.

We've now reached the end of this article and if you're not a Groovy user yet, I hope this artcile will give you a better understanding of what Groovy has to offer in your projects, and if you knew and used Groovy already, that you learned about all the new features of the language. The next step for you, dear reader, is to go [download Groovy 1.6](http://groovy.codehaus.org/Download). And if you wish to dive deeper into [Groovy](http://groovy.codehaus.org/), [Grails](http://grails.org/) and [Griffon](http://griffon.codehaus.org/), I also invite you to join us at the [GR8 Conference](http://www.gr8conf.org/), a **conference dedicated to Groovy, Grails and Griffon**, taking place in Copenhagen, Denmark, where experts and makers of these technologies will guide you through with practical presentations and hands-on labs.
# The final version of Groovy 1.6 is there


This is with very great pleasure and honor that I'm announcing the **final release of Groovy 1.6**, on behalf of the Groovy development team and SpringSource.  
Obviously, 1.6 is a very important milestone for the project, with several great new features and improvements:

*   **great runtime performance improvements**
*   **multiple assignments**
*   optional return in `if`/`else` and `try`/`catch` blocks
*   **AST transformations** and all the provided transformation annotations like `@Singleton`, `@Lazy`, `@Immutable`, `@Delegate` and friends
*   the **Grape module and dependency system** and its `@Grab` transformation
*   various Swing builder improvements, thanks to the Swing / Griffon ([http://griffon.codehaus.org](http://griffon.codehaus.org/)) team
*   as well as several Swing console improvements
*   the integration of **JMX builder**
*   **JSR-223 scripting engine built-in**
*   various **metaprogramming improvements**, like the EMC DSL, per-instance metaclasses even for POJOs, and runtime mixins

An article will be published in the coming days on InfoQ and [GroovyMag](http://www.groovymag.com/) coming back on all those features and novelties with more details.

You can **download Groovy 1.6** at the usual place:[http://groovy.codehaus.org/Download](http://groovy.codehaus.org/Download)  
Additional installers and bundles will be provided soon.

And you can also have a look at the [JIRA changelog](http://jira.codehaus.org/browse/GROOVY?report=com.atlassian.jira.plugin.system.project:changelog-panel) listing features, improvements and bug fixes.

Very big thanks to all the developers who contributed to the project, in particular our most prolific ones like Paul, Roshan, Danno and Jochen, and to all our users who've helped shape the project, thanks to their great feedback and suggestions.

Let me also mention an interesting event which is shaping up: the **GR8 Conference**, a conference dedicated to Groovy, Grails and Griffon, organized by the Danish JUG and SpringSource!  

You can learn more about the event on the conference website: [http://www.gr8conf.org](http://www.gr8conf.org/) or by following the twitter account: [GR8 Conference Twitter account](http://twitter.com/gr8conf)  

The conference takes place in Copenhagen, Denmark, and will provide**several practical sessions and hands-on labs** **to get you up-to-speed on those great Groovy-based technologies**. The registration should be open in the coming days, so get ready!
# Groovy 1.6-RC-2 is out! Final version fast approaching!


The Groovy development team and SpringSource are pleased to announce the **second candidate for Groovy 1.6**.  
This release is a bug fix release, and as you can see by looking at the [JIRA issues closed](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&styleName=Html&version=13832) (almost a hundred), a lot of work has been done to ensure that our next major release is of great quality, and various improvements have been introduced -- check for instance the much nicer and thourough [output of GroovyDoc](http://groovy.codehaus.org/gapi/)!

This version obviously also contain all the performance improvements and features of the latest betas and RC. You can read more about them by reading the previous announcements:

*   [Groovy 1.6-beta-1](http://docs.codehaus.org/display/GROOVY/2008/05/02/Groovy+1.6-beta-1+release+with+great+performance+improvements)
*   [Groovy 1.6-beta-2](http://docs.codehaus.org/display/GROOVY/2008/10/09/Release+of+both+Groovy+1.5.7+and+Groovy+1.6-beta-2)
*   [Groovy 1.6-RC-1](http://docs.codehaus.org/display/GROOVY/2008/12/22/Release+Candidate+for+Groovy+1.6+available)

You can download Groovy 1.6-RC-2 at the usual place: [http://groovy.codehaus.org/Download](http://groovy.codehaus.org/Download)

And now, **we need your help to test drive this release candidate**! We need you to find possible critical bugs or regressions, so please make sure you try 1.6-RC-2 with your project, to be able to upgrade as soon as possible to the latest and greatest Groovy.

Thank you all for your hard work and your contributions. We're looking forward to your feedback.
# The Groovy 1.6 release candidate is out!


The Groovy development team and SpringSource are happy to announce the release of the first release candidate of Groovy 1.6.  
  
The JIRA report for this new version lists 74 bug tickets, 26 improvements and 8 new features:  
[http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&styleName=Html&version=14009](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&styleName=Html&version=14009)  
  
Among the bugs being fixed, we tackled issues about:  

*   the compiler
*   bytecode errors
*   varargs handling
*   covariant returns
*   Windows startup scripts

As well as a few regressions:  

*   the `args` variable not bound in Groovy scripts
*   a performance regression in `MarkupBuilder`
*   a problem with `DOMCategory` which was particularly problematic for Grails

Fixes in line error reporting should be handy for IDE vendors, as well as for Cobertura code coverage.  
Compatibility with Java has also been improved slightly, for instance the empty for(;;) {} loop wasn't behaving the same as in Java (no loop, instead of an infinite loop).  
  
The XML support continues to be enhanced, for instance with:  

*   better handling of namespaces with `XmlNodePrinter` and `NamespaceBuilderSupport`
*   new GDK methods in `DOMCategory`
*   you can customize the nodes in `XmlParser`
*   a new builder for StAX, thanks to an external contribution

In other improvements:  

*   Groovysh can be extended, giving you access to certain key internal structures
*   the stacktrace sanitization can be customized should you want to print out nicer stacktraces.
*   new GDK methods have been added for File handling and Date formatting
*   a new `@PackageScope` AST transformation was added to support the package-scope visibility Groovy didn't support
*   improvements to our OSGi manifest for better OSGi support
*   the default resolve strategy used for `.with{}` method has been changed to `DELEGATE_FIRST`
*   GroovyDoc now supports multiple locations in sourcepath
*   an @since tag should be used in documenting the GDK methods so users know when a given GDK method has been added to Groovy

Beyond continuous improvements in Groovy's Swing support thanks to our [Griffon](http://griffon.codehaus.org/) Swing team, the Swing console has seen some interesting improvements as well:  

*   when you have a stacktrace showing up because of an exception being thrown in your scripts, or when you have a compiler error, you'll get clickable messages in the output window, making it easier to navigate to the offending line of code causing the problem
*   you can also now opt to hide the script recopy in the output window
*   and you can also have a visual representation of output results, for instance with Swing components not attached to any parent being displayed on the output, and the nice thing to consider is also the fact anybody is able to customize the output visualizations.

Last but not least, Vladimir Vivien's [JmxBuilder](http://www.infoq.com/news/2008/12/jmx_builder) originally hosted at [Google Code](http://code.google.com/p/groovy-jmx-builder/) was contributed back to Groovy, further improving our existing support of JMX.  
  
Beyond all these bug fixes and other improvements, you still have all the novelties and improvements listed in the betas:  

*   [release notes for 1.6-beta-1](http://glaforge.free.fr/weblog/index.php?itemid=241)
*   [release notes for 1.6-beta-2](http://glaforge.free.fr/weblog/index.php?itemid=256)

Please make sure you try this release candidate within your projects without waiting for the final release, so that we can ensure the final version works well for you.  
  
As usual, you can download Groovy here: [http://groovy.codehaus.org/Download](http://groovy.codehaus.org/Download)   
Noteworthy as well is that we have "retrotranslated" Groovy 1.6-RC-1 to JDK 1.4, should you have to stay with a JDK 1.4 for running Groovy:[http://repository.codehaus.org/org/codehaus/groovy/](http://repository.codehaus.org/org/codehaus/groovy/)  
  
Thanks a lot to all the contributors and committers who made this release possible!
# SpringSource acquires G2One


![](http://www.springsource.com/files/u5/SpringSource-Acquires.png)I'm very pleased to echo, here on my blog, the [announcement of the acquisition of G2One, the Groovy/Grails company I co-founded, by SpringSource](http://www.springsource.com/g2one), the company behind the Spring framework!

Everybody knows [Spring](http://www.springframework.org/) and [SpringSource](http://www.springsource.com/) already, its wealth of Enterprise projects, and how it quickly became the de facto Enterprise standard for building mission-critical applications. Both Groovy and Grails will bring more dynamicity and agility to the Spring portofolio projects, thanks to tighter integration, cross-polination, and further extensibility. At the same time, the two G's will most probably bring a fun coolness factor into the mix, like the icing on the cake!

And you can certainly imagine some areas where integrating Groovy in existing Spring powered projects may be advantageous. Think for a minute about what we could achieve with Groovy integration in the Spring portfolio: think of scripted deployments on dm Server? Writing Spring batch jobs with Groovy scripts, that even administrator could develop and maintain? Easily manipulating Spring exposed JMX beans with Groovy's JMX support? Introspecting a deployed live application with a remote Groovy shell or sending script probes? I'm sure we'll find tons of ways to gain from such an integration.

Also, speaking about integration, let me also mention my pet topic of mine: Domain-Specific Languages. You know it's been a while since Spring supported seamlessly integrating and mixing Groovy and Java wired beans together. But with the high flexibility of Groovy, its malleable syntax and powerful meta-programming APIs, Groovy on Spring will unleash the power of Domain-Specific Languages in the Enterprise world! Subject matter experts can already take advantage of Groovy to write business rules in Groovy for their mission critical applications: but here, Spring would become the fabric tying this business logic to Enterprise services, and Groovy the language for clearly expressing business concerns.

Now, more concretely, for Groovy, what does it mean? I see several key benefits to this acquisition.

First of all, SpringSource's Eclipse team will join forces with our own Eclipse team to shift gears in the development of the Groovy/Grails Eclipse plugin. The lack of state of the art Groovy support in Eclipse can still be a limiting factor to adoption in the wild. However improved the plugin has gotten over the past year, lots of work is still needed to bring it on-par with expectations people have when working with their usual Java IDEs. So hopefully, in the coming months, you should see improved support of both Groovy and Grails in Eclipse.

Secondly, SpringSource has extensive experience in managing community-led projects like Tomcat, so their input will be beneficial to the way we run the Groovy project. Also, don't worry, Groovy will not change its license (Groovy is licensed under the ASL 2 license), or anything like that: SpringSource is committed to sustaining and helping the development of the Groovy dynamic language, to bring it to new heights!

Thirdly, I think Groovy will also benefit from Spring's visibility in the Enterprise space and Java ecosystem by bringing added visibility and better and wider marketing. Although Groovy is already the most popular alternative language for the JVM, additional help is always good to make Groovy even more popular!

All in all, I'm very happy to join SpringSource, to continue developing Groovy under their umbrella and with their help and support, and I'm sure everybody will benefit from this closer relationship between our teams. I also encourage you to read [Graeme's post](http://graemerocher.blogspot.com/2008/11/groovy-and-grails-join-spring-family.html) which goes deeper in the benefits for the Grails community as well and read the [FAQ regarding the acquisition](http://www.springsource.com/files/G2OnePublicFAQ.pdf), as well as the [press release](http://www.springsource.com/node/836). Both Graeme and I, as well as the rest of the [G2One](http://www.g2one.com/) team, will remain committed to the projects, and will continue to develop and improve them in the coming years.
# Sun abandons Swing!


I'm really sad to hear the [report Kirill makes](http://www.pushing-pixels.org/?p=758) on **Sun progressively abandonning Swing** (also posted on [java.net](http://weblogs.java.net/blog/kirillcool/archive/2008/11/sun_setting_dow.html)).

Swing is really a very good framework for building rich client applications, and from what I've heard and seen, it's even better than what exists in the .Net world, or compared to things like SWT or Cocoa. Sun is leaving a gem in the cold to bet everything on a half-backed JavaFX technology.

With the focus on JavaFX, Sun progressively lost all its key talented employees who preferred sailing to more gorgeous seas -- I can't blame them for that. With the new app framework, the timing framework, SwingLabs, painters, new look'n feels, a wealth of OSS and commercial components, Swing had great chances to keep up with the rest of the world, and even keep its bleeding edge and stay ahead of the curve. Alas, Swing is dying in favor of a new technology nobody cares about -- why would one use JavaFX when Adobe's Flex and Microsoft's Silverlight are so much more advanced and ready for prime-time, thought and tool'ed for the designer in mind?

There are days where I really don't understand Sun and its decisions. Why abandonning such a great technology? I know it's not always the best technologies that win and prevail, but when you've got a competitive advantage in one area, why not keeping it? Instead of betting everything on the new shiny toy of the day? A shiny toy that's been shamelessly crashing all the JavaOne keynote demos?

I'm perplexed!
# GroovyMag, the Groovy / Grails magazine is out!


![](http://www.groovymag.com/images/gm1_200.jpg)I'm very happy to echo the release of the first issue of [GroovyMag](http://www.groovymag.com/main/), the Groovy and Grails magazine! This is an electronic PDF magazine which will bring you news, articles and tutorials around the [Groovy](http://groovy.codehaus.org/) dynamic language for the JVM and the [Grails](http://grails.org/) agile web application framework.

As the [site](http://www.groovymag.com/main/) shows:

> GroovyMag covers a wide variety of topics in the Groovy and Grails world, featuring some of the best and brightest names in the Groovosphere. Our first issue includes a Grails tutorial, a Groovy/Swing tutorial, community news and more.

In this first issue, you'll find:

*   A preface by Michael Kimsal, the creator of GroovyMag
*   Groovy and Grails community news, and a featured Grails plugin, by Dave Klein
*   A Grails introduction article, by Robert Fischer
*   Builder Swing rich applications with Groovy, by Andres Almiray
*   An opinion piece on Groovy being the future of Java, by Shawn Hartsock
*   An interview of Marcus Irven of Minggl, a company bulding products in Grails

GroovyMag looks very promising, and I wish the best of luck to Michael and its editors, authors and columnists. I also look forward to finding some time to contribute to the magazine myself! [Go check it out](http://www.groovymag.com/main/), it's worth every cent!
# Both Groovy 1.5.7 and 1.6-beta-2 are out!


This is with great pleasure that the Groovy development team and [G2One](http://www.g2one.com/) announce the **joint release of both Groovy 1.5.7** -- current stable and maintenance branch -- and **Groovy 1.6-beta-2** -- the upcoming major release.  
  
Groovy 1.5.7 contains mainly bug fixes (61 bug fixes), but also some minor API improvements (20 improvements) backported from the1.6 branch, whereas Groovy 1.6-beta-2 brings a wealth of novelty (68 bug fixes and 38 improvements and new features). Here, we'll mainly cover the new features of beta-2.  
  
Following up on our major compile-time and runtime performance improvements in beta-1, we continued our efforts in that area for beta-2. But you'll also be interested in discovering the changes and new features brought by this new release.  
  
## Multiple Assignments  
  
In beta-1, we introduced the possibility to define multiple assignments. However, we faced some issues and ambiguities with the subscript notation, so we adapted the syntax slightly by using parentheses instead of square brackets. We also now cover all the assignment use cases, which wasn't the case previously.  
  
You can define and assign several variables at once:  
  
```groovy
def (a, b) = [1,2]  
assert a == 1  
assert b == 2  
```
  
And you can also define the types of the variables in one shot as follows:  
  
```groovy
def (int i, String j) = [1, 'Groovy']  
```
  
For the assignment (without priori definition of the variables), just don't use the 'def' keyword:  
  
```groovy
def a, b  
(a, b) = functionReturningAList()  
```
  
Otherwise, apart from the syntax change, the behavior is the same as in beta-1: if the list on the right-hand side contains more elements than the number of variables on the left-hand side, only the first elements will be assigned in order into the variables. Also, when there are less elements than variables, the extra variables will be assigned null.  
  
## Optional return for if/else and try/catch/finally blocks  
  
Although not a syntax change, but at least a new behavior: it is now possible for `if`/`else` and `try`/`catch`/`finally` blocks to return a value. No need to explicitly use the `return` keyword inside these constructs, as long as they are the latest statement in the block of code.  
  
As an example, the following method will return 1, although the `return` keyword was omitted.  

```groovy
 def method() {  
    if (true) 1 else 0  
 }  
```
  
You can have a look at our [test case](http://fisheye.codehaus.org/browse/~raw,r=13627/groovy/trunk/groovy/groovy-core/src/test/groovy/lang/SynteticReturnTest.groovy) to have an overview of this new behavior.  
  
## AST Transformations  
  
Although at times, it may sound like a good idea to extend the syntax of Groovy to implement new features (like this is the case for instance for multiple assignments), most of the time, we can't just add a new keyword to the grammar, or create some new syntax construct to represent a new concept. However, with the idea of AST (Abstract Syntax Tree) Transformations initiated and introduced in beta-1, we are able to tackle new and innovative ideas without necessary grammar changes.  
  
With AST Transformations, people can hook into the compiler to make some changes to the AST in order to change the program that is being compiled. AST Transformations provides Groovy with improved compile-time metaprogramming capabilities allowing powerful flexibility at the language level, without a runtime performance penalty.  
  
In beta-1, two AST Transformations found their way in the release, pioneered by our talented Groovy Swing team. With the @Bindable transformation marker annotation, property listeners are transparently added to the class for the property that is being annotated. Sames goes for the @Vetoable annotation for vetoing property changes.  
  
In beta-2, new transformations have been created:  

*   `@Singleton` to transform a class into a singleton ([example](http://fisheye.codehaus.org/browse/~raw,r=13529/groovy/trunk/groovy/groovy-core/src/test/org/codehaus/groovy/transform/vm5/GlobalTransformTest.groovy))
*   `@Immutable` to forbid changes to an instance once it's been created ([example](http://fisheye.codehaus.org/browse/~raw,r=13619/groovy/trunk/groovy/groovy-core/src/test/org/codehaus/groovy/transform/vm5/ImmutableTransformTest.groovy))
*   `@Delegate` transparently implement the delegation pattern ([example](http://fisheye.codehaus.org/browse/~raw,r=13592/groovy/trunk/groovy/groovy-core/src/test/org/codehaus/groovy/transform/vm5/DelegateTransformTest.groovy))
*   `@Lazy` for lazily initializing properties ([example](http://fisheye.codehaus.org/browse/~raw,r=13545/groovy/trunk/groovy/groovy-core/src/test/org/codehaus/groovy/transform/vm5/LazyTransformTest.groovy))
*   `@Category` / `@Mixin` helps mixin category methods at compile-time ([example](http://fisheye.codehaus.org/browse/~raw,r=12588/groovy/trunk/groovy/groovy-core/src/test/groovy/lang/vm5/MixinAnnotationTest.groovy))
*   `@Newify` allows to omit using the `new` keyword for creating instances, simply doing Integer(5) will create an instance, and also gives you the ability to use a Ruby-esque syntax with `Integer.new(5)`

Documentation will come on those transformations in time for the final release. In the meantime, don't hesitate to ask questions on the mailing-lists if you'd like to know more.  
  
## Swing builder  
  
The swing builder which pioneered AST transformations added support for binding to simple closures, i.e. `bean(property: bind { otherBean.property } )` is the same as `bind(source: otherBean, target: property)`. It is also a closure so you can do more complex expressions like `bean(location: bind {pos.x + ',' + pos.y} )` -- but the expression needs to stay simple enough: no loops or branching, for instance.  
  
## Grape, the adaptable / advanced packaging engine  
  
Also leveraging AST Transformations, Groovy 1.6-beta-2 provides a preview of the Groovy Advanced or Adaptable Packaging Engine. Groovy scripts can require certain libraries: by explicitly saying so in your script with the @Grab transformation or with the Grape.grab() method call, the runtime will find the needed JARs for you. With Grape, you can easily distribute scripts without their dependencies, and have them downloaded on first use of your script.  
  
For more information on Grape, please read the [documentation](http://groovy.codehaus.org/Grape).  
  
## Per instance metaclass even for POJOs  
  
So far, Groovy classes could have a per-instance metaclass, but POJOs could only have on metaclass for all instances (ie. a per-class metaclass). This is now not the case anymore, as POJOs can have per-instance metaclass too. Also, setting the metaclass property to null will restore the default metaclass.  
  
## ExpandoMetaClass DSL  
  
A new DSL for EMC was created to allow chaining the addition of new methods through EMC without the usual object.metaClass repetition. You can find some examples in our test cases again: [here](http://fisheye.codehaus.org/browse/~raw,r=12759/groovy/trunk/groovy/groovy-core/src/test/org/codehaus/groovy/runtime/PerInstanceMetaClassTest.groovy) and [there](http://fisheye.codehaus.org/browse/~raw,r=13016/groovy/trunk/groovy/groovy-core/src/test/groovy/vm5/ActorTest.groovy).  
  
## Runtime mixins  
  
One last feature I'll mention today is runtime mixins. Unlike the @Category/@Mixin combo, or even the @Delegate transformation, as their name imply, mixin behavior at runtime. You can find examples [here](http://fisheye.codehaus.org/browse/~raw,r=13119/groovy/trunk/groovy/groovy-core/src/test/groovy/lang/vm5/MixinTest.groovy), which also combine the use of the EMC DSL  
  
## Useful links  
  
You can [download both versions here](http://groovy.codehaus.org/Download), and the JARs will be available shortly on the central Maven repository.  
  
And you can read the [release notes from JIRA for 1.5.7](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&styleName=Html&version=14242) and the [release notes for 1.6-beta-2](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&styleName=Html&version=14261).  
  
## Further down the road  
  
We adapted the Groovy roadmap a little: as features which were supposed to be in 1.7 have already been implemented in 1.6, the scope of 1.7 is reduced and 1.8 is made useless, so after 1.6, we'll focus on 1.7 which will mainly bring one new major feature (the ability to define anonymous inner classes in Groovy, to bridge the small difference gap with Java), and afterwards, we'll be able to focus our energy on Groovy 2.0 improving and rewriting parts of the Groovy core to bring in even more performance and to pave the way for even more power features in future versions.  
  
We're looking forward to hearing about your feedback on those two releases.  
Thanks a lot to everybody for their help and respective contributions.
# Listing the properties of a class in order


In the same vein as my recent article on [how to know the variables which are bound or not in a script](http://glaforge.free.fr/weblog/index.php?itemid=247), a user asked [how he could list in order the properties defined in a class](http://markmail.org/message/pmg6h5wfpclwqemd). Unfortunately, using MyClass.metaClass.properties won't guarantee the order in which properties were created. But reusing the technique in my previous article, one can visit the Groovy AST, in order, and just look at the property definitions, fill an ordered list of these properties, and return it once the traversal is finished. Here's what I came up with:

```groovy
import org.codehaus.groovy.ast.expr.*
import org.codehaus.groovy.ast.stmt.*
import org.codehaus.groovy.ast.*
import org.codehaus.groovy.control.*
import org.codehaus.groovy.classgen.*
import java.security.CodeSource

def scriptText = """
class Customer {
    def name
    def phone
    def address1
    def address2
}
"""

// we define a custom visitor that traverses the AST just to look at class properties
class PropertyVisitor extends ClassCodeVisitorSupport {
    def orderedProperties = []
    void visitProperty(PropertyNode node) {
        orderedProperties << node.name
    }
 
    protected SourceUnit getSourceUnit() {
        return source;
    }
}

// we define our custom PrimaryClassNodeOperation
// to be able to hook our code visitor
class CustomSourceOperation extends CompilationUnit.PrimaryClassNodeOperation {
    CodeVisitorSupport visitor
    void call(SourceUnit source, GeneratorContext context, ClassNode classNode) throws CompilationFailedException {
        classNode.visitContents(visitor)
    }
}

// we use our own class loader to add our phase operation
class MyClassLoader extends GroovyClassLoader {
    CodeVisitorSupport visitor
    protected CompilationUnit createCompilationUnit(CompilerConfiguration config, CodeSource source) {
        CompilationUnit cu = super.createCompilationUnit(config, source)
        cu.addPhaseOperation(new CustomSourceOperation(visitor: visitor), Phases.CLASS_GENERATION)
        return cu
    }
}

def visitor =  new PropertyVisitor()
def myCL = new MyClassLoader(visitor: visitor)
// simply by parsing the script with our classloader
// our visitor will be called and will visit the properties of the class in order
def script = myCL.parseClass(scriptText)

assert ['name', 'phone', 'address1', 'address2'] == visitor.orderedProperties
```

Seeing that such AST analysis can be useful from times to times, I even think we could add some GroovyShell#parseWithVisitor(myscript, myvisitor) to avoid writing the same boiler-plate code of setting up the classloader, compilation unit, and so on. This could be pretty handy. After a discussion with Jochen, we even thought some kind of debugging visitor could be handy, where you'd visit the AST interactively, executing some code on certain nodes, and the tool would record everything, so that you can later reuse that visit. This could be a fun little experiment, and a handy tool when someone needs to do some analysis of the code.
# Groovy in Action book now in Japanese!


![](http://book.mycom.co.jp/MYCOM/image/book/978-4-8399-2727-1.jpg)After the [German translation of ](http://www.amazon.de/Groovy-Einsatz-Andrew-Guillaume-Laforge/dp/3446412387)[Groovy in Action](http://groovy.canoo.com/gina), there's now a Japanese version also available! But not only has it been translated, but it has also been improved and covers Groovy 1.5.6 and contains fixes to all the errata of the original version.

Here's the announcement from Dierk:

> I'm very happy to announce that the japanese edition of "Groovy in Action" has just hit the shelves.
>
> Please visit the [publisher's page](http://book.mycom.co.jp/book/978-4-8399-2727-1/978-4-8399-2727-1.shtml) or [on Amazon Japan](http://www.amazon.co.jp/dp/4839927278/).
>
> Kazuchika Sekiya and his five friends did an awesome job in not only translating the book "as is" but also updating it to the latest Groovy version (1.5.6), adapting all listings and explanations. Furthermore, they went through all known errata of the original version.
>
> Above all, they did not blindly translate word-by-word but challened the meaning of every sentence, asked for clarification, and came up with improved wordings that avoid any kind of ambiguity.
>
> It should not be left unmentioned that the translators work for Sun Microsystems Japan in their day job but did all that hard work in their spare time.
>
> I'm very thankful for the experience of having seen this translation develop and now seeing the grace of the final result. Let's spread the word about Groovy!
>
> Thank you, guys - domo arigato gozaimasu!
# JavaZone: Writing Groovy DSLs presentation online


I've just uploaded my [JavaZone](http://javazone.no/incogito/session/Writing+Domain-Specific+Languages+with+Groovy.html) slides of the Domain-Specific Language presentation available on Slideshare.

{{< speakerdeck cde49b5be5f84f5088048076df87c5a8 >}}

> **Abstract:** Domain-Specific Languages are an "architectural hot-spot", as coined recently by InfoQ editors. With dynamic languages such as Groovy, it is easy to create a mini-language modelling a particular business domain. Thanks to these DSLs, developers and subject matter experts will be able to share a common metaphor, to deliver, hand in hand, the final application to the end users.

> **Outline:** Groovy offers a great deal of flexibility in terms of concise and expressive syntax, and through its dynamic nature. After an introduction to the Groovy dynamic language, and to the concepts of DSLs, their motivation, strenghts and weaknesses, Guillaume Laforge, project lead of Groovy and spec lead of JSR-241 standardizing the Groovy language, will guide you through the advanced Groovy concepts that will help you create your own embedded DSL. He will show you how to integrate them in your JEE application, and also explain how to best design such business languages to ensure their adoption by the end users, their quality, testability, andcapacity to evolve over time to suit the needs of the day. In the IT industry, understanding the domain within which customers evolve is a key factor in the success of a project. From this domain and its wealth of concepts, as software developers and architects, we can derive a design that is aimed at solving problems encountered in the day-to-day business. So far, we mostly solved these brainteasers with computer science paradigms like Object-Oriented Programming, n-tier architectures, or with tools such as rules engines to stay close to the domain at hand. In this session, our goal will be to investigate how the paradigm of Domain-Specific Languages can be leveraged to help our teams build solutions closer to our users' needs and requirements, and how it can provide a viable, efficient and expressive alternative problem-solving pattern. The technology of choice for enabling DSL solutions for your projects will be Groovy, a dynamic language for the Java platform.
# Griffon shows its claws: Grails-like rich Swing client framework released


The mythical eagle/lion is out the door, with a 0.0 version number! [Griffon](http://groovy.codehaus.org/Griffon) is a Grails-like framework for building rich Swing client applications (applets, webstart, standalone). Andres was [hinting](http://www.jroller.com/aalmiray/entry/coming_soon) at the [first release](http://www.jroller.com/aalmiray/entry/griffon_takes_flight) of this new project, and [Danno just announced it](http://shemnon.com/speling/2008/09/announcing-griffon-00-1.html) officially after having shown some [nice preview](http://shemnon.com/speling/2008/08/griffon-and-greet-starting-to.html) of what it's all about by showing a Twitter client built with Griffon.

The Groovy swing team's long been hard at work to provide you with powerful declarative Swing UIs with the Groovy Swing builder, and they've now switched gears to go a big step further by really empowering developers to write, build and distribute clean MVC apps.

So, now, if you want to learn more about Griffon, the best thing to do is to just follow the white rabbit prey:

*   The [Griffon project page](http://groovy.codehaus.org/Griffon)
*   [Downloading and installing Griffon](http://groovy.codehaus.org/Installing+Griffon)
*   And the, just follow the [Griffon quick start](http://groovy.codehaus.org/Griffon+Quick+Start)

Congratulations to [Danno](http://shemnon.com/speling/), [Andres](http://www.jroller.com/aalmiray/) and [James](http://jameswilliams.be/blog/entry/index) for their hard work! They've been [tweeting](http://twitter.com/aalmiray) [like](http://twitter.com/shemnon) [mad](http://twitter.com/ecspike) these past days while getting Griffon ready.

**Update:** Geertjan wrote some interesting articles on Griffon:

*   [Getting Started with Swing MVC Development on Griffon](http://groovy.dzone.com/news/hello-griffon)
*   [Flying with Griffon](http://groovy.dzone.com/news/flying-with-griffon)
*   [The 5 Best Things About Griffon](http://blogs.sun.com/geertjan/date/20080912)
*   [Porting an existing Swing application to Griffon](http://groovy.dzone.com/news/playing-anagrams-griffon)
# Groovy and Grails at the Paris JUG tomorrow night


It's a bit of a late notice, but if you're in Paris these days, you may wish to come to the Paris JUG tomorrow night (Tuesday, September 9th). I'll be presenting an introduction to [Groovy](http://groovy.codehaus.org/) (the dynamic language for the JVM), as well as a presentation on [Grails](http://grails.org/) (the agile and productive web application framework) with the help of my friend and former colleague [Fabrice Robini](http://blog.octo.com/index.php/2008/09/08/138-paris-jug-groovy-et-grails).

You can register [here](http://jugevents.jugpadova.it/jugevents/event/registration.form?event.id=7939) and get more information about the [agenda](http://www.parisjug.org/xwiki/bin/view/Meeting/20080909) of that Paris JUG night.

See you all tomorrow evening!
# Knowing which variables are bound or not in a Groovy script


A few weeks ago on the Groovy mailing-lists, a user wanted to know a way to find which variables were bound or not in a Groovy script, in the context of some custom rules engine. In a Groovy script, names that are not local variables, method parameters, etc. can come from the "binding" associated with a script. This is the way we "inject" variables and values into a script. A usual technique for retrieving variables lazily (for instance when you don't want to put in the binding a variable that is heavy to compute or retrieve) is to create a custom Binding class and override the methods for getting variables from it. But if you really really want to know before executing the scripts (to avoid any side effect upon execution) what variables are bound or not, I've come up with the following script which lists the bound and unbound variables, without having to execute the script.

```groovy
import org.codehaus.groovy.ast.expr.*
import org.codehaus.groovy.ast.stmt.*
import org.codehaus.groovy.ast.*
import org.codehaus.groovy.control.*
import org.codehaus.groovy.classgen.*
import java.security.CodeSource

// example script to analyze
def scriptText = '''
   def foo(args) { args && !d }
   Closure c = { 4 }
   int b = 6
   try {
       println(a + 5 - b + c() / foo(a))
   } catch (Throwable t) {
       println b
   } finally {
       throw d
   }
   assert b
'''

// define a visitor that visits all variable expressions
class VariableVisitor extends ClassCodeVisitorSupport {
   def bound = [] as SortedSet
   def unbound = [] as SortedSet
   void visitVariableExpression(VariableExpression expression) {
       // we're not interested in some special implicit variables
       if (!(expression.variable in ['args', 'context', 'this', 'super'])) {
           // thanks to this instanceof
           // we know if the variable is bound or not
           if (expression.accessedVariable instanceof DynamicVariable) {
               unbound << expression.variable
           } else {
               bound << expression.variable
           }
       }
       super.visitVariableExpression(expression)
   }

   protected SourceUnit getSourceUnit() {
       return source;
   }
}

// we define our custom PrimaryClassNodeOperation
// to be able to hook our code visitor
class CustomSourceOperation extends CompilationUnit.PrimaryClassNodeOperation {
   CodeVisitorSupport visitor
   void call(SourceUnit source, GeneratorContext context, ClassNode
classNode) throws CompilationFailedException {
       classNode.visitContents(visitor)
   }
}

// we use our own class loader to add our phase operation
class MyClassLoader extends GroovyClassLoader {
   CodeVisitorSupport visitor
   protected CompilationUnit
createCompilationUnit(CompilerConfiguration config, CodeSource source)
{
       CompilationUnit cu = super.createCompilationUnit(config, source)
       cu.addPhaseOperation(new CustomSourceOperation(visitor:
visitor), Phases.CLASS_GENERATION)
       return cu
   }
}

def visitor =  new VariableVisitor()
def myCL = new MyClassLoader(visitor: visitor)
// simply by parsing the script with our classloader
// our visitor will be called and will visit all the variables
def script = myCL.parseClass(scriptText)

println "Bound variables:   ${visitor.bound}"
println "Unbound variables: ${visitor.unbound}"
```
# Meeting Neil Armstrong and speaking of Groovy and Grails


![](/img/misc/Neil-Armstrong-OCTO-USI.jpg)

I had the pleasure to participate in [OCTO](http://www.octo.com/)'s [IT University](http://www.universite-du-si.com/) (Université du SI in French) a couple weeks ago. The conference was really great, and I think France really needed such a high-quality IT event as there was no real good event like that until now. So big kudos to the organizers.

Apart from great food, excellent speakers covering interesting topics, I had the pleasure of spending time with my friends from the [OSSGTP](http://www.ossgtp.org/xwiki/bin/view/Main/WebHome) community (Vincent, Guillaume, Patrick, Mag, Didier, Fabrice, Erwan), with my former colleagues, and with some great guys like Ross Mason, Erik Meijer (with great tshirts as usual), and more. But perhaps the most impressive, interesting and emotional-heavy moment of the conference was the closing keynote by astronaut **Neil Armstrong**, as featured on the picture on the side. This man is so humble, interesting, funny, elegant, that everybody really enjoyed listening to him speaking about the space conquest, distilling some nice and funny anecdotes and making parallels with IT, the story of computers, etc. Awesome! It was such a big honnor to have him there!

Back on my presence at the show: I've given two talks at the conference. The first one on Grails, and how you can [innovate without constraints](http://www.slideshare.net/glaforge/innover-sans-contrainte-intgrer-sans-rupture), while being able to properly integrate your innovations back in your IT infrastructure, using [Grails](http://grails.org/). My friend and former colleague Fabrice Robini was the key driver behind this very well attended and appreciated talk.

And I also spoke about [Domain-Specific Languages](http://www.slideshare.net/glaforge/domainspecific-languages-avec-groovy) and how Groovy can help you create your own. 
# Groovy and Grails trainings by G2One in North American


If you're in the **North America** and you want to get up to speed with Groovy and Grails, [G2One](http://www.g2one.com/), the Groovy/Grails company, has just announced its [updated training schedule](http://www.g2one.com/training/) for this year.

From August to November, we'll be in:

*   San Jose (CA)
*   Chicago (IL)
*   Orange County (CA)
*   Austin (TX)
*   Calgary (Canada)
*   and Atlanta (GA)

You can find the [exact dates online](http://www.g2one.com/training/). And you can already register for the [San Jose](http://www.acteva.com/booking.cfm?bevaid=163134) and [Chicago](http://www.acteva.com/booking.cfm?bevaid=163135) dates in August.

These public trainings are the ideal opportunity to learn those technologies by listening to the guys who actually provide them: you learn Groovy and Grails right from the horse mouth! No other horses like us understand Groovy and Grails better! Also, with a nice mix of lecture and hands-on labs, there's no doubt you'll become an expert soon.

For further information, beyond the [G2One site's training section](http://www.g2one.com/training/), you can have a look at the [overal course description](http://www.g2one.com/training/GroovyGrails_3_Day_Workshop_Overview.pdf) to know what's inside the tin.
# The IT conference you can't miss if you're in Paris!


 [](http://www.universite-du-si.com/)

If you're in Paris, next week, make sure you don't miss the "[Université du SI](http://www.universite-du-si.com/)" (IT University) conference, organized by my former colleagues from [OCTO Technology](http://www.octo.com/). This conference is going to rock! Quite frankly, I think France was seriously lacking a good IT conference, and I think OCTO is going to deliver on that promise. I've been told they are pretty soon running out of entry passes as we're close to the deadline, so it's your [last chance to register](http://www.universite-du-si.com/Inscription.aspx).

If you want to hear [Neil Armstrong](http://www.universite-du-si.com/Speakers.aspx#Neil_Armstrong) speak about how he went to the moon, listen to a famous [French philosopher](http://www.universite-du-si.com/Speakers.aspx#Michel_Serres), hear what [C++ inventor Bjarne Stroustrup](http://www.universite-du-si.com/Speakers.aspx#Bjarne_Stroustrup)has to say, you've knocked at the right door. The [line-up of speakers](http://www.universite-du-si.com/Speakers.aspx) is pretty impressive. The [various presentations](http://www.universite-du-si.com/ParcoursLibre.aspx) cover a wide range of very interesting topics, under 4 main categories:

*   Architecture,
*   IT Governance,
*   Methodologies, and
*   Technologies.

I'll personally have the pleasure and honor to also speak there, and will cover my two pet topics: [Groovy](http://groovy.codehaus.org/) and its ability to let you write Domain-Specific Languages, and [Grails](http://grails.org/) for helping people be more productive when developing business apps.

Here are the abstracts of my two talks (in French, I'm sorry!):

*   [Les Domain-Specific Languages avec Groovy](http://www.universite-du-si.com/ParcoursLibre.aspx#domain-specific-languages)  
    Les Domain-Specific Languages sont des artifacts architecturaux à la mode, comme l'indiquait récemment un rédacteur sur InfoQ. Avec les langages dynamique tels que Groovy, il est aisé de créer un mini-langage modélisant un domaine d'expertise particulier. Grâce à ces DSLs, développeurs et experts métier seront capable de partager une métaphore commune, de délivrer, main dans la main, l'application aux utilisateurs finaux. Groovy offre un niveau élevé de flexibilité en termes d'expressivité et de concision de sa syntaxe et au travers de sa nature de langage dynamique. Après une introduction aux concepts de DSLs et leur motivation, Guillaume Laforge, chef de projet de Groovy et spec lead du JSR-251 standardisant le langage Groovy, vous guidera au travers des concepts avancés de Groovy vous permettant de créer votre propre mini-langage métier. Il vous montrera comment intégrer ces langages dans vos applications Java EE, et expliquera également comment au mieux définir ces langages métier, pour s'assurer leur adoption par les utilisateurs finaux, leur qualité, leur testabilité, et leur capacité à évoluer au cours du temps pour répondre au mieux aux besoins du jour, \` toujours en perpétuelle évolution.  
      
    
*   [T18 - Innover sans contraintes, intégrer sans ruptures](http://www.universite-du-si.com/ParcoursLibre.aspx#technologies-non-mainstream-standards-dsi)  
    Le business case est innovant et les contraintes métier imposent des délais serrés... Pour répondre à ce besoin, il existe des solutions open-source "intégrées" permettant d'être très rapidement opérationnel et d'accélérer les développements. Comment favoriser l'innovation sans contraintes et garantir une intégration sans rupture dans le S.I dans le respect de ses normes et standards !? Retour d'expérience sur [Grails](http://grails.org/), framework de développement d’applications Web sur la JVM.
# Groovy 1.6-beta-1 release with great performance improvements


This is with great pleasure that [G2One](http://www.g2one.com/) and the Groovy development team announce the **first beta of Groovy 1.6**.

Beyond the **73 bug fixes** and **24 improvements** listed in the release notes above, the main focus was on performance improvements.

## Compilation and runtime performance improvements

As you may have already noticed with Groovy 1.5.5, **the compiler is 3 to 5 times faster**than in previous releases. This improvement is available both in this development version and in the 1.5.x stable branch. Thanks to class lookup caches, the bigger the project, the faster the compilation will be.

However, the most noticeable changes will be in the general runtime performance improvements of Groovy. We used several benchmarks from the Great Language Shootout to measure our progress. On those we selected, compared to the current Groovy 1.5.6 stable release, the **performance improvements range from 150% to 460%**. Micro-benchmarks obviously don't reflect the kind of code you have in your own projects, but the overal performance of your projects should improve significantly.

Beyond delivering stable and quality releases, **our main focus over the past 10 months has clearly been on performance**.  
Between Groovy 1.0 and 1.5.1, on these same tests, we had already gained up to 80% speed improvements, and even between "dot releases" (1.5.1 and 1.5.6) we gained again up to 40% more. However, it's really in the development branch that we've integrated advanced call site caching techniques and bytecode diets in the runtime to get the 150-460% speed improvements mentioned above.

## Important new features

Apart from performance related work, bug fixing and minor improvements, let me highlight two new key features which are under development.

## Multiple assignments

First of all, I'll mention **multiple assignments**.

A code sample is always worth a thousand words:

```groovy
def listOfN(numOfElem) { 1..numOfElem } 
def a, b 
// variables will contain each successive element of the list 
// and variables beyond the count of elements will be null 
[a, b] = listOfN(1) 
// a list of one element 
assert a == 1 assert b == null 
// if there are more elements, they won't be assigned to any variable 
[a, b] = listOfN(10) 
// a list of ten elements 
assert a == 1 
assert b == 2 
// and you can swap variables with this notation 
[a, b] = [b, a] 
assert a == 2 
assert b == 1
```

## AST Transformations

The other key feature are the **AST Transformations**. It is more of an advanced feature that is useful for people knowing the internals of Groovy. But fortunately, some practical transformations can be of great interest for Swing developers, for instance.

When the Groovy compiler compiles Groovy scripts and classes, at some point in the process, the source code will end up being represented in memory in the form of a Concrete Syntax Tree, then transformed into an Abstract Syntax Tree. The purpose of AST Transformations is to let developers hook into the compilation process to be able to modify the AST before it is turned into bytecode that will be run by the JVM. Using annotations to decorate certain classes, fields or methods, a transformation can be applied to the AST of these elements.

A concrete example of the kind of transformations we can achieve with AST Transformations is the new @Bindable annotation. This is particularly useful if you are a Swing developer. See this example:

```groovy
class MyBean { @Bindable String pro }
```

When you decorate a field with @Bindable, property change listener methods will be transparently added to the bytecode of the class, so that you are able to monitor changes to the value of this field without having to manually write those methods yourself. No need to create an addPropertyListener() and removePropertyListener() method anymore, to fire property change events manually in your property setters, etc.

Danno Ferrin gives us an [interesting overview of this annotation](http://shemnon.com/speling/2008/04/bindable-observable-properties.html) on his blog.

Other useful and interesting transformations and annotations will be coming in the future.

## Annotation definition

Last but not least, as we mentioned annotations above, Groovy 1.5 was still lacking the ability to let us create annotations in Groovy -- they still had to be written in Java. Now it's possible to **define annotations in Groovy** itself with the usual Java syntax.

## Noteworthy remarks

Groovy 1.6-beta-1 is built against JDK 5, but we will provide JDK 1.4 "retro-translated" versions of Groovy.  
Note however that you may not necessarily experience the same performance improvements when running on JDK 1.4, as certain enhancements take advantage of JDK 5 (util.concurrent VM optimizations, for instance).  
The bytecode generated by the Groovy compiler, as before, still targets the 1.4 JVM bytecode, except for annotations, enums and generics.

## Useful links

You can download this new beta here:  
[http://groovy.codehaus.org/Download](http://groovy.codehaus.org/Download)

And read the release notes from JIRA here:  
[http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&styleName=Html&version=14008](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&styleName=Html&version=14008)

## Conclusion

Thanks a lot to all those who have helped us making this release: users, contributors, committers, G2One employees.  
This performant and innovative new version wouldn't be the same without all your hard work.  
Special thanks to Paul King, Danno Ferrin, Alex Tkachman and Jochen "blackdrag" Theodorou for their commitment and quality work.

We're **very interested in hearing about your feedback** on this release.  
Even if it's not the final 1.6 stable release and that you stick with 1.5.x in production, we would like to know how this beta performs in your respective projects, whether you notice any problem or regression. Please report anything you may find.

Enjoy!
# Groovy / Grails meetup, next Monday evening, in San Francisco


If you're going to JavaOne this year, and if you're interested in Groovy and Grails, you can't miss [G2One](http://www.g2one.com/)'s free [Groovy / Grails meetup](http://www.g2one.com/meetup/), Monday evening, 7pm, at the W Hotel, across the street from Moscone.

It's going to be a great opportunity to meet the guys behind both [Groovy](http://groovy.codehaus.org/) and [Grails](http://grails.org/), learn about the latest news about these projects, see some cool demos, and hear about customers who've decided to use Grails in their projects. You'll be able to also get great Groovy books signed by authors [Venkat Subramaniam](http://www.pragprog.com/titles/vslg/programming-groovy) and [Scott Davis](http://www.pragprog.com/titles/sdgrvr/groovy-recipes).

After an hour and half of keynote, testimonials and cool demos, drinks and apetizers will be provided, and after the break will take place the [NFJS meeting](http://www.nofluffjuststuff.com/nfjsmeetupJ1.jsp) with an interesting panel discussion.

So, to recap, we're pleased to invite you to the free [Groovy/Grails meetup](http://www.g2one.com/meetup/), on Monday 5th, at 7pm, at the W Hotel, across the street from Moscone.

Please make sure to [register](http://www.g2one.com/meetup/registration/register) to confirm your presence.
# Grails, nominated for JAX innovation award


This week takes place the 2008 [JAX conference](http://it-republik.de/jaxenter/jax/), in Germany. Last year, [Groovy won the first prize](http://docs.codehaus.org/display/GROOVY/2007/04/26/Groovy+wins+first+prize+at+JAX+2007+innovation+award) of the JAX innovation award, and this year, Grails was submitted and has just been [nominated by the jury](http://www.jaxmag.com/itr/news/psecom,id,41565,nodeid,146.html).[Guillaume Laforge](http://www.g2one.com/company.html#guillaume), Groovy project lead and initiator of the Grails project, will be at JAX this week and will represent the Grails team and project.

From the nomination announcement:  

> Now it is official: The ten nominees for the JAX Innovation Award. The winners of the award are kept top secret and will be made public next week at the JAX. The award, which is endowed with price money of 20,000 Euro altogether, originated from an initiative of the Software & Support publishing company.
> 
> Among many submissions from all over Europe our jury has selected these ten contributions. The contribution's innovative value, creativity, elegance and relevancy for practice have been the assessment criteria of the jury.
> 
> *   Apache Sling
> *   Biometric Authentification
> *   GIANTsuite AdCreator
> *   Grails
> *   GreenFire
> *   Intrexx Xtreme 4
> *   Java business transaction performance management across the entire application lifecycle
> *   jBPM
> *   PETA
> *   Visual Rules Business Rules Management System
> 
> It is the intention of the JAX Innovation Award to place inspiring innovations from Europe in the limelight and thus help them to get their chance of success. All interested people can enter this contest. Contributions could be submitted by companies but also by individual people, from research and education or from other organizations that contribute to Java, Eclipse or SOA with their project.
# Groovy 1.5.5 released: compiler 3-5x faster


[G2One, Inc.](http://www.g2one.com/) and the Groovy development team are pleased to announce the release of **Groovy 1.5.5**, a bug fix release of the 1.5.x stable branch.

Beyond all the [bug fixes and consistency improvements](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&styleName=Html&version=14028), the major aspect of this release is certainly the improvements in compilation speed. As part of our **ongoing efforts to improve the performance of Groovy**, we have worked hard on compilation speed, and we backported those improvements from the upcoming Groovy 1.6, to ensure that all users using stable versions of Groovy can benefit from these performance increases. The **Groovyc compiler should now be from 3 to 5 times faster**, which will make big Groovy / Java and Grails projects much snappier to compile.

A first beta of the upcoming Groovy 1.6 will follow in the coming weeks, and the team focus is still on performance improvements. Groovy 1.6 contains this enhanced compiler, but also brings runtime improvements in many areas, including on number arithmetics where Groovy was known to be slow.

Go [download Groovy 1.5.5](http://groovy.codehaus.org/Download) and read the [changelog](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&styleName=Html&version=14028) for more details on the release.
# Groovy / Grails support in NetBeans and GlassFish


Sun engineer Matthias Schmidt has just published an article on the progress of the [Groovy and Grails support in NetBeans](http://blogs.sun.com/schmidtm/entry/news_from_grailsland). The [Aquarium](http://blogs.sun.com/theaquarium/) also features the ongoing work on support of [Grails in Glassfish](http://blogs.sun.com/theaquarium/entry/netbeans_support_for_groovy).

On NetBeans front, Matthias Schmidt and Martin Adamek started working on a plugin back in November. You'll need to use a [NetBeans nightly build](http://deadlock.netbeans.org/hudson/job/trunk/lastSuccessfulBuild/artifact/nbbuild/dist/zip/), and download the Groovy/Grails plugin from the updace center. The plugin already provides:

*   Method-completion including JavaDoc display for Groovy and Java
*   Code Folding of Groovy source files
*   Starting, stopping of the Grails server
*   Importing existing Grails projects with a week arranged display of project structure
*   Groovy/Grails module settings integrated into NetBeans options dialog
*   Marking of source code errors
*   Easy navigation of Groovy source code by using a navigator view
*   Customizing of Grails environment and server port
*   Auto-deploy to the Glassfish application server
*   Starting common Grails tasks from context menu
*   Status of running Grails server displayed in status-line
*   Syntax highlighting

This is a promising beginning, but there's definitely more to come:

*   Debugging support
*   MultiView for easy navigation between corresponding Model-View-Controller files
*   Refactoring support

On GlassFish's side, Eduardo Pelegri [reports](http://blogs.sun.com/theaquarium/entry/netbeans_support_for_groovy) improvements and bug fixes for [running Grails applications in GlassFish](http://blogs.sun.com/theaquarium/entry/kicking_the_tires_of_grails) and shares a link to the [roadmap of the Groovy/Grails support in GlassFish](http://wiki.glassfish.java.net/Wiki.jsp?page=GroovyGrailsPlanning).
# JSON.Net, the Groovy way


On [Ajaxian](http://ajaxian.com/archives/jsonnet-20), the other day, I spotted an article about [JSON.Net](http://www.codeplex.com/Json), a project aiming at simplifying the production and consumption of JSON data for the .Net world, and I wanted to contrast what I've read with what we are doing with [Groovy](http://groovy.codehaus.org/) and [Grails](http://grails.org/). I rarely speak about the Microsoft world, but the latest features of C# 3 are very interesting and powerful, particularly the anonymous types, their closures (whatever they are called), and LINQ for querying relational or tree structured data.

For instance, here's how JSON.Net produces JSON content:

```csharp
JObject o = JObject.FromObject(new
{
    channel = new
    {
        title = "James Newton-King",
        link = "http://james.newtonking.com",
        description = "James Newton-King's blog.",
        item =
            from p in posts
            orderby p.Title
            select new
            {
                title = p.Title,
                description = p.Description,
                link = p.Link,
                category = p.Categories
            }
        }
    });
```

Here, we can see the new anonymous type feature, with the new {} construct to easily create new data structure, without requiring the creation of classes or interfaces. And in the item element, we notice LINQ at work providing an SQL like notation to select the posts ordered by title.

In Groovy and Grails land, we are reusing the map notation to [create JSON content](http://grails.org/doc/1.0.x/guide/6.%20The%20Web%20Layer.html#6.1.7%20XML%20and%20JSON%20Responses), that we then coerce to JSON using the as operator:

```groovy
import grails.converters.JSON

def data = [
    channel: [
        title: "James Newton-King",
        link: "http://james.newtonking.com",
        description: "James Newton-King's blog.",
        item: 
            posts.sort { it.title }.collect { 
            [
                title: it.title,
                description: it.description,
                link: it.link,
                category: it.categories
            ]
        }
    ]
]

// then, if you want to render this structure as JSON inside a Grails controller:
render data as JSON
```

Unlike LINQ with its SQL-like notation, Groovy favors a more functional approach, using the sort() and collect() taking closures to do the filtering and aggregation. These methods are added by the Groovy Development Kit to the usual Java collection classes.
# A Domain-Specific Language for unit manipulations


Domain-Specific Languages are a hot topic, and have been popularized by languages like [Groovy](http://groovy.codehaus.org/) and Ruby thanks to their malleable syntax which make them a great fit for this purpose. In particular, **Groovy allows you to create internal DSLs**: business languages hosted by Groovy. In a recent research work, Tiago Antão has [decided to use Groovy](http://tiago.org/ps/2008/02/24/groovyscalarubypython-on-jvm/) to **model the resistance to drugs against the Malaria disease**. In two blog posts, Tiago explains some of the [tactics he used](http://tiago.org/ps/2008/02/25/dsl-tactics-in-groovy-1many/), and how to [put them together](http://tiago.org/ps/2008/02/27/chloroquine-malaria-treatment-and-groovy-dsl-tactics-in-groovy-2/) to create a mini-language for health related studies. In this work, he needed to represent quantities of medecine, like 300 miligram of Chloroquinine, a drug used against Malaria. Groovy lets you add properties to numbers, and you can represent such quantities with just `300.mg`. Inspired by this idea, the purpose of this article is to examine how to build a mini-DSL for manipulating measures and units by leveraging the [JScience library](http://www.jscience.org/).

First of all, let's speak about JScience. JScience is a Java library leveraging generics to represent various measurable quantities. JScience is also the Reference Implementation for [JSR-275: javax.measure.\*](http://www.jcp.org/en/jsr/detail?id=275). Whether it is for measuring mass, length, time, amperes or volts (and many more), the calculations you can do are type-safe and checked at compile-time: you cannot add a second to a kilogram, your program wouldn't compile. This is definitely one of the strength of the library. However fluent the library is, the notation used to represent an amount of some unit is still not as readable as scientist could wish.

How do you represent a mass with JScience?

```java
import static javax.measure.unit.SI.*;
import javax.measure.*;
import org.jscience.physics.amount.*;

// ...

Amount m3 = Amount.valueOf(3, KILO(GRAM));
Amount m2 = Amount.valueOf("2 kg");
Amount sum = m3.plus(m2);
```

The first expression leverages static imports to represent the [KILO](http://jscience.org/api/javax/measure/unit/SI.html#KILO(javax.measure.unit.Unit)) ([GRAM](http://jscience.org/api/javax/measure/unit/SI.html#GRAM)) unit, while the second simply parses the mass from a String. The last line does just an addition between the two masses. Still, it doesn't look like what a physicist would write. Wouldn't we want to use a mathematical notation, like `3 kg + 2 kg`? We will see how you can do this in Groovy.

Our first step will be to add units to numbers. We can't write `2 kg`, as it's not valid Groovy, instead, we'll write `2.kg`. To so, we'll add some dynamic properties to numbers, thanks to the [ExpandoMetaClass](http://groovy.codehaus.org/ExpandoMetaClass)mechanism.

```groovy
import javax.measure.unit.*
import org.jscience.physics.amount.*

// Allow ExpandoMetaClass to traverse class hierarchies
// That way, properties added to Number will also be available for Integer or BigDecimal, etc.
ExpandoMetaClass.enableGlobally()

// transform number properties into an mount of a given unit represented by the property
Number.metaClass.getProperty = { String symbol -> Amount.valueOf(delegate, Unit.valueOf(symbol)) }

// sample units
println( 2.kg )
println( 3.m )
println( 4.5.in )    
```

See how we created kilograms, meters and inches? The "metaclass" is what represents the runtime behavior of a class. When assigning a [closure](http://groovy.codehaus.org/Closures) to the getProperty property, all the requests for properties on Numbers will be rooted to this closure. This closure then uses the JScience classes to create a Unit and an Amout. The delegate variable that you see in this closure represents the current number on which the properties are accessed.

Okay, fine, but at some point, you'll need to multiply these amounts by some factor, or you will want to add to lengths together. So we'll need to do leverage Groovy's [operator overloading](http://groovy.codehaus.org/Operator+Overloading) to do some arithmetics. Whenever you have methods like multiply(), plus(), minus(), div(), or power(), Groovy will allow you to use the operators \*, +, -, /, or \*\*. Some of the conventions for certain of these operations being a bit different from those of Groovy, we have to add some new operator methods for certain of these operations:

```groovy
// define opeartor overloading, as JScience doesn't use the same operation names as Groovy
Amount.metaClass.multiply = { Number factor -> delegate.times(factor) }
Number.metaClass.multiply = { Amount amount -> amount.times(delegate) }
Number.metaClass.div = { Amount amount -> amount.inverse().times(delegate) }
Amount.metaClass.div = { Number factor -> delegate.divide(factor) }
Amount.metaClass.div = { Amount factor -> delegate.divide(factor) }
Amount.metaClass.power = { Number factor -> delegate.pow(factor) }
Amount.metaClass.negative = { -> delegate.opposite() }

// arithmetics: multiply, divide, addition, substraction, power
println( 18.4.kg * 2 )
println( 1800000.kg / 3 )
println( 1.kg * 2 + 3.kg / 4 )
println( 3.cm + 12.m * 3 - 1.km )
println( 1.5.h + 33.s - 12.min )
println( 30.m**2 - 100.ft**2 )

// opposite and comparison
println( -3.h )
println( 3.h < 4.h )
```

We can also do comparisons, as shown on the last line above, since these types are comparable. Again, free of charge. Something we have covered yet is compound units, such as speed, which is a mix of a distance and a duration. So, if you wanted to use a speed limit, you would like to write `90.km/h` but our DSL in its current state would only allow you to write `90.km/1.h`, which doesn't really look nice. To circumvent this issue, we could create as many variables as units. We could have a `h` variable, a `km` variable, etc. But I'd prefer something more _automatic_, by letting the script itself provide these units. In Groovy scripts, you can have local variables (whenever you define a variable, it's a local variable), but you can also pass or access variables through a binding. This is a convenient way to pass data around when you integrate Groovy inside a Java application, for instance, to share a certain context of data. We are going to create a new Binding called UnitBinding which will override the `getVariable()` method, so that all non-local variables which are used withing the Groovy script are looked up in this binding. You'll notice a special treatment for the variable 'out', which is where the `println()` method looks for for the output stream to use.

```groovy
// script binding to transform free standing unit reference like 'm', 'h', etc
class UnitBinding extends Binding {
    def getVariable(String symbol) {
        if (symbol == 'out') return System.out
        return Amount.valueOf(1, Unit.valueOf(symbol)) 
    }
}

// use the script binding for retrieving unit references
binding = new UnitBinding()

// inverse units
println( 30.km/h + 2.m/s * 2 )
println( 3 * 3.mg/L )
println( 1/2.s - 2.Hz )
```

The velocity now looks much more like the mathematical notation everybody would use. Now that all this magic is done, there's still one last thing we could do. Sometimes, you may want to convert different units, like feet and meters or inches and centimers. So, as the last step of our units DSL experiments, we'll add a `to()` method to do convertions.

```groovy
// define to() method for unit conversion
Amount.metaClass.to = { Amount amount -> delegate.to(amount.unit) }

// unit conversion
println( 200.cm.to(ft) )
println( 1.in.to(cm) )
```

At this point, we are able to easily manipulate amounts of any unit in a very convenient and natural notation. The _magic_ trick of adding properties to numbers makes the process of creating a unit DSL straightforward. This DSL is just a small part of the equation, as you may certainly want to represent other business related concepts, but this article will have shown you how to decorate a powerful existing library, so that the code becomes more natural to use by the end users of your DSL. In further articles, we'll discover some other tricks! Stay tuned!
# JavaPolis interview with Guillaume Laforge, Groovy project lead


At [JavaPolis '07](http://www.javapolis.com/confluence/display/JP07/Home), Dick Wall and Carl Quinn of [JavaPosse](http://www.javaposse.com/) fame have [interviewed Guillaume Laforge](http://parleys.com/display/PARLEYS/A+Groovy+interview+at+JavaPolis%2707?showComments=true), the [Groovy](http://groovy.codehaus.org/) project manager, and asked him about:

*   the latest release of [Groovy 1.5 and its novelties](http://www.infoq.com/articles/groovy-1.5-new),
*   more details on the come back of the 'infamous' for loop,
*   the support of generics,
*   the inclusion of closures in Java compared to Groovy's closures,
*   what Grails is and why it matters,
*   how simple it is to leverage Grails in IT's today infrastructure,
*   the first class support of SQL and XML in Groovy,
*   and also what the future will hold in the upcoming Groovy releases.

Go and view the [interview on Parleys.com](http://parleys.com/display/PARLEYS/A+Groovy+interview+at+JavaPolis%2707?showComments=true).
# Learn all about Groovy and Grails at the 2GX conference, Reston, VA


If you want to learn everything about Groovy and Grails, get in touch with all the projects committers and contributors, and have a great time, you should definitely not miss the [Groovy / Grails Experience](http://www.groovygrails.com/gg/2gexperience) that will take place in Reston, VA, USA -- February 21 - 23, 2008

There's a pretty impressive [list of speakers](http://www.groovygrails.com/gg/conference/speakers?showId=131), and the [session schedule](http://www.groovygrails.com/gg/conference/schedule?showId=131) looks pretty tasty. It's the best opportunity to get the right information straight from the horse's mouth. A lot of topics will be covered, ranging from introductions to Groovy / Grails up to more advanced topics like DSLs, design patterns in dynamic languages, Java integration, Swing UIs, GORM, and more.

The conference is on February 21st-23rd, so there's not much time left to get ready and register. But courtesy of [G2One](http://www.g2one.com/), the Groovy/Grails professional services company, and NFJS, if you register with the promo code **2gx2008g2one**, you'll even get a **$150 discount**!

Groovy and Grails have recently been coined as the technologies to learn in 2008, this conference will help you get started.

*   [The future is now -- Java development in 2008](http://glaforge.free.fr/weblog/index.php?itemid=231) by Andy Glover
*   [Top Five Java Technologies to Learn in 2008](http://www.manageability.org/blog/stuff/five-java-technologies-to-learn-in-2008) by Carlos Perez
*   The [debate on TheServerSide](http://www.theserverside.com/news/thread.tss?thread_id=48270) about Carlos Perez' post

So with [Groovy 1.5](http://www.infoq.com/articles/groovy-1.5-new) and [Grails 1.0 released](http://www.theserverside.com/news/thread.tss?thread_id=48360) in the previous weeks and months, and the [2GX conference](http://www.groovygrails.com/gg/2gexperience), you're going to rock in 2008!
# A Groovy kind of love


It's funny, but before working on the [Groovy](http://groovy.codehaus.org/) project, there was a song I've always liked: [A Groovy Kind of Love](http://www.lastfm.fr/music/Phil+Collins/_/A+Groovy+Kind+of+Love), by Phill Collins. Do you think it was premonitory? That I'd work on Groovy? And speaking of Groovy love... I've come across some nice love messages towards Groovy that I wanted to share with you.

[Jorge Lugo](http://jorgeonprogramming.blogspot.com/2008/02/why-i-like-groovy.html), a software engineer in the Washington DC area, sums up pretty well the appeal Groovy has to Java developers:

> **Why I like Groovy**  
> I became interested in Groovy recently when I discovered that it is like Ruby, but is meant for the Java language and platform. Groovy provides Ruby-like features with out having to abandon the Java language, frameworks and tools that I've been using for years.  
> \[...\]  
> In Conclusion, Groovy is a great language. I hope to use it more often in the future.

I hope Jorge will attend the [2GX conference](http://www.groovygrails.com/gg/2gexperience), as it'll be a tremendous opportunity to dive into Groovy and [Grails](http://grails.org/)!

Rob Breidecker, who lives in St-Louis, MO, USA, is [learning Groovy](http://evolutionarygoo.com/blog/?p=162) and seems to pretty much like what he's learned so far:

> **Giving Groovy a Chance**  
> Last year I learned Ruby and Rails and found them to be fun to program in and also very productive. I was in particular very impressed with how well thought out Rails was. After years of programming Web applications I could see the power of automating many of the unpleasant and mundane tasks that go along with Web development.  
> Since Java is still my bread and butter, I am spending time this year learning Groovy and eventually hope to start learning Grails. So far I like what I have seen with Groovy. It shares many of the language features of Ruby and is very easy to install (especially if you already have a JVM installed on your machine). I also get to use all of the existing Java classes I am already familiar with, so I am able to be productive with Groovy right out of the gate. Is there anyone out there playing with Groovy and would like to share what kinds of real world things are you doing with it?

For Java developers, it's obviously way easier to learn a language like Groovy with its Java-like syntax, and because it's leveraging all the APIs, tools, frameworks you've learned to master over the time. Same for Grails, with its Spring and Hibernate background. **Betting on Groovy and Grails is the best way to protect your investment**.

And probably the best and funniest love message at the end, mostly in time for the Valentine's day, by [Carlos Orrego](http://www.jroller.com/orrego/entry/i_am_married_to_java):

> **I am married to Java, but i have a lover... Groovy**  
> Java has been there for me many years. Solid, stable, reliable, mature, old... I know java well, i think she knows me too.  
> Then i met Groovy. Young, sexy, dynamic, agile... I am getting to know Groovy, i am getting butterflies in my stomach again.  
> The best things is that they get along just fine. They even talk together in harmony.  
> What else can i say?

That's a Groovy kind of love!
# The Groovy Zone, community news site for the Groovy and Grails developers


A new source of information on [Groovy](http://groovy.codehaus.org/) and [Grails](http://grails.org/) has just been launched: the [Groovy Zone](http://groovy.dzone.com/). Rick Ross et al. have built upon the [DZone](http://www.dzone.com/) community-driven linkblog, and [JavaLobby](http://www.javalobby.com/), to create various "Zones" on numerous topics like Java, AJAX, CSS, and also Groovy and Grails. [Andres Almiray](http://www.jroller.com/aalmiray/), [Steven Devijver](http://glaforge.free.fr/weblog/index.php?itemid=229) and myself have become "zone leaders", to shepherd the Groovy and Grails content.

[![](http://glaforge.free.fr/weblog/media/GroovyZoneLogo.png)](http://groovy.dzone.com/)

We had [AboutGroovy](http://www.aboutgroovy.com/) where Scott Davis lists on the interesting news in the Groovy and Grails spheres, and Glen Smith's[GroovyBlogs](http://www.groovyblogs.org/) blog aggrgator listing several super interesting blogs related to Groovy and Grails... and now we have the GroovyZone!

I wrote a first little article showing how to [transition your Java code into Groovy](http://groovy.dzone.com/news/java-groovy-few-easy-steps), showing Groovy's Java-superset nature while learning a new Groovy feature one at a time. I stole the idea from Andres and Paul who used these kind of samples in their Groovy conference presentations -- give to Caesar what is Caesar's! As time permits, I'll continue showing some simple examples, to help Java developers get up to speed with Groovy, to make their Java code more Groovy, and to learn new features in each article.
# MarkMail archives the Groovy mailing-lists and shows their success


Jason Hunter from [MarkLogic](http://www.marklogic.com/) (and [JDOM](http://www.jdom.org/) fame) has crawled the [Groovy mailing-lists archives](http://groovy.markmail.org/) with his gorgeous [MarkMail](http://markmail.org/) interface.

Not all the archives have been indexed so far, as we're still missing some older archives from before April 2004, but there's already about 70K messages loaded. In the following screenshot, you can see the number of messages sent to the lists per month, across the course of time.

![](/img/markmail/markmail-list-graph.png)

An interesting remark: you'll certainly have noticed the jump in the traffic around January 2007. It coincides with the release of Groovy 1.0, our first official final and stable release, after years of betas. Almost overnight (or "over-month" shall I say), the traffic on the lists doubled!

MarkMail makes clever use of JavaScript to make some nice horizontal scrolling animations to go from the list view, to the email view.

![](/img/markmail/markmail-list-view.png)

The email view with thread grouping, etc:

![](/img/markmail/markmail-list-email-view.png)

Although the mailing-list archives are also available on [Gmane](http://dir.gmane.org/search.php?match=groovy) and [Nabble](http://www.nabble.com/codehaus---Groovy-f11866.html), I also encourage you to try the [new MarkMail interface](http://groovy.markmail.org/)!
# Groovy not Enterprise-ready, you're kidding?


Graeme pointed me at a [white-paperish article](http://www.huxili.com/reports/ID000188) claiming Groovy would not be Enterprise-ready. If the article had been acurate, I would have welcomed it, and we could have found ways to improve Groovy to make it ready, but unfortunately, the author did not do his job properly, and only spread FUD by saying Groovy doesn't hold to its promises.

As this article is pretty thin on the technical aspects, I won't explain why his conclusions are wrong -- and also because [Graeme explained this already](http://graemerocher.blogspot.com/2008/01/re-groovy-and-jruby-enterprise-ready.html). Instead, I'll just comment on a few of his claims.

> Some even claims that Java should be replaced by their preferred dynamic language.

I don't know who "some" is in this sentence, but at least, that's not me. Developers should always have the choice: the best tool for the job. [Groovy](http://groovy.codehaus.org/) has initially been conceived to complement Java, not to replace it -- which doesn't mean that you can't build a full project using Groovy only, as demonstrated by the powerful [Grails framework](http://grails.org/). Java's a great language, and a wonderful platform. Unlike other[platforms](http://davidvancouvering.blogspot.com/2008/01/say-it-aint-so-ruby-on-rails-not-thread.html), Java's threadsafe, it optimizes access to databases, it scales extraordinarily well, etc.

> SAP, one of the largest providers of enterprise software and services in the world, have released a new community driven product based on Groovy.

Yes, SAP, among other big vendors (IBM, Oracle, JBoss) who did the same, has decided to use [Groovy](http://groovy.codehaus.org/) and [Grails](http://grails.org/) for its new innovative project. Do you think a company like SAP would have chosen Groovy and Grails if these technologies would not have been Enterprise-ready? See a couple of links on this topic:

*   A [testimonial on Graeme's blog](http://graemerocher.blogspot.com/2007/12/sap-announces-composition-on-grails-10.html)
*   And the [project itself](https://www.sdn.sap.com/irj/sdn/wiki?path=/display/Community/Composition+on+Grails)

> On the JRuby side, it has solid backing from Sun Microsystems and has been integrated into NetBeans IDE

Right, Sun's been investing in JRuby by hiring the two lead developers. They've been putting a lot of marketing effort on this, to surf the hype wave of Ruby on Rails. But **Sun has also helped the Groovy project** by giving us access to a nice Sun Fire T2000 machine for our performance testing needs, they've let us create a JSR for standardizing Groovy in the Java Community Process, and they are also currently working on [Groovy and Grails support in NetBeans](http://martin.adamek.sk/). There's just less marketing money spent on Groovy and Grails.

> Before applying Groovy or JRuby to your enterprise applications, their suitability and reliability should be evaluated seriously.

Very true, and you should definitely not just trust anything you read on the web. You have to do your own homework, and evaluate the technical solution in a realistic context, rather than believing in some micro-benchmark or amateurish white-paper.

> Groovy and JRuby are still very young and has not yet been confirmed in production.

For JRuby, I can't comment, despite the fact I haven't heard of much well-known JRuby-powered systems in production, but hopefully, someone can comment on this blog to get this straight. But at least, for Groovy, I personally know quite a few mission-critical applications that already embed Groovy. I can even tell you **Groovy's handling million-dollars hedge funds daily in a Londonian financial institution**. I can also tell you that US **Fortune 500 insurance company Mutual of Omaha is running a risk calculation engine with thousands of lines of Groovy business rules**. And what about the**US National Cancer Institute which also uses Groovy to validate patients file details**? And one of the **top major American credit card company** (in the top 20 on Fortune 500) that also uses Groovy in production? And Groovy would not be Enterprise-ready?

> First, we observed that the Groovy runtime is not stable, that is, memory consumption increased linearly with repeating times. In other words, a certain amount of memory is lost - i.e. memory leakage - during each evaluation of the script. This is a serious flaw of the Groovy runtime; Groovy can not be used in long-running server environment unless alternative solutions can be found to avoid memory leakage. The simplest solution is "runtime recycling" -- throwing away the Groovy runtime after each execution and let JVM recycle Groovy runtime memory.

There is **no leakage of memory in Groovy** at all. Each time you evaluate a script at runtime, a new class is created in memory. And the classloader just remembers this class, in case it may be used further on down the road, instead of bearing the cost of recompiling / reevaluating it each time. However, if you wanted to just evaluate it once, discard the classloader or the Groovy shell used afterwards. It's as simple as that. No memory leaked at all. Just use the APIs as they are intended to be used, and don't claim that they are flawed because you didn't understand how to use them properly.

> In certain server environments the current solution by recycling Groovy runtime is not enough and you may still have memory leakage problem. This is because certain servers always keep the classes in memory even they are no longer required. One of the example is the JBoss application server. In JBoss, classes are not unloaded from the memory even they are not required by the system. Of course, this is a design problem of JBoss and may be changed in future versions.

I don't know the JBoss internals enough to comment on this one, but as the Groovy classes are loaded by the Groovy classloader itself, I suspect the JBoss infrastructure would just let the classloader to be garbage collected otherwise it would be mostly impossible to make serious applications work on JBoss AS, which I highly doubt. Hopefully, someone with more JBoss knowledge can better comment on this.

Groovy has been **very stable and mature for a long time already**. It is being **used by many high-profile companies and institutions throughout the world with great success**. It is a pity to see such FUD spread of Groovy by an amateurish white-paper written by someone who doesn't seem to have done his researches well.

**Update #1:** I've added a new Enterprise use case for Groovy, where one of the US Fortune 20 credit card / bank company leverages Groovy, as someone pointed me at in a mail.

**Update #2:** Steven made a [nice technical analysis on groovy.dzone.com](http://groovy.dzone.com/news/groovyshell-and-memory-leaks), so if you want to learn more about the technical aspects of the story, and better understand the memory and classloading behavior in Groovy, go right there.
# What's new in Groovy 1.5


[Groovy](http://groovy.codehaus.org/), the Java-like dynamic language for the JVM, matures over time like good wines. After the successful release of Groovy 1.0 in January 2007, the next major milestone with the 1.5 label already hits the shelves. With it, come several interesting novelties that we will examine in this article. The major addition to the language is the support of Java 5 features with annotations, generics and enums, making Groovy **the sole alternative dynamic language for the JVM fully supporting frameworks like Spring, Hibernate, JPA**, Google Guice, or TestNG. Apart from the new Java 5 features, a few syntax enhancements find their way in the language, as well as a more powerful dynamic behavior customization, a Swing UI builder on steroids, and improved tooling support.

## A groovier Groovy and why it matters

Groovy's key selling point has always been its **seamless integration with Java**. You can mix and match Groovy and Java classes together in very easy ways: You may have a Groovy class extending a Java class implementing a Groovy interface, and vice versa. Most of the other alternative JVM languages unfortunately won't let you seamlessly interchange classes of two different languages. So if you want to use the best language for the job without compromising your nice class hierarchy, you won't have many options to choose from, and Groovy gives you all the freedom for integrating both languages in the most transparent way.

Groovy shares the same libraries, the same object model, the same threading model, and the same security model as Java. In a way, you can consider Groovy as an implementation detail of your Java project, **without having to bear problematic impedance mismatch issues**.

Groovy is Java, and Groovy makes Java groovier. Compared with other languages, Groovy is certainly the language that provides the **flattest learning curve to Java developers**, thanks to a very similar syntax.

This is even more important to keep in mind that Groovy generates normal Java bytecode and uses the usual JDK libraries, so you won't need to learn whole new APIs or have complex integration mechanisms: out of the box, Groovy and Java are interchangeable. The added benefit is that you can **protect the investment** you made in Java **skills for your developers**, or in **costly application servers**, or third party or **home-grown libraries**, as you can reuse all of them without a problem from Groovy.

Speaking of calling into JDK, third party, or in-house libraries, alternative languages which don't support strong typing, can't always call all Java methods because of the fact they can't choose a certain polymorphic variation of the same method. When choosing an alternative language to improve your productivity or make your code more readable, if you need to call other Java classes, you will have to be very careful to the choice of language you will make, as you may encounter some road blocks along the way.

These days, all major Enterprise frameworks require the use of features like annotations, enums or generics, to be leveraged at their fullest extent. Fortunately, with Groovy 1.5, developers can benefit from the support of all these Java 5 features in their projects. Let's see how annotations, enums and generics can be used from Groovy.

## Java 5 additions

The Groovy compiler always generates Java bytecode which is compatible with older Java VMs, but relies on JDK 1.4 for the core libraries it is using. However, for certain of these Java 5 additions, using Java 5 bytecode was required, so that, for example, the generated classes may contain the bytecode information representing annotations with runtime retention policy. So although Groovy 1.5 can run on JDK 1.4, certain of these features will only be usable on JDK 5 - when this is the case, it will be mentioned in this article.

### Variable arguments

In Java 5, the ellipsis notation was created to denote methods with variable length arguments. With those little triple dots, Java lets users put as many parameters of the same type at the end of a method - actually, the vararg parameter is just an array of elements of that type. Varargs were already present in Groovy 1.0 - and still work with a JDK 1.4 runtime, but it is good to show how you can use them. Basically, whenever the last argument of a method is an array of objects, or a parameter declaration with a triple dot, you can pass multiple parameters to this method.

A first example will show the usage of varargs in Groovy with the ellipsis:

```groovy
int sum(int... someInts) {
    def total = 0
    for (int i = 0; i < someInts.size(); i++)
        total += someInts[i]
    return total
}

assert sum(1)       == 1
assert sum(1, 2)    == 3
assert sum(1, 2, 3) == 6
```

The assertions used in this example show how we can pass as many ints as desired. It is also interesting to see that, for more syntax compatibility with Java, the classical for loop has been added into Groovy - despite the presence of the groovier version with the in keyword that can also transparently iterate over various array or collection types.

Note that it is possible to have varargs support even with an array as last parameter by declaring the method as follows:

```groovy
int sum(int[] someInts) { /* */ }
```

This snippet is really trivial, and there are obviously more expressive ways of calculating a sum. For instance, if you have a list of numbers, you can sum all of them in a single line of code:

```groovy
assert [1, 2, 3].sum() == 6
```

Varargs in Groovy don't require JDK 5 as the underlying Java runtime, unlike annotations that we are now going to look at in the following section.

### Annotations

As shown in the [documentation of JBoss Seam](http://docs.jboss.com/seam/1.3.0.ALPHA/reference/en/html/ch10.html) which supports Groovy for writing its entities, controllers and components, annotations like `@Entity`, `@Id`, `@Override` and others can be used to decorate your beans:

```groovy
@Entity
@Name("hotel")
class Hotel implements Serializable
{
     @Id @GeneratedValue
     Long id

     @Length(max=50) @NotNull
     String name

     @Length(max=100) @NotNull
     String address

     @Length(max=40) @NotNull
     String city

     @Length(min=2, max=10) @NotNull
     String state

     @Length(min=4, max=6) @NotNull
     String zip

     @Length(min=2, max=40) @NotNull
     String country

     @Column(precision=6, scale=2)
     BigDecimal price

     @Override
     String toString() {
         return "Hotel(${name}, ${address}, ${city}, ${zip})"
     }
}
```

The Hotel entity is marked with the @Entity annotation, and it's given a name through @Name. Different parameters can be passed to your annotations like in the @Length annotation constraint where different upper and lower bound can be set for validation purpose. You can also notice **Groovy properties** in action: Where are all the getters and setters? Where are the public or private modifiers? You don't have to wait for Java 7 or 8 to get properties! By convention, defining a property is as simple as String country: a private country field will be auto-generated, as well as a public getter and setter. **Your code becomes naturally more concise and readable**.

Annotations can be used on classes, fields, methods and method parameters, like in Java. There are, however, two gotchas to be aware of. Firstly, you can use annotations in Groovy, but you cannot yet define them - however, it will be possible in an upcoming version of Groovy. Secondly, although the syntax is almost 100% the same as in Java, there is a little difference when an array of values is passed in parameter of the annotation: instead of curly braces to surround the elements, Groovy requires the use of square brackets to offer a more homogeneous syntax - since Groovy lists and arrays use square brackets to surround their elements as well.

With annotations in Groovy 1.5, you can easily define your [JPA or Hibernate annotated beans](http://www.curious-creature.org/2007/03/25/persistence-made-easy-with-groovy-and-jpa/) in Groovy, add an @Transactional annotation on your Spring services, test your Swing UI with TestNG and [Fest](http://www.jroller.com/aalmiray/entry/testing_groovy_uis_with_fest). All the useful and powerful enterprise frameworks leveraging annotations can be used from your Groovy-powered projects.

### Enums

Whenever you need a fixed set of constants of a same type, Enums come in handy. Say you need a clean way to define constants for days without resorting to using integer constants? Then Enums are your friend. The following snippet shows how to define the days of the week:

```groovy
enum Day {
     SUNDAY, MONDAY, TUESDAY, WEDNESDAY,
     THURSDAY, FRIDAY, SATURDAY
}
```

Once you have defined your enum, you can use it as in Java with the usual notation `Day.MONDAY` and you can spice up your `switch` / `case` statements with it as well:

```groovy
def today = Day.SATURDAY
switch (today) {
     // Saturday or Sunday
     case [Day.SATURDAY, Day.SUNDAY]:
         println "Weekends are cool"
         break
     // a day between Monday and Friday
     case Day.MONDAY..Day.FRIDAY:
         println "Boring work day"
         break
     default:
         println "Are you sure this is a valid day?"
}
```

Notice that Groovy's `switch` is a bit more powerful than C-like languages switches in that it is possible to use any kind of object in the switch and case. Instead of stacking up seven different case block with each enumerated value, you can regroup them in lists or ranges: whenever the value is in the list or the range, the case will be true and its associated instructions will be executed.

A more complex example inspired by the Java tutorial takes a more astronomical perspective on enums, and shows how your enums can have properties, constructors and methods:

```groovy
enum Planet {
     MERCURY (3.303e+23, 2.4397e6),
     VENUS   (4.869e+24, 6.0518e6),
     EARTH   (5.976e+24, 6.37814e6),
     MARS    (6.421e+23, 3.3972e6),
     JUPITER (1.9e+27,   7.1492e7),
     SATURN  (5.688e+26, 6.0268e7),
     URANUS  (8.686e+25, 2.5559e7),
     NEPTUNE (1.024e+26, 2.4746e7)

     double mass
     double radius

     Planet(double mass, double radius) {
         this.mass = mass;
         this.radius = radius;
     }

     void printMe() {
         println "${name()} has a mass of ${mass} " +
                 "and a radius of ${radius}"
     }
}
Planet.EARTH.printMe()
```

Like annotations, enums in Groovy require a JDK 5+ to run on, as Java 5 bytecode is generated.

### Static imports

In our previous examples of enums, we always had to prefix the enumerated value with its parent enum class, but thanks to static imports (which work even on a JDK 1.4 runtime) we can save some characters by dropping the Planet prefix:

```groovy
import static Planet.*

SATURN.printMe()
```

No more Planet prefix. But of course, static imports aren't only available for enums, but also work for other classes and static fields. What about doing some math?

```groovy
import static java.lang.Math.*

assert sin(PI / 6) + cos(PI / 3) == 1
```

Both the static methods of `java.lang.Math` and its static constants were statically imported to make the expression more concise. But if the abbreviations of sine and cosine are not readable for you, you can use aliasing in Groovy with the as keyword:

```groovy
import static java.lang.Math.PI
import static java.lang.Math.sin as sine
import static java.lang.Math.cos as cosine

assert sine(PI / 6) + cosine(PI / 3) == 1
```

Aliasing also works with normal imports too, not just static imports, and it can be pretty handy for adding some shortcut notation to very long class names as found in many frameworks, or for renaming methods or constants with non-obvious names, or not following your naming convention standards.

### Generics

A somewhat more controversial feature of Java 5 also finds its way in the latest release of Groovy 1.5 with Generics. Initially, it may feel odd to add even more typing information to a dynamic language, after all. Java developers usually believe that because of type erasure (for backward compatibility reasons with older versions of Java) no information is left in the class bytecode to represent the generic type. However, this is wrong, since through the reflection API, you are able to introspect a class to discover the types of its fields or of its methods arguments with the generics details.

So for instance, when you declare of field of type `List<String>`, somewhere in the bytecode, this information is kept in the form of some meta-information, although this field is really just of type `List`. This kind of reflexive information is used by enterprise frameworks like JPA or Hibernate to be able to relate a collection of elements from an entity to the entity representing the type of these elements.

To put this into practice, let us check if the generics information is kept on class fields:

```groovy
class Talk {
     String title
}

class Speaker {
     String name
     List<Talk> talks = []
}

def me = new Speaker(
     name: 'Guillaume Laforge',
     talks: [
         new Talk(title: 'Groovy'),
         new Talk(title: 'Grails')
     ])

def talksField =  me.class.getDeclaredField('talks')
assert talksField.genericType.toString() ==
    'java.util.Listt<Talk>'
```

We defined two classes: a Speaker class giving Talks at conferences. In the Speaker class, the talks property is of type `List<Talk>`. Then, we create a Speaker instance with two nice shortcuts for initializing the name and talks properties, and for creating a list of Talk instances. Once this setup code is ready, we retrieve the field representing the talks, and we check that the generic type information is correct: yes, `talks` is a `List`, but a `List` of `Talks`.

### Covariant return types

In Java 5, if you have a method in a subclass with the same name and parameter types as in a parent class, but with a return type derived from the parent method's return type, then we can override the parent method. In Groovy 1.0, covariant return types were not supported. But in Groovy 1.5, you can use them. Additionally, if you are trying to override a method with a return type not deriving from the parent class method's return type, a compilation error will be thrown. Covariant return types also work with parameterized types.

Beyond the support of Java 5 features which brought a few additions to the language, a few other syntax enhancements have been introduced in Groovy 1.5, and we are going to discover them in the following section.

## Syntax additions

### Elvis operator

Apart from the Java 5 features that brought annotations, generics and enums into Groovy, a new operator finds its way into the language: ?: the Elvis operator. When you see the operator in question, you will easily guessed why it was nicknamed that way - if not, think in terms of Smiley. This new operator is, in fact, a shortcut notation for the ternary operator. How many times are you using the ternary operator to change the value of a variable if its content is null to assign it some default value? The typical case in Java is as follows:

```groovy
String name = "Guillaume";
String displayName = name != null ? name : "Unknown";
```

In Groovy, since the language is able to "coerce" types to boolean values as needed (for instance where conditional expressions are required like in if or while constructs), in this statement, we can omit the comparison to null, because when a String is null, it is coerced to false, so in Groovy, the statement would become:

```groovy
String name = "Guillaume"
String displayName = name ? name : "Unknown"
```

However, you will still notice the repetition of the name variable, which would violate the DRY principle (Don't Repeat Yourself). As this construct is pretty common, the Elvis operator was introduced to simplify such recurring cases, and the statements become:

```groovy
String name = "Guillaume"
String displayName = name ?: "Unknown"
```

The second occurrence of the name variable is simply omitted and the ternary operator is no more ternary and is shortened to this more concise form.

It is also worth noticing that there are no side effects to this new construct, since the first element (here the name) is not evaluated twice as it would be the case with the ternary operator, so there's no need to introduce some intermediate temporary value to hold the result of the first evaluation of the first element of the ternary operator.

### Classical for loop

Although Groovy is not strictly speaking a 100% superset of Java, the Groovy syntax comes closer to the Java syntax after each release, and more and more Java code is also valid Groovy. The net benefit of this is that when you begin with Groovy, you can copy and paste Java code in your Groovy classes, and this should just work as expected. Then, over time, as you learn the language, you start throwing away the semi-colons which are not mandatory in Groovy, using GStrings (interpolated strings), or closures, etc. Groovy offers a rather flat learning curve to Java developers.

However, there was one omission to this Java-syntax compatibility in the fact the classical `for` loop inherited from Java's C background wasn't allowed in Groovy. Initially, the Groovy developers thought it was not the nicest syntax of all and preferred using the `for` / `in` construct which was more readable. But as the Groovy users regularly asked for this old construct to be also part of Groovy, the team decided to bring it back to Groovy.

With Groovy 1.5, you can either chose the Groovy `for` / `in`, or prefer the classical for loop:

```groovy
for (i in 0..9)
     println i

for (int i = 0; i < 10; i++)
     println i
```

At the end of the day, it is probably more a matter of taste, and long time Groovy users usually prefer the most concise syntax with the `for` / `in` loop instead.

### Named parameters without parenthesis

With its malleable and concise syntax, and its advanced dynamic capabilities, **Groovy is an ideal choice for implementing internal Domain-Specific Languages**. When you want to share a common metaphor between subject matter experts and developers, you can leverage Groovy to create a dedicated business language which models the key concept and business rules of your application. An important aspect of these DSLs is to make the code very readable, and also easier to write by non-technical persons. To achieve this goal even further, the grammar of the language was tweaked to allow us to use named parameters without the surrounding parenthesis.

First of all, in Groovy, named parameters look like this:

```groovy
fund.compare(to: benchmarkFund, in: euros)
compare(fund: someFund, to: benchmark, in: euros)
```

By adding new properties to numbers — which is possible in Groovy but beyond the scope of this article - we can also write code like this:

```groovy
monster.move(left: 3.meters, at: 5.mph)
```

Now by omitting parenthesis, the code can become a little clearer as shown below:

```groovy
fund.compare to: benchmarkFund, in: euros
compare fund: someFund, to: benchmark, in: euros
monster.move left: 3.meters, at: 5.mph
```

Obviously, this is not a big difference, but each statement becomes closer to real plain English sentences, and removes the usual boiler-plate technical code of the host language. This little enhancement of the grammar of the Groovy language gives more options to the designers of the business DSL.

## Improved tooling support

A common show-stopper when Groovy was a young language, was the lack of good tooling support: both the tool chain and the IDE support weren't up to the task. Fortunately, with the maturity and success of Groovy and the Grails web framework, this situation has changed.

## Introduction of the "joint" compiler

Groovy is well-known for its transparent and seamless integration with Java. But this is not just about being able to call Java methods from Groovy scripts, no, the integration between both languages goes well beyond that. For instance, it is totally possible to have a Groovy class extending a Java class which in turns implements a Groovy interface, or vice versa. This is something other alternative languages don't alway support, unfortunately. However, when mixing Groovy and Java classes together, so far, you had to be careful when compiling both type of classes by cleverly choosing the order of compilation, and when cyclic dependencies were spanning both languages, you may have hit a "chicken and egg" problem. Fortunately with Groovy 1.5, this is not the case anymore, and thanks to a contribution from JetBrains, the makers of the award winning [Java IDE IntelliJ IDEA](http://www.jetbrains/idea/), a "joint" compiler is available with which you can compile both Groovy and Java sources together in one go without having to think about dependencies between classes.

If you want to use the joint compiler from the command-line, you can call the groovyc command as usual, but specify the -j flag which will enable the joint compilation:

```bash
groovyc *.groovy *.java -j -Jsource=1.4 -Jtarget=1.4
```

For passing parameters to the underlying javac command, you can prefix the flags with the J prefix. You can also use the joint compiler through its Ant task from you Ant or Maven build files:

```xml
<taskdef name="groovyc"
         classname="org.codehaus.groovy.ant.Groovyc"
         classpathref="my.classpath"/>

<groovyc
     srcdir="${mainSourceDirectory}"
     destdir="${mainClassesDirectory}"
     classpathref="my.classpath"
     jointCompilationOptions="-j -Jsource=1.4 -Jtarget=1.4" />
```

### Maven plugin for Groovy

For the Maven users, there is also a fully featured Maven plugin hosted at Codehaus which allows you to build your Java / Groovy applications: compile your Groovy and Java code, generate documentation from the JavaDoc tags, or it even lets you write your own Maven plugins in Groovy. There is also a Maven archetype to bootstrap your Groovy project more rapidly. For more information, you may have a look at the documentation of the plugin: <http://mojo.codehaus.org/groovy/index.html>

### The GroovyDoc documentation tool

As a Java developer, you are used to documenting your code through JavaDoc tags in the comments of your classes, interfaces, fields, or methods. In Groovy, you can also use such tags in your comments, and have them being used by a tool called GroovyDoc to generate the equivalent JavaDoc documentation for all your Groovy classes.

There's an Ant task you can define then use to generate the documentation as follows:

```xml
<taskdef name="groovydoc"
     classname="org.codehaus.groovy.ant.Groovydoc">
     <classpath>
        <path path="${mainClassesDirectory}"/>
        <path refid="compilePath"/>
     </classpath>
</taskdef>

<groovydoc
     destdir="${docsDirectory}/gapi"
     sourcepath="${mainSourceDirectory}"
     packagenames="**.*" use="true"
     windowtitle="Groovydoc" private="false"/>
```

## New interactive shell and the Swing console

Groovy distributions always contained two different shells: a command-line shell as well as a Swing console. Groovysh, the command-line shell, has never been very friendly in terms of interactions with its user: whenever you wanted to execute a statement, you had to type 'go' or 'execute' after each one, so that it got executed. For quick prototyping or playing with some new API, typing 'go' each time was very cumbersome. The situation has changed in Groovy 1.5, since a new interactive shell is born. No need to type 'go' anymore.

This new shell features several enhancements, such as the use of the JLine library which provides ANSI coloring, tab completion for commands, line editing capabilities. You can work with different script buffers, remember already imported classes, load existing scripts, save the current script to a file, browse the history, etc. For detailed explanations of the supported features, please have a look at the [documentation](http://groovy.codehaus.org/Groovy+Shel).

The command-line shell isn't the only one that received some care, the Swing console has also been improved, with a new toolbar, with advanced undo capabilities, the possibility to increase or decrease the font size, syntax highlighting. A lot of polishing has been applied to the console.

### IntelliJ IDEA JetGroovy plugin

I will save the best of tooling support till the end of this section by mentioning the JetGroovy plugin: a free and Open Source IntelliJ IDEA plugin dedicated to the support of both Groovy and Grails. This plugin has been developed by JetBrains themselves, and provides unmatched support for both the language and the web framework.

To list a few of the available features of the Groovy support:

-   **Syntax highlighting** for all the syntax, plus different warnings for types not recognized, or when static type information is not known to help spot potential errors.
-   Ability to **run Groovy classes, scripts and JUnit test cases written in Groovy**.
-   **Debugger**: You can debug step by step across your Java and Groovy code, set breakpoints, show variables, the current stack, etc.
-   Joint compiler: the compiler **compiles both Groovy and Java** classes together and is able to resolve dependencies between both languages.
-   **Code completion** for packages, classes, properties, fields, variables, methods, keywords, and even specific support for the Swing UI builder.
-   Advanced class search and find usage.
-   **Refactorings**: most of the usual refactorings you've come to love in Java are available as well and work across Java and Groovy, like "surround with", introduce, inline or rename a variable, renaming for packages, classes, methods, and fields.
-   **Imports optimizations and code formatting**.
-   Structure view: to have a bird's eye view of your classes.

At the end of the day, you won't even notice whether you're developing a class in Groovy or in Java, considering the level of interplay and support offered inside IntelliJ IDEA. This is definitely a plugin to install if you're considering adding some dose of Groovy in your Java project, or if you plan to develop Grails applications.

More information can be found on [JetBrains website](http://www.jetbrains.net/confluence/display/GRVY/Groovy+Home).

Although I'm only mentioning the plugin for IntelliJ IDEA, for your Groovy developments, you don't have to change your habits. You can also use the Eclipse plugin which is regularly improved by the IBM Project Zero developers, or Sun's brand new support of Groovy and Grails in NetBeans.

## Performance improvements

Along with new features, this new release of Groovy brings noticeable performance improvements as well as lower memory consumption, compared to previous versions. In our informal benchmarks measuring the duration of all our test suites, we noticed speed improvements between 15% to 45% compared with our beta versions of Groovy 1.5 - and certainly higher figures can be expected by comparing with the now old Groovy 1.0. More formal benchmarks have yet to be developed, but those figures have also been confirmed by developers from an insurance company that is using Groovy to write the business rules of their policy risk calculation engine, and from another company who ran several tests on highly parallel machines. Overall, Groovy 1.5 should be faster and leaner in most situations. Your mileage may vary depending on your own context of usage of Groovy.

## Enhanced dynamic capabilities

Through the symbiotic relationships between the Groovy and Grails projects, new dynamic capabilities have been introduced in Groovy, after having matured in the heart of Grails.

Groovy is a dynamic language: put simply, it means that certain things like method dispatch happens at runtime, instead of at compile-time as it is the case of Java and other languages. There is a specific runtime system, called the MOP (stands for Meta-Object Protocol) that is responsible for the dispatching logic. Fortunately, this runtime system is open enough so that people can hook into the system and change its usual behavior. For each Java class and for each Groovy instance, there is an associated meta-class which represents this runtime behavior of your objects. Groovy offered various ways to interact with the MOP by defining custom meta-classes by extending some base class, but thanks to the contribution from the Grails project, a groovier kind of meta-class is available: the expando meta-class.

Again,code samples are easier to help us understand the concept. In the following example, the `msg` String instance has got a meta-class that we can access through the metaClass property. Then we change the meta-class of the `String` class to add a new method called up to the String class, to have a shortcut notation for the `toUpperCase()` method. To do so, we assign a closure to the up property of the meta-class which is created as we assign it the closure. This closure takes no argument (hence why it starts with an arrow), and we call the `toUpperCase()` method on the delegate of the closure, which is a special closure variable which represents the real object (here the String instance).

```groovy
def msg = "Hello!"
println msg.metaClass

String.metaClass.up = { -> delegate.toUpperCase() }
assert "HELLO!" == msg.up()
```

Through this meta-class, you can query the methods and/or properties which are available:

```groovy
// print all the methods
obj.metaClass.methods.each { println it.name }
// print all the properties
obj.metaClass.properties.each { println it.name }
```

You can even check that a certain method or property is available, with a finer granularity than through any instanceof check:

```groovy
def msg = 'Hello!'
if (msg.metaClass.respondsTo(msg, 'toUpperCase')) {
    println msg.toUpperCase()
}

if (msg.metaClass.hasProperty(msg, 'bytes')) {
    println  foo.bytes.encodeBase64()
}
```

These mechanisms are extensively used in the Grails web framework for instance to create dynamic finders: no need for DAOs in most circumstances, as you are able to call a `findByTitle()` dynamic method on a Book domain class. Through meta-classes, Grails automatically decorates the domain classes with such methods. Furthermore, if the method doesn't exist yet, it will be created and cached on first use. This can be accomplished by other advanced hooks as explained below.

Beyond those examples we've seen so far, expando meta-classes also provide some complementary hooks. Four other kind of methods can be added to an expando meta-class:

-   `invokeMethod()` lets you intercept all methods calls,
-   while `methodMissing()` will be called on last resort only of no other method is found.
-   `get`/`setProperty()` intercepts access to all properties,
-   whereas `propertyMissing()` is called when no property can be found.

With expando meta-classes, customizing the behavior of the types of your application becomes easier and can save precious time of development compared with the previous version of Groovy. Obviously, not everybody needs to use those techniques, but they can be handy in a number of situations where you want to apply some AOP (Aspect Oriented Techniques) to decorate your classes, and when you want to simplify and make more readable the business code of your application, by removing some unnecessary boiler-plate code.

## Swing on steroids

The Groovy project has the chance to have a team of talented Swing developers who worked hard to enhance the capabilities of Groovy to build user interfaces in Swing. The basic brick for building Swing UIs in Groovy is the SwingBuilder class: at a syntactical level in your source, you can visually see how Swing components are nested within each other. A simplistic example from the Groovy website shows how to simply create a little GUI:

```groovy
import groovy.swing.SwingBuilder
import java.awt.BorderLayout

import groovy.swing.SwingBuilder
import java.awt.BorderLayout as BL

def swing = new SwingBuilder()
count = 0
def textlabel
def frame = swing.frame(title:'Frame', size:[300,300]) {
    borderLayout()
    textlabel = label(text:"Clicked ${count} time(s).",
                      constraints: BL.NORTH)
    button(text:'Click Me',
              actionPerformed: {count++; textlabel.text =
              "Clicked ${count} time(s)."; println "clicked"},
              constraints:BorderLayout.SOUTH)
}
frame.pack()
frame.show()
```

In the novelties, the Swing builder concept has been extend to provide custom component factories. There are additional modules, not bundled with Groovy by default, which integrates the Swing components from JIDE or from the SwingX project into the usual Swing builder code.

Although this topic would deserve a full article, I'm only going to list some of the other improvements in this release, for instance, the `bind()` method. Inspired by the beans binding JSR (JSR-295), you can easily bind components or beans together to have them react upon changes made on each other. In the following example, the size of the insets of the button will be changed according to the value of the slider component:

```groovy
import groovy.swing.SwingBuilder
import java.awt.Insets

swing = new SwingBuilder()
frame = swing.frame {
     vbox {
        slider(id: 'slider', value:5)
        button('Big Button?!', margin:
             **bind(source: slider,
                  sourceProperty:'value',
                  converter: { [it, it, it, it] as Insets }))
     }
}
frame.pack()
frame.size = [frame.width + 200, frame.height + 200]
frame.show()
```

Binding components together is such a common task when building user interfaces, that this task has been simplified through this binding mechanism. There are also some other automatic binding options that can be used, but again, a dedicated article would probably be better.

In other new and noteworthy features, a few handy new methods have been added which leverage closures to call the infamous `SwingUtilities` class, and to start new threads: `edt()` will call `invokeAndWait()`, while `doLater()` will call `invokeLater()`, and `doOutside()` will just launch a closure in a new thread. No more ugly anonymous inner classes: just use closures through those shortcut methods!

Last but not least, separating the description of the view and its associated behavior logic has never been easier, thanks to the `build()` method on `SwingBuilder`. You can create a separate script which only contains the view, while the interactions or bindings between components are in the main class, making a clearer separation in the MVC model.

## Summary

In this article, the new and noteworthy features have been outlined, but we have barely scratched the surface of this new version of Groovy. The big highlights are mainly around the new Java 5 features, such as annotations, enums or generics: it makes Groovy perfectly capable of being integrated nicely and seamlessly with Enterprise frameworks such as Spring, Hibernate, or JPA. With the improvements in the syntax and with the enhanced dynamic capabilities, Groovy will let you customize your business logic by creating embedded Domain-Specific Languages, that you can easily integrate at the extension points of your application. The developer experience has progressed significantly through the work poured in the tooling support, this is no more a show stopper to the adoption of Groovy. Overall, with Groovy 1.5, the goal of simplifying the life of developers has never been so well fulfilled, and Groovy should definitely be part of all the Java developers' toolbox.
# InfoQ: What's new in Groovy 1.5?


My [announcement](http://glaforge.free.fr/blog/groovy/224) of the release of Groovy 1.5 triggered the publication of an article that I wrote for InfoQ detailing the new features in this new release. If you want to know what it contains, I invite you to read my article on InfoQ: [http://www.infoq.com/articles/groovy-1.5-new](http://www.infoq.com/articles/groovy-1.5-new)

And if you want to know a bit more about the [Groovy](http://groovy.codehaus.org/) language history, or about my reasons to be part of this project, or if you want to know more about the founders behind [G2One](http://www.g2one.com/), the Groovy and Grails company, here are a few pointers you may be interested in:

*   [Interview of Guillaume Laforge](http://www.infoq.com/news/2007/12/interview-laforge-groovy) at QCon 2007, in March, in London
*   [G2One's team interview](http://www.javalobby.org/java/forums/t103434.html) on JavaLobby
*   A recent [interview](http://www.javalobby.org/java/forums/t103434.html) of me by the excellent Geertjan Wielenga from Sun on JavaLobby, who asked very good questions.

Let me give you a few other interesting pointers to presentations I've given recently:

*   My [keynote ](http://grails-exchange.com/guillaume-laforge#groovy-keynote)on Groovy at the [Grails eXchange](http://www.grails-exchange.com/) conference in London ([slides](http://www.grails-exchange.com/files/Guillaume-Laforge-Groovy-Keynote-Grails-eXchange-2007.pdf))
*   A [talk on Domain-Specific Languages in Groovy](http://www.grails-exchange.com/files/Guilliaume%20LaForge%20-%20DomainSpecificLanguages.pdf), also given at the Grails eXchange conference
*   I've also given a [talk on Groovy](http://ijtc.firstport.ie/UserFiles/IJTC_2007_Guillaume-Laforge-Groovy.ppt) and one on [Grails](http://ijtc.firstport.ie/lecture.aspx?lid=37) at the [Irish Java Technology Conference](http://ijtc.firstport.ie/) in Dublin. This was the first conference of this new conference series, and for a start, that was really wonderful, well organized, with a nice lineup of speakers. Kudos to the organizers.

And next week, I'll be at [JavaPolis](http://www.javapolis.com/confluence/display/JP07/Guillaume+Laforge) with [Dierk Koenig](http://www.amazon.com/gp/product/1932394842/ref=cm_plog_item_link) to present a general session on [what's new in Groovy 1.5](http://www.javapolis.com/confluence/display/JP07/Groovy+Update), and a BOF on the [cool things you can do with Groovy](http://www.javapolis.com/confluence/display/JP07/Groovy+BOF+Update). I'll be happy to meet you there if you're attending JavaPolis!
# Groovy 1.5 released


[G2One, Inc.](http://www.g2one.com/), the Groovy & Grails professional services company, and the Groovy development team are proud to announce the release of Groovy 1.5.  
  
Groovy is a **dynamic language for the JVM that integrates seamlessly with the Java platform**. It offers a **Java-like syntax**, with language features inspired by Smalltalk, Python or Ruby, and lets your reuse all your Java libraries and **protect the investment you made in Java skills, tools or application servers**. Groovy can be used for various purposes, from adhoc shell scripting leveraging Java APIs, to full-blown web applications built on Spring and Hibernate through the [Grails](http://grails.org/) web framework. It can also be integrated very easily in your applications to externalize business logic, create **Domain-Specific Languages**, or to provide templating, XML parsing capabilities, and much more.  
  
This major release integrates features offered by Java 5: **annotations, generics, static imports** and **enums**, making Groovy the sole alternative dynamic language for the JVM that lets you leverage frameworks that use annotations like **Spring**'s @Transactional or **JBoss SEAM** which both provide extended Groovy support, or generics to help **JPA** or **Hibernate** properly handle typed collections.  
  
In this release, **new meta-programming capabilities** have been contributed thanks to the work of the Grails project developers, pursueing our symbiotic relationship. A few syntax enhancements have also found their way into it to help **ease the development of Domain-Specific Languages**. A great attention to **performance improvements** made this new version much snappier than before, as witnessed by a reports we had by teams working on mission-critical applications using Groovy as a business language.  
  
Since Groovy 1.0, the team also worked on improving the tool chain by creating a **joint Java / Groovy compiler** to let you mix and match Groovy and Java classes in the same compilation step. A**GroovyDoc** equivalent to JavaDoc lets you document your Groovy classes. The **interactive shell** is now really interactive and provides useful command completions for making you more productive, and the**Groovy Swing console** has also been improved thanks to our talented Swing team and the help of Swing expert Romain Guy.  
  
Apart from improvements or the creation of these new tools, you should have a look at JetBrains' JetGroovy, a fantastic **Groovy and Grails plugin** which provides advanced coding capabilities to IntelliJ IDEA:  

*   **syntax highlighting**,
*   **code completion**,
*   **scripts and unit tests running ability**,
*   **debugging capabilities**,
*   and even **refactorings**!

Of course, if you're an Eclipse user, you can still use the Groovy Eclipse plugin, or Sun's work in progress NetBeans plugin for Groovy and Grails.  
  
An upcoming article on InfoQ that will be published in the following days will detail the novelties of this new version in more depth. So, please stay tuned!  
In the meantime, you can listen to the [interview of Groovy Project Manager](http://www.infoq.com/news/2007/12/interview-laforge-groovy) and G2One VP Technology Guillaume Laforge that was recorded at QCon 2007, in March, in London or read [G2One's team interview](http://www.javalobby.org/java/forums/t103434.html) on JavaLobby.  
  
I would like to thank everybody who was involved in this release in a way or another: the Groovy developers for their hard work, patch and documentation contributors, users reporting bugs or requesting new features or improvements, book authors.  
  
Several well-known companies have put great efforts in helping us making Groovy what it is today:  

*   **IBM**: Eclipse plugin improvements and upgrade to support this latest version of the language,  
    
*   **Oracle**: JMX support improvements to call remote beans as if they were local,  
    
*   **Sun**: Rooms for our developer meetings, and a wonderful 8-core 8-CPU machine for our high-load concurrency testing,  
    
*   **JetBrains**: for the joint java/groovy compiler & their awesome plugin,  
    
*   **JBoss**: for their help on ironing out our support for annotations and generics.

It would be impossible to list everybody, but you're all part of this effort, and you made the success of Groovy, and the quality of this new milestone. Thanks and well done to you all!  
  
You can read the detailed [JIRA release notes](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&styleName=Html&version=13904) of the changes since the last release candidate:  
  
And now, just download Groovy 1.5 and give it a try:  
[http://groovy.codehaus.org/Download](http://groovy.codehaus.org/Download)  
  
\--  
Guillaume Laforge  
Groovy Project Manager  
Vice-President Technology at G2One, Inc.  
[http://www.g2one.com](http://www.g2one.com/)
# G2One: a Groovy and Grails company


As we've [announced ](http://www.nabble.com/Announcing-G2One%3A-The-Groovy-Grails-Company-tf4599726.html)it on the Groovy and Grails mailing-lists today, [G2One, Inc.](http://www.g2one.com/) is born. Founded by [Graeme Rocher](http://graemerocher.blogspot.com/2007/10/g2one-groovygrails-company-is-born.html) (ex-CTO of [SkillsMatter](http://glaforge.free.fr/weblog/index.php?itemid=223) and Grails project lead), Alex Tkachman (ex-COO of [JetBrains](http://www.jetbrains.com/)makers of the [best Java IDE in the world](http://www.jetbrains.com/idea/)) and myself (Software Architect at [OCTO](http://www.octo.com/), Groovy Project Manager and JSR-241 Spec Lead), the company will provide training, support, consulting, and commercial products around [Groovy](http://groovy.codehaus.org/) and [Grails](http://grails.org/), making **G2One the official source for Groovy and Grails expertise**!

It's going to be a wonderful new adventure. After years spent working on Groovy at nights and week-ends, it's going to be pretty refreshing, and it's going to be a great opportunity to shift gears to spread the good word, iron out both projects, and at last working full-time on my pet projects.

[![groovy, grails, java ee, grails exchange](http://www.grails-exchange.com/custom/images/Grails-exchange-im-speaking-@-280-84.jpg "Guillaume LaForge at Grails eXchange 2007")](http://www.grails-exchange.com/pcd/1001)Speaking of evangelism a little, I hope you (my faithful readers) won't miss the [Grails eXchange](http://www.grails-exchange.com/) conference next week in London: it's going to be **the** place to be to learn **everything you've ever wanted to learn about Groovy and Grails**. It's not too late to register, so hurry up before it's too late! It's a three-day conference featuring three tracks on Groovy, Grails and Java EE/AJAX/Web 2.0. There's a pretty nice line-up of [speakers](http://www.grails-exchange.com/speakers/pcd/1001) from Google, Interface21, JBoss, Sun, etc, and the list of [sessions](http://www.grails-exchange.com/programme-grails-exchange/pdc/1001) really looks awesome to me.

The coming months should be really amazing. First of all, at the end of the week, we'll release the first release candidate of Groovy 1.1. Then, next week, we'll be doing the 4th annual Groovy Developer Conference to pave the way for Groovy 2.0. Sun was very kind to host us this year again for this meeting (big thanks to Charlie for helping us). And mid-November, we'll release Groovy 1.1, a couple of weeks before the final release of Grails 1.0!

The pace of our Groovy world will really increase, my friends.
# Groovy 1.1-beta-3 released, RC-1 and 1.1-final around the corner


Dear Groovy community,

**Groovy 1.1-beta-3 is there**, paving the way for an RC-1 in the following weeks, and if all goes well, for 1.1-final in October, right in time for the [Grails eXchange conference](http://www.grails-exchange.com/) that takes place in London. This conference will also be the opportunity for the Groovy developer team to meet for the **fourth Groovy Developer Conference**! With Groovy 1.1 released by then, it'll be time to think about what's going to happen for the next major version of Groovy.

Before going through the new release, let me recap some of the nice things that have been happening lately around Groovy:

*   [JetBrains](http://www.jetbrains.com/) released a second milestone to the wonderful [Groovy & Grails IntelliJ IDEA plugin](http://www.jetbrains.net/confluence/display/GRVY/Groovy+Home), so be sure to check it out, as you'll feel at ease developing Groovy with all the bells and whistles of your beloved IDE. You've never programmed Groovy and Grails with so much pleasure.
*   IBM's [ProjectZero](http://www.projectzero.org/wiki/bin/view/) team is also helping us improving the [Eclipse plugin](http://groovy.codehaus.org/Eclipse+Plugin).
*   [Sun](http://www.sun.com/) gave us access to a nice server beast so we can conduct some high-concurrency load testing on Groovy.

So what's in this release you may wonder? Well, there are a few nice novelties, but they should be the last ones before 1.1.

First of all, Alex Tkachman, along with Jochen, worked very hard on **improving the performance** of Groovy. On some micro-benchmark seen on the blogosphere, we even got a 100% improvement. Of course, depending on your usage of Groovy, your mileage may vary, but let me congratulate Alex for this great achievement.

Now regarding new features:

*   The last mile of Java 5 related feature is included: you can **use and define enums in Groovy**.
*   The closure and map coercion to interfaces mechanism has been extended to work on concrete classes too.
*   The ternary operator can be shortcut to simplify `a != null ? a : "default value"` into `a ?: "default value"`. We call it the **Elvis operator** -- a beer for those who guess why we've chosen that name.
*   In the dynamic space, Graeme Rocher has been continuing enhancing and **improving the ExpandoMetaClass** and has added some new methods like methodMissing(), respondsTo() or hasProperty(). Don't forget to check the [documentation](http://groovy.codehaus.org/Dynamic+Groovy) and the child pages.
*   It is now possible to customize the [variable resolving strategy in closures](http://fisheye.codehaus.org/browse/~author=graeme/groovy/trunk/groovy/groovy-core/src/test/groovy/lang/ClosureResolvingTest.groovy?r=6945) (not yet documented), so that you can decide whether you want to the resolution to go to the delegate first or only, to the closure itself, or to the owner.
*   Jason Dillon has been working on **improving the good old Groovy Shell** (groovysh). It is still a work-in-progress, so by default, it is not activated, but you may try it by setting a NEWSHELL environment variable to a dummy value. Some completion is there thanks to JLine, **ANSI color** makes things more friendly on most platforms (Windows being the exception as always), and the driving idea behind those evolutions was **getting rid of the infamous "go" command**.
*   [Romain Guy](http://www.curious-creature.org/), on his side, along with the help of [Danno Ferrin](http://shemnon.com/speling/) and [Andres Almiray](http://www.jroller.com/aalmiray/). have **polished the Groovy Swing Console look'n feel**.
*   One last nugget, some improvements have been worked on to allow a better integration between the groovyc and javac Ant task letting you use the javac Ant task as a sub-element of the groovyc Ant task -- however, for big projects with a lot of classes, it may be pretty hungry for memory.

With all that, it's time to give the usual links. Apart from those new features or improvements, we've closed a fair amount of bugs too, if you want to have a closer look at what we've worked on, you can have a look at the [JIRA issues closed for beta-3](http://jira.codehaus.org/secure/IssueNavigator.jspa?reset=true&pid=10242&fixfor=13590).

You can [download Groovy](http://groovy.codehaus.org/Download) at the usual place: Joachim Bauman is updating the [Windows native installer](http://groovy.codehaus.org/Windows+NSIS-Installer) (which also contains Antti Karanta's [native launcher](http://glaforge.free.fr/weblog/index.php?itemid=222) for Windows) and he should make it available in the following days.

One last closing word: the documentation of the website is available too, and over those past months, the **documentation climbed to about 900 pages** worth of PDF export! Even bigger than the fine [GinA](http://www.manning.com/koenig/)lady!

Keep Groovying, thanks to all the developers and contributors for their help, and stay tuned for RC-1 and 1.1 pretty soon!
# Groovy 1.1-beta-2 with contributions from JetBrains and JBoss


The Groovy team is pleased to announce the **release of Groovy 1.1-beta-2**, yet another step on our aggressive roadmap towards the release of Groovy 1.1 in October.

For this release, I would like especially to highlight two key contributions to the project:

*   First of all, after we've added [Java 5 annotation support in Groovy 1.1-beta-1](http://docs.codehaus.org/display/GROOVY/2007/04/30/Groovy+1.1-beta-1+with+annotation+support), this time, it was **generics**' turn. Thanks to the help of some JBoss developers who've [integrated Groovy in JBoss Seam](http://blog.hibernate.org/cgi-bin/blosxom.cgi/Emmanuel%20Bernard/groovyseamed.html), we've been able to test our **support for annotations and generics**, and to make sure we would release a quality milestone to our users. **Groovy is the first alternative dynamic language for the JVM that supports annotations and generics**, so that you can integrate Groovy with any Enterprise application frameworks like EJB 3 / JPA, [JBoss Seam](http://www.infoq.com/news/2007/06/seam2beta), Google [Guice](http://glaforge.free.fr/weblog/index.php?itemid=208), Spring, etc.
*   Secondly, I'm very happy to report the **contribution of JetBrains to the development of Groovy**. While working on the [IntelliJ IDEA plugin for Groovy and Grails](http://groovy.codehaus.org/IntelliJ+IDEA+Plugin+(JetBrains+Edition)), the **talentuous JetBrains team provided us with a joint Java/Groovy compiler**! No more nightmare to cleanly separate Java and Groovy code to avoid cyclic references and tedious build configuration, you can now use the Groovyc compiler to [compile both Groovy and Java](http://blackdragsview.blogspot.com/2007/07/joint-compilation-in-groovy.html) sources in a single step.

Apart from those two great contributions that we have integrated in the project, we've worked on many other areas since the release of the first beta:

*   We have ironed out the usage of Java 5 annotations (for instance [annotations for method parameters](http://docs.codehaus.org/display/GROOVY/2007/06/14/The+annotation+support+has+been+extended+to+include+support+for+Method+Parameter+Annotations) were missing).
*   As I've already mentioned, we've added **support for generics** in Groovy, so that the generated bytecode properly includes the reflection information needed at runtime by various tools such as JPA. In the area of Java 5 features, [static imports](http://groovy.codehaus.org/Static+Import+Usage) were also available in Groovy in beta-1 to make the code even more concise and readable.
*   Still pursuing the **symbiotic relationship between the Groovy and Grails projects**, the Grails team has integrated in Groovy its new [ConfigSlurper](http://docs.codehaus.org/display/GROOVY/ConfigSlurper) mechanism to configure your applications more easily.
*   The **classical for loop** is now back in Groovy after a lot of user requests.
*   Named parameters are also now possible on top-level statements, without parentheses, so that expressive code can be written like in: move x: 10.centimers, y: 8;centimeters or fund.compareWith bench: NIKEI, over: 2.months

Apart from that, we also focused on cleaning up the Groovy grammar, improving the code coverage and the performance of Groovy in highly concurrent scenarios for paralle machines. Overall, roughly a hundred bug fixes, enhancements or new features have been integrated in this new release. On the tooling front, the [Eclipse plugin recently released version 1.0.1](http://docs.codehaus.org/display/GROOVY/2007/06/29/Version+1.0.1+of++the+Groovy+Eclipse+Plugin+is+now+available.), while the progress on the [IntelliJ IDEA plugin](http://www.jetbrains.net/confluence/display/GRVY/Groovy+Home) has been awesome, you should also check it out.

You can download Groovy 1.1-beta-2 from the [download area](http://groovy.codehaus.org/Download). You can find the full release notes in our [JIRA bug tracker](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&styleName=Html&version=10436).

Thanks to all users, contributors and committers for allowing us to make this great release.
# QOTD: Eclipse is the PC of IDEs when IntelliJ IDEA is the Mac


Funny [quote on the Groovy user mailing-list](http://www.nabble.com/Status-of-the-eclipse-plug-in--tf3962848.html#a11256927), when someone was complaining that [IntelliJ IDEA](http://www.jetbrains.com/idea/) wasn't Open-Source:

> I want a platform that "just works" i don't care what it looks like underneath. It is why I have a Mac with Mac OS X and why I use [IntelliJ IDEA](http://www.jetbrains.com/idea/). Eclipse is the PC of IDEs. When you're younger and have the time and energy to spend hours settings things up, dealing with driver problems (read plugins), install things over and over and deal with the incomptabilities between different drivers (read plugins) you're ok with a PC (read Eclipse)  
>   
> When you get passed this phase and just want to get things done on a platform that doesn't get in the way and becomes invasive then you choose a platform that does this for you like the Mac (read IntelliJ). It just works out the box and everythig is nicely integrated, including the [Groovy plugin](http://groovy.codehaus.org/IntelliJ+IDEA+Plugin+(JetBrains+Edition)) ;-)
# G2One, the Groovy and Grails meetup at JavaOne


If you are attending JavaOne and are already in San Francisco on Monday, you have to come to [G2One, the Groovy and Grails meetup](http://www.nofluffjuststuff.com/groovygrailsmeetup/registration/register). The fine folks of the [NFJS](http://www.nofluffjuststuff.com/) tour are hosting this meeting to gather the Groovy and Grails community. G2One is taking place at the [W Hotel](http://www.google.com/maps?q=181+3rd+St,+San+Francisco,+California+94103,+USA&ie=UTF8&z=16&om=1&iwloc=addr) near the Moscone Center, on Monday evening. It's the best opportunity to meet the people who make Groovy and Grails.

Will be present for presentations, demos, and panel discussions:

*   [Guillaume Laforge](http://glaforge.free.fr/blog/groovy) ([Groovy](http://groovy.codehaus.org/) Project Manager),
*   [Graeme Rocher](http://graemerocher.blogspot.com/) ([Grails](http://grails.org/) Project Lead and author of [The Definitive Guide to Grails](http://www.apress.com/book/bookDisplay.html?bID=10205)),
*   [Dierk Koenig](http://www.amazon.com/gp/blog/A368TUB0Q1IE3F) (author of [Groovy in Action](http://www.manning.com/koenig/)),
*   [Andrew Glover](http://www.thediscoblog.com/) (co-author of [Groovy in Action](http://www.manning.com/koenig/)),
*   [Jason Rudolph](http://jasonrudolph.com/) (author of [Getting Started with Grails](http://www.infoq.com/minibooks/grails)),
*   [Neal Ford](http://memeagora.blogspot.com/) (Dynamic Language expert).

You can consult the [agenda ](http://www.nofluffjuststuff.com/groovygrailsmeetup/registration/register)and [register online](http://www.nofluffjuststuff.com/groovygrailsmeetup/registration/register). Hurry up, there's only 250 places left! You can even win copies of the Groovy and Grails books, and a Playstation 3! We'll all be delighted to keep you all up-to-date with what's going on in the Groovy and Grails community.
# Groovy 1.1-beta-1 with annotation support


After [Groovy was awarded the first prize of the JAX conference](http://glaforge.free.fr/weblog/index.php?itemid=210) in Germany last week for being the **most innovative and creative project in 2007 in the Java community**, we're pleased to announce the**release of Groovy 1.1-beta-1**.

This release is the first beta release after the [release of Groovy 1.0](http://glaforge.free.fr/weblog/index.php?itemid=200). But it's a very important release as we've been working on key features putting Groovy clearly as the **de facto enterprise scripting solution**. Indeed, Groovy is now the first and sole alternative language for the JVM that **supports Java 5 annotations**. Groovy 1.1-beta-1 also supports Java 5 **static imports**.

You can now use Groovy to write your [EJB 3 / JPA beans](http://www.curious-creature.org/2007/03/25/persistence-made-easy-with-groovy-and-jpa/), to wire your components with [Google Guice](http://glaforge.free.fr/weblog/index.php?itemid=208), to [mark your services transactional](http://jroller.com/page/buggybean?entry=using_groovy_spring_and_javaconfig1) with Spring's `@Transactional` annotation, to develop [JBoss Seam](http://www.jboss.com/products/seam)entities, or to be able to write unit tests with [JUnit 4](http://groovy.codehaus.org/Using+JUnit+4+with+Groovy) or [TestNG](http://code.google.com/p/testngroove/). If you want the best and **seamless Java integration**, and be able to use the latest frameworks around that leverage Java 5 annotations, look no further, Groovy is the unique solution to your scripting and dynamic needs. Whether you hack a script in your shell, or if you want to implement [Domain-Specific Languages](http://groovy.codehaus.org/Writing+Domain-Specific+Languages), Groovy has everything you need to make you more productive.

Of course, this release contains a nice list of bug fixes and improvements, making Groovy a very stable and viable platform on its own, or for your integration needs. You can find the list of all the [bugs and improvements on JIRA](http://jira.codehaus.org/browse/GROOVY).

Just to highlight some of the other interesting gems you'll find in this release, note that [Groovy mocks](http://groovy.codehaus.org/Groovy+Mocks) now let's you deal with properties as well, you can group list and map elements with a discriminator closure with the groupBy() method from the GDK, the use directive now returns the value returned by the closure it is passed, and you can add maps together. All in all, minor features, but which might come in handy from time to time. A more interesting one is probably the [ExpandoMetaClass](http://groovy.codehaus.org/Groovy+Mocks) from Grails has been brought back to Groovy.

You can download Groovy from the [usual location](http://groovy.codehaus.org/Download). You'll be able to download the [binary distribution](http://dist.groovy.codehaus.org/distributions/groovy-binary-1.1-BETA-1.zip), the [source distribution](http://dist.groovy.codehaus.org/distributions/groovy-src-1.1-BETA-1.zip), and a [zip of the online documentation](http://dist.groovy.codehaus.org/distributions/groovy-docs-1.1-BETA-1.zip) (over 500 pages) and the JavaDoc.

While the core Groovy team was working on the language, the [Groovy Eclipse Plugin](http://groovy.codehaus.org/Eclipse+Plugin) team has been making awesome progress, and the (soon-to-be-released) plugin now sports [good code-completion capabilities](http://www.rippleinteractive.com/blog/2007/04/10/1176254940000.html). But we also have good news for the [IntelliJ IDEA](http://www.jetbrains/idea) lovers, JetBrains is working full-steam to provide their own Groovy plugin, so stay tuned for additional news in that area.

A part of the Groovy and Grails team will be present at [JavaOne 2007](http://sun.com/javaone) in San Francisco to present the cool things you can do with Groovy, or how Grails reivents Spring / Hibernate development, so please come and say hi if you're around. This year, Groovy and Grails will be very well represented, there will be [8 Groovy sessions](http://www28.cplan.com/cc158/sessions_catalog.jsp?ilc=158-1&ilg=english&isort=&isort_type=&is=yes&icriteria1=+&icriteria2=+&icriteria7=+&icriteria9=&icriteria8=groovy) and [3 Grails sessions](http://www28.cplan.com/cc158/sessions_catalog.jsp?ilc=158-1&ilg=english&isort=&isort_type=&is=yes&icriteria1=+&icriteria2=+&icriteria7=+&icriteria9=&icriteria8=grails). Overall, twice as much as last year.

Additionaly, on Monday evening, just before JavaOne, there will be a special GroovyOne community event from 7pm to 10pm at the W Hotel organized by the fine folks from [NoFluffJustStuff](http://www.nofluffjuststuff.com/) and the[AboutGroovy](http://aboutgroovy.com/) community site. It will be a great opportunity to meet core Groovy and Grails developers, leads and book authors. More details to follow.

On behalf of the Groovy team, we wish you will enjoy this new release!
# Groovy.Net, annotations, mocks, applet, and so on


After [Groovy won the JAX 2007 innovation award](http://glaforge.free.fr/weblog/index.php?itemid=210), I took some time to look at what was going on in the blogosphere. There's always a lot of activity in the Groovy-sphere. It never ceases to amaze me how prolific the community is. Let's list some of the interesting posts I've come across this week-end.

*   Chanwit managed to make [Groovy run on .Net!](http://chanwit.blogspot.com/2007/04/groovy-running-fine-on-net.html) This is pretty cool IMHO. He used IKVM for that. You'll have to try it out.
*   Alex shows how to use the native Groovy mocks to [mock properties](http://themindstorms.blogspot.com/2007/04/groovy-mocks.html).
*   Andres has created a special [Groovy applet](http://www.jroller.com/page/aalmiray/?anchor=live_grapplet_test) to let you write Groovy code in your script tags in your HTML pages!
*   Glen is [having fun](http://blogs.bytecode.com.au/glen/2007/04/28/1177707183592.html) with [Scriptom](http://groovy.codehaus.org/COM+Scripting) (Groovy COM/ActiveX module) to synchronize his [Remember the Milk](http://www.rememberthemilk.com/) todo list, with Outlook.
*   Danno is [comparing the upcoming Java closure notation with Groovy's closure notation](http://shemnon.com/speling/2007/04/colosures-in-java-too-much-typ.html). I'm sure you'll easily know which one is the sexiest and how a language that supports weak typing can be more concise and expressive.
*   Warner experiments with [Higher-Order Messaging](http://www.warneronstine.com/blog/articles/2007/04/27/my-groovy-hom-take-2) with a Groovy implementation.

Next week should be pretty interesting too as we're going to release the first beta of **Groovy 1.1** in time just before [JavaOne](http://java.sun.com/javaone/sf/index.jsp) where there will be a lot of sessions dedicated to [Groovy](http://www28.cplan.com/cc158/sessions_catalog.jsp?ilc=158-1&ilg=english&isort=&isort_type=&is=yes&icriteria1=+&icriteria2=+&icriteria7=+&icriteria9=&icriteria8=groovy) and [Grails](http://www28.cplan.com/cc158/sessions_catalog.jsp?ilc=158-1&ilg=english&isort=&isort_type=&is=yes&icriteria1=+&icriteria2=+&icriteria7=+&icriteria9=&icriteria8=grails). Groovy will be the first alternative language for the JVM to support some Java 5 features. **Groovy 1.1 supports annotations and static imports**. If you plan to use another language than Java and leverage other key frameworks using annotations like [Spring](http://www.infoq.com/news/2006/12/spring-config), [EJB 3 / JPA](http://www.curious-creature.org/2007/03/25/persistence-made-easy-with-groovy-and-jpa/), [TestNG](http://groovy.codehaus.org/Using+TestNG+with+Groovy) or [Guice](http://glaforge.free.fr/weblog/index.php?itemid=208), your best option will be Groovy as it will be the sole alternative language supporting those frameworks.
# Groovy awarded JAX innovation first prize!


[JAX](http://jax.de/konferenzen/jax07/index_eng.php) is the **most important Java conference in Germany**. Every year, the organizers are running a [contest](http://jax-award.de/jax_award/index_eng.php) to select the **most innovative and creative projects**. From[over 40 proposals](http://jax-award.de/jax_award/proposal_ovw_eng.php), the jury selected only [ten nominees](http://jax-award.de/jax_award/nominierung_eng.php). Although great projects were selected, like the Matisse GUI builder in NetBeans, or the [Nuxeo](http://www.nuxeo.com/) Enterprise Content Management solution, **[Groovy won the first prize](http://jax-award.de/jax_award/gewinner_eng.php)**! It is a great honor and a huge pleasure for us to receive such a prize, especially knowing the cool projects we were competing with, or the [past winners](http://jax-award.de/jax_award06/gewinner_en.php) like the Spring framework.

[Dierk König](http://www.amazon.com/gp/blog/A368TUB0Q1IE3F), author of the best-selling "[Groovy in Action](http://groovy.canoo.com/gina)" book, received the prize on behalf of the Groovy community, after having presented several sessions on Groovy at this conference. Dierk took a [picture of the prize](http://farm1.static.flickr.com/188/473237227_f497cadb73.jpg?v=0) if you want to see what it looks like.

**This award proves how innovative, creative and influential the Groovy project is for the Java community**. After a **1.0 release** this year, and a **book**, with IDE makers working on **IDE plugin support** for the language, with many **companies betting on Groovy** for writing business rules or for scripting their products, with dedicated [news sites](http://aboutgroovy.com/) and [feed aggregators](http://www.groovyblogs.org/), with [dedicated conferences](http://www.grails-exchange.com/) and tracks, and with over [10 sessions](http://www28.cplan.com/cc158/sessions_catalog.jsp?ilc=158-1&ilg=english&isort=&isort_type=&is=yes&icriteria1=+&icriteria2=+&icriteria7=+&icriteria9=&icriteria8=groovy) about [Groovy](http://www28.cplan.com/cc158/sessions_catalog.jsp?ilc=158-1&ilg=english&isort=&isort_type=&is=yes&icriteria1=+&icriteria2=+&icriteria7=+&icriteria9=&icriteria8=groovy) and [Grails](http://www28.cplan.com/cc158/sessions_catalog.jsp?ilc=158-1&ilg=english&isort=&isort_type=&is=yes&icriteria1=+&icriteria2=+&icriteria7=+&icriteria9=&icriteria8=grails) at the upcoming [JavaOne](http://java.sun.com/javaone/sf/index.jsp) conference, Groovy stands out of the crowd and proves it's a very **successful and mature project**.

I would like to seize this opportunity to thank all the Groovy committers and contributors who helped develop this project, as well as the whole Groovy community without which Groovy wouldn't be as great and as cool as it is today. This award is really to all of you, and you're all part of this incredible success.
# Guicy: a Groovy Guice?


![](http://crazybob.org/uploaded_images/juice-770770.gif)I recently came across [Bob Lee](http://crazybob.org/)'s brand new IoC/DI framework: [Guice](http://code.google.com/p/google-guice/). I'm usually using [Spring](http://www.springframework.org/) for that purpose, and also because it goes much farther than just IoC/DI, but I thought I'd give Guice a try, especially because I wanted to play with [Groovy](http://groovy.codehaus.org/)'s support for annotations. So I [downloaded Guice](http://google-guice.googlecode.com/files/guice-1.0.zip), and read the nice getting started[documentation](http://docs.google.com/Doc?id=dd2fhx4z_5df5hw8) I also took a snapshot of Groovy 1.1 that supports Java 5 annotations. With guice-1.0.jar and aopalliance.jar on my classpath, and with the latest Groovy snapshot distribution properly installed, I was ready to go!

So, how do we start? Well, first of all, you must have some service contract that you'd like to depend on and to inject in some client code. Nothing really fancy here, I just shamelessly took inspiration from the documentation:

```groovy
interface Service {
    void go()
}
```

Now, I need a concrete implementation of this service:

```groovy
class ServiceImpl implements Service {
    void go() {
        println "Okay, I'm going somewhere"
    }
}
```

So far so good, now, we'll need some client code that needs a service to be injected. This is where you're going to see some specific juicy annotation coming into play.

```groovy
class ClientWithCtor {

    private final Service service

    @Inject
    Client(Service service) {
        this.service = service
    }

    void go() {
        service.go()
    }
}
```

Here, I'm creating a client class where I'm using constructor injection. The sole thing we have to do here is just use the `@Inject` annotation. But of course, so far, the wiring isn't specified anywhere, and we have to do it now. Guice has the concept of Modules which contain programmatic code to wire classes together.

```groovy
class MyModule implements Module {
    void configure(Binder binder) {
        binder.bind(Service)
            .to(ServiceImpl)
            .in(Scopes.SINGLETON)
    }
}
```

We are binding the `Service` interface to the `ServiceImpl` implementation. And we also mention the scope of the injection: we want to have one single implementation of that service available. Instead of specifying the scope in the module, you could also use a `@Singleton` annotation on the `ServiceImpl` class.

Now that everything is in place, we can create a Guice's injector and retrieve and call a properly wired client with the following code:

```groovy
def injector = Guice.createInjector(new MyModule())

def clientWithCtor = injector.getInstance(ClientWithCtor)
clientWithCtor.go()
```

Instead of the constructor-based approach, I prefer using a setter-based approch. And since Groovy creates getters and setters automagically when you define a property, the code is a bit shorter:

```groovy
class ClientWithSetter {

    @Inject Service service

    void go() {
        service.go()
    }
}
```

And the code for injecting is still the same:

```groovy
def clientWithSetter = injector.getInstance(ClientWithSetter)
clientWithSetter.go()
```

I'm not sure I'd use Guice for a customer project anytime soon, but for small projects where I want a xml-free DI framework, that might do! However, I might be tempted to use Grails' [Spring bean builder](http://grails.org/Spring+Bean+Builder)instead, since it's a pretty cool way to avoid the usual XML-hell when working with Spring. Also, in conclusion, it seems that Groovy's new support for annotations work quite well, as demonstrated also by Romain while [integrating Groovy and JPA](http://www.curious-creature.org/2007/03/25/persistence-made-easy-with-groovy-and-jpa/). I'm sure this will propel **Groovy as the de facto enterprise scripting solution** leveraging the wealth of frameworks and libraries using annotations.
# Groovy and Grails news, conferences and IDE support


As always, lots of great things are happening in the [Groovy](http://groovy.codehaus.org/) and [Grails](http://grails.org/) community. If you'd like to stay up-to-date with the news, but if you don't want to spend the whole day reading our high-traffic [mailing-lists](http://www.nabble.com/codehaus---Groovy-f11866.html), you should certainly consider subscribing to one of these two resources:

*   [AboutGroovy](http://www.aboutgroovy.com/): The community portal news site about everything Groovy and Grails, with frequent news items, podcast interviews, pointers to important resources.
*   [GroovyBlogs](http://www.groovyblogs.org/): A JavaBlog-like news agregator agregating the Grooyv and Grails mailing-lists feeds, and many feeds from famous bloggers spreading the Groovy and Grails love.

Both of these resources have been developed in Grails! [GroovyBlogs](http://www.groovyblogs.org/) has even been developed in [under 24 hours by Glen Smith](http://blogs.bytecode.com.au/glen/2007/02/27/1172521648562.html)!

## Conferences

I also wanted to say a few words about upcoming conference events.

*   A preliminary search on [JavaOne](http://java.sun.com/javaone/sf/index.jsp)'s online [catalog](http://www.cplan.com/javaone2007/contentcatalog/) shows no less than 8 sessions mentioning Groovy! It's alreday two more sessions than last year's JavaOne! Of higher important to me, of course, are the two sessions I'm involved with:
    
    *   **TS-1742: Cool things you can do with the Groovy programming language**, with Guillaume Alléon and Dierk Koenig.
    *   **BOF-6133: Grails: Spring + Hibernate development re-invented**, with Graeme Rocher.
    
    So don't forget to come to JavaOne and hear about the latest news about Groovy and Grails.
    
*   Now, for a shorter-term aspect, let me mention I'll be at [QCon](http://qcon.infoq.com/qcon/) this week, in London. I'll be happy to present two sessions:
    
    *   [Implementing Domain-Specific Languages in Groovy](http://qcon.infoq.com/qcon/speakers/show_speaker.jsp?oid=154): Johwn Wilson and myself will be explaining how to create DSLs with the help of Groovy. That's an area where Groovy particularly shines, thanks to its maleable syntax and its natural expressivity.
        
    *   [Grails: Spring + Hibernate development re-invented](http://qcon.infoq.com/qcon/speakers/show_speaker.jsp?oid=154): As Graeme Rocher will be at [Sun's TechDays in London](http://uk.sun.com/sunnews/events/2007/mar/revolution/techdays07/grails.html), he couldn't do the two sessions in parallel, so I'm replacing Graeme, and will be explaining how Grails simplifies the development of Web applications.
    
*   [Sun TechDays in Paris](http://fr.sun.com/sunnews/events/2007/mar/techdays/): on March 20th/21st, I'll be on stage at Sun's Parisian TechDays worldwide tour to speak about Groovy as an [alternative language for the JVM](http://fr.sun.com/sunnews/events/2007/mar/techdays/agenda.jsp#agenda-2). Like last year, James Gosling will be present! And I still recall the pleasure I felt when [Gosling told me he'd used Groovy on a couple of internal projects at Sun](http://glaforge.free.fr/weblog/index.php?itemid=185&catid=2) and said he enjoyed it a lot! That's also what he has written in his foreword of our book: [Groovy in Action](http://groovy.canoo.com/gina). Speaking of "GinA", I also encourage you to [read Slashdot's review](http://books.slashdot.org/article.pl?sid=07/02/28/1435250).
    
*   Last but not least, the much awaited [Grails eXchange conference](http://www.grails-exchange.com/) will take place in London at the end of May: a dedicated conference to Groovy and Grails! This is the first event of this kind, but more are to be expected, both in the US and in Europe! An incredible line of renown speakers have already signed in: Rod Johnson, Joe Walker, Rob Harrop, Rod Cope, Dierk Koenig, Joe Walnes, etc... This is your best opportunity to meet all the guys who make Groovy and Grails, and to hear the latest tricks from famous Java champions.

## Groovy IDE Plugins

Some additional Groovy news: the complaint we often hear about is the lack of tooling support. Groovy has had basic plugins for all the major IDEs and text editors, but this is not sufficient. Fortunately, IDE support is high on our list for 2007, and I can tell you there are some great things to come on that front:

*   First of all, the [Eclipse plugin](http://groovy.codehaus.org/Eclipse+Plugin) is making great progress, and code-completion is not very far. You should read Ed's blog to see [some nice screenshots](http://www.rippleinteractive.com/blog/2007/03/07/1173331980000.html) of the completion he's working on this month.
    
*   Some guys at Sun are also investigating how to develop and [Grails IDE for NetBeans](http://cld.blog-city.com/grails_on_netbeans__a_project_in_the_making.htm). It could be based on the stagnant [Coyote Groovy plugin](http://groovy.codehaus.org/NetBeans+Plugin), and would provide wizards for Grails artifacts, as well as all the Groovy support that's needed.
    
*   My [favorite Java IDE](http://www.jetbrains.com/idea/) is not forgotten either, since [JetBrains](http://www.jetbrains.com/) is investigating how to retrive the [GroovyJ](http://groovy.codehaus.org/IntelliJ+IDEA+Plugin) plugin and to make it work as good as they made their JavaScript or Ruby integrations.
    

So you can expect a very high and good support for Groovy and Grails in the mainstream IDEs!

As I said, a lot is happening in the Groovy and Grails community, it's hard to follow everything. 2007 is really the year of Groovy and Grails!
# New version of the Groovy Eclipse Plugin


Scott Hickey, the project lead of the [Groovy Eclipse plugin](http://groovy.codehaus.org/Eclipse+Plugin) has just announced the availability of the plugin which now uses the offcial [Groovy 1.0 release](http://glaforge.free.fr/weblog/index.php?itemid=200). The details of the announcement are reproduced below. There's even some **basic code completion **available!

Recently, EclipseZone proposed a [Getting Started article](http://www.eclipsezone.com/eclipse/forums/t88129.rhtml) explaining the basic usage of the Groovy plugin.

> There is a new version of the Groovy Eclipse Plugin available on the update site. For installation instructions, please see the wiki page [http://groovy.codehaus.org/Eclipse+Plugin](http://groovy.codehaus.org/Eclipse+Plugin).
> 
> This version of the plugin supports Groovy 1.0. Thanks to everybody who made Groovy 1.0 possible.
> 
> Please make sure to update the Eclipse project build path for any existing projects to use Groovy 1.0. For the plugin to function correctly, it is important the version of Groovy used by the plugin and the version included in the build path are the same.
> 
> This version of the plugin features:
> 
> *   Run as Groovy now only shows up on Groovy files that are executable instead of all Groovy files
> *   Run as Junit is now available for Groovy unit tests, which will display the standard Eclipse Junit view. Run as Groovy for Junit tests will still display inthe console view.
> *   Run as Groovy and Run as JUnit now create Groovy Launch configurations, which will also show up in the Launch history. This enables the run last launched toolbar button to work.
> *   Alt-Shift-X-G runs a Groovy file, also creating a Launch Configuration
> *   Alt-Shift-X-D starts the debugger, also creating a Launch Configuration
> *   Popup menu on Projects now has options to launch the Groovy Console in a separate window or the Groovy console in the standard Eclipse console. Both are launched with the project classpath.
> *   Limited **code assist**, for methods and variables defined in the same file and Default Groovy Methods
> *   Going forward, plugin updates should be picked up automatically with "Search for updates..." instead of "Search for new features"
> 
> The plugin has come a long ways over the last nine months. It wouldn't have been possible without the tremendous effort put forth by Edward Povazan, James Ervin, and David Kerber. Thanks you guys!
> 
> Scott
# Groovy 1.0 is there!


The Groovy developer team and myself are proud and delighted to announce the **final release of Groovy 1.0**.

Groovy is a **dynamic language for the JVM that integrates seamlessly with the Java platform**.  
It offers a **Java-like syntax**, with language features inspired by Smalltalk, Python or Ruby, and lets your reuse all your Java libraries and **protect the investment you made in Java skills, tools or application servers**.  
Groovy can be used for various purposes, from adhoc shell scripting leveraging Java APIs, to full-blown web applications built on Spring and Hibernate through the [Grails](http://grails.org/) web framework.  
It can also be integrated very easily in your applications to externalize business logic, create [Domain-Specific Languages](http://en.wikipedia.org/wiki/Domain-specific_programming_language), or to provide templating capabilities, and much more.

A lot of passion and energy has been put in this new version after **two release candidates that have been tested against real-world projects**: on a **mission-critical insurance application**, on the [XWiki](http://www.xwiki.org/xwiki/bin/view/Main/WebHome)2nd generation wiki engine, as well as on the [RIFE](http://rifers.org/) framework and through the [Spring 2.0](http://springframework.org/) scripting integration.

Groovy 1.0's distribution can be downloaded from the usual place:  
[http://dist.codehaus.org/groovy/distributions/](http://dist.codehaus.org/groovy/distributions/?C=M;O=D)

The JARs should be in Maven's repositories soon, but in the meantime, you can find them here:  
[http://dist.codehaus.org/groovy/jars/](http://dist.codehaus.org/groovy/jars/?C=M;O=D)

We hope you will enjoy this release as much as we enjoyed working on it.  
Let me thank the whole Groovy team and all the past Groovy committers for their hard work -- too many persons to name everybody!  
Big thanks to all our users who have been helping us spot bugs, answer questions on the lists, or contribute documentation and ideas.  
It's been a wonderful experience to work with you all to deliver this important milestone of the Groovy project.

On behalf of the whole team, I also seize this opportunity to wish you **all the best for this new year**.  
**May 2007 be a groovy year**! If you haven't used Groovy yet, make sure that learning Groovy is on your list of resolutions for 2007!  
And if that's the case, and you wish to learn Groovy or to dive deeper, you should certainly read "**[**Groovy in Action**](http://groovy.canoo.com/gina)**", **_the_** Groovy reference book published by Manning.
# Groovy development funding


The news is on the streets, on eWeek: [Groovy gets funding for its development](http://www.eweek.com/article2/0,1895,2074908,00.asp), thanks to Big Sky hiring the most prolific Groovy commiter: [Jochen Theodorou](http://blackdragsview.blogspot.com/). Big Sky is the company behind the [No Fluff Just Stuff symposium tour](http://www.nofluffjuststuff.com/index.jsp) and for their 2007 tour, they will offer a dedicated Groovy and Grails track!

[InfoQ](http://www.infoq.com/news/2006/12/groovy-sponsorship) also features a [nice article](http://www.infoq.com/news/2006/12/groovy-sponsorship) with Jay Zimmerman and Jochen Theodorou's interviews.

In the press release, Jay Zimmerman, the founder of Big Sky had this to say:

> The move will help ensure that "2007 will be remembered in the Java community as the year the Groovy revolution started," Zimmerman said. "With more than 4 million Java developers worldwide, we see a very bright and robust future for Groovy."

I also firmly believe that 2007 will be a milestone in the life of the project and we'll see an amazing adoption rate increase for both [Groovy](http://groovy.codehaus.org/) and [Grails](http://grails.org/). Having a full-time commiter on Groovy will definitely help the project move at a much faster pace.

There's an incredible convergence going around Groovy and Grails these days:

*   Releases of Groovy 1.0 and Grails 0.4
*   A full-time commiter on Groovy
*   Two [books on Groovy](http://groovy.canoo.com/gina) and one on [Grails](http://www.amazon.com/Definitive-Guide-Grails/dp/1590597583/sr=8-2/qid=1165386946?ie=UTF8&s=books&tag2=abougroo-20).
*   A dedicated Groovy and Grails website: [aboutGroovy.com](http://aboutgroovy.com/)
*   Also a dedicated Groovy and Grails conference: the [Grails eXchange 2007](http://skillsmatter.com/grailsexchange)
*   And we're going to hold our third Groovy Developer Conference in Paris at the end of January to pave the roadmap of Groovy 2.0.

Man, that's going to be a Groovy and busy year!

I'm so happy that my friend Jochen can now spend his time on Groovy! Through his hard work, Groovy improved drastically over the years, and has become a widely acclaimed platform of choice for companies needing a powerful dynamic language with the best Java integration possible. Congratulations, my friend!
# Groovy and Grails community site launching...


All about [Groovy](http://groovy.codehaus.org/) and [Grails](http://grails.org/) on a dedicated community news site! Soon to be launched!

Yes, you read it. There's going to be a site devoted to everything [Groovy](http://groovy.codehaus.org/) and Grails! The news is unleashed, on the streets. At the time of this writing, the site isn't up yet, but there's a countdown telling us there's still 1 day and 16 hours left before [http://aboutgroovy.com](http://aboutgroovy.com/) is open. It will be online just before the start of the [Spring Experience conference](http://www.thespringexperience.com/speaker_view.jsp?speakerId=728) taking place in Hollywood, Florida. I'll be speaking there by the way: I'll be presenting [Grails](http://grails.org/) and along with Rod Johnson, we'll explain how integrating Spring and [Groovy](http://groovy.codehaus.org/) together.

On the Groovy mailing-lists, Scott Davis spoke a bit about [http://aboutgroovy.com](http://aboutgroovy.com/) saying it'll be a dedicated news site, much like Digg, [InfoQ](http://www.infoq.com/groovy) or Slashdot.

Scott told us that this site will:

*   spotlight strong blogs like [CodeForFun](http://codeforfun.wordpress.com/) or [Craig Walls](http://jroller.com/page/habuma/20061127) -- of Spring in Action fame
*   cover corporate articles like the ones from [Oracle](http://www.oracle.com/technology/pub/articles/grall-grails.html) and [BEA](http://dev2dev.bea.com/pub/a/2006/10/introduction-groovy-grails.html)
*   publish tutorials (Scott Hickey has a nice three article series on bootstrapping a Groovy+Java project with Ant, JUnit, and [Cobertura](http://groovy.codehaus.org/Code+Coverage+with+Cobertura))
*   PDF chapters from Graeme's excellent book: [The Definitive Guide to Grails](http://www.amazon.co.uk/Definitive-Guide-Grails-Graeme-Rocher/dp/1590597583), and the equally excellent [Groovy in Action](http://www.amazon.co.uk/Groovy-Action-Dierk-Konig/dp/1932394842/ref=pd_bxgy_b_text_b/026-7604440-4591668)
*   offer links to screen casts, podcasts, and video interviews

If you're speaking at a JUG, or if you are working for a company that uses Groovy/Grails extensively and would like to be featured in a case study, they'll be happy to interview you. You'll also be able to submit links, write articles, tips'n tricks, cool hacks, you name it.

Icing on the cake: [http://aboutgroovy.com](http://aboutgroovy.com/) is built on Grails 0.3.1! As Scott told us, they're drinking the kool-aid, and it seems pretty tasty!
# InfoQ covers the release of RC-1 and interviews me


[InfoQ](http://www.infoq.com/), the wonderful news site that tracks innovation and change in the enterprise community, has [just covered the release of Groovy RC-1](http://www.infoq.com/news/2006/12/groovy-rc1). Scott Delap, one of InfoQ's editors, also seized the opportunity to[interview myself](http://www.infoq.com/news/2006/12/groovy-rc1) about this release, the situation of the project, present and future.

The [Groovy](http://groovy.codehaus.org/) dynamic language and its [Grails](http://grails.org/) web framework based on proven and scalable OSS components face a nice success in situations where language expressivity matters, and where rapid development time and compatibility with the Java platform are key to answering customers needs. Groovy and Grails are used for applications ranging from risk computation for insurance companies to Grid Computing solutions for aerospace companies.

This new version slightly improves the overall performance of the platform and proposes a few improvements to the core engine for better compatibility and integration with Java. A good number of bugs have also been fixed while new small refinements have been added to further raise the bar of dynamic capabilities and expressiveness.

I'll be presenting two sessions at the [Spring Experience conference](http://www.thespringexperience.com/) in Florida at the end of the week:

*   I'll be on stage with Rod Johnson to show how well [Groovy and Spring integrates together](http://www.thespringexperience.com/speaker_topic_view.jsp?topicId=222)
*   and I'll also be [introducing Grails](http://www.thespringexperience.com/speaker_topic_view.jsp?topicId=263), a Groovy-based web framework which relies on Spring under the hood

Please come and say hi if you're around. Also, stay tuned for further info, I might tell you some other very good news at the end of the week!
# We've just released Groovy RC-1!


This is with great pleasure that I'm announcing the release of the first release candidate of Groovy. Groovy RC-1 is a very important milestone in the life of the project. It also means 1.0 will be released very shortly thereafter. The plan is to release the final version before the end of the month.

This release contains a re-implemented and reworked Meta-Object Protocol, which is the core of Groovy's runtime system which decides how the dispatch of method calls, property and attribute access works. This new MOP brings more flexibility and a finer-grained control of those mechanisms. But unless you need tweaking that advanced dispatching logic, those changes won't affect you.

Groovy RC-1 contains a lot of bug fixes and improvements -- about a hundred have been worked out in this release. Among the interesting improvements, you'll note that coercion mechanisms are improved and now customizable for your own POGOs through the asType(Class) method. You can even coerce Maps to interfaces, as well as Closures to single-method interfaces. The 'in' keyword now becomes a fully supported boolean operator, not only in the for loop. Last but not least in the dynamicity of the language, you can decide which method to call with GStrings, like in: foo."$methdName"(\*args).

So far, the old closure notation with the vertical pipe was still allowed, and the @Property syntax was silently ignored in the latest release. Now that the transition period is over, in RC-1 both are definitely illegal. I hope you will all have already updated your codebase.

For a mode detailed list of the bug fixes and improvements, please refer to [JIRA](http://jira.codehaus.org/secure/ReleaseNote.jspa?projectId=10242&styleName=Html&version=12104). You can download Groovy RC-1 at the [usual place](http://dist.groovy.codehaus.org/distributions/?C=M;O=D).

Thanks goes to all the team for its efforts, and particularly Jochen Theodorou for his hard work. Big bravos to John Wilson for the XML support and the MOP, Guillaume Alléon for patches and Groovy SOAP, Dierk Koenig and it co-authors for the great Groovy in Action book, and the Eclipse plugin team as well. And also thanks to the brand new commiters who are bringing some fresh blood to the team, for instance Paul King who helped us improve some important error messages! The list is too long to name everybody!

Happy Groovying!
# From named-parameters to Domain-Specific Languages


There have always been a few irritating things to me in Java. However, working on Groovy made me go beyond these limitations, or all the useless boiler-plate code one has to write. If I had to ask for some new features in Java 7, that would certainly be:

*   have closure support (or delegate or whatever you call that)
*   native syntax for common data structures like lists and maps
*   named parameters

Today, I'm going to say a few words about the last item on my list: named parameters.

A few days ago, I read Patrick who was speaking about [var args and Java's lack of named parameters](http://blogs.opensymphony.com/plightbo/2006/08/var_args_and_javas_lack_of_nam.html). It also remind me about Paul's ideas regarding [improvements ](http://paulhammant.com/blog/at-least-one-unilateral-improvement-to-java.html)we could bring to Java. I'm definitely on the same wave-length on those Java wishes.

Regarding named-parameters, despite living on the JVM (and hence its limitations), Groovy decided to provide a simple solution for passing named parameters to methods: we're leveraging the native syntax for Maps and the omition of square brackets. So in Groovy, when you define a map, you can use that native syntax:

```groovy
def myMap = [aKey: 1, anotherKey: 2, lastKey: 3]
```

This is quite convenient. But we went a bit further, because when we pass a map as a method argument, we can omit the brackets, so in the end, you can make method calls look like:

```groovy
myAccount.debit(amount: 500, currency: "euro")
monster.move(x: 400, y: 300, z: 200)
```

As Groovy allows you to add methods to all classes, you'd probably better add some more readable amounts, like with:

```groovy
500.euros
200.dollars
```

So the debit() method could look like that, without named parameters and parentheses:

```groovy
myAccound.debit 500.euros
```

And we're getting closer to [Domain-Specific Languages](http://en.wikipedia.org/wiki/Domain-specific_programming_language). Operator overloading would also help making the intent potentially clearer:

```groovy
myAccound + 500.euros
myAccound - 200.dollars
myAccount << 500.euros
myACcount >> 500.euros
```

I guess method calls are often clearer to read though

Back to DSLs, with named-parameter, closures, operator overloading, if I take again my bank account example again, we could imagine money transactions like that:

```groovy
def someMoney = 500.euros
InTransaction.do {
    accOne.credit( amount: someMoney )
    accTwo.debit( amount: someMoney )
}
```

Or to symbolize the money transfer between accounts:

```groovy
InTransaction.do { accOne << 500.euros << accTwo }
```

Again on named-parameters, Patrick was mentioning DAO finder methods. They could advantageously be replaced with:

```groovy
dao.findBy(name: "Harry", lastName: "Potter")
dao.findAllBy(author: "Rowling")
```

[Grails](http://grails.org/) even goes further with finder methods by intercepting imaginary method calls that translate into queries:

```groovy
def results = Book.findByTitle("The Stand")
results = Book.findByTitleLike("Harry Pot%")
results = Book.findByReleaseDateBetween( firstDate, secondDate )
results = Book.findByReleaseDateGreaterThan( someDate )
results = Book.findByTitleLikeOrReleaseDateLessThan( "%Something%", someDate )
```

Be careful to those who don't like long method names! But of course, there are [other solutions](http://grails.org/GORM#GORM-DomainClassQuerying) for doing queries.
# Tip: View unread mails in Gmail


When you're subscribed to many mailing-lists, you often have hundreds of mails a day that you don't even bother reading. So usually, you mark them as read. But if you're like me and that your using tags as folders and sort all incoming mailing-lists in those folders, when you want to mark all mails as read, you need to go to each label and select them all, mark them as read each time. It starts to become a little boring. I'd love having a button "mark all as read" in Gmail. Unfortunately, that's not the case. The biggest pain though, is to have to go to each label's view to mark things as read. Fortunately, I came across a nice tip to allow me to view all unread mails altogether, without having to let everything go in my inbox (which I don't want).

So... the trick: in the search box, type "**label:Unread**", and you'll have a view of all your unread emails, whatever label there are labelled with.

Now, to go further, I still wish there were a "mark all as read" button in each view. That would save up some time and hassle. Moreover, if one could "save" searches, and have them in some "custom searches" category, that would be awesome! And while we're in the wish-list-kind-of-blog-post, if Gmail could imap or pop my other email accounts, that'd be lovely :-)

**Update #1:** [Cédric](http://beust.com/) mentionned a shorter alternative: "is:unread".
# Java's and Groovy's King at Versailles


![](/img/misc/javaday-gosling-laforge.jpg)

A few weeks ago at [JavaDay 2006](http://fr.sun.com/javaday2006/), a nice one-day conference organized by Sun, I've had the pleasure to meet [James Gosling](http://blogs.sun.com/roller/page/jag). James is the main creator of Java, and as I'm leading the [Groovy](http://groovy.codehaus.org/) project, and that the conference was happening in Versailles, city of the former French kings reknown castle, it's like two language kings were meeting there!

The picture taken on the left is from [Chris](http://userfriendly.free.fr/christopher/en/), my friend and former colleague. Read his [blog](http://userfriendly.free.fr/christopher/en/), it's full of great content! Of course, you'll have recognized James on the left, and me on the right... and not the reverse order ;-)

Overall, JavaDay was a nice conference, and I've had the opportunity to be speaking at two panels, one with James Gosling about our feedback from JavaOne 2006, and the othere on the French vitality in the Open Source area by being a member of the [OSS-GTP](http://www.ossgtp.org/)association gathering French commiters and contributors to key OSS projects.

It was also a nice occasion to meet persons I've been reading in blogs like Romain Guy (Swing guru) or Ludovic Champenois (Sun), and to meet again guys like Tugdual Grall (Oracle), Emmanuel Bernard (JBoss), Alexis Moussine-Pouchkine (Sun), or Eric Mahé (Sun).

One of my favorite moment was when **James Gosling told me that he had used Groovy on a couple of projects and that he liked it very much**! What a delight and a pleasure to hear him saying that of my pet project, the project I've been working on on my spare time for years now!

  
  
**Update:** Someone else took a [better picture of Gosling and myself](http://static.flickr.com/21/182667370_79811bd501_o.jpg).
# Groovy in Action, Manning


![](/img/misc/gina-1.jpg)

Yesterday, while blogging about the latest [Groovy](http://groovy.codehaus.org/) and [Grails](http://grails.org/) news, I mentioned the arrival of [Groovy in Action](http://www.manning.com/koenig/) soon to be published by Manning. And I forgot to show you the beautiful cover of the book. "Groovy in Action" is mainly written by Dierk Koenig, assisted with Andrew Glover, Paul King, Jon Skeet and myself. [James Gosling](http://blogs.sun.com/roller/page/jag) was kind to write us a foreword for the book, and when I met him at [JavaDay 2006](http://fr.sun.com/javaday2006/) two weeks ago, it was such a delight to hear him telling me that he had used Groovy in a couple of projects at Sun and that he liked it very much!  
  
For a first taste of the book, here is the abstract:

> Groovy in Action is a comprehensive description of the Groovy programming language, its libraries, and its everyday use. With the release of JSR 241, Groovy has become the second standard language for the Java platform. The book introduces Java developers to the new dynamic features that Groovy brings to this platform.  
>   
> The first part of the book explains the basic parts of Groovy: datatypes, control flow, object model, and handling specifics. The second part elaborates on enhancements that Groovy brings to standard Java development: builders and template engines, JRE improvements (GDK), integration options, and the special support for XML, regular expressions and database programming. The hands-on experience part of the book presents various tips & tricks for daily programming work, covers unit testing and build support, and shows how to even script Windows via Groovy. An additional bonus track is dedicated to Grails, the Groovy Web Application Framework.  
>   
> Groovy in Action introduces the language by example, showing lots of reusable pieces of code while explaining the underlying concepts. Java developers who are new to Groovy will find a smooth transition into the dynamic programming world. Groovy experts will find new aspects and triggers of creativity as well as a solid reference.

Despite only the first few chapters are available through the Early Access Program, if you're curious to know what's going to be in the book, Dierk Koenig provided [table of content](http://www.nabble.com/RE%3A-Groovy-in-Action-now-in-MEAP-p5275813.html) on the Groovy mailing-lists.
# Groovy, Grails, JSR-223, books, conferences and so on...


A lot of great and interesting things are happening these days on the dynamic language front. Of course, for those who've been there or followed the blog reports and articles, this year's been a pretty Groovy year so far, as I had promised last year. For instance, the [6 sessions](http://glaforge.free.fr/weblog/index.php?itemid=172) about [Groovy](http://groovy.codehaus.org/) & [Grails](http://grails.org/) at JavaOne 2006 were well attended and packed. But that's not all, Groovy and Grails are present at various[events](http://groovy.codehaus.org/Events), such as the [iX](http://www.ix-konferenz.de/programm.php?konferenzid=11&st=Programm) conference in Germany, where Dierk Koenig and Marc Guillemot will be speaking. Another great thing that happened just a few days ago was the very first [Groovy and Grails seminar](http://skillsmatter.com/groovy-grails-seminar)where Dierk and [Graeme Rocher](http://graemerocher.blogspot.com/) talked about Groovy and Grails!

Apart from this great and positive coverage we've had lately, two new versions of Groovy and Grails have been released. Groovy released its [last version before the first Release Candidate](http://docs.codehaus.org/display/GRAILS/2006/07/14/Grails+0.2+Released), while Grails released a [second and promising version](http://docs.codehaus.org/display/GRAILS/2006/07/14/Grails+0.2+Released). For having played with Grails recently, I can tell you that's real fun to use: in a few spare cycles I had during the commuting to work, I was able to develop a full application with all its views, controllers, CRUD operations, in no time. It's really amazing, and when I showed that to some of my colleagues, they couldn't believe I only had to write about 20 lines of business code!

What else...

*   Along with the new Groovy release, [Sundar](http://blogs.sun.com/roller/page/sundararajan/20060715) upgraded the Groovy script engine for [JSR-223's scripting APIs](http://jcp.org/en/jsr/detail?id=223) so that you can have the grooviest experience on Mustang.
*   [Groovy in Action](http://www.manning.com/koenig/) is now available through Manning's MEAP early access program! So if you can't wait for the paper version, please read the almost final chapters from Manning's site! This book is really going to become "THE" reference documentation for Groovy, and parts of it might be reused to improve the average quality documentation we've currently have online.

So, frankly, I'm very happy these days to see Groovy and Grails progressing so nicely and quickly towards their final releases. The dynamic languages on the JVM are a nice way to move forward to a more agile and versatile enterprise environment. And it feels good to be part of this movement. The coverage we get at conferences, with blog posts, articles or even inquiries from big corporations makes me feel like we're on the right track!
# JavaDay 2006, Groovy spec lead, and wedding


Lots of things are happening to me these days. First of all, I just got married a week ago with the lovely woman I've been living with for a few years already. [Tug](http://eek.ook.org/), my friend & Groovy commiter came straight from England to our wedding and took [some shots of Stéphanie and me](http://www.flickr.com/photos/tug/sets/72157594173964767/show/). Thanks a lot to all our family and friends who were so kind to come celebrate this happy moment with us, and to all those who sent us their best wishes.

The second thing is that I've just been nominated as the [JSR-241](http://jcp.org/en/jsr/detail?id=241) Spec Lead. I hope under this new reign and with the upcoming release of [Groovy 1.0](http://groovy.codehaus.org/), Groovy will be recognized as the de facto and enterprise standard scripting language for the JVM, and perhaps even included in Java 7? Who knows... JDK 6 will bundle Derby... so why not another scripting language... :-)

And the last thing I wanted to mention tonight: I'll be speaking at the [JavaDay 2006](http://fr.sun.com/javaday2006/) conference at Versailles, France, for a session entitled "Xwiki, Hibernate, Groovy, ... The French Java OpenSource Vitality" where you'll see numerous French chaps from the [OSS-GTP](http://ossgtp.org/) group who are active commiters to reknown OSS projects, and who will speak about their pet OSS projects. I'll also be part of the round table with [James Gosling](http://blogs.sun.com/roller/page/jag) for a "Round Table - JavaOne 2006: Ask The Experts". This conference is on Thursday, and I'm looking forward to seeing you there!
# InfoQ: a community news site for the architects


Remember Floyd Marinescu? The founder of [TheServerSide](http://www.theserverside.com/)? He's now working hard on a new community news site which has just been unleashed/unlaunched: [InfoQ](http://www.infoq.com/). InfoQ is a community of communities delivering news, articles, interviews, presentations, opinions, and even mini-books on various topics targeting an audience of software and technical architects, project leads and managers. Currently, five communities (or main topics if you prefer) are available:

*   [Java](http://java.infoq.com/)
*   [.Net](http://dotnet.infoq.com/)
*   [Ruby](http://ruby.infoq.com/)
*   [SOA](http://soa.infoq.com/)
*   [Agile](http://agile.infoq.com/)

What's nice about this concept of communities is that you can very easily subscribe or browse only the content you're interested in. Moreover, those communities are handled by some famous and reknown contributors, like Scott Ambler for the Agile section, or Obie Fernandez for the Ruby part. The personalization goes even further, because you can also select some sub-topics / tags specific like Architecture, Modeling, Domain-Specific Languages, etc. That's an orthogonal clustering of information. And with all these nice aspects, everything is so... Web 2.0 ;-) Full of AJAX everywhere, but for the best, not just for the shiny and trendy aspect of it.

During JavaOne 2006, I've had the pleasure to have my presentation about "Simplifying Enterprise Development with Groovy" recorded by Floyd, so within a few months, you'll have the pleasure (or not) to watch me speak about Groovy! InfoQ already published a news entry about [Oracle's decision to participate in the development of Grails and Groovy](http://www.infoq.com/news/Oracle-helps-Groovy-and-Grails).

Good luck Floyd with this new endeavour! I'll be a faithful reader! As a Software Architect in my profesional life, at [OCTO Technology](http://www.octo.com/), a consulting company focusing on architecture, that was the kind of site I was looking for.
# Builders in dynamic languages


[Groovy](http://groovy.codehaus.org/) introduced the concept of [builders ](http://www-128.ibm.com/developerworks/java/library/j-pg04125/)a few years ago, and it's great to see other dynamic languages borrow this concept. Functional languages have even already done things like that for decades! In the past, Groovy borrowed a lot of brilliant ideas to languages like Ruby or Smalltalk, and some times, that's the reversed situation where others seem to borrow ideas from Groovy.

*   [JRuby](http://jruby.sourceforge.net/) created a [clone of our AntBuilder](http://glaforge.free.fr/weblog/index.php?itemid=154&catid=2)
*   Ruby/Rails've got their own [Ruby builders](http://www.xml.com/lpt/a/2006/01/04/creating-xml-with-ruby-and-builder.html)
*   And I just came across an article today showing some builders in JavaScript as well with the [JavaScript DOM builder](http://www.vivabit.com/bollocks/2006/04/06/introducing-dom-builder)

[Grails](http://grails.codehaus.org/) also makes heavy use of the [builder concept](http://grails.org/Builders) by letting users easily create Hibernate criteria queries, define domain classes constraints, or specify AJAX XML fragments. The builder concept is really a creative way to create [fluent API](http://www.martinfowler.com/bliki/FluentInterface.html)s and [DSL](http://en.wikipedia.org/wiki/Domain-specific_language)s. I'm sure we'll find other great usage scenarios for it.
# Groovy interview on IndicThreads


After my [interview](http://glaforge.free.fr/weblog/index.php?itemid=138) back in august 2005, I'm happy to let you know about my [latest interview](http://www.indicthreads.com/interviews/429/groovy_grails_scripting_enterprise_java.html) I've just made for [IndicThreads](http://www.indicthreads.com/). In this interview, I'm speaking of course about [Groovy](http://groovy.codehaus.org/) and [Grails](http://grails.codehaus.org/), our innovative and advanced web framework lead by [Graeme Rocher](http://graemerocher.blogspot.com/).
# Scripting at JavaOne 2006


Scripting is definitely in fashion these days on the Java Virtual Machine. The [JavaOne 2006](http://java.sun.com/javaone/sf/) [session catalog](http://www.cplan.com/javaone2006/contentcatalog) is online, and by browsing it, you'll notice there are several sessions and BOFs dedicated to scripting. By simply searching for the word "scripting" in the content catalog viewer, you'll count no less than 13 sessions speaking about scripting.

This will be my first time at JavaOne. And a big first time since I'll be presenting a session! Along with [Tugdual Grall](http://www.grallandco.com/blog/index.html) from Oracle, we'll be presenting **TS-1246** entitled **"Simplify Enterprise Development With Scripting"** in the _"Core Platform, JAVA SE"_ track. The abstract of the session is:

> Scripting languages (a.k.a. dynamic languages) provide a different style of programming than system languages such as the Java programming language. They enable developers to rapidly glue components together to build applications. The Java platform now has multiple scripting solutions - Groovy, JRuby, Jython, and Rhino - that offer the power of Java technology by using the simplicity of typeless, interpreted scripting languages. This session demonstrates how scripting can simplify your everyday life by helping you administer clusters of servers or test or mock up your web services in no time. Through concrete demonstrations, the presentation explains how the dynamic nature of those languages can bring more agility to your service-oriented architecture and your fashionable AJAX applications. Finally, it discusses the future of scripting to give you a taste of tools you'll be using tomorrow.

So if you're coming to JavaOne this year, be sure to attend our session, and come and say hi!

[Groovy](http://groovy.codehaus.org/) and [Grails](http://grails.codehaus.org/) will be fairly well covered this year. Grails has got its own [BOF session](https://www28.cplan.com/javaone06_cv_124_1/sessions_catalog.jsp?ilc=124-1&ilg=english&isort=1&is=%3CISEARCH%3E&ip=yes&itrack=+&isession_type=+&isession_id=&iabstract=grails&ispeaker=&ispk_company=) (**BOF-2521** about _Grails_, and **TS-1664** about _"RAD for the Java Platform Web Tier: Frameworks Smackdown"_) presented by [Graeme Rocher](http://graemerocher.blogspot.com/), the Grails project lead.

[Groovy](http://groovy.codehaus.org/) is mentionned in **6 sessions**!

*   There's Tugdual and I's talk on "Simplifying Enterprise Development With Scripting" (TS-1246),
*   Graeme's BOF on Grails (BOF-2521),
*   as well as Rod Cope yearly session on Groovy: "Groovy = Java Technology + Ruby + Python for the JVM" (TS-3273).

There should be a very interesting BOF on "Dynamic Scripting Languages" (BOF-0554). And to finish, there are two very interesting use cases of Groovy integration:

*   "Flash-Gridding with Java Technology: Using Glassfish, Jini/JavaSpaces, and Groovy as an Environment for an Open Source, Self-Assembling Supercomputer" (TS-3714)
*   "Groovy Goes RFID with Smart Sensors for Real-World Control" (TS-5386)

I was also pretty curious to see whether other scripting languages were represented, and I only noticed one session dedicated to JRuby: "JRuby: Bringing Ruby to the JVM Software" (TS-3059). Jython is mentionned in some talks (including the ones on Groovy), with only one session including a demo using Jython. BeanShell is mentionned in the session on TestNG. Rhino is mentioned in my talk only. But JavaScript is very present in that on the client-side, for web applications, there's always been a lot of presentations speaking about it. So overall, it seems Groovy took the lion-share of the scripting languages for the JVM and we've got almost twice the coverage of last year. I'm very pleased to see the progress Groovy made both in terms of the quality of the project, and the mindshare we've garnered so far.
# Google Summer of Code 2005 TShirt


As a gift for mentoring students for the [Google summer of code 2005](http://code.google.com/summerofcode.html) around some project ideas for [Groovy](http://groovy.codehaus.org/), I just received a nice tshirt roughly on time for Christmas!

![](/img/misc/google-soc-tshirt.jpg)
# Debugging XML parser issues


There are often some issues that can waste several hours of your precious time: XML parser incompatibilities depending on your platform and application, i18n problems where several elements of your architecture aren't configured well to serve correct encoded and localized content, class loader hierarchy nightmares, or even Jar Hell when different libraries you depend on require different versions of the same jar. Today, I'm going to concentrate on the first problem: XML parser issues.

I was having a problem of interoperability between my Java web services and a .Net client consumming them. And it appeared that a bug in certain versions of Xalan made the XML payloads generated by .Net not parseable and generated some odd stacktrace on my backend with a pretty obscure message (NAMESPACE\_ERR message). It took me quite some time to discover what the problem really was. In short, my old version of Xalan couldn't grok default namespaces inherited from parent nodes.

While debugging this problem, I created a little JSP page, to help me understand clearly which version of Xerces and Xalan I was using. I had no problem under Tomcat 5.0.x and Sun's JDK 1.4.2\_06, but the problem appeared with Websphere 5.1 and IBM's JDK 1.4.2. My JSP page will tell you which versions of Xalan and Xerces you're using, from which Jars they are loaded, and it'll also print your system properties.

Just so that I can cut'n paste it some day in the future if I have a problem with XML parsers again, here it is:

```jsp
<%@ page import="java.util.Properties"%>
<%@ page import="java.util.Enumeration"%>
<%@ page import="javax.xml.transform.TransformerFactory"%>
<%@ page import="javax.xml.parsers.DocumentBuilderFactory"%>
<%@ page import="javax.xml.parsers.ParserConfigurationException"%>
<%@ page import="javax.xml.parsers.SAXParserFactory"%>
<%@ page import="javax.xml.parsers.FactoryConfigurationError"%>
<%@ page import="javax.xml.transform.TransformerFactoryConfigurationError"%>
<%@ page import="java.net.URL"%>
<%@ page import="org.apache.xalan.xslt.EnvironmentCheck"%>
<%@ page import="java.io.PrintWriter"%>
<%@ page contentType="text/html;charset=UTF-8" language="java" %>
<%!
    private String getJarForClass(Class clazz) {
        String clsResPath = clazz.getName().replaceAll("\\.","/")+".class";

        ClassLoader clsLoader = clazz.getClassLoader();
        if (clsLoader == null) clsLoader = ClassLoader.getSystemClassLoader();

        URL clsResURL = clsLoader.getResource(clsResPath);
        return clsResURL != null ? clsResURL.toExternalForm() : "unknown";
    }
%>
<%
    String transformerClassName = "";
    try {
        Class clazz = TransformerFactory.newInstance().getClass();
        transformerClassName = clazz.getName() + "
(" + getJarForClass(clazz) + ")";
    } catch (TransformerFactoryConfigurationError e) {
        transformerClassName = e.getMessage();
    }

    String documentBuilderClassName = "";
    try {
        Class clazz = DocumentBuilderFactory.newInstance().newDocumentBuilder().getClass();
        documentBuilderClassName = clazz.getName() + "
(" + getJarForClass(clazz) + ")";
    } catch (ParserConfigurationException e) {
        documentBuilderClassName = e.getMessage();
    }

    String saxParserFactoryClassName = "";
    try {
        Class clazz = SAXParserFactory.newInstance().getClass();
        saxParserFactoryClassName = clazz.getName() + "
(" + getJarForClass(clazz) + ")";
    } catch (FactoryConfigurationError e) {
        saxParserFactoryClassName = e.getMessage();
    }

%>

    XML parsers debugging
    
    Debug parameters
<%
    Properties p = System.getProperties();
    Enumeration keys = p.keys();
    while( keys.hasMoreElements() ) {
        String key = (String) keys.nextElement(); %>
        <%
    }
%>
    
   
        
        
    
     
            
      Xalan version
            
      <%= org.apache.xalan.Version.getVersion() %>
        
     
        
     
            
      TransformerFactory
            
      <%= transformerClassName %>
        
     
        
     
            
      DocumentBuilder
            
      <%= documentBuilderClassName %>
        
     
        
     
            
      SAXParserFactory
            
      <%= saxParserFactoryClassName %>
        
     
        
     
            
      Xalan debug environement check:
            
      <% (new EnvironmentCheck()).checkEnvironment(new PrintWriter(out)); %>
        
     
     
            
      <%= key %>
            
      <%= System.getProperty(key) %>
        
     
    
   
    
```
# AntBuilder: Imitation is the Best Form of Flattery


I've just come across a [clone](http://antbuilder.rubyforge.org/) of [Groovy](http://groovy.codehaus.org/)'s AntBuilder. It's being built with [JRuby](http://jruby.sourceforge.net/) and allows you to write your build scripts in JRuby by reusing Ant's tasks.

That was a pleasure to see Ruby inspired by our concept of builders, and now, they also copy our own builders. I'd simply say that imitation is the best form of flattery. Kudos guys!
# Big thanks for the second Groovy meeting


Last week took place the second GroovyOne meeting in Paris, gathering the main Groovy developers. The event went fairly well, despite some disagreement we need to iron out, we made quite a lot of[progress](http://docs.codehaus.org/display/GroovyJSR/Paris+Groovy+Meeting+report) on the Groovy front towards 1.0.

It's been a real pleasure to meet together again, and I must say I really [had a lot of fun](http://www.flickr.com/photos/tags/jsr241) there. But this meeting could not have been possible without the help and sponsoring of different actors. That's why I particularly want to thank all those who helped me make this happen.

First of all, [Codehaus](http://www.codehaus.org/)' [Bob McWhirter](http://www.openxource.com/) alloted a budget to help us pay for the accomodations. And we were also generously sponsored by two Groovy fans building software which embed Groovy: [Ludovic Dubost](http://www.ludovic.org/) who's working on [XWiki](http://www.xwiki.org/), an Open Source second generation Wiki engine and application platform, and [Benjamin Mestrallet](http://www.exoplatform.com/) who's been building [eXo Platform](http://www.exoplatform.com/), powerful Open Source corporate portal and content management system. And the final thanks go to [Alexis Moussine-Pouchkine](http://blogs.sun.com/roller/page/alexismp), a Sun architect and consultant, who kindly granted us access to a fully-equiped meeting room in Sun's parisian Customer Briefing Center.
# Four years to fix a trivial bug...


My friend Christopher just told me a [very old bug in the JDK](http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4508058) has eventually been fixed in Mustang!

**UTF-8 encoding does not recognize initial BOM**

> Java does not recognize the optional BOM which can begin a UTF-8 stream. It treats the BOM as if it were the initial character of the stream.A Utf-8 stream can optionally beign with a byte order mark (see, for example [http://www.unicode.org.unicode/faq/utf\_bom.html](http://www.unicode.org.unicode/faq/utf_bom.html)). This is the character FEFF, which is represented as EF BB BF in utf-8. Java's utf-8 encoding does not recognize this character as a BOM, though; the result of reading such a stream is a set of characters beginning with FEFF.

I'm glad it's now fixed! I've been working around this bug for a long time already. I've even applied some patches to work around this issue to [Groovy](http://groovy.codehaus.org/) as well as in [IntelliJ IDEA](http://www.jetbrains.com/idea) -- thanks to Maxim who introduced my suggested fix inside this wonderful IDE.
# Re: Ted Neward on anonymous generic methods


C#'s fanatic Ted Neward is amazed at how cool C#'s [anonymous generic methods](http://blogs.tedneward.com/CommentView,guid,f96809ba-7332-4df7-84c8-490ec66c584f.aspx) are. He then gives an example of a little program that filters some entries according to a critiria, using some generic types and delegates. It's about finding all persons from a set of persons whose last name is "Neward". Sam Pullara even showed his own version of the [same program in Java](http://www.javarants.com/B1823453972/C1464297901/E20051108213800/index.html) and explains that [IntelliJ IDEA](http://www.jetbrains.com/)allowed him to type roughly 10% of the characters of the program thanks to the wonderful completion and code templating capabilities of that IDE.

What strikes me is how verbose both versions are. Even C# with its delegate isn't particularly less verbose, except a few lines saved. No real readability, expressiveness or productivity gained -- though I must confess I do like all those nifty little features available in the upcoming C# 3.0. Naturally, I was tempted to give my own [Groovy](http://groovy.codehaus.org/) version of the problem. Here it is, and please note the conciseness and clarity of the following code:

```groovy
class Person {
    @Property String firstName
    @Property String lastName
    @Property int age
    String toString() { "Person{firstName='$firstName', lastName='$lastName', age=$age}" }
}

def persons = [
    new Person(firstName: "Cathi", lastName: "Gero", age: 35),
    new Person(firstName: "Ted", lastName: "Neward", age: 35),
    new Person(firstName: "Stephanie", lastName: "Gero", age: 12),
    new Person(firstName: "Michael", lastName: "Neward", age: 12),
]

def newards = persons.findAll{ it.lastName == "Neward" }

newards.each{ println it }
```
# Google Base, Ning, or how to store your life


We've got [PIM applications](http://en.wikipedia.org/wiki/Personal_information_manager), all sorts of [PDAs](http://www.palm.com/), rich client GUIs or webapps on the internet or behind the corporate intranet's firewalls. There's the [MDA](http://www.andromda.org/) approach to generate apps from datamodels, or[application generation engines](http://www.reflexe.fr/) that build applications dynamically thanks to the interpretation of a metamodel. All these applications and interfaces to store all kind of data, personal or business related, generally sports a fixed and frozen structure. New developments are always needed for evolving your applications, and costly redeployments and interuption of services are often triggered.

Then, there's the [Semantic Web](http://www.w3.org/2001/sw/), and [RDF stores](http://simile.mit.edu/reports/stores/), like [Jena](http://jena.sourceforge.net/)/[Joseki](http://www.joseki.org/) or [Kowari](http://www.kowari.org/). You can store all the information you want in some unstructured way ([RDF triples](http://www.w3.org/RDF/)), that can be understood by other applications, if you share common ontologies through [RDFS](http://www.w3.org/TR/rdf-schema/) or [OWL](http://www.w3.org/TR/owl-features/), and common namespaces like [Dublin Core](http://dublincore.org/). Some interesting querying systems like [SPARQL](http://www.w3.org/TR/rdf-sparql-query/) can allow you to query multipe documents and stores at the same to help you mix together different channels of information. Unfortunately, so far, the Semantic Web never really took off because of its inherent complexity to deploy and understand.

These days, there's a couple of other concepts that've taken the blogosphere by storm: [REST](http://rest.blueoxen.net/cgi-bin/wiki.pl) and tags. [Flickr](http://www.flickr.com/) lets you store pictures, share and tag them, as well as [del.icio.us](http://del.icio.us/) which allows you to tag and share your bookmarks, [Google maps](http://maps.google.com/) to share geographic data. There are also some nice REST interfaces to mix and match those online services through their public APIs. [Mashups listings](http://www.programmableweb.com/matrix) are appearing to explain who's glueing with whom. And you can also subscribe to everything through [RSS](http://blogs.law.harvard.edu/tech/rss) or [Atom](http://www.intertwingly.net/wiki/pie/FrontPage) feeds.

A few weeks ago, [Marc Andreessen](http://en.wikipedia.org/wiki/Marc_Andreesen) ([Netscape](http://en.wikipedia.org/wiki/Netscape_Communications_Corporation)'s founder himself) introduced [Ning](http://www.ning.com/) to the world! It builds on the concepts of tags, REST and a custom content store, to allow its users to build [social software](http://www.emilychang.com/go/ehub/)on top of their framework. Building your own application is as simple as creating a few types to store instances in their [content store](http://developerdocumentation.ning.com/post.php?Post:slug=ContentStore) (no tedious SQL code anymore for your data model!), and writing a few[PHP](http://www.php.net/) files that let users interact with their data. Or you can even clone an existing application and customize it to suit your needs! Anything is shareable (information is either public or private) and taggable. All applications and data are available through some [pivot URLs](http://developerdocumentation.ning.com/post.php?Post:slug=Pivot) which are a kind of automatic RESTified interface of the whole system. Brilliant, really brilliant.

And now comes [Google](http://www.google.com/), and its [Google Base](http://base.google.com/). [Not](http://dannyayers.com/archives/2005/10/25/google-base/) [much](http://www.seweso.com/blog/2005/10/google-base.php) [is](http://blog.outer-court.com/forum/11831.html) [known](http://blog.outer-court.com/forum/11876.html) [as](http://battellemedia.com/archives/001960.php) of yet, but I'm sure we'll get more tidbits real soon. Google Base will probably be the next big thing. I was sure Google would create such a thing because they claim their goal is to organize the world's data. And your own personal data as well. So it seemed like a logical step to create another killer application which would allow you to store an d share all kind of structured and unstructured information. They've already got the backend ready for that with their [GFS](http://labs.google.com/papers/gfs.html) (distributed Google File System) and their [BigTable](http://andrewhitchcock.org/?post=214) (a huge flexible and evolutive[database](http://torrez.us/archives/2005/10/24/407) ) system. Imagine you can define your own types, in a very flexible and malleable way, that you can create list and item views of that data, that you can share these things with your friends, and tag them? And imagine also that there are APIs on top of Google Base to interact remotely with your data and make your own data-driven application interact with each other? That's a Semantic Web driven by data and by [folksonomies](http://en.wikipedia.org/wiki/Folksonomy).

I've always dreamt of building something like that, and it seems both Google Base and Ning are going in the right direction. It seems even more useless now for me to start a project like that, since those bright guys are doing it! I've always wanted to store my life, to brain dump my ideas into a common base, programmable through APIs, cross- linkable and categorizable with tags. It seems like my ideas for the future of information technology are taking shape at Google labs... today. I'm impatient to try that out.
# JBoss' Wiki portlet, why not XWiki?


Sometimes, there are some unlogical choices that are being made: [JBoss chooses](http://www.theserverside.com/news/thread.tss?thread_id=36452) [JSPWiki](http://www.jspwiki.org/) as a base for their Wiki portlet in JBoss Portal. They choose to fork and trim JSPWiki (rather than contributing to it) to be able to embed a Wiki engine in their portal as a portlet. Fine. But why not choosing [XWiki](http://www.xwiki.org/)? XWiki:

*   is a member of the [JBoss Open Source Federation](http://www.jboss.org/federation/MemberXWiki),
*   can already be [integrated in JBoss Portal](http://www.jboss.org/federation/MemberXWiki),
*   and moreover can also be integrated in any portlet container (The proof is that the [eXo Platform](http://www.exoplatform.com/) already embeds XWiki as a portlet).

That's weird, isn't it?
# Web services RPC calls over Google Talk


With the recent release of [Google Talk](http://www.google.com/talk/), the fine chaps at Google entered the Instant Messenging market. The most clever step in that direction was their choice of protocol for their IM solution: [XMPP](http://www.xmpp.org/). XMPP was popularized and standardized through the IETF by the [Jabber](http://www.jabber.org/) software foundation with its famous _open, secure, ad-free alternative to consumer IM services like AIM, ICQ, MSN, and Yahoo_ (quoted from their site).

A particular benefit of choosing an open platform is that it takes advantage of available client GUIs for instance, and moreover, it can leverage specific and standardized extensions of the XMPP protocol -- called JEPs. The Jabber foundation developed an interesting set of complementary protocol extensions by allowing custom XML payloads to be developed. And there's one JEP of interest for us today: [JEP-0009](http://www.jabber.org/jeps/jep-0009.html). This JEP defines a method for transporting XML-RPC encoded requests and responses over Jabber/XMPP.

[JiveSoftware](http://www.jivesoftware.org/) developed a Jabber library called [Smack](http://www.jivesoftware.org/smack/) that you can use to "speak XMPP"! They recently [improved this library](http://www.jivesoftware.org/smack/smack_gtalk.jsp) to support Google Talk pecularities (TLS/SSL connection). With this library, we can also build our own payloads to support JEP-0009 and to programmatically make RPC calls.

Final point to glue everything together: my brilliant friend [John Wilson](http://www.wilson.co.uk/), who wrote the [Groovy XML-RPC](http://groovy.codehaus.org/Groovy+XML-RPC) module, built upon the Smack library and its XML-RPC code to add XML-RPC support through Google talk! Groovy's XML-RPC is particularly easy to use to expose XML-RPC services through some clever use of closures in Groovy. That means it's now possible to do [remote procedure calls through Jabber](http://groovy.codehaus.org/Groovy+Jabber-RPC).

After all these presentations, it's high time to hack some code, isn't it? Let's create a simple echo service, which will simply echoes whatever we send to it.

Let's write the server:

```groovy
import groovy.net.xmlrpc.*
import org.jivesoftware.smack.GoogleTalkConnection

def srv = new JabberRPCServer()

// here is our echo service, that's a simple closure method!
srv.echo = { return it }

// let's start the server
def serverConnection = new GoogleTalkConnection()
serverConnection.login("serverId", "serverPassword")
srv.startServer(serverConnection)

// let the server run for 60 seconds
while(true) { sleep 60*1000 }
```

Now that we've written the server, it's time to create our client:

```groovy
import groovy.net.xmlrpc.*
import org.jivesoftware.smack.GoogleTalkConnection

// let's connect to Google Talk
def clientConnection = new GoogleTalkConnection()
clientConnection.login("clientId", "clientPassword")

// create a transparent proxy around the remote service 
def serverProxy = new JabberRPCServerProxy(clientConnection, "serverId@gmail.com")

// it's time to call our service as if we were manipulating a local object
println serverProxy.echo("Hello World!")
println serverProxy.echo(345)
```

Currently, the improved Groovy XML-RPC library is in CVS Head only, so if you're impatient and can't wait for a new Groovy release, you'll have to build it yourself from sources! You propably also noticed you need two GTalk buddies who've authorized each other to make this sample work.

A good question to ask yourself is _"uh, well, cool, but what can I do with that?"_ Here's a potential use case John told me about where you could want to use Groovy's XML-RPC support over Google Talk :

> Some people want to use VNC to manage their home server, however you do not want to open a port on your firewall to allow VNC access from the internet (VNC is not very secure). The VNC server will "reverse connect" to an external client. So you could run a jabber RPC server which launched the VNC server telling it to reverse connect to your external machine

I can also imagine some other use cases, like:

*   triggering Continuous Integration servers which would support Jabber's XML-RPC support
*   doing some home automation to make you house warm when you come back from work in a cold winter
*   etc.

There are many possibilities, and I'm sure others will find some clever use cases for that. I can imagine Google Talk providing some cool services as well in the future, and I'm pretty sure they will.

You may also wonder why not using raw XML-RPC or standard SOAP for these kind of services? That's another possibility, of course. It's up to you to use whatever protocol you want after all, but I thought it'd be interesting to show you how we can leverage Google's own Jabber infrastructure. Moreover, you don't have to open a port on your firewall to allow access to a given port (safe against port scanning), nor you have to have a DNS entry for the machine hosting the service: all goes through the Google Talk server.

I hope you enjoyed this little funny toy. It may have brought to you a glimpse of what services Google could provide through its open and extensible platform.
# Talking about Google Talk...


Okay, [Google](http://www.google.fr/) released its [Google Talk](http://www.google.com/talk/) client and its related services. This all sounds good and well, but alas, for us, poor corporate users, we have yet to figure out if it'll ever work through our nasty proxies (with authentication) and firewalls (port 5222 should be opened?). I've tried tweaking the proxy settings myself, but it didn't work. Unfortunately.

On paper, Google Talk certainly looks promising, taking into account the great services Google have come up with so far, but there's really not much more than other competitors already provide. And in fact, we have yet to see the great features not available anywhere that we all expect from Google. We've become pretty demanding users... (and as we say in French "Qui aime bien châtie bien").

Apart from the integration with [GMail](http://gmail.google.com/), there's nothing really innovative that other services like [Yahoo! Messenger](http://fr.messenger.yahoo.com/) or [Skype](http://www.skype.com/) (doesn't seem to work across firewalls either) don't already provide. And worse, in their email invitations they send, they claim:

> Google Talk also works across all firewalls.

but I have yet to see it becoming a true statement... But if ever it really manages to work everywhere, then that's becoming interesting to have a reliable Jabber server to play with, and that would be even greater if we could also get an (Java) API giving access to the notification means of the client. I guess we could do some cool things (Continuous Integration notifications, and so on). Time will tell...

In the meantime, if someone can tell me how to use it from work, I'm game, otherwise, I think I'll stay with my good old and faithful [Yahoo! Messenger](http://fr.messenger.yahoo.com/) which has always been working at work like a charm (except once where the company blocked \*.yahoo.\*).

**Update #1**: It seems that Google is already aware of the problem I'm facing with regards to passing through corporate firewalls. They had this to answer my information request:

> Thanks for contacting us about this problem. We're aware of the issue, and our engineers are working diligently to find a solution.

**Update #2**: Google Talk's client must probably not be working across all firewall configurations. The proof is that other clients like Psi work perfectly with Google Talk from work. So it really must be the client which's got some problems currently.
# Spring in French: c'est le printemps !


At out last [OSS-Get Together](http://ossgtp.xwiki.org/xwiki/bin/view/Main/18Aout2005) meeting in Paris last thursday, we've had the chance to have [Thierry Templier](http://templth.blogspot.com/), a [Spring modules](http://glaforge.free.fr/weblog/index.php?itemid=139) and a [Jencks](http://jencks.org/) commiter, make an introductory presentation of the [Spring Framework](http://www.springframework.org/)

On our wiki, he made available two powerpoints in French:

*   a big [118-slides presentation on Spring](http://ossgtp.xwiki.org/xwiki/bin/download/Main/18Aout2005/PRES+SPRING+OSSGTP.PPT),
*   and a specific one on [Spring and JCA](http://ossgtp.xwiki.org/xwiki/bin/download/Main/18Aout2005/PRES+SPRING+JCA+OSSGTP.PPT).

That's a lot of content to read for those of you speaking Molière's tongue.

Moreover, on his blog, he's got a very interesting entry explaining how to [inject Groovy beans](http://templth.blogspot.com/2005/08/use-groovy-with-spring.html) with Spring or how to [access CICS transactions](http://templth.blogspot.com/2005/08/access-cics-with-spring.html) from Spring!
# The Guru of Groovy shares his Thoughts


As stated on Javalobby: "[The Guru of Groovy shares his Thoughts](http://javalobby.org/java/forums/t43566.html)"! Well, it seems like I'm that Guru! And that's been my first official interview. That was a quite fun and interesting exchange of mails between Andrew and me, and it allowed me to develop a few interesting points I never had time to explain.

Andrew Glover, [Vanward Technologies](http://www.vanwardtechnologies.com/welcome.php)' CTO, is a fan of [Groovy](http://groovy.codehaus.org/). He wrote several great articles on DeveloperWorks in a "[Practically Groovy" series](http://www-128.ibm.com/developerworks/views/java/libraryview.jsp?search_by=practically+groovy:)". I've recently had the pleasure to be [interviewed by him](http://www.vanwardtechnologies.com/glaforge01.php)regarding Groovy, and here's what the abstract says:

> As the defacto Guru of Groovy, Guillaume Laforge has guided the project through the ambitious JSR migration as well as setting the tone and the climate for the Groovy team. Read on as Guillaume shares his experiences as Groovy's governor, his thoughts on Groovy's future and why you should consider giving it a spin.

So if you want to know a bit more about Groovy's history, present and future, or how I got involved in Groovy, go [read it](http://www.vanwardtechnologies.com/glaforge01.php)!

**Update #1:** The interview is also featured on [TheserverSide](http://www.theserverside.com/news/thread.tss?thread_id=35851).

**Update #2:** On [java.net](http://today.java.net/pub/n/FutureofGroovyInt) as well
# Wifi Rabbit for Continuous Integration


Call me a geek, but I'd really love to buy me one of these little [Wifi rabbits](http://www.nabaztag.com/). The Nabaztag rabbit is a 23-cm high white rabbit with moving ears, and a set of flash LEDs of different colors. You can pair it with another rabbit so that when you move the first one's ears, will automatically make the other one move its ears accordingly, even if your in another town or country (as long as you have a permanent DSL connection). Nabaztag can sing songs, or through some service subscription, he can react to the stock market trends, or to the weather, flashing in yellow when the sun is shinning.

After our recent [OSS-GT meeting](http://ossgtp.xwiki.com/xwiki/bin/view/Main/21Juillet2005) with talks on AOP (by Alexandre Vasseur from AspectJ/AspectWerkz) and CruiseControl (by Jérôme Lacoste, a CC contributor), it reminded me about [Mike Clark](http://www.clarkware.com/cgi/blosxom)'s book on[Pragmatic project automation](http://pragmaticprogrammer.com/starter_kit/au/index.html) -- that I need to order some day. In this book, Mike is talking about lava lamps to show that a build of your project failed, when your Continuous Integration server tries to build your project. I wonder if we can use that 95 euros Nabaztag to react upon build success or failure. Since Nabaztag can react upon certain emails containing particular keywords, I guess we could make glow red when the build fails, and green when it builds successfully.

That's a pretty neat geek gadget! And I've found many other ones on the [Mageekstore](http://ww1.mageekstore.com/) (content in French), like an [USB/MP3 player watch](http://www.mageekstore.com/boutique/fiche_produit.cfm?type=5&ref=MTRMP3&code_lg=lg_fr&pag=1&num=0), various USB lights, [Swiss army-knives](http://www.mageekstore.com/boutique/fiche_produit.cfm?type=1&ref=SWMEM&code_lg=lg_fr&pag=1&num=0) with integrated USB key, or a [coffee mug USB warmer](http://www.mageekstore.com/boutique/fiche_produit.cfm?type=5&ref=CUPWR&code_lg=lg_fr&pag=1&num=0)... Too many funny toys!
# Aquarelle de Versailles


Pour mon anniversaire, Stéphanie m'a offert du matériel pour faire de l'aquarelle : un carnet à dessin et un coffret avec 16 couleurs. Comme le temps était plutôt agréable et clément ce week-end, nous avons décidé de pique-niquer auprès du Grand Canal du Château de Versailles. J'ai emmené tout mon attirail, et j'ai réalisé ma première aquarelle, que voici :

![](/img/misc/versailles-aquarelle.jpg)
# Initial release of the GroovyJ IntelliJ plugin!


Franck Rasolo, our IntelliJ expert, just released and announced the inital version of the GroovyJ IntelliJ IDEA plugin!

> The Groovy team is pleased to announce the first public release of GroovyJ, a plug-in that integrates the Groovy language into IntelliJ IDEA.
> 
> You may browse the current [GroovyJ status page](http://groovy.codehaus.org/GroovyJ+Status) which lists the features shipped with this initial release.
> 
> In a nutshell, with GroovyJ:
> 
> *   a default Groovy runtime is automatically installed as a global library
> *   Groovy files can be edited with some amount of syntax highlighting
> *   'Run Configurations' can be created for runnable Groovy scripts
> *   Groovy scripts can be run with the output being captured in the embedded console window
> *   Groovy scripts located under module source/test folders will be automatically compiled when compiling modules
> 
> Note: This plug-in is available through IDEA's plug-in manager and requires IntelliJ IDEA 5.0 build #3378 or higher.
# JavaOne: Groovy reactions!


The [JavaOne](http://java.sun.com/javaone/) crowd is applauding [Groovy](http://groovy.codehaus.org/)! And the blogosphere is full of friendly comments towards our dynamic and agile scripting language for the JVM.

[Jeremy Rayner](http://www.javanicus.com/blog2/) (our co-[JSR-241](http://www.jcp.org/en/jsr/detail?id=241) spec lead, and JSR project lead) compiled a list of blog posts related to Rod Cope's JavaOne presentation, titled "Groovy = Java Technology + Ruby + Python for the JVM". Rod Cope, [OpenLogic](http://www.openlogic.com/)'s CTO and Founder, has already given a few talks about Groovy, and evangelizes its use at various events. But he doesn't only "speak" about Groovy, he's also eating his own dog food, because his company flagship product [BlueGlue](http://www.openlogic.com/page.php?pname=software/overview#) embeds over 100,000 lines of Groovy code!

Here's the list compiled by Jeremy:

*   [Artima](http://www.artima.com/weblogs/viewpost.jsp?thread=116723)'s Eric Armstrong proposed a thourough article on Groovy, saying JavaOne's day One was a Groovy day!
*   [The Server Side](http://www.theserverside.com/articles/article.tss?l=JavaOne_Day1) also talked about the presentation and it seemed that my [Scriptom](http://glaforge.free.fr/weblog/index.php?itemid=101) (my pet sub-project and creation) yielded Wooww's and Aahh's moments in the audience, when Rod controlled an Excel spreadsheet from a groovysh console! Awesome!
*   Even funnier, a[microsoftie](http://blogs.msdn.com/ericgu/archive/2004/07/08/177351.aspx) talked about Groovy!
*   Dion, a long time Groovy affictionado, [discusses](http://www.almaer.com/blog/archives/000262.html) Microsoft's Eric Gunnerson comments
*   Ed Burns seems to be also [impressed](http://weblogs.java.net/blog/edburns/archive/2005/06/ed_burns_javaon_2.html) with Groovy's terseness.
*   ClientJava.com is having his ["whoa cool" moment](http://www.clientjava.com/blog/2005/06/27/1119917179424.html) while staring at Rod's Excel manipulation through Scriptom. And a user even commented that: _"There is probably no specific reason you'd have to use Groovy besides the "cleaness" that you mention it provides"_.
*   Finally, Ryan Daigle talks about two nice use cases regarding how to leverage [Ant](http://ryandaigle.com/pebble/2005/06/27/1119913090784.html) from Groovy, and how you can easily [script ActiveX/COM components](http://ryandaigle.com/pebble/2005/06/27/1119913775584.html)

Overall, it seemed everybody was pretty entertained by Rod's great presentation, and enthousiasted by the progresses Groovy made over a year of hard and passionate work. I'm impatiently looking forward to the day we'll release our first final release!

Groovy's more and more used in production settings, like Rod's BlueGlue, or Ludovic Dubost's [XWiki](http://www.xwiki.org/) which hosts a farm of over 3500 Groovy-powered wikis with well over 600,000 page views per month. And we've got some financial companies which already use or are planning to use Groovy to allow its business analysts to customize their apps' behavior and business logic.

JavaOne's day One was a Groovy Day, and we can forsee a bright future for Groovy! Mustang's betas incorporate the JSR-223 scripting APIs that Groovy totally supports, so they may even ship the next betas with Groovy if Sun wanted. A big name company (I can't name yet) should probably talk soon about how they leverage Groovy to control and administer clusters of application servers... And there's more to come, so stay tuned and [download Groovy](http://groovy.codehaus.org/Download) ASAP!
# Maven Developer's Notebook


I'm glad I just received my [Maven Developer's Notebook](http://mavenbook.xwiki.com/xwiki/bin/view/Main/Book), from O'Reilly. My friend [Vincent Massol](http://blogs.codehaus.org/people/vmassol/) and Tim O'Brien co-authored this great book on [Maven](http://maven.apache.org/), a definitely needed reading for all those who want to learn more about Maven, or who wants to get started quickly. I had the chance of being one of the reviewers and it allowed me to learn quite a few tricks in the process, at the same time I was converting one of my projects at work to a "mavenized" build process and integrating it inside [Luntbuild](http://www.pmease.com/luntbuild/) for continuous integration. I particularly liked the "best practices" aspects both authors managed to give throughout the different labs. This book is a must read, go and get it at your nearest bookstore!
# Groovy development: aiming for quality


A new [milestone of Groovy was released](http://docs.codehaus.org/display/GROOVY/2005/06/15) a few days ago. The general goal of this release was quality. 80-90% of our work was targeted at improving the user experience, as much as we could. One of the main complaints so far has always been regarding the ugly error reporting that Groovy was generating. Whether that be in the shell, or embededed, or when compiling your Groovy source code. It was pretty hard to figure out what the error was by looking at a meaningless message and hundreds of lines of exceptions.

So how did we improve that situation? Apart from cleaning the stacktraces both for compile-time or runtime errors, we've worked hard on two fronts:

*   Compile-time error reporting: a snippet of the offending code is shown, as well as a line and column number,
*   Compile-time checks: different checks are made to check variable definitions, or scoping rules.

Rather than an ugly stacktrace, the following output is an improvement, judge for yourself:

```
D:\groovy\samples>groovy errors.groovy
errors.groovy: 2: expecting anything but ''\n''; got it anyway @ line 2, column 13.
   println "foo
               ^

1 Error
```

Regarding the compile-time checks, we finally spent some time on implementing the checks we're used to have in the standard java toolchain:

Checks for classes and scripts:

*   check no variable is defined more than once

Checks for classes only:

*   check every variable is defined before usage
*   check that abstract methods are implemented when the class is not abstract
*   check that no final methods are overwritten
*   check that no final class is used as direct parent
*   check that no access from a static context to a dynamic declared variable is possible, example:
    
    ```
    class A { def var; def static m() { println var } }
    ```
    

That's a real pleasure to see the progresses made these last months in the maturation of Groovy. With just a bunch of passionate developers, we can really do great things. And the recent improvements should pave the way of a successful alternative language for the JVM.
# Lucene's fun


I played with Lucene today to index a CSV file representing the Unicode characters metadata. Lucene is so easy and fun to use, that's really the kind of libraries I like very much. I took some inspiration from my friend Jeremy who [played with Lucene and Groovy](http://javanicus.com/blog2/items/178-index.html) recently, by translating into Groovy some examples of [Lucene in Action](http://www.lucenebook.com/).

I've always been interested in i18n issues, charset/encoding malarkey, and so on. It's always a pain to deal with... but it's pretty damn interesting, and that's often a problem that native English speakers overlook.

In a previous article, you learned how to remove diacritical marks from strings (in particular [removing accents]({{< ref "/posts/2005/04/27/how-to-remove-accents-from-a-string" >}})), and I wanted to know how the JDK or IBM's ICU4J know how to decompose strings in their canonical form. Of course that's done through some data file containing that information. You can find [such a file](http://www.unicode.org/Public/UNIDATA/UnicodeData.txt) on the [Unicode website](http://www.unicode.org/). It contains information on each character regarding how to transform it to lowercase or uppercase, how to decompose it in its canonical form, or to learn its standard Unicode name.

I took this file, indexed its content and fields, and could easily use Lucene's search capabilities in no time to discover more about Unicode characters. As usual, here are some code snippets in Groovy!

So first of all, let's create an index out of that Unicode data file:

```groovy
import org.apache.lucene.analysis.standard.StandardAnalyzer
import org.apache.lucene.document.Document
import org.apache.lucene.document.Field
import org.apache.lucene.index.IndexWriter

def writer = new IndexWriter(new File("index"), new StandardAnalyzer(), true)

new File("UnicodeData.txt").eachLine { line ->
    def ucharFields = line.split(';', 15)
    if (ucharFields[0].length() == 4) {
        def doc = new Document()
        doc.add(Field.Keyword("code", ucharFields[0]))
        doc.add(Field.Text("name", ucharFields[1]))
        doc.add(Field.Keyword("category", ucharFields[2]))
        doc.add(Field.Keyword("clazz", ucharFields[3]))
        doc.add(Field.Keyword("bidi", ucharFields[4]))
        doc.add(Field.Keyword("decomposition", ucharFields[5]))
        doc.add(Field.Keyword("numeric", ucharFields[8]))
        doc.add(Field.Keyword("mirrored", ucharFields[9]))
        doc.add(Field.Keyword("uppercase", ucharFields[12]))
        doc.add(Field.Keyword("lowercase", ucharFields[13]))
        doc.add(Field.Keyword("titlecase", ucharFields[14]))
        writer.addDocument(doc)
    }
}
writer.optimize()
writer.close()
```

For each line of the document representing a character, I split it using ";" as the delimiter for the fields of the CSV. And I create a Lucene Document and adds some fields and content. You'll notice the different fields I'm interested in: like the name of the character, its uppercase or lowercase equivalent, etc. You can find [more information](http://www.unicode.org/Public/UNIDATA/UCD.html) about those fields in case you feel like learning more about that.

If you downloaded Lucene's jar and put both the jar and the UnicodeData.txt file in the same directory as your scripts, you can use the following command-line to create your index:

```bash
groovy -cp lucene-1.4.3.jar UIndexer.groovy
```

It will take some time, but it will create an index subdirectory containing Lucene's index.

Now that you have your index ready, you can query it with the following script:

```groovy
import org.apache.lucene.analysis.standard.StandardAnalyzer
import org.apache.lucene.queryParser.QueryParser
import org.apache.lucene.search.IndexSearcher
import org.apache.lucene.store.FSDirectory

def indexDir = new File("index")
def q = args[0]

def fsDir = FSDirectory.getDirectory(indexDir, false)
def is = new IndexSearcher(fsDir)

def queryParser = new QueryParser("name", new StandardAnalyzer())
def query = queryParser.parse(q)

def start = new Date().time
def hits = is.search(query)
def end = new Date().time

println "Found ${hits.length()} characters in ${end - start}ms:\n"

for ( i in 0 ..< hits.length() ) {
    def doc = hits.doc(i)
    println("${doc['code']} () -> ${doc['name']}")
    println("       category: ${doc['category']}")
    println("          class: ${doc['clazz']}")
    println("           bidi: ${doc['bidi']}")
    println("  decomposition: ${doc['decomposition']}")
    println("        numeric: ${doc['numeric']}")
    println("       mirrored: ${doc['mirrored']}")
    println("      uppercase: ${doc['uppercase']}")
    println("      lowercase: ${doc['lowercase']}")
    println("      titlecase: ${doc['titlecase']}")
    println("")
}
```

It opens the index, and takes a query as its first command-line argument. It parses the query, and searches the index, and in the end, it will return some useful results.

For instance, you can make some queries to know which characters contain the word cedilla in their name:

```bash
groovy -cp lucene-1.4.3.jar USearcher.groovy cedilla
```

And you can also search particular fields:

```bash
groovy -cp lucene-1.4.3.jar USearcher.groovy "category:Lu"
```

Those queries will print all the corresponding Unicode characters you're looking for.

As you can see through those two samples, creating the index, or searching the index is really simple and straightforward. Lucene does it jobs fairly well, and I just love it for that.
# Maven scripting in Groovy


Recently, on Maven's user list, someone wanted to be able to script Maven with Groovy, like it was already possible with BeanShell or Jython thanks to specific Jelly tags. But unfortunately, Maven didn't provide that kind of support for Groovy.

But there are good news on that front since [Jeremy Rayner](http://javanicus.com/blog2/) contributed a nice [Groovy Ant task](http://groovy.codehaus.org/Groovy+Ant+Task).

That Ant task will be available in the upcoming Groovy release (jsr-02), so if you want to play with Maven and Groovy, you'll have to build Groovy from sources in the meantime. But I'm going to reveal how to script Maven with Groovy in advance.

In your **maven.xml**, you can access Maven's POM:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project default="groovy" xmlns:ant="jelly:ant">
 <goal name="groovy">
   <ant:taskdef name="groovy" classname="org.codehaus.groovy.ant.Groovy" classpathref="maven.dependency.classpath"/>
   <ant:groovy>
       println pom.eachPropertyName{ println it }
       println pom.name
   </ant:groovy>
 </goal>
</project>
```

Don't forget to add Groovy in your dependencies:

```xml
   <dependency>
     <groupId>groovy</groupId>
     <artifactId>groovy-all</artifactId>
     <version>1.0-jsr-02-SNAPSHOT</version>
     <properties>
       <classloader>root</classloader>
     </properties>
   </dependency>
```

Currently, only the POM is added in the script context, but other variables or properties may be added, but you can already access almost everything from Maven's project. Don't hesitate to ping me if you've got some specific requests.
# How to remove accents from a String


My little puzzle of the day is to find how to remove accents from a String. There are different alternatives, different strategies, but none really suits my needs -- or my taste.

The naive approach is to use `String.replace()` to replace manually all characters, with a correspondance table, like "é" should be replaced with "e", etc. That's fine for some languages I know, like French or German, or even some latin languages, since we share the same alphabet. But with Russian, Greek, or some asian languages, my knowledge won't suffice! So I can't reliably produce a big hashtable with that knowledge. What a pity!

The other two approaches are using a `Normalizer` class which decomposes a string in its smallest constituents. Thus, a character with an accent is composed of a non-accentuated character and a diacritical mark. Then, once I have this expanded string, I can easily remove all characters representing a diacritical mark, because they all belong to a certain Unicode category.

Sun's JDK contains a non-public class called sun.text.Normalizer (which should be added to the JDK's public APIs), and [IBM's ICU](http://icu.sourceforge.net/) (International Components for Unicode) package also contains such a class. The following function will return a string without accents or other marks:

```java
public String removeAccents(String text) {
    return Normalizer.decompose(text, false, 0)
                     .replaceAll("\p{InCombiningDiacriticalMarks}+", "");
}
```

Using Sun's internal class is not a very portable solution, but using IBM's 3MB-gorilla JAR may be overkill for just removing accents. But after all, what are 3 megabytes when your machines have gigas of RAM and disk space? Would it slow your apps down? Probably not.

Does somebody know of another way to remove accents from a String?

**Update (2011/07/28):** Sun's JDK 6 now includes a Normalizer class. So for example, if you want to transform the accentuated letters to their non-accentuated form, you can do this:

```java
Normalizer.normalize(title, Normalizer.Form.NFD)
          .replaceAll("\p{InCombiningDiacriticalMarks}+", "")
```

Update (2012/03/14): George suggests in the comments a better category: \\\\p{IsM} which covers more combining marks than just accents.
# Maven tip: using Ant's optional FTP task


[Maven](http://maven.apache.org/) is a pretty powerful tool, but sometimes, simple things can get complicated... I had to customize my build to upload some files through FTP. But it wasn't just a mere artifact to upload through FTP to the enterprise repository, so I couldn't use Maven's artifact plugin and its FTP method. So the solution was to use Ant's optional FTP task.

At first, it doesn't seem very complicated, since Maven can basically use any Ant task very easily, but the fact is that this optional Ant task is dependent on another library that you have to add to Maven's root classloader, otherwise you'll get a NoClassDefFound! And moreover, I couldn't even find NetComponents on ibiblio!

To save you that pain, please read the instructions below. It is inspired from [a solution](http://java2.5341.com/msg/101580.html) I've found by googling, but the problem is that it is not the cleanest solution, since you have to hack Maven to add the library in the root classpath, and modify Maven's own private configuration. That's not very portable! My friend [Vincent Massol](http://blogs.codehaus.org/people/vmassol), author of [JUnit in Action](http://tinyurl.com/7hprk) and of the upcoming [Maven Developer's Notebook](http://blogs.codehaus.org/people/vmassol/archives/001003_maven_book_and_maven_quiz.html), helped me improve upon that solution to make it portable across different build environments, without requiring to modify Maven's own configuration.

Here are the instructions:

*   Download NetComponents from: [http://www.savarese.org/oro/downloads/NetComponents-1.3.8.tar.gz](http://www.savarese.org/oro/downloads/NetComponents-1.3.8.tar.gz)
*   Uncompress the archive, take the NetComponent.jar and put it in a new directory:
    `${user.home}/.maven/repository/net-components`
*   Rename the jar to `NetComponents-1.3.8a.jar`
*   Add the dependency in your `project.xml`:

    ```xml
        <dependency>
          <groupid>net-components</groupid>
          <artifactid>NetComponents</artifactid>
          <version>1.3.8a</version>
          <b><properties>
            <classloader>root</classloader>
          </properties>
        </dependency>
    ```

    The `root` is there to tell Maven to load that dependency with its root classloader, so that it is available to Maven's Ant which is loaded by that root classloader.

*   Now, you can add a goal in your `maven.xml` file to call the FTP task, and don't forget to create a task definition:

    ```xml
    <!--?xml version="1.0" encoding="UTF-8"?-->
    <project default="java:compile" xmlns:ant="jelly:ant">

      <goal name="ftp">
        <taskdef name="ftp" classname="org.apache.tools.ant.taskdefs.optional.net.FTP"></taskdef>
        <ant:ftp server="yourserver.domain.com" userid="foo" password="bar" action="list" listing="list.txt">
          <fileset>
            <include name="*.html"></include>
          </fileset>
        </ant:ftp>
      </goal>

    </project>
    ```


For the purpose of this example, the above goal lists the `*.html` files in your remote home folder. It will create a `list.txt` file containing the result of that listing. But of course, all FTP operations are available to you.

Now just type `maven ftp` and you're done! Was it that hard? Well, once you've read that, it isn't, but still...

I hope it'll save you some precious minutes, if not hours if you're not a Maven guru.

For further information, here are some pointers:

*   [Original solution](http://java2.5341.com/msg/101580.html)
*   [Ant's optional FTP task](http://ant.apache.org/manual/OptionalTasks/ftp.html)
*   [NetComponents distribution](http://www.savarese.org/oro/downloads/NetComponents-1.3.8.tar.gz)
# Finding styled paragraphs in a Word document


When working with Word documents, you'd often like to be able to extract relevant content automatically thanks to some scripts. That's exactly what I wanted to do this afternoon. I have a Word document which contains some scripts written with a specific style, and I wanted to extract those snippets, so that I may be able to check that they compile or that the unit tests they represent be asserted successfully.

As usual, you need to choose the right tool for the job. And for me, the right tool was my lovely [Scriptom](http://groovy.codehaus.org/COM+Scripting) module for [Groovy](http://groovy.codehaus.org/). Scriptom allows you to fill in the gap between Groovy scripts and your native ActiveX/COM components (on Windows obvioulsy).

I've found an [interesting article](http://msmvps.com/jonathangreensted/archive/2004/12/07/22717.aspx) explaining how one can do to find Word styles efficiently. The code was in C#, so the small burden was to convert C# code into Groovy, but that wasn't very complicated. I also put together all adjacent styled text so that I may build entire scripts (and not one line each time). And I was done!

The little program takes two arguments: the file name, and the style you wish to find in that document. You use simple and double quotes to surround the style name. I've regrouped together all contiguous styles together. And what else... well, the other comments are in the source code! So let's see what the code looks like!

```groovy
import org.codehaus.groovy.scriptom.ActiveXProxy

def style = ""
def fileName = ""

if (args.length != 2) {
    println "Usage: groovy extractStyle yourFile.doc yourStyle"
    System.exit(1)
} else {
    fileName = args[0]
    style = removeQuotes(args[1])
}

// creating the Word application
def word = new ActiveXProxy("Word.Application")
try {
    // opening your document
    word.Documents.Open(new File(fileName).canonicalPath)

    // getting the content of the document
    def doc = word.ActiveDocument
    def range = doc.Content
    // prepare the search of styled text
    range.Find.ClearFormatting()
    range.Find.Style = style

    def start, end = 0
    def text = ""
    def found = true
    // while there is styled text to find...
    while (found) {
        // execute the find command

        found = range.Find.Execute().value
        start = range.Start.value
        if (end != start && end != 0) {
            // seperate found occurencies with a separator
            println("=" * 72)
            println text
            text = ""
        }
        // get the text content of the styled text found
        // without the last newline
        text += removeNewLine(range.Text.value) + "\n"
        end = range.End.value
    }
} finally {
    // quitting the Word application
    // without saving the changes (wdDoNotSaveChanges = 0)
    word.Quit(0)
}

/** Remove potential simple or double quotes around the name of the style to find */
String removeQuotes(String s) {
    if (s.startsWith(/'/) && s.endsWith(/'/) || s.startsWith(/"/) && s.endsWith(/"/))
        return s.substring(1, s.length() - 1)
    else
        return s
}

/** Remove the last new line character which doesn't render well under DOS */
String removeNewLine(String s) {
    switch (s.length()) {
        case 0: return ""
        case 1: return ""
        default: return s.substring(0, s.length() - 1)
    }
}
```
# Castor tip: generating Java classes for XSD simple types


At work, I'm using [Castor](http://castor.codehaus.org/) XML to Java binding to marshall/unmarshall messages in my Web Services, inside a custom framework (Struts, OJB, JAXM, etc). I have defined my messages as XSD Schemas, and I'm using [Castor's Maven plugin](http://maven.apache.org/reference/plugins/castor/) to auto-generate my Java classes at build time.

All is good and well... Hmm, almost! Castor's SourceGenerator generates Java classes for complex types and elements, but not for simple types, and unfortunately, I badly needed to marshall those simple types as well. But fortunately, I've found a little trick to transform simple types to complex types, so that Castor can generate the associated Java classes, with its useful and handy marshall() methods.

Let's take a little example. Say you have a simple type which is just a restriction upon strings:

```xml
<xs:simpletype name="ApplicationType">
  <xs:restriction base="xs:string">
    <xs:minlength value="1"></xs:minlength>
    <xs:maxlength value="32"></xs:maxlength>
  </xs:restriction>
</xs:simpletype>
```

This type won't give you a Java class, thus you'll have to transform it into a complex type, and here is how you can do that:

```xml
<xs:simpletype name="String32">
  <xs:restriction base="xs:string">
    <xs:minlength value="1"></xs:minlength>
    <xs:maxlength value="32"></xs:maxlength>
  </xs:restriction>
</xs:simpletype>

<xs:complextype name="ApplicationType">
  <xs:simplecontent>
    <xs:extension base="ths:String32"></xs:extension>
  </xs:simplecontent>
</xs:complextype>
```

Though I'm happy with that trick, I've however filed a [JIRA issue](http://jira.codehaus.org/browse/CASTOR-1079) in Castor's bugtracker, so that they can add a new option to allow us to generate Java classes for simple types too.
# RIFE rocks the pants off of Rails


Rails is kinda cool. Any framework that ease the development of CRUD-oriented webapps is a real time saver. There's been a lot of well-deserved hype around Ruby on Rails lately. But I'm not sure that's really that revolutionary. I've always thought that a good Java Web framework can do the same. Perhaps with a few more lines of code, since we all know that Java tends to be more verbose than some scripting languages. But overall, does it really matter? Especially since you tend to be much more productive in Java with a top-notch IDE like [IntelliJ](http://www.jetbrains.com/)!

One of the nice little apps written with Rails is [Tada list](http://www.tadalist.com/): well, basically, that's, er... a ToDo list. That's hard to find a more verbose definition! To show that one can do the same things in Java, with a nice framework, [Geert Bevin](http://rifers.org/blogs/gbevin/) created a better clone of Tada: [Blabla List](http://blablalist.com/)!

Geert found some severe security issues with Tada, and with just 50% lines of code more than the Rail's equivalent, he nonetheless implemented the same features, but he also fixed the security problems of Tada, and even added a [REST API](http://rifers.org/wiki/display/BLA/REST+API), reorderable lists and drag'n drop support!

How did he do that in Java? He used [Laszlo](http://openlaszlo.org/) for the cute flash user interface, and the wonderful [RIFE](https://rife.dev.java.net/) framework which really rocks the pants off of Rails. Conclusion: A good Java MVC framework can do at least as good as Rails, if not better.

So now, you know what you have to do? Just [sign up for free](http://blablalist.com/) and start keeping track of your todos online!
# Re: How Groovy can get her groove back


I think [Angsuman](http://blog.taragana.com/index.php?p=146) diserve an answer.

> It looks like Groovy is in dire needs of a project manager.

We've got one already. Of course, he's been pretty busy with his [Active\*](http://protique.com/) projects lately, but I think now he's really back on the project. It's often hard to cope with both a demanding job, and a demanding Open Source project. It's tough to find time for both. Fortunately, he's not alone on the Groovy project. While he was too busy, I took the interim and maintained Groovy and managed to deliver a few successful betas with a lot of bug fixes. But that's just the tip of the iceberg. In November, with Jeremy, we organized a JSR meeting, and I've recruited a few new commiters to help us solidify our groovy-core base, so that it is able to receive the upcoming new parser. And the JSR work and discussions never stopped.

> One of the basic things we all learned along the way is that software is not about perfection. It is about delivering a good enough rock solid product on time. There is always version 2 to add more features. Nobody expects version 1 to be the ultimate solution.

Often people mix OSS projects and IT projects. I don't think they are the same. The constraints aren't the same. For IT projects, you pay for something, so you oughta get back something you paid for in a reasonable timeframe, but in OSS-land, when the developers are just working in their spare time, besides their day job, how can you be so demanding? So far, I've spent both time and money in Groovy, and I don't have anything back! Except, of course, the pleasure to have a few delighted users thank me for our awesome project.

What we want in Groovy 1.0 is to solidify the basic core features of Groovy, which have been there early in the project life. And contrary to what most persons think, we haven't added any significant new feature in the language for more than 6 months! We're finally standardizing the meaning of language constructs we never really took the time to implement correctly and propertly in a coherent manner (like the semantics of continue/break/return inside a closure).

The scope of the project is the same as it was several months ago. In our implementation there's just room for extensibility. Like supporting Java 5 annotations with the help of the Java 5 grammar we've based the new parser upon, or adding a new operator (.@) to help us diminsh the level of ambiguity in the scoping rules.

> In today world people have come to expect stable beta (remember JDOM betas?), unlike what James comments in Spille blog. If the build is to be highly unstable then it should probably be in alpha stages. Beta stages are all about refinement and limiting feature set to get a release.

We made mistakes in our numbering scheme, that's granted. We should have started with 0.1, 0.2, 0.x, then get to a 1.0-beta-x, and finally perhaps some 1.0-RC-x, before delivering groovy-final-1.0. We're trying to fix that by changing slightly our tags: there will be a new beta soon (beta-10 within two weeks), and the few next milestones will be tagged jsr-x and will include the new parser. And after that, we should probably release Groovy 1.0 before the end of Q2. I won't give you a firm and definitive target date, it's simply impossible, because we're not an IT project, and we can't know what could happen to any of us (a new demanding job, a baby, whatever...)

In IT-land, there are four variable you can play with: scope, cost, time and quality:

*   The scope hasn't changed for months, and we want to keep the features which had already been there since day one, otherwise, why use Groovy if Groovy has just got the same features as BeanShell or Jython?
*   The cost is just our spare time and limited number of developers, and we can't really tweak that variable, since it depends a lot on our day jobs, family, and personal constraints, (even though we recruited a few new commiters who help us solidify the base)
*   The quality mustn't be compromised,
*   The time variable is the only one we can play with to improve the quality.

> Even Open Source projects are not immune to this paradigm, specially for a project which have garnered so much interest.

We've garnered a lot of interest. An incredible amount. And I'm glad about that. I hope we won't dissapoint anyone, or at least that just a few will be upset by our decisions. I wonder whether other OSS projects have had that much pressure on developers' shoulders. Could you name even one? Expectations are very high regarding Groovy.

> I think the theme which comes out of these discussions is that Groovy project leads needs to fix a reasonable date of release 1 and stick to it making compromises along the way. And it needs help.

We're going to deliver Groovy with the original scope James envisionned. Not much more, not much less. We're focusing on the core functionnalities. We've already wired the new parser in CVS Head within just a few days of work, and the progress was amazingly quick to show up. We're going to ship it perhaps in the next beta (beta-10) if we delay the beta for one or two weeks, or we'll ship it at the end of February. We need to settle on the best date for a first warm-up of the parser.

We've also started sketching our [roadmap](http://groovy.codehaus.org/Roadmap) more accurately to offer more visibility to our beloved users and community.

> Guillaume commented on the pressure on the Groovy’s developers. That is true. However for an Open Source project which has garnered so much interest, press and enthusiasm all around it is to be expected. That the price for fame :)

Oh really, am I becoming famous? :-) Ah, no... only the project! Well, I've never worked on Groovy to become famous anyway. I wanted the right tool for the job. I got involved into Groovy because I needed a scripting language for the JVM, to allow us to write some dynamic logic, business rules, modifyable at runtime, without the hassle of re-deploying software everytime, just because some business logic changed in the course of time. Groovy's going to bring agility in your projects, and will be a real time saver for your shell scripting needs, wiring platform specific capabilities (like with [Scriptom](http://groovy.codehaus.org/COM+Scripting)) and the vast wealth of available java components and libraries.

Groovy is the right tool for agility business.
# Groovy's dead, long live Groovy!


Incredible, I've just learnt that [Groovy was dead](http://www.pyrasun.com/mike/mt/archives/2005/01/28/19.10.21/index.html), according to Mike! So I understand that's why Cédric would like to know the [final date for the burial](http://beust.com/weblog/archives/000235.html).

It's interesting to see how much pressure the [Groovy](http://groovy.codehaus.org/) project has on its little shoulders. So far, to my knowledge, I don't really see any other OSS project for which the users and the blogosphere had so many expectations. Well, back in time, 6 months ago, yeah, we could've said Groovy was somewhat a zombie, but I don't think that's true anymore, with the latest months activity. We're certainly not good at public relations these days, we've got some efforts to make on that front.

With the team, we've discussed a roadmap for the next few months, but really, it's hard to give a definitive date. We're going to release beta-10 within two weeks, then, a month later, we'll be able to play with jsr-1 (formerly known as beta-11) which will use the new parser if you activate the right flag. Then the next jsr-x versions will use only that new parser by default. I think June could be a plausible target date for Groovy 1.0 final. We'll see if that's possible with our limited resources. I think we should publish a Roadmap page on our website, so that our users know what to expect from us.

John Rose wrote an initial grammar with Antlr as a diff with a Java 1.3 grammar, and [Jeremy Rayner](http://javanicus.com/blog2/) ported it to a Java 1.5 grammar. Last week, [James Strachan](http://radio.weblogs.com/0112098/) worked on wiring this new grammar and parser into the Groovy runtime, and the progress was pretty fast. And with confidence, I can already tell you that within a month and a half, you'll be able to play with the "New Groovy". Currently, there are still a few rough edges of course, and there's still heaps of work to do, especially on the builders, on fixing the semantics of the method invocation and the scoping rules, on implementing the closures' logic coherently, but that's doable.

So really, is Groovy dead? I don't think so.
# Groovy code-completion in IntelliJ


JetBrains improved the custom file type support in IntelliJ, in the Irida EAPs. If you have defined your Groovy syntax file correctly, you can have syntax highlighting, brace highlighting, and even... code-completion!

In my [Groovy syntax file](http://glaforge.free.fr/groovy/Groovy.xml) (which works in [Irida #3185](http://www.intellij.net/eap/products/idea/download.jsp)), I defined two sets of keywords: one for the keywords of the language, and the other one for the [Groovy methods](http://groovy.codehaus.org/groovy-jdk.html), like each(), findAll(), etc. And guess what? Simply hit CTRL-Space as usual, and presto, you can complete your code.

Here is a little picture of what it looks like:

![](/img/misc/groovyIntelliJ.jpg)

The completion works only for keywords and the [Groovy methods](http://groovy.codehaus.org/groovy-jdk.html), but until someone develops a Groovy plugin for IntelliJ IDEA, this basic completion rocks!
# Auto-completion in a DOS console


When I'm on an old PC, what frustrates me a lot is when I can't auto-complete file names or paths when I'm in a DOS Console. If your computer (an old Win2K box like I have at work) is not configured for completion, it's easy to re-enable it by modifying two keys in the registry:

*   `HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Command Processor\CompletionChar`
*   `HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Command Processor\PathCompletionChar`

To both keys, assign an hexadecimal value representing the key used for completing statements. I'm quite used to the tab key for that purpose, so I set the hexadecimal value to 0x09.  

Of course, I couldn't resist to use [Groovy](http://groovy.codehaus.org/) and [Scriptom](http://glaforge.free.fr/weblog/groovy.codehaus.org/COM+Scripting) (Windows ActiveX/COM bridge for Groovy I developed recently) to automate the process, here is how:

```groovy
import org.codehaus.groovy.scriptom.ActiveXProxy

wshell = new ActiveXProxy("WScript.Shell")
wshell.RegWrite("HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Command Processor\\CompletionChar", 9, "REG_DWORD")
wshell.RegWrite("HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Command Processor\\PathCompletionChar", 9, "REG_DWORD")
```
# Converting a Word document to HTML


If you're under Windows, and that you need to do some shell scripting with ActiveX/COM components, Scriptom will certainly help you. Today, my boss just asked me if we could use [Scriptom](http://groovy.codehaus.org/COM%20Scripting) to convert a Word document into an HTML equivalent. And I decided to see if that was possible. To my delight, my little Scriptom module, backed by [Jacob](http://danadler.com/jacob/), helped me solve this integration problem with only 6 lines of Groovy code!

```groovy
import org.codehaus.groovy.scriptom.ActiveXProxy
import java.io.File

word = new ActiveXProxy("Word.Application")
word.Documents.Open(new File(args[0]).canonicalPath)
word.ActiveDocument.SaveAs(new File(args[1]).canonicalPath, 8)
word.Quit()
```

Now, I just need to launch:

```bash
groovy word2html.groovy specification.doc specification.html
```

And I've got a nice Word to HTML converter! Well... I know, not that nice. First of all, it's a Windows-only solution, but that fits my requirements regarding the platform I'm running on, but the other negative aspect is that the generated HTML is really, really ugly. I really wonder why Microsoft can't do a cleaner output. For the moment, I'm happy with that solution.

You probably noticed the magic number 8. It's the HTML format option. The available formats are:

*   0: `wdFormatDocument` (no conversion)
*   1: `wdFormatTemplate`
*   2: `wdFormatText`
*   3: `wdFormatTextLineBreaks`
*   4: `wdFormatDOSText`
*   5: `wdFormatDOSTextLineBreaks`
*   6: `wdFormatRTF`
*   7: `wdFormatUnicodeText`
*   8: `wdFormatHTML`

I haven't yet figured out how to be able to use constants directly in Groovy. I'll have to make Scriptom grok M$'s constants.

The example I've talked about has been tested with groovy-beta-9, Word 2000 and my additional Scriptom module for Groovy (don't forget to [install](http://groovy.codehaus.org/COM%20Scripting) it if you want to try that sample).
# Noeuds de cravate


Qui dit nouveau boulot, dit être bien habillé. Il faut être classe et élégant. Evidemment, il n'y a pas que le premier jour qu'il faut l'être ! Mais c'est l'occasion de réviser ses classiques, et je pense particulièrement au noeud de cravate.

J'ai une ribambelle de cravates dont les noeuds sont déjà faits. Je n'ai pas besoin de les refaire. Sauf si vraiment je ne suis pas satisfait du résultat. Mais en l'occurence, pour un nouveau costume, avec une nouvelle chemise, j'ai aussi opté pour une nouvelle cravate.

Les [noeuds de cravate](http://membres.lycos.fr/vernaye/cravates/noeuds.html) ne sont généralement pas très compliqués à faire. Tout du moins, le grand classique du genre : le [noeud simple](http://membres.lycos.fr/vernaye/cravates/simple.html) (aussi appelé four-in-hand à l'anglaise) est par définition simple à réaliser.

Le noeud simple est le plus couramment utilisé. Il est facile à mémoriser. Il convient bien à tout type de cravate : fine ou épaisse. Par contre, son principal défaut est qu'il semble toujours être légèrement de travers. L'effet est peut-être moins flagrant lorsque la cravate est très serrée ou si elle est suffisamment large. Mais généralement, on préfèrera des noeuds plus complexes qui ont une meilleure tenue et sont bien droits. Malheureusement, les noeuds plus compliqués conviennent moins bien aux cravates courtes et épaisses, et surtout, ils sont plus difficiles à mémoriser.

Les [noeuds les plus courants](http://www.jules.fr/guide/noeuds.asp) sont :

*   le noeud simple,
*   le [noeud double](http://membres.lycos.fr/vernaye/cravates/p_albert.html)(dérivé du noeud simple),
*   le [Windsor](http://membres.lycos.fr/vernaye/cravates/windsor.html), et
*   le [demi-Windsor](http://membres.lycos.fr/vernaye/cravates/d_windsor.html).

Le noeud double (aussi appelé double-simple ou Prince Albert) est un sans doute un peu moins oblique que son petit frère, le noeud simple, et il se prête bien aux cravates suffisamment longues et pas trop épaisses.

Les noeuds de la famille des Windsor sont eux plus stables et non pas ce léger effet de travers qu'ont les noeuds simples. Par contre, comme tout noeud plus complexe, je trouve qu'il va mieux aux cravates fines, et cela permet de donner beaucoup plus d'ampleur et de volume au noeud. Un petit effet classe non-négligeable.

Mais il n'y a pas que les noeuds simples et les Windsor, il y en a bien d'autres ! Je ne parlerai pas du [noeud papillon](http://membres.lycos.fr/vernaye/cravates/bow.html), mais je voudrais vous en lister quelques autres :

*   le [Plattsburgh](http://membres.lycos.fr/vernaye/cravates/plattsburgh.html) (Dovorian),
*   le [Balthus](http://membres.lycos.fr/vernaye/cravates/balthus.html) (dérivé du Plattsburgh),
*   le Cavendish,
*   le [Grandchester](http://membres.lycos.fr/vernaye/cravates/grantchester.html),
*   le [Hanovre](http://membres.lycos.fr/vernaye/cravates/hanovre.html),
*   l'Oriental,
*   le [Kelvin](http://membres.lycos.fr/vernaye/cravates/kelvin.html) (dérivé de l'Oriental),
*   le [Nicky](http://membres.lycos.fr/vernaye/cravates/nicky.html),
*   l'Onassis,
*   le petit noeud,
*   le Pratt,
*   le Saint-Andrews,
*   le Victoria.

Ce sont des noeuds standards, par opposition au noeufs fantaisistes qui ne risqueraient pas de passer inaperçu :

*   l'[Ascot](http://membres.lycos.fr/vernaye/cravates/ascot.html),
*   le [croisé](http://membres.lycos.fr/vernaye/cravates/croise.html) (Christensen ou Prince Hugues).

Tout ce que je viens de vous raconter est expliqué en détail sur cet [excellent site](http://membres.lycos.fr/vernaye/cravates/noeuds.html) avec des schémas pour pouvoir reproduire chacun de ces noeuds. A mettre dans ses favoris.
# A bit of Groovy history...


First of all, I wish a Happy New Year to all my readers! The first days of a new year are often days of recollection, where we look back at the previous year. What happened? Was it a good year? Did we succeed in our endeavours? Any downside or missed target? Etc...

Today, I want to give you some insight in the Groovy history, as it was written last year, in 2004. It's been a pretty busy year, in fact. Till the JSR got started, we were working like mad on Groovy, adding feature after feature, certainly not taking care enough of bugs, but still, that was a good time. Then came the JSR process, which somehow stopped all our efforts, because of uncertainty, and other considerations, like fear of not doing well with regards to that JSR process. Unfortunately, Groovy's development almost stopped. Some of the core developers even left, because of the inactivity, and frustration of not being allowed to change things, or because of the lack of management in the project since our leader started working on other projects, taking all of his time.

But around october, I was really fed up with that state of things. I really wanted things to change! Groovy was somehow dying, if no action were taken. That's why I started a big effort on making the Groovy ship move again. With my friend, [Jeremy Rayner](http://javanicus.com/blog2/), we managed to wake up everybody, to organize a JSR meeting in November, and I spent a huge amount of time fixing bugs in the current implementation to make a [beta-8 release](http://article.gmane.org/gmane.comp.lang.groovy.devel/2091) and to help our users as much as I could on the forums. I "hired" also some new developers who helped me in the process. Thanks a lot to them all (Russel Winder, Jochen Theodorou, Dierk Koenig, and Scott Stirling). The JSR is also progressing thanks to the efforts of Jeremy Rayner, and John Rose with his first cut at the new Groovy grammar. For this new year, Jeremy gave us a pretty good summary and [overview of the work in the JSR process](http://article.gmane.org/gmane.comp.lang.groovy.devel/2159).

We've been [biled](http://www.jroller.com/page/fate/?anchor=the_groovy_sinking_ship), we're certainly going to receive some other similar criticism. Hani's got pretty good points, and we're trying to address those concerns and the concerns of our users as much as we can. I hope Groovy will mature even more in 2005, and I think we should have a fairly good and standardized implementation.

The primary reason for that blog entry was to guide you through the history behing the JSR process. That's Richard Manson-Haefeld who's mostly responsible for that, and he just blogged about it. He guides us through the [history of the Groovy JSR](http://rmh.blogs.com/weblog/2005/01/groovy_a_bit_of.html).

2005 should be a Groovy year! So, Groovy new year to everybody!
# Scripting ActiveX/COM components with Groovy


During my three weeks break before my next job, I decided I'd work on two things: first, I'll play with Groovy a little more (playing != fixing bugs like mad like those last two months to get beta-8 out in the wild), and I'll work on my "Learning Groovy" book for O'Reilly.

In this blog post, I'll talk about my last two days playing with Groovy and... [Jacob](http://danadler.com/jacob/), a Java COM Bridge library developed by [Dan Adler](http://danadler.com/), to interact with Windows components. So, of course, it's Windows-only.

I created [Scriptom](http://groovy.codehaus.org/COM+Scripting): a new module (optional Groovy component) that allows you to script any COM or ActiveX component with Groovy. That is you can control applications like Internet Explorer or Excel with groovy scripts.

Groovy's metaprogramming facilities make it a language of choice for doing some funny stuff like writing transparent proxies, mock objects, or other wacky stuff, like our builders (Ant builder, Swing builder, or Markup builder). You can intercept calls to non-existant methods and make them do something for you, like creating a new tag, or an Ant task, etc.

Being able to write some meta-object was the key to this problem of interoperability between Groovy and COM components. I wrote a pair of classes implementing [GroovyObjectSupport](http://cvs.codehaus.org/viewrep/~raw,r=1.3/groovy/groovy/groovy-core/src/main/groovy/lang/GroovyObjectSupport.java), to make a kind of proxy around some of the Jacob internals. So any call to a method or property of my proxy would delegate the call to the foreign component. But let's stop chatting about the inner workings, and let's see some examples of what we can do!

First of all, if you wanna play with Scriptom, the best thing is to go [read the documentation](http://groovy.codehaus.org/COM+Scripting)! Everything is explained: how to get it, how to install it, and some samples are there as well for good measure. Scriptom's been tested on groovy-1.0-beta-8 and Windows XP Home Edition.

As everything is explained in the documentation, I won't show you all the examples, but let's just look at the one for scripting Internet Explorer:

```groovy
import org.codehaus.groovy.scriptom.ActiveXProxy

// instanciate Internet Explorer
def explorer = new ActiveXProxy("InternetExplorer.Application")
// set its properties
explorer.Visible = true
explorer.AddressBar = true

// navigate to a site by calling the Navigate() method
explorer.Navigate("http://glaforge.free.fr/weblog")
```

You're using Internet Explorer as if it were a standard Java or Groovy object! Pretty neat, uh?

There are several other examples in the documentation and in the sources. If ever an application provides some ActiveX or COM components, you can script it with Groovy. For instance, you could suck up some data from a database with Groovy SQL, and write an Excel spreadsheet with formulas to manipulate the data. Or you can script Media Player to make it play all the sounds in a given directory that you'd have chosen with a native Windows folder chooser, etc. Many possibilities that all the VBScript gurus and Windows Scripting Host admins will like. Moreover, you can interact with Java and Groovy. So you have the best of both worlds: the JVM world and its wealth of libraries, and the native Windows world.

I've chosen Jacob over JCom because it seems to be able to allow us to wire our own event handlers, which is not possible with JCom, as far as I know. So my next step will be to provide some funky way of writing our own event handlers in Groovy, probably with some closures... Stay tuned!

That's fun, and I hope you'll enjoy playing with Scriptom! That's my late Christmas gift to you!
# Groovy support in IntelliJ


Kjetil JD submitted a [feature request](http://www.intellij.net/tracker/idea/viewSCR?publicId=40320) on JetBrains' tracker for adding Groovy support to IntelliJ:

> **Integrated Groovy-support**  
> Integrated support for Java bytecode-based scripting languages should be better integrated in IntelliJ. Groovy is the only Java bytecode scripting language that has a backing JSR and should be the first to be implemented with proper support like Java and XML has.

For the moment, the Groovy IntelliJ plugin is somewhat stalled, we didn't make any progress on that front, so a little help from our JetBrains friends would be most welcome.

So far, at the time of this writing, it's interesting to note that the feature request received 937 votes, and is already ranked at the 12th position of the most voted features! Thus, if you're interested in seeing Groovy support in your [favourite IDE](http://www.jetbrains.com/idea), please cast your votes on that [feature request](http://www.intellij.net/tracker/idea/viewSCR?publicId=40320)!
# Groovy Conference 1


So far, I didn't blog about our first ever Groovy Conference we held on November 11th and November 12th. But at least, here are some pictures taken there. I've created a [Flickr](http://www.flickr.com/) account and put [my pictures](http://www.flickr.com/photos/72768689@N00/tags/groovy/) son it.

Jeremy Rayner [blogged](http://web1.2020media.com/j/jez/javanicuscom/blog2/items/165-index.html) about the conference, and also took [some pictures](http://www.flickr.com/photos/jez/tags/groovy/), and wrote down a [few notes](http://javanicus.com/blog2/items/166-index.html) about the conference.
# IntelliJ, as a team communication tool


Everyday, when you work with your team mates, you exchange information through different communication channels. If you work in the same offices, you can simply speak and make stand-up meetings. If you work with different teams spread across different places, different buildings, or even different countries--especially true for Open Source projects--you can pick up your ([Skype](http://www.skype.com/)) phone, and write emails, or chat through instant messenging or IRC.

But sometimes, it feels a bit frustrating to use those archaic mediums. When you wish to share some code snippets, to study a stacktrace another developer got, to know on which files other developers are working on, the usual communication means feel less handy, less intuitive to use. So what could we do to improve that?

I've been thinking about that topic for a few years already, but so far, I've never found anything to my taste, and I somehow thought nobody had the same vision as I have. I believe we can do something to enhance our development tools to leverage the communication means we use everyday, but in a suboptimal way. Here comes [Kirill Maximov](http://www.maxkir.com/kirblog/), a [JetBrains](http://www.jetbrains.com/idea) developer, working in the [Fabrique ](http://www.jetbrains.com/fabrique)team. Kirill is starting the development of a cross-IDE plugin: a communication tool integrated within your IDE. He blogged about it on his weblog: he discusses the [ideas](http://www.maxkir.com/kirblog/2004/11/developers-communications-tool.html) we brainstormed together, and provides us with a[roadmap](http://www.maxkir.com/kirblog/2004/11/features-outline.html).

For the begining, the plugin should work on IntelliJ IDEA only, but it may be ported to other IDEs in the long term. And it will provide some basic features, such as:

*   IDEA as a primary platform
*   using P2P transports (IP-multicast as a first channel)
*   finding your online team mates
*   showing the presence status
*   managing user rosters
*   exchanging text messages (standard IM feature)
*   exchanging Java stacktraces
*   viewing files currently edited by other colleagues

In the following releases, some more high-level functionalities could be implemented:

*   porting to other IDEs (Eclipse, JBuilder or NetBeans)
*   using other transport layers (Jabber, P2P)
*   viewing idle time
*   broadcasting messages to all team members or sub-teams
*   chating with multiple colleagues
*   exchanging code snippets
*   code navigation (click on the stacktrace and jump in your code!)
*   sending unit tests
*   pair programming (the extremos will like that!)
*   diffing local and remote files
*   subscribing to events (when a colleague starts editing the file you're working on)
*   etc.

I'm looking forward to play with your plugin, Kiril! I wish you good luck, and I hope I'll be able to help you spread the word, and potentially give a coding hand.
# On board JetBrains!


JetBrains, JetBrains... You all know I love that company, and I love their products. Especially IntelliJ that I've using for a few years already as my main and primary Java IDE. That really, really rocks. And you've probably seen the picture of me wearing my [JetBrains TShirt](http://glaforge.free.fr/weblog/index.php?itemid=85)...

So what's the news today? JetBrains's just released their [OnBoard monthly online magazine](http://www.onboard.jetbrains.com/). That's worth a read! The featured articles are:

*   Language Oriented Programming: The Next Programming Paradigm
*   Applying Code Generation Approach in Fabrique
*   IntelliJ IDEA: Structural Search and Replace, What, Why and How-to
*   Extending Omea with New Resource Types

Of particular interest, Sergey Dmitriev's--long awaited for those in the know--article about Meta-programming: "[Language Oriented Programming](http://www.onboard.jetbrains.com/articles/04/10/lop/)". That's a real paradigm shift!

It's a pretty interesting vision. I'm really keen on small DSL languages for specialized domain models. Moreover, it's also interesting from the point of view of meta-programming. That rings a bell in my mind, since [Groovy](http://groovy.codehaus.org/) supports some meta-programming facilities, like our builders for instance.

On a side note, unrelated to the OnBoard magazine, I'd like to say that JetBrains is very kind with Open Source projects. They've just granted [Groovy](http://groovy.codehaus.org/) developers a license. A nice gift!
# Becoming an O'Reilly book author


A few months ago, [O'Reilly](http://www.oreilly.com/) contacted the [Codehaus](http://www.codehaus.org/) to find some Groovy experts for writing a book about [Groovy](http://groovy.codehaus.org/), the scripting language for the JVM. I was very interested in writing such a book, and I asked another expert, Chris Poirier, if he'd fancy co-authoring the book with me, and he accepted. That's how we started writing "Learning Groovy", in the famous animals/learning series.

This article is not about how to become an author, but rather, how O'Reilly helps you get up to speed with the task. Apart from helping you with your outline, with constant and useful feedback from your editors and so on, one of the things they do is to give you a nice welcome package as a new O'Reilly book author. Today, I just wanted to describe what they've just sent me.

As I'm writing a "Learning" series kind of book, my editor sent me two other Learning books: "[Learning Java](http://www.oreilly.com/catalog/learnjava2/)", and "[Learning Python](http://www.oreilly.com/catalog/lpython/)". That gives me some good references to take inspiration from.

But that's not all, after my contract was signed, they sent me a Welcome package. Here is what it contains:

*   A letter from Tim O'Reilly congratuling me, summarizing what the goal is, how he wrote his first book, how the editor's feedback is key, etc...
*   A really nice O'Reilly TShirt with a "Tarsier" (the little animal with big round eyes from "[Unix in a Nutshell](http://www.oreilly.com/catalog/unixnut3/)"),
*   A few O'Reilly stickers (I'm wondering where I could stick them though),
*   A document on how to best market our book,
*   A copy of "[The Elements of Style](http://www.amazon.com/exec/obidos/tg/detail/-/020530902X/qid=1084807900/sr=1-1/ref=sr_1_1/103-2263184-9239067?v=glance&s=books)", from William Strunk Jr. and E.B. White,
*   A book on three audio CDs "[On Writing Well](http://www.amazon.com/exec/obidos/tg/detail/-/0060006641/102-2174389-8230509?v=glance)", from William Zinsser.
*   A little book about the O'Reilly animals, showing some of the animals used on their book covers.

I think that's a really nice Welcome package, when you start writing your first book, especially when English is not your mother tongue. "[The Elements of Style](http://www.amazon.com/exec/obidos/tg/detail/-/020530902X/qid=1084807900/sr=1-1/ref=sr_1_1/103-2263184-9239067?v=glance&s=books)" is a real reference in the field. Good choice. I knew it by reputation, but now, I'll be able to read it myself.

Do you want to know what other great advantage of being an author at O'Reilly there is? We're granted a free access on [Safari](http://safari.oreilly.com/), their online bookshelf. Really, really cool!

So, thank you O'Reilly, Mike and Brett for your feedback, and for all these gifts.

I'm a happy author!
# Pair Wiki-ing


Ever had to work collaboratively, concurrently on the same document in real-time? So far, the offering for dealing with collaborative documents authoring is rather oriented towards an asynchronous mode.

You have Microsoft Word which allows you to make revisions, changes, highlights. You can use the good old email system by sending mails in a ping-pong way (no concurrent modifications allowed). You may also use a versioning system such as CVS or Subversion to edit documents in parallel and merge both work copies.

The lucky Mac owners also have SubEthaEdit which makes real-time modifications possible on the same document. But if you're under Windows, as far as I know, there's no application available which really provides such a level of collaborative features. I'll have to hear from persons using SubEthaEdit over the net, rather than over Wifi hotspots... Is it possible by the way?

[Jeremy Rayner](http://www.javanicus.com/blog2/) has created a little Java application called [NetPad](http://javanicus.com/blog2/items/113-index.html) that offers some real-time capabilities. But as we tried it over the net, it's not yet ideal, due to some network issues (time-outs and such, problem of content syncing when buffers differ).

By the way, today's Jeremy's Birthday! He's 0x20 years old! So, Mr Rayner, I wish you a very happy birthday, full of joy and geek gifts!

Jeremy and I had to work together on a document yesterday night. We are preparing a London meeting for the Groovy's JSR Expert Group and Groovy developers which will take place there in mid-november. We tried NetPad but weren't very successful, so we decided to have a mixed approach: chatting on IRC and at the same time using this little marvel called [Biscuit Barrel](http://javanicus.com/blog2/items/113-index.html). Biscuit is an incredible simple and light Wiki application, leveraging [Groovy](http://groovy.codehaus.org/) scripting and [Radeox](http://radeox.org/space/start) wiki-markup rendering from [SnipSnap](http://snipsnap.org/space/start) and Confluence fame. With it, you can even write dynamic macros, create dynamic pages and templates, integrate SiteMesh, etc... (there are obviously some professional wikis with such features as well, like [XWiki](http://www.xwiki.org/xwiki/bin/view/Main/WebHome): a very powerful GPL wiki). Though not a prime-time or scalable Wiki, Biscuit is pretty neat and snappy to use on your localhost, or within an intranet.

So Jeremy and I chatted on #groovy yesterday. We were editing a Biscuit page in a close to real-time manner. And IRC was used to pass each other the editing token. Once one of the two was "editing", the other should not edit it. Once the editor is "done", you can take the "editing" token. Simple solution for a complex system! With this brainstorming taking place, and a wiki to take notes, we really managed to have a very productive and entertaining session. Thus for near real-time collaboration on a document, it can be as simple as using IRC+Wiki.

How are you guys doing real-time collaborative authoring? Any tips, any software to try for that kind of constraints? I'm all ears and wish that a better solution exists. Otherwise I'll have to create my own some day!
# Groovy's birthday and news


A year ago, [James Strachan](http://radio.weblogs.com/0112098/) and [Bob McWhirter](http://blogs.codehaus.org/people/bob/) gave birth to [Groovy](http://groovy.codehaus.org/): a dynamic and agile scripting language for the JVM. Nobody really knows who is the father, and who is the mother, neither do we know how the fecundation happened. Anyhow, James always used to say that it was all Bob's fault, but indeed, James had so many groovy ideas that it's hard to believe it's not his own fault. He kept saying: "Wouldn't it be groovy if we could do this and that...". Hence the name "Groovy". That's roughly how it all started.

I wasn't involved in Groovy in the early days, but I came across groovy by reading some blog posts here and there. About a month after the first commits on Codehaus' CVS repository (Aug 28th), I looked closely at the code and at the (old) Groovy wiki. I read some interesting ideas, and I really got excited by that project. I really felt like it could fill some gaps in our J2EE stack and tool chain.

By that time, I was working for a company which was building a nice offering in the MDA market: you design a data-model with a Swing data-modeling application, you deploy this "metamodel" on the database of a kernel webapp hosted in a servlet container. And here you go, you have a working data-centric application, with complex and customisable list and item views, powerful search capabilities spanning several kinds of business objects, fine-grained role and profile authorisations, etc... In the developer version of this offering, there will be means for creating your own UI widgets that you can use in the forms used to edit your items. Those UI widgets are simply Java classes. But in order to create/edit/deploy them, the process is rather long and tedious, since you have to restart your webapp to reload them. At that point of the story, I really thought it would be nice to use Groovy to develop those widgets, without having to compile them and to reload your webapp. A nice gain at development time (especially since the customers themselves can write their own widgets).

There are many places where you can benefit from scripting languages in your projects. Whether it be Groovy, or any other scripting language for the JVM. I fell in love with some of the Groovy features, such as [native syntax for lists and maps](http://wiki.codehaus.org/groovy/SyntaxForTuplesListsMaps), [closures](http://groovy.codehaus.org/closures.html), markup, etc.

In decemeber 2003, I got involved in the development of Groovy, after I had submitted a few patches to improve Groovy's cleverness with regards to charsets and file encodings. Since then, I did various things, but a big part of my work was with all those [little groovy methods](http://groovy.codehaus.org/groovy-jdk.html) that help us being more productive. Things like `String.padLeft()` to `Url.getText()`, etc...

So what's the status right now, after one year? Groovy is already quite stable. It's not yet perfect, some features are still missing, but I use it on a daily basis to write some scripts, such as flushing some JMS queues, retrieving web resources and parse them to monitor particular changes, and I'm doing many other things with it as well.

A few months ago, [JSR-241](http://www.jcp.org/en/jsr/detail?id=241) was submitted to the JCP. This process will enable us to have a more formal process to define the language and will provide a default reference implementation. It will also give wider acceptance and trust, so that developers around the world may integrate Groovy within their projects with confidence. This process is currently moving slowly but surely, development of Groovy is also evolving accordingly till we settle on some language design decisions. But already, we're approaching consensus on some of the ideas which are debated. In the meantime, some nice byte-code optimsations have been done for instance, some great features may see the light of day in the future, such as AST macros, etc. Stay tuned!

The IDE integration is moving too: [Zohar Melamed](http://roller.anthonyeden.com/page/zohar) is working on the Eclipse plugin to make it work on Eclipse 3. A lot of changes happened in Eclipse's APIs which make this porting effort tougher than expected. And on my side, I'm teaming up with Franck Rasolo (developer of the [TestDox IDEA plugin](http://plugins.intellij.net/plugins/view/?id=Testdox%20IDEA%20Plugin)) to create a brand new full-featured IDEA IntelliJ plugin. So as I said in the previous paragraph: stay tuned!

For those who would like to learn Groovy by the book, you'll be glad to learn that different books are in the works at O'Reilly, Manning and other publishers. [John Wilson](http://www.wilson.co.uk/) is writing a "Groovy in Action", while Chris Poirier and myself are working on a "Learning Groovy". In mid 2005, you should have a lot to read!

After this little "status message", I wish a happy birthday to Groovy. I hope that all the developers already playing with Groovy and embedding it within their own apps are happy with it. Thanks again to James and Bob for having given birth to such a cute and useful project, thanks to all those great developers and friends I met thanks to this project. I wish you all a Groovy Birthday!
# Une huile de Vézelay


![](/img/misc/vezelay.jpg)

Pour mes premiers essais de peinture à l'huile, j'ai choisi une vue plutôt originale de la région de Vézelay (dans l'Yonne), en prenant le contre-pied des angles classiques qui se tournent vers la basilique. J'ai décidé de peindre le point de vue que l'on voit à partir des hauteurs.

La peinture à l'huile est un médium particulièrement agréable à peindre. Les mélanges des couleurs dans le vif donnent des effets intéressants, de même que la superposition de couches, gras sur maigre, avec un fond bien sec. En effet, j'ai réalisé ce tableau en deux passes : une première pour le fond (ciel, champs et forêt), puis une seconde couche pour les feuillages des arbres, ainsi que le petit village.

A noter que la peinture n'était pas sèche lorsque j'ai pris la photo, c'est pour cela que l'on voit quelques reflets sur la gauche du tableau.

Pour en connaître plus sur Vézelay, vous pouvez consulter le [site de la ville](http://www.ville-vezelay.com/).
# Continuous Integration with DamageControl


[DamageControl](http://damagecontrol.codehaus.org/), I believe, is one of the great tools an Open Source project must have. For those who don't know this great project hosted at [Codehaus](http://www.codehaus.org/), it is one incarnation of a continuous integration system, like CruiseControl or others...

Basically, this is a tool which allow developers to make their project build automatically upon each commit to ease integration. Each time a modification is done on your Source Control Management system, it triggers a build. It's particularly handy when associated with a full build including test suites.

In real-time, you're advertized if the build succeeds or not, through different means, be it through mail, IRC or Instant Messenging.

Thanks to DamageControl, I can see that my last commit on [Groovy](http://groovy.codehaus.org/) was successful. And even better, you can put on your web site a link to a picture indicating that the build succeeded or failed. If it's green, that's cool!
# JetBrains fashion victim


![](/img/misc/Guillaume-JetBrains.jpg)

I am a [JetBrains](http://www.jetbrains.com/) fashion victim. I've just received my JetBrains TShirt this morning.

It was quite early (say 8 o'clock) for a saturday when I'm used to wake up late late late, especially after coding [Groovy](http://groovy.codehaus.org/) late at night... when that damn postman rang at the door. I wanted to slaughter this bastard for waking me up that early... I even wanted to not open the door. But I remembered that I was supposed to receive a TShirt some day, thanks to my participation in a very private society of IntelliJ IDEA affictionados called "Team JetBrains"...

To make a long story short, JetBrains promised us (members of this secret and stealth community) to send us TShirts, but they promised long long ago... But nothing was ever coming. They had issues with the different TShirts makers they contacted and/or contracted. So at the end, we though we would never receive anything. Except our Personal License which we were given early when Aurora was out, thanks to our active participation in the [Early Access Programm](http://www.intellij.net/eap). The TShirt was our "Arlésienne"...

But indeed, the day has come, and I got this TShirt that you can see on the picture on the left: Yes, that's me who's wearing proudly that nice TShirt. This week was quite interesting also because I've been awarded a [GMail](http://gmail.google.com/) account, thanks to a little game of magic number that Alain Ravet launched. The game was a draw: both Dmitry Lomov (from JetBrains) and me were the closest to the magic number. But Alain's dog decided between the two. And Dmitry won. But Robert Beeger had another GMail invitation left, so he offered it to the second: me! Thank you Robert for your GMail invitation, I'm very grateful to you.

Now it's time to have fun, so have a nice Week-end everybody. And thank you very much JetBrains for my TShirt.
# First OSS-Get Together in Paris


For the first time in Paris, an **_Open Source Software Get-Together_** was organized by [Vincent Massol](http://blogs.codehaus.org/people/vmassol/) of [Cactus](http://jakarta.apache.org/cactus/) fame and author of [JUnit in Action](http://www.manning.com/catalog/view.php?book=massol) book. It was a lot of fun to meet him and other French OSS developers. I though we weren't numerous to work on Open Source projects in France, but after all, it seems I was wrong. Moreover, I was stunned to meet someone working for the same company as myself, and I didn't even know him! The world is such a small place indeed.

We talked about our different projects on which we are working at night, on our free time. Almost half of us were [Maven](http://maven.apache.org/) developers or contributors (Emmanuel Venisse, Arnaud Heritier and Vincent Massol), the other developers present were working on [EasyStruts](http://easystruts.sourceforge.net/) (Emmanuel Boudrant), [Twister](http://www.smartcomps.org/twister/) (Matthieu Riou), [JCaptcha](http://jcaptcha.sourceforge.net/) (Marc-Antoine Garrigue) and [Groovy](http://groovy.codehaus.org/) (myself the Groovy Despot).

For this first meeting (others will come soon) Vincent invited us at the headquarters of [Pivolis](http://www.pivolis.com/), an innovating _pivotal provider_ providing offshore development. After that, we went to a restaurant near _les Champs-Elysées_. We like this concept very much: revamping the world while eating and/or drinking is somewhat part of the French culture.

I was really glad to meet you all guys, and I'm longing to meet you again soon. Now, for the pictures, please click on the _more_ link just below:

  
![](/img/ossgtp/MAG-VM-Pivolis.jpg)

![](/img/ossgtp/EV-AH-Pivolis.jpg)  
Emmanuel and Arnaud

![](/img/ossgtp/EB-MR-Pivolis.jpg)  
Emmanuel and Matthieu

![](/img/ossgtp/EV-VM-AH-Hippo.jpg)  
Emmanuel, Vincent and Arnaud

![](/img/ossgtp/EB-MR-Hippo.jpg)  
Emmanuel and Matthieu

![](/img/ossgtp/MR-GL-Hippo.jpg)  
Matthieu and Guillaume (doh! that's me!)
# Tip O' the day : SSH on Windows


My fellow readers might remember my problems with SSH which have often bothered me. I faced again a similar issue:

I wanted to upload a new Groovy snapshot Jar, before we release RC-1 next week. As a Groovy despot, with the help of some wonderful hausmates (particularly Trygve and Bob) I managed to authenticate myself with ssh-agent + ssh-add on the Codehaus server, so that maven doesn't require me to enter my passphrase for my key.

For the record, I'm using Cygwin on a windows XP box, with OpenSSH installed.

Here is the trick, in a cygwin-bash terminal type:

```
eval `ssh-agent`
ssh-add
maven -Dmaven.username=xxxx yourGoal
```

And I was done...
# New Groovy Snapshot


Since Groovy's move from one server to another, we could not deliver the latest jars. We're sorry for that, but we're doing our best to fix all the little issues you've encountered (broken links, missing jar, etc) It's not without difficulty that I managed to upload the latest snapshot of groovy, but I'm glad to announce that there is a new groovy-1.0-rc1-snapshot.jar.

You can find it here:

[http://dist.codehaus.org/groovy/dist/groovy/jars/](http://dist.codehaus.org/groovy/dist/groovy/jars/)

If you're still using beta-4, please upgrade to the latest snapshot. Though there are still some bugs we haven't fixed yet regarding "verify errors" and such, this snapshot is already much more stable. Next week, we should release a new distribution.

Enjoy.
# Seen on maven IRC


Being a groovy despot, I was in the process of redeploying groovy's web site and also the latest snapshot jars of the distribution which a lot of guys have asked for. But I was having some problems with my setup, ssh connection, maven goals, etc. With Trygve and Bob, we were chatting about that, and here is an interesting snippet of the ongoing discussion:

> trygvis: bob: dist is a recursive symlink
> bob: yes, I know
> bob: it's broken
> bob: I'll fix it
> bob: and I'll smack the next person who tells me about it
> trygvis: DO IT NOW! [Guillaume] LOL :-)))
> bob: FUCK YOU
> trygvis: OK!!
# IntelliJ : SSH2 finally finds its way...


I've been waiting for that for months already. I've been whining and whining again about the lack of an internal SSH2 implementation in IntelliJ. And now, it is there!

As you perhaps already know by reading my weblog, I'm a [Groovy](http://groovy.codehaus.org/) developper. And the Groovy project is hosted at [Codehaus](http://www.codehaus.org/) which makes use of SSH2 for accessing the CVS repository.

I had tried, but without success, [different alternatives](http://glaforge.free.fr/weblog/index.php?itemid=63), such as using Putty/pling/pageant, but I didn't manage to create a connection. So I ended up using Thomas Singer's wonderful [SmartCVS](http://www.smartcvs.com/). This tools sort of [saved my life](http://glaforge.free.fr/weblog/index.php?itemid=64). I'm very grateful to you Tom...

But now, IntelliJ supports SSH2 out of the box! At first glance, I didn't even noticed, because I was used to see the different supported methods: pserver, local, ext and SSH. But Robert S. Sfeir showed me the way on the newsgroups by telling me it was there... Uh? He must be kidding ? Well, no, he wasn't, when in the CVS SSH panel, now there's a radio button to choose between SSH1 and SSH2, and you can choose your private key. The only little omission though, is that you have to type by hand the full type to your private key because there's no button for choosing the path from a dialog box. But I'm sure it'll be fixed in the next release.

Thank you JetBrains (and in particular Olesya) for your great work on such a great product!
# A groovy web server


Based on a suggestion made by Jamie McCrindle, I decided it was time to add some missing [Groovy methods](http://groovy.codehaus.org/groovy-jdk.html) related to sockets.

So far, I have added a [bunch of IO/streams methods](http://glaforge.free.fr/weblog/index.php?itemid=74) enhancing the JDK core classes, but there were no methods dealing with sockets. But now, this time is over.

I have added two methods:

*   Socket.withStreams(Closure) which takes a closure as argument, and has acces to an input stream and an output stream, and
*   ServerSocket.accept(Closure) which takes a closure argument which uses a socket as argument

What's better than a sample code to illustrate that ? Hey, we're going to implement a simplistic Hello World web server. Here it is...

```groovy
import java.net.*

def server = new ServerSocket(9991)

while(true) {
  server.accept { socket ->
    socket.withStreams { input, output ->
      try {
        input.eachLine { line ->
          println line
          if (line.length() == 0) {
            throw new GroovyRuntimeException()
          }
        }
      } catch (GroovyRuntimeException b) { }
      output.withWriter { writer ->
        writer << "HTTP/1.1 200 OK\n"
        writer << "Content-Type: text/html\n\n"
        writer << "Hello World!"
      }
    }
  }
}
```

Enjoy!

Thank you Jamie for your code ;-)

**Update 2013/02/20:** I've tweaked the above script to use the proper closure syntax that we settled with in Groovy 1.0
# First steps in TDD-land


Unit tests aren't really new for me, but so far, on the different projets on which I worked recently, I haven't really had the opportunity to develop "test firt". Moreover, I could not test much because those projects were not pretty test-friendly (static instances all around, nothing close to IoC/DI anywhere around). And also, on web-based and GUI projects, it is not that easy to write tests (when I have time, I should definitely have a look at those HTTP and Swing testing frameworks). Because of those projects, I was quite used to test things here and there with main methods and System.out.println()... you'll agree with me that it's not really professional. Not easy to make regression tests as well. Shame on me!

As a pet project, everybody must have one I guess, I'm a developer on the [Groovy](http://groovy-lang.org/) scripting language. Each time we develop something, we always test it, thanks to the geniusly designed Groovy testing framework settled by James. So I'm quite used to unit testing my work. But most of the time, even in Groovy, I code first, then test afterwards. I haven't taken the habit of writing the test first, then trying my best to make it pass. But recently, James improved the build process, so it's going to be easier to work test firt though (ability to launch a single test, and a quick-test maven goal was added).

Things are changing, at my new company, I'm starting a new project: a JMS implementation over a MOM (Message-Oriented Middleware). And I ceized the opportunity to make my first steps in TDD-land. And I must admit that I'm quite satisfied with this approach.

In order to retrieve the administered objects from a JNDI context, I created my own little embeded JNDI provider. That's my first real test-first piece of software. As I didn't know much of the implementation of such a beast, I thought testing it first was a good idea. And indeed it is: testing first allows me to guide my hand and my brain during the development process. As I discover the spec, as I read the Javadoc, I create tests that match those requirements, then try to implement them. This method should throw an NPE if the Name object is null? Ok, a new test. This NamingEnumeration.hasMore() method should return false if there's no more elements? Ok, once again a new test. At the end of the day, I have a fair amount of tests that correspond to the spec I must implement.

I won't detail more my implementation, but simply wanted to express my delighted feeling. I must admit that TDD is quite a pleasant and fruitful experience. And I can now understand better people infected by the test-first virus. As I code, as I understand better what I'm supposed to implement, the tests guide me and make me more confident with my code. With the nice JUnit integration within [IntelliJ IDEA](http://www.jetbrains.com/)(my favourite IDE and the best I've used so far) I'm feeling good when I see the famous green bar. As much as I can, and if I can convert my colleagues to the TDD approach, I'll be continuing writing JUnit tests first.

Another green bar, yes!!!
# Heads-up on File and Stream groovy methods


Over the week-end, I implemented new groovy methods, as defined in GROOVY-208 Plus a few complementary methods.  

*   `getText()`:
    *   `BufferedReader.getText()`
    *   `File.getText()`
    *   `File.getText(encoding)`
    *   `Process.getText()`

You can now easily read the full content of a file or of a buffered reader and get it as a String.

```groovy
// retrieve the content of the file  
def content = new File("myFile.txt").text  
// you can specify the encoding of the file  
// note that since getText() has a parameter,   
// you cannot call it with something like text("UTF-8")   
content = new File("myFile.txt").getText("UTF-8") 
```

There is also a getText() method on Process which gathers the output of a process:

```groovy
stringOutput = "ls".execute().text // Unices  
stringOutput = "dir".execute().text // Windows
```

*   `write()`:
    *   `File.write(text)`
    *   `File.write(text, encoding)`

As we've defined read methods for reading the content of the file in one go, you can also write it in a single step as well. Note that write overwrite the previous content of the file. If you don't want the behaviour, use the append() method.

// write the text in the file  
new File("myFile.txt").write("Hello world")  
// you may also specify the encoding  
new File("myFile.txt").write("\\u20AC: is the symbol for the Euro currency", "UTF-16LE")

*   `append()`:
    *   `File.append(text)`
    *   `File.append(text, encoding)`

In the same spirit, I decided to add some append() methods to append text at the end of the File.

```groovy
def f = new File("myFile.txt").append("Hello World\\n")  
f.append("Hello again, that's me!")  
```

You can also specify the encoding. Of course, don't write in the same file with different encodings, no editors would be able to read it ;-)  

```groovy
def f = new File("myFile.txt").append("Hello World\\n", "UTF-16BE")  
f.append("Hello again, that's me!", "UTF-16BE")
```

*   `newWrite()`:
    *   `File.newWriter(encoding)`
    *   `File.newWriter(encoding, append)`
    *   `File.newWriter(append)`
    *   `File.newPrintWriter(encoding)`

Missing newWriter() methods have been added. It's now possible to specify the encoding used to write files, and optionnaly to specify wether we're in append mode.

```groovy
def writer = new File("myText.txt").newWriter("UTF-8", true)  
writer.write("\u20AC: euro symbol\n")  
writer.write('$: dollar symbol\n')  
writer.close()
```

*   `File.newReader(encoding)`

Previously, when creating a new Reader from a file, the encoding was automatically guessed, thanks to CharsetReaderToolkit I had implemented which smartly guessed the charset used to encode the file. Now, it is possible to overide this mechanism:

```groovy
def reader = new File("myText.txt").newReader("UTF-8")
```

*   `withWriter()`:
    *   `File.withWriter(encoding, closure)`
    *   `File.withWriterAppend(encoding, closure)`
    *   `OutputStream.withWriter(encoding, closure)`

I extended the withWriter methods, so that we may specify an encoding, and also specify the append more:

```groovy
// no need of course to close the writer,   
// since it's gracefully taken care of by the method  
newFile("myText.txt").withWriterAppend("UTF-8") { writer ->
    writer.write("\u20AC: euro symbol\n")  
    writer.write('$: dollar symbol\n')  
}  
```

*  `BufferedWriter.writeLine(text)`

In the example above, you may also use the new writeLine() method on BufferedReader, which is cleaner than appened "\\n" after each call to write(), so the example becomes:

```groovy
newFile("myText.txt").withWriterAppend("UTF-8") { writer -> 
    writer.writeLine('\u20AC: euro symbol') // cleaner than "\n" obviously  
    writer.writeLine('$: dollar symbol')  
}
```

Note that it appends a platform dependant new line.  

*   `File.readBytes()`

I've finally changed the readBytes() method to return an array of bytes instead of a List of Bytes which was quite ineficient:

```groovy
def bytes = new File("myText.txt").readBytes()
```

With all these methods, I thing we pretty can do anything we want! We should certainly cover all the scope of IO methods, especially of text files with optional specification of the encoding used.
# Timing a closure in Groovy


When you want to make some optimizations to your code, you often use the good old System.currentTimeMillis() method to time certain parts of your application. I wanted to do a similar thing when hacking some Groovy scripts recently, and the idea came to me that I could simply create a timing closure! So here it is, for your eyes only:

```groovy
timer = { closure ->
    start = System.currentTimeMillis()
    closure()
    println System.currentTimeMillis() - start
}
```

Then you can use your brand new timing closure:

```groovy
timer { "sleep 10".execute().waitFor() }
```

That's not rocket science, but closures are really a powerful feature. Everyday I wish Java had such a feature built-in.
# Happy Birthday Codehaus


A year ago, [Codehaus](http://www.codehaus.org/) saw the light of day. And since, it gathered a lot of bright and talented persons working on innovative and very good quality projects. And moreover, those projects have a friendly licence scheme (I'm not a GPL/LGPL lover).

For a few months, I've been part of the Hausmates, thanks to my efforts in developing some code for [Groovy](http://groovy.codehaus.org/), and I'm really proud of beeing part of it.

I wish a very happy birthday to Codehaus, and to all those who made it happen. Thank you Bob, and thank you James for Groovy ;-)
# Groovy-JDK doc: Parsing Java with QDox


Perhaps you noticed recently that there's a new interesting page on Groovy's website ? Well, all pages are interesting of course! But there's a new page describing the [Groovy methods](http://groovy.codehaus.org/groovy-jdk.html) enhancing the core JDK classes.

In groovy, you have additional methods that you can call on standard Java classes. For instance, you can use the [eachLine()](http://groovy.codehaus.org/groovy-jdk.html#meth33) method on java.io.File. With this method, you'll be able to easily read a text file line after line, and do whatever with this line inside a closure without having to care about things like closing streams. Let's illustrate this with an example :

```groovy
def foo = new File("myTextFile.txt")
foo.eachLine{ line -> println line }
```

But there are numerous other Groovy methods like the [Collection.map()](http://groovy.codehaus.org/groovy-jdk.html#meth146) for mapping all objects of a collection and transform them, or [List.sort()](http://groovy.codehaus.org/groovy-jdk.html#meth172) to sort a collection with a special closure, much simpler than a custom comparator. But so far, all these methods were not documented anywhere, and a new Groovy user would have had to look at the source code closely to discover all the methods available. That's why I told [James Strachan](http://radio.weblogs.com/0112098/) we could create a simple tool to generate a documentation for all these Groovy methods to help us... And obviously, James said... "Groovy!" And that's what I did, I created such a tool in Groovy, and using a nice little library called QDox.

[QDox](http://qdox.codehaus.org/) is a really neat and simple library whose founder is [Joe Walnes](http://joe.truemesh.com/blog/), a brilliant [ThoughtWorkers](http://thoughtworks.com/) and a [Hausmate](http://www.codehaus.org/). QDox's main and sole function is to parse JavaDoc comments and build a graph of objects representing the comments, and the structure of a Java class with its fields, methods, parameters, etc... And it does the job pretty well.

I created a Groovy class called [DocGenerator.groovy](http://cvs.groovy.codehaus.org/groovy/groovy-core/src/main/org/codehaus/groovy/tools/DocGenerator.groovy?rev=1.15&view=auto) which parses the [DefaultGroovyMethods](http://cvs.groovy.codehaus.org/groovy/groovy-core/src/main/org/codehaus/groovy/runtime/DefaultGroovyMethods.java?rev=1.108&view=auto) class containing all the Groovy methods. I created a JavaDocBuilder, added a source (a Reader on the class to parse), retrieved all the public static methods, then created some [HTML output](http://groovy.codehaus.org/groovy-jdk.html). Pretty straightforward and efficient. Thanks for this nice library.

In the next revision of this DocGenerator tool, I'm going to implement different outputs, especially a framed version (with a JavaDoc look'n feel), and an XML version which then could be used by the [Groovy Eclipse plugin](http://wiki.codehaus.org/groovy/HackingEclipsePlugin) as a source information for code-completion.
# CVS and SSH2, not so easy


Yesterday, I was granted commit rights on the [Groovy](http://groovy.codehaus.org/) source tree, at [Codehaus](http://www.codehaus.org/). Of special interest for me :

*   I developed a utility class which helps Groovy create new Readers for text files with the correct encoding already set (I'm really keen on charset/encodings issues),
*   Adding some new Groovy methods to the core JDK classes,
*   Working on an automatic documentation generation engine "a la" Javadoc, so that it may be possible to browse all the methods that have been added to the core JDK classes.

James asked me if I wanted a CVS access to deal with those matters of interest instead of tunneling through him, and I gladfully accepted. But, alas, here starts the nightmare...

So far, I was a happy Windows user, and a happy IntelliJ user, but I'm starting to change my mind. It seems that IntelliJ does not speak SSH2. It's clever enough to deal with SSH1, but not SSH2 so far (as far as I know, it that's not the case, please, please tell me how that works!) Thus, I've had to do everything through the good ol'command line. I've set up a [page on Codehaus](http://wiki.codehaus.org/general/HowToDevelopWithCygwinUnderWindows) about that. Read on the steps to follow that I have reproduced here...

1.  First of all, you have to install CYGWIN on your platform: download it here and don't forget to check the options OpenSSH (will be needed for key pair generation) and CVS (you know how useful it may be), let's assume you've installed it in c:\\cygwin which is the default installation directory
2.  Add c:\\cygwin\\bin to your system path
3.  Open up a bash terminal and type ssh-keygen -t dsa to create an SSH key pair with the default name id\_dsa and id\_dsa.pub, and don't forget your pass phrase, otherwise your keys will be useless, (put both keys in c:\\cygwin\\home\\jsmith\\.ssh)
4.  Give Bob the despot (or the person responsible for the task) your public key (id\_dsa.pub) so that he installs it on the CVS server
5.  Once Bob tells you your account is created and your key installed, type eval \`ssh-agent\` in a terminal (it will tell you it's running in background with pid xxx)
6.  Type ssh-add to add your SSH key to the ssh-agent you've just launched to take care of the SSH connection and authentication
7.  In order to test your connection, you can follow this optional step : type ssh jsmith@cvs.codehaus.org to test if the connection succeeds then logout. If it fails, you're in trouble! Review all the steps carefully! eventually, export CVS\_RSH=ssh to tell CVS that you're using CVS through SSH
8.  You're done, now use cvs commands like cvs -d :ext:jsmith@cvs.codehaus.org:/scm/cvs -co groovy to checkout the latest flavour of groovy (or whatever other project)

So now, you can call yourself a Codehaus commiter
# IntelliJ prayer


That's incredible, but Robert S. Sfeir is at it again in the [EAP forum](http://www.intellij.net/forums/thread.jsp?forum=22&thread=63779&tstart=0&trange=15#760113). He produced one more prayer that we should all be repeating again and again. (I hope he won't mind me from quoting his holy words)

> Our IDEA who art in heaven  
> Hollowed be thy name  
> Thy IDE come, the EAP done  
> On earth as it is in heaven,  
> Give us this day our daily build,  
> And forgive our bug reports,  
> As we forgive those who report against us,  
> But lead us not into frustration,  
> Now and forever...
# IntelliJ version of Miranda Rights


After my suggestion of Miranda as a code name for the upcoming EAP of IntelliJ IDEA, there was a [funny quote from Robert S. Sfeir](http://www.intellij.net/forums/thread.jsp?forum=22&thread=63081#659938) in the forums regarding this suggestion. It's a new version of the Miranda Rights :

> You have the right to refactor. Anything you refactor can be used against you in your code and calls. You have the right to have IDEA present now and during any future refactorings. If you cannot afford an IDEA license, one will be appointed to you, free of charge, during EAP, if you wish.
# Code name for IntelliJ IDEA 5.0


[IntelliJ IDEA 4.0](http://www.intellij.com/) is not yet out of its Early Access Program phase that a [discussion](http://www.intellij.net/forums/thread.jsp?forum=22&thread=63081) already started in the forums for the code name of the next EAP cycle.

There are already a few propositions for the next code name. Among them:

*   **StarGate** (hmm, not that good)
*   **Avani** (which means earth in some indian languages)
*   **Stella** (which will not be used because it was already used for IDEA 2.0 for those who remember)
*   **Avalon** (already used by Microsoft's new UI framework, and the Apache Avalon framework)
*   **Rhea** (suggested internally at JetBrains by [Eugene Belyaev](http://www.eugenebelyaev.com/begblog/))
*   **Aardvark** (maybe too harsh to pronounce)
*   **Atlantis** (mythological sunken island)
*   **Athena** (greek goddess)
*   **Lachesis**, **Clotho** or **Athropos** (the three moirae)
*   **Ananke** (necessity), **Erebus**
*   **Vedra** (as in Vedra Valles)
*   **Miranda** (that's my suggestion, already used by Miranda-IM, and it [reminds something to outlaws in the US](http://glaforge.free.fr/weblog/index.php?itemid=58))
*   **Olesya** (CVS integration developer), **Katja** or **Laika** (first female dog in space)
*   Derivations of Simple (**Simplex**, **Simplicity**, **SimpleA**...)
*   **Dione** (another Greek goddess)
*   **Aphrodite**, **Athena**, **Adonis** (to stick with "A" and the Greek mythology)
*   **Artemida** (tiger hunter... JDK 1.5 hunter)
*   **Archimedes** (another sinking idea...)
*   **Revolution** (somewhat related to the Aurora cruiser)
*   **Banana** (quite funny one)
*   **Donut** (for hungry developers)

I like Miranda, of course, because that's my suggestion, but I also like Rhea and Ananke, they sound good to my ears. What would you suggest ?
# Groovy: a sample script


In the [IntelliJ forums](http://www.intellij.net/forums/), I came across an off-topic (but funny) [post](http://www.intellij.net/forums/thread.jsp?forum=22&thread=58983&message=645130&q=536f6d65626f647920746f6c64206d65206f6e6365207468617420746865726520617265206f6e6c792074776f20776f72647320696e2074686520456e676c69736820#645130) by Robert Gibson who was wondering :

> Somebody told me once that there are only two words in the English language which contain each vowel, once only, in alphabetical order. Anybody know what the other one is?

Indeed, there are more than two words corresponding to those constraints. I then wrote a little Java class which took all the words of a [words file](http://www.und.edu/org/crypto/crypto/words/english_word_list/) (with 100k words) and tested if they matched a regexp corresponding to those constraints.

But for the fun and for living on the cutting edge, I decided to also write a [Groovy](http://groovy-lang.org/) script doing the very same thing. In fact, it's much more consise, and overall, I've fallen in love with closures. I'd love to have closures in Java.

Here is my little script (in fact, it is my second ever written Groovy script after my [LOAF implementation](http://glaforge.free.fr/weblog/index.php?itemid=46&catid=2))

```groovy
def foo = new File("wordlist.txt")
foo.eachLine{ word ->
  if (word ==~ "^[^aeiou]*a[^aeiou]*e[^aeiou]*i[^aeiou]*o[^aeiou]*u[^aeiou]*$" ) 
    println word
}
```
# Some good rules for an efficient ant build script


Some time ago I came across an interesting article on Apache's wiki entitled ([Apache Wiki: The Elements Of Ant Style](http://nagoya.apache.org/wiki/apachewiki.cgi?TheElementsOfAntStyle). It's a very thourough overview of good practices for writing clean, readable, reusable and efficient Ant build files.

Today, through [magpiebrain](http://www.magpiebrain.com/archives/000151.html), I read on [OnJava](http://www.onjava.com/) another very interesting and concise article giving [15 Ant best practices](http://www.onjava.com/pub/a/onjava/2003/12/17/ant_bestpractices.html). It's much shorter than the previous article on Apache's wiki, but still, with those 15 practices you'll manage to improve some messy build scripts. Believe me !
# Une gouache de macareux


Voici un nouveau tableau que j'ai réalisé à la gouache. Il s'agit de trois petits macareux, que j'ai peints pour offrir en guise de cadeau de Noël pour ma mère... Encore une chance qu'elle n'a pas internet chez elle, sinon, elle pourrait découvrir la surprise avant l'heure !

![](/img/misc/Macareux.jpg)
# LOAF : a Groovy implementation


[LOAF](http://postneo.com/postwiki/moin.cgi/LoafHome) is taking the community by storm. I do firmly believe it gonna rock the world. Social software is the way to go : the next revolution. But as far as I know there were no LOAF implementation in [Groovy](http://groovy-lang.org), a promising programming language.

So let's see how simple it is to write a LOAF implementation using Groovy:

```groovy
class LOAF {
    static main(args) {
        def loaf = new LOAF()
    }
}
```

I'm a beginner in Groovy, so use at your own risk. Play with it, it's free as in beer !
# Wiki-like Java HTML editor !


Well, sometimes, we happend to make some fun stuff at work. Don't we ? Currently, we're developping a RAD tool for creating applications using a framework we've been developping for some time already. It's a classical Swing app. We decided to create a contextual help system : Each time a component is selected in the GUI (whether it be a tabbed pane or a node in a JTree), we show the corresponding help page in another frame that the user may show or hide as he wishes when he needs some help. I use a JEditorPane with an HTMLEditorKit to show those HTML help pages.

Well, you'll tell me there's nothing fun there, of course. The interesting part comes from the fact that I developped a wiki-like system for creating the content of those help pages. At work, nobody like writing documentation unfortunately, but with this new tool, you just check the edit checkbox, and you can WYSIWYG-ly edit your HTML page : create headings, paragraphs, styles, lists, etc. You can insert images, and create links to other pages. When creating a link, you have the choice of linking to an existing page, or you can automagically create a new page ! Indeed, I created a wiki-like system for creating, editing and viewing HTML help pages in our app.

Another idea we've had is to allow the final users to be able to append some user-defined comments on the help pages of our app. I think it's a rather innovative idea to be able to edit yourself the help system.

If I have some time, maybe I'll turn that into a nice IntelliJ IDEA plugin, so that one may edit some simple HTML pages, for storing some developper documentation.

In a future post, I'll give you something to play with. So stay tuned !
# Halloween Jukebox


It's soon Halloween ! If you're making a party at home, like my girl friend and me, you'll want to frighten your friends a little bit. Some make-up, some fancy closes, some pumpkins, etc... and some... hhoorrriibblleee soooouuunnnndddsss !

I found on the net some nice wave sounds like evil laugthers, screams, ghosts noises, etc. Stéphanie wanted to make a Windows Media Player playlist with those sounds. Cool... But as a Java Geek, I decided to make something better ! That's why I decided to write a little Halloween jukebox.

The aim of this jukebox is to play random sounds from selected sub-directories (representing a category) containing sounds, at defined interval of time.

You will find the jar here : [HalloweenJukebox.jar](http://glaforge.free.fr/projects/halloweenjukebox/HalloweenJukebox.jar), and you will also have to download a zip with a few sounds there [sounds.zip](http://glaforge.free.fr/projects/halloweenjukebox/sounds.zip).

**Instructions** : save the jar file on your computer, save the zip file as well and unpack it somewhere. Double-click on the jar file to launch the jukebox. Select the "sound" directory where you have unzipped sounds.zip.

**Explanations** : in the GUI, you'll see on the left a list of sub-directories checked, that's the sounds you've chosen to play. Below you'll recognize the play and stop button. And you will also be able to select the time interval between each sound. Thanks to javax.sound, all sounds will be mixed in real-time, overlapping each other if you've chosen a short interval, it'll make some terrific soundtrack for your party ;-)

Enjoy, and Happy Halloween !
# IntelliJ IDEA : ShowEncoding plugin


A bit more than a year ago, I wrote some utility classes related to file encodings/charsets. Those classes got integrated to IntelliJ IDEA. Those classes are useful for knowing the encoding of a byte array, or a file, or an input stream. You'll be able to know whether your file is encoded using UTF-8, or whether it used ISO-8859-1, or windows' specific windows-1252.

Unfortunately, inside IntelliJ IDEA, it is not currently possible to know the charset of the files edited. I filed a feature request in june. Unfortunately, this feature has not yet been implemented.

That's why I decided to write my own plugin for discovering the charset used in my files.

For download and more information, you can browse these links :

*   [Project page on the Wiki](http://www.intellij.org/twiki/bin/view/Main/ShowEncodingPlugin)
# Unicode, charset, encodings


Today, through Java blogs, I came across [Joel Spolsky's post](http://www.joelonsoftware.com/articles/Unicode.html) regarding **_The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets_**. I have to recommend anybody curious about i18n issues to read this very good introduction. I wish I had read that before, two years ago, when I had to deal with different file encodings ;-)

This article remind me of one of my old home projects, back in the summer 2002. I was developing (and I'm still doing so) with IntelliJ IDEA at work, and I had messed up with some critical XML files because I was playing with the default encoding used by IntelliJ in the preferences panel... I was so ashamed that I decided to file some feature requests about automatic charset recognition for my beloved Java IDE. And even better, I coded some java classes that I gave Maxim Shafirov. And my code was finally integrated (perhaps modified to suit their needs) into IDEA 3.0.

For people interested in this package, you can have a look at my project page : [GuessEncoding](https://github.com/codehaus/guessencoding).
# Une esquisse de Renaud


Inspiré par Titouan Lamazou, j'ai immité le geste du peintre en barbouillant une feuille de Canson, je vous laisse admirer le résultat.  

![](/img/misc/renaud.jpg)
# Allergie aux piqûres de taon


Les taons sont vraiment de sales bêbêtes. Et le problème le plus embêtant, c'est que je suis allergique à leurs piqûres. Alors en Alsace, sur le terrain en pleine campagne où se déroulaient les expériences scientifiques de ma petite-amie, il y en avait à revendre de ces insectes ! Et je me suis fait piquer deux fois : une fois à chaque main. En quelques heures mes mains ont littéralement doublé de volume. A tel point que lors de notre excursion à Europapark en Allemagne, j'ai dû me faire bander les mains par un infirmier du point Croix Rouge.  
  
En voici la preuve :  

![mains bandées après les piqûres de taon](/img/misc/mains-bandees.jpg)  

En rentrant sur Strasbourg, nous avons appelé un médecin pour qu'il me fasse une petite piqûre (une autre ?) de cortisone (cette fois-ci) et pour me donner des médicaments adéquats. Voici à peu près à quoi ressemblaient mes mains lorsqu'il m'a retiré mes bandages :  

![](/img/misc/grosse-main.jpg)  

Impressionnant, n'est-ce pas ?
# Premier tableau : les falaises d'Etretat


J'ai décidé il y a quelques semaines de me remettre à la peinture, d'abord en faisant quelques toiles à la gouache, pour passer bientôt à la peinture à l'huile. En guise de cadeau à ma bien-aimée, j'ai décidé de peindre les falaises d'Etretat, que nous avions eu le plaisir d'admirer à la Toussaint 2002.  
  
Voici donc le résultat de cette première tentative de peinture :  

![Les falaises d'Etretat](/img/misc/Etretat.jpg)
# Beignets d'acacia


L'époque est maintenant révolue, mais à l'approche de l'été, les acacias fleurissent. Et qui dit acacia, dit... beignets de fleurs d'acacia. Il y a quelques semaines, alléché par l'odeur des fleurs de ces arbres qui prennent racines non loin de chez moi, j'ai décidé de préparer moi-même de ces délicieux beignets que ma mère sait si bien faire. Histoire également de faire découvrir cette saveur à ma tendre bien aimée.  
  
Nous sommes donc allés cueillir des grappes de fleurs, que nous avons ensuite équeutées. Après cela, nous avons préparé la pâte à beignet, puis mélangé avec les fleurs d'acacia. Après cela, on forme quelques cuillères de mélange qu'on immerge dans la friture, pour en resortir quelques instants après des beignets croustillants qu'il ne reste plus qu'à sucrer et... à déguster !  
  
Voici la recette dont je me suis inspiré, que j'ai trouvée sur l'excellent site de recettes [marmiton.org](http://www.marmiton.org/) :

> **Préparation :** 15 mn  
>   
> **Ingrédients** (pour 4 gourmands) :
> 
> *   500 g de farine
> *   2 oeufs
> *   2 verres de lait
> *   1 pincée de sel
> *   2 cuillères à soupe de sucre
> *   fleurs d'acacia (un saladier de taille moyenne)
> 
> **Préparation :**
> 
> *   Dans un saladier, mélanger la farine, les oeufs, le sel, le sucre et le lait.
> *   Egrainer les fleurs de l'accacia de leur grappe, rincer légérement à l'eau, égoutter.
> *   Mélanger les fleurs à la pâte à beignets.
> *   Dans une friteuse, faire bouillir de l'huile (ou de la végétaline) et y verser des cuillères du mélange.
> *   Quand les beignets sont bien dorés, les retirer avec une écumoire.
> *   Les sucrer légèrement et servir frais.

Et voila, maintenant, il ne vous reste plus qu'à déguster !
# Calcul du jour de Pâques (suite)


Imaginons que nous souhaitons créer un calendrier. Bien ! Mais pour être encore plus sympathique, nous allons rajouter sur ce calendrier les **jours fériés**. Ce n'est pas un problème pour les dates fixes comme le 1er janvier ou le 11 novembre. Mais il existe d'autres jours fériés qui sont dits "**mobiles**". Dans de très nombreux pays occidentaux, la pluspart de ces jours fériés mobiles sont définis par rapport à la date du jour de Pâques. Or, il faut déjà connaître le jour de Pâques. Effectivement, nous allons donc nous intéresser au calcul du jours de Pâques, qui est une fête religieuse dont la date est définie relativement à une phase lunaire proche de l'équinoxe de printemps du 21 mars. Je vous épargnerai les détails, mais voici une petite classe que vous pourrez modifier à loisir pour calculer le jours de Pâques.  
  
Je vous épargne les détails de l'algorithme, car on peut le trouver sur Internet, mais au moins, vous en aurez une implémentation en Java !  

```java
public class EasterDefinition
{
    private static int alpha(int year)
    {
        if (year <= 1582)
            return 0;
        else if (year <= 1699)
            return 7;
        else if (year <= 1899)
            return 8;
        else if (year <= 2199)
            return 9;
        else
            return 10;
    }

    private static int beta(int year)
    {
        if (year <= 1582)
            return 0;
        else if (year <= 1699)
            return 4;
        else if (year <= 1799)
            return 3;
        else if (year <= 1899)
            return 2;
        else if (year <= 2099)
            return 1;
        else if (year <= 2199)
            return 0;
        else
            return 6;
    }

    private static int r1(int year)
    {
        return (19 * (year % 19) + 15 + alpha(year)) % 30;
    }

    /** 
     * Nombre de jours entre Pâques et le 21 mars.
     *
     * @param year l'année dont on souhaite connaître le jour de Pâques.
     * @return le nombre de jours.
     */
    private static int r(int year)
    {
        int r1m = r1(year);
        return r1m < 28 ? r1m : (r1m == 28 ? (year % 19 > 10 ? 27 : 28) : 28);
    }

    private static int t(int year)
    {
        return (2 * (year % 4) + 4 * (year % 7) + 6 * r(year) + 6 - beta(year)) % 7;
    }

    /**
     * Calcule le jour de Pâques pour une année donnée.
     *
     * @param year l'année dont on souhaite connaître le jour de Pâques.
     * @return le jour de Pâques.
     */
     public static void main(String[] args)
     {
         int year = 2003;
         int rm = r(year);
         int tm = t(year);

         int day = rm + tm <= 9 ? rm + tm + 22 : rm + tm - 9;
         int month = rm + tm <= 9 ? Calendar.MARCH : Calendar.APRIL;
     }
}
```
# Calcul du jour de Pâques


Toujours dans l'optique de créer un **Agenda partagé** pour l'application **OpenProspect**, il me faut mettre sur mon calendrier... les **jours fériés** ! Jusque là, tout va bien... Mais en cherchant un peu, on s'aperçoit que les jours fériés, c'est pas si simple que ca !  
  
En effet, rien qu'en France, ce n'est pas si simple : il y a les jours fixes, et les jours mobiles. Il faut effectuer un calcul compliqué pour obtenir le jour de Pâques et les jours calculés relativement à Pâques (jeudi de l'Ascension et lundi de Pentecôte).  
  
Mais cela se complique, car en dehors de France, dans certains pays, les jours fériés ne sont pas les mêmes suivant les régions ! Aux Etats-Unis par exemple, il existe des jours fériés spécifiques à un état particulier !  
  
On trouve des ressources intéressantes sur Internet :  
  

*   Un [site excellent](http://www.jours-feries.com/) pour calculer TOUS les jours fériés d'un très grand nombre de pays,
  
*   Un autre [calcul du Jour de Pâques](http://www.bdl.fr/minitel/calendrier/date_paques.html) en Javascript (regarder le code source de la page HTML)

Bref, si l'on souhaite afficher sur un calendrier tous les jours fériés, on n'est pas sorti de la veille ;-). Bon courage !
# Apache XML-RPC, côté client


Pour le fun, j'ai eu envie d'essayer l'[API XML-RPC de la fondation Apache](http://ws.apache.org/xmlrpc/). Pour être précis, je vouais expérimenter avec les APIs de Blogger et MetaWeblog qui permettent de mettre à jour les Weblogs à distance. Ce sont des APIs standardisées que la pluspart des Weblog comprennent.  
  
Ainsi, par exemple, l'outil de publication [w.Bloggar](http://wbloggar.com/) permet de éditer/modifier/créer des nouvelles entrées dans votre blog. Pour cela, il fait appel aux procédures distantes (Remote Procedure) du serveur hébergeant votre blog.  
  
Pour le cas qui m'intéresse, j'utilise chez mon hébergeur le Blog Nucleus. C'est un blog GPL, donc gratuit, avec toutes les fonctionnalités que l'on peut attendre d'un tel outil de publication (multi-weblog, interface d'administration, multi-utilisateur, ban IP, commentaires, plugin divers et variés, etc...)  
  
J'ai donc téléchargé l'API XML-RPC d'Apache, j'ai lancé mon IDE Java préféré ([IntelliJ IDEA](http://www.intellij.com/)), j'ai créé un nouveau projet avec une petite classe NucleusClient et sa méthode main() pour tester Nucleus et son support des APIs de weblogging...  
  
C'est déconcertant de facilité ! Vive XML-RPC ! Jugez-en par vous-même :  

```java
import org.apache.xmlrpc.XmlRpcClient;
import org.apache.xmlrpc.XmlRpcException;
import java.util.Vector;
import java.io.IOException;

public class NucleusClient
{
    public static void main(String[] args) throws IOException, XmlRpcException
    {
        XmlRpcClient rpcClient = 
            new XmlRpcClient("http://www.yourhost.com/weblog/nucleus/xmlrpc/server.php");

        Vector params = new Vector();
        params.addElement("1"); // blogId
        params.addElement("YourAccount");
        params.addElement("YourPassword");
        String result = (String)rpcClient.execute("metaWeblog.getPost", params);
        System.out.println("result = " + result);
  }
}
```

  
  
En quelques lignes, on appelle un Service Web (reposant sur XML-RPC). On utilise pour cela la classe XmlRpcClient à qui l'on passe l'URL du blog, on crée un vecteur contenant les paramètres de la méthode distante, et on execute la requête. Il ne reste plus qu'à récupérer le résultat !
# Les jours de la semaine


D'après ce qu'on peut lire dans la [FAQ des calendriers](http://www.auduteau.net/calendar/cal5.shtml#5_7) :  
  

> La norme internationale ISO-8601 (mentionnée dans la section 5.6) assigne un numéro à chaque semaine de l'année. Une semaine chevauchant deux années se voit assigné un numéro dans l'année qui contient le plus grand nombre de ses jours.  
>   
> Ce qui revient à dire que La semaine 1 de toute année est celle qui contient le 4 janvier ou que la semaine 1 de toute année est celle qui contient le 1er jeudi de janvier.  
>   
> La majorité des années ont 52 semaines mais les années qui commence un jeudi et les années bissextiles commençant un mercredi en possède 53.

  
  
En d'autres termes, le 1er janvier peut-être soit dans la semaine 1, soit dans la semaine 52 ou 53, c'est-à-dire dans la dernière semaine de l'année d'avant.  
  
Mais en Java, qui se base soi-disant sur la norme ISO-8601, il se trouve que le 1er janvier est **toujours** dans la semaine numéro 1.  
  
Qui a tort ? Qui a raison ?
# About


**Guillaume Laforge** is **Developer Advocate** for [Google Cloud](https://cloud.google.com/),
where he spreads the word to developers about the serverless compute space, service orchestration solutions, and **generative AI** .

Guillaume is a [Java Champion](https://javachampions.org/),
a co-author of [Groovy in Action](https://www.manning.com/books/groovy-in-action-second-edition),
and a founding member of the French tech podcast [Les CastCodeurs](http://lescastcodeurs.com/).

Guillaume is the co-founder of the [Apache Groovy](http://groovy.codehaus.org/) programming language project,
which he led under the umbrella of G2One (a Groovy/Grails startup where he was the **VP Technology**), then SpringSource, VMware, and the Pivotal spin-off. 
When the project joined to the Apache Software Foundation, he was the Chair of the Apache Groovy Project Management Committee (PMC).
He is a member of the [Micronaut](http://micronaut.io/) Technology Advisory Board.
He initiated the creation of the [Grails](http://grails.org/) web application framework,
and founded the [Gaelyk](http://gaelyk.appspot.com/) project, a lightweight toolkit for developing applications in Groovy for Google App Engine.

He is a **frequent conference speaker** [presenting](/talks) on serverless technologies, microservice orchestration and architecture,
machine learning, conversational interfaces, Google Cloud projects & services, Apache Groovy, Micronaut, Web API design,
at events like Devoxx and Voxxed Days, JavaOne, JAX, GR8Conf, Greach, DevTernity, QCon, Cloud Next, among others.

Before joining Google, at Restlet (acquired by [Talend](https://www.talend.com/)),
Guillaume was taking care of the **Product Leadership** of the products, and was **leading Developer Advocacy**.
Prior to that, he was leading the Groovy team at G2One, SpringSource, VMware and Pivotal.
Before working full-time on Groovy, Guillaume worked as a **Software Architect** for [OCTO Technology](http://www.octo.com/),
a consultancy focusing on architecture and agile methodologies, where he developed new customer offerings around Groovy and Grails.

## Contact

|                                       |     |                                                                       |
| ------------------------------------: | --- | --------------------------------------------------------------------- |
|     ![](/img/icons/twitter-black.svg) |     | [twitter.com/glaforge](https://twitter.com/glaforge)                  |
|    ![](/img/icons/mastodon-black.svg) |     | [@uwyn.net/@glaforge](https://uwyn.net/@glaforge)                     |
|     ![](/img/icons/bluesky-black.svg) |     | [glaforge.dev](https://bsky.app/profile/glaforge.dev) |
|      ![](/img/icons/github-black.svg) |     | [github.com/glaforge](https://github.com/glaforge)                    |
|    ![](/img/icons/linkedin-black.svg) |     | [linkedin.com/in/glaforge](https://www.linkedin.com/in/glaforge)      |
| ![](/img/icons/speakerdeck-black.svg) |     | [speakerdeck.com/glaforge](https://speakerdeck.com/glaforge)          |